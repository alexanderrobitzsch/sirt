[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Alexander Robitzsch. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Robitzsch, . (2024). sirt: Supplementary Item Response Theory Models. R package version 4.2-57. https://CRAN.R-project.org/package=sirt","code":"@Manual{sirt_4.2-57,   title = {sirt: Supplementary Item Response Theory Models},   author = {Alexander Robitzsch},   year = {2024},   note = {R package version 4.2-57},   url = {https://CRAN.R-project.org/package=sirt}, }"},{"path":[]},{"path":"/index.html","id":"supplementary-item-response-theory-models","dir":"","previous_headings":"","what":"Supplementary Item Response Theory Models","title":"Supplementary Item Response Theory Models","text":"use sirt suggestions improvement found bugs, please email robitzsch@leibniz-ipn.de. Please always provide minimal dataset, necessary demonstrate problem, minimal runnable code necessary reproduce issue, can run given dataset, necessary information used librarys, R version, OS run , perhaps sessionInfo().","code":""},{"path":"/index.html","id":"cran-version","dir":"","previous_headings":"","what":"CRAN version","title":"Supplementary Item Response Theory Models","text":"official version sirt hosted CRAN may found . CRAN version can installed within R using:","code":"utils::install.packages(\"sirt\")"},{"path":"/index.html","id":"github-version","dir":"","previous_headings":"","what":"GitHub version","title":"Supplementary Item Response Theory Models","text":"version hosted development version sirt. GitHub version can installed using devtools :","code":"devtools::install_github(\"alexanderrobitzsch/sirt\")"},{"path":"/reference/automatic.recode.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic Method of Finding Keys in a Dataset with Raw Item Responses — automatic.recode","title":"Automatic Method of Finding Keys in a Dataset with Raw Item Responses — automatic.recode","text":"function calculates keys dataset raw item responses. starts setting frequent category item 1. , iteration keys changed highest item discrimination found.","code":""},{"path":"/reference/automatic.recode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic Method of Finding Keys in a Dataset with Raw Item Responses — automatic.recode","text":"","code":"automatic.recode(data, exclude=NULL, pstart.min=0.6, allocate=200,     maxiter=20, progress=TRUE)"},{"path":"/reference/automatic.recode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic Method of Finding Keys in a Dataset with Raw Item Responses — automatic.recode","text":"data Dataset raw item responses exclude Vector categories excluded searching key pstart.min Minimum probability initial solution keys. allocate Maximum number categories per item. argument used function tam.ctt3 TAM package. maxiter Maximum number iterations progress logical indicates iteration progress displayed","code":""},{"path":"/reference/automatic.recode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic Method of Finding Keys in a Dataset with Raw Item Responses — automatic.recode","text":"list following entries item.stat Data frame item name, p value, item discrimination calculated key data.scored Scored data frame using calculated keys item.stat categ.stats Data frame statistics categories items","code":""},{"path":"/reference/automatic.recode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatic Method of Finding Keys in a Dataset with Raw Item Responses — automatic.recode","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: data.raw1 ############################################################################# data(data.raw1)  # recode data.raw1 and exclude keys 8 and 9 (missing codes) and # start with initially setting all categories larger than 50  res1 <- sirt::automatic.recode( data.raw1, exclude=c(8,9), pstart.min=.50 ) # inspect calculated keys res1$item.stat  ############################################################################# # EXAMPLE 2: data.timssAusTwn from TAM package #############################################################################  miceadds::library_install(\"TAM\") data(data.timssAusTwn,package=\"TAM\") raw.resp <- data.timssAusTwn[,1:11] res2 <- sirt::automatic.recode( data=raw.resp ) }"},{"path":"/reference/brm.sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions for the Beta Item Response Model — brm-Methods","title":"Functions for the Beta Item Response Model — brm-Methods","text":"Functions simulating estimating Beta item response model (Noel & Dauvier, 2007). brm.sim can used simulating model, brm.irf computes item response function. Beta item response model estimated discrete version enable estimation standard IRT software like mirt TAM packages.","code":""},{"path":"/reference/brm.sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functions for the Beta Item Response Model — brm-Methods","text":"","code":"# simulating the beta item response model brm.sim(theta, delta, tau, K=NULL)  # computing the item response function of the beta item response model brm.irf( Theta, delta, tau, ncat, thdim=1, eps=1E-10 )"},{"path":"/reference/brm.sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Functions for the Beta Item Response Model — brm-Methods","text":"theta Ability vector \\(\\theta\\) values delta Vector item difficulty parameters tau Vector item dispersion parameters K Number discretized categories. default NULL means simulated item responses real number values 0 1. integer K chosen, values discretized values 0, 1, ..., \\(K\\)-1 arise. Theta Matrix ability vector \\(\\bold{\\theta}\\) ncat Number categories thdim Theta dimension matrix Theta item loads. eps Nuisance parameter stabilize probabilities.","code":""},{"path":"/reference/brm.sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Functions for the Beta Item Response Model — brm-Methods","text":"discrete version beta item response model defined follows. Assume item \\(\\) \\(K\\) categories resulting values \\(k=0,1,\\dots,K-1\\). value \\(k\\) associated corresponding transformed value \\([0,1]\\), namely \\( q (k)=1/(2 \\cdot K), 1/(2 \\cdot K) + 1/K, \\ldots,  1 - 1/(2 \\cdot K) \\). item response model defined $$ P( X_{pi}=x_{pi} | \\theta_p)  \\propto       q( x_{pi} )^{ m_{pi} - 1 } [ 1- q( x_{pi} ) ]^{ n_{pi} - 1 } $$ density discrete version Beta distribution shape parameters \\(m_{pi}\\) \\(n_{pi}\\). parameters defined $$ m_{pi}=\\mathrm{exp} \\left[ ( \\theta_p - \\delta_i + \\tau_i ) / 2 \\right]     \\qquad \\mbox{} \\qquad     n_{pi}=\\mathrm{exp} \\left[ ( - \\theta_p + \\delta_i + \\tau_i ) / 2 \\right]                 $$ item response function can also formulated $$ \\mathrm{log} \\left[ P( X_{pi}=x_{pi} | \\theta_p) \\right]  \\propto       ( m_{pi} - 1 ) \\cdot \\mathrm{log} [ q( x_{pi} ) ] +       ( n_{pi} - 1 )  \\cdot \\mathrm{log} [ 1- q( x_{pi} ) ]                       $$ item parameters can reparameterized \\( a_{}=\\mathrm{exp} \\left[ ( - \\delta_i + \\tau_i ) / 2 \\right]\\) \\( b_{}=\\mathrm{exp} \\left[ ( \\delta_i + \\tau_i ) / 2 \\right]\\). , original item parameters can retrieved \\(\\tau_i=\\mathrm{log} ( a_i b_i)\\) \\(\\delta_i=\\mathrm{log} ( b_i / a_i)\\). Using \\( \\gamma _p=\\mathrm{exp} ( \\theta_p / 2) \\), obtain $$ \\mathrm{log} \\left[ P( X_{pi}=x_{pi} | \\theta_p) \\right]  \\propto        a_{} \\gamma_p  \\cdot \\mathrm{log} [ q( x_{pi} ) ] +        b_i / \\gamma_p   \\cdot \\mathrm{log} [ 1- q( x_{pi} ) ] -       \\left[ \\mathrm{log} q( x_{pi} ) + \\mathrm{log} [ 1- q( x_{pi} ) ] \\right]                       $$ formulation enables specification Beta item response model structured latent class model (see TAM::tam.mml.3pl; Example 1). See Smithson Verkuilen (2006) motivations treating continuous indicators normally distributed variables.","code":""},{"path":"/reference/brm.sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Functions for the Beta Item Response Model — brm-Methods","text":"simulated dataset item responses brm.sim applied. matrix item response probabilities brm.irf applied.","code":""},{"path":"/reference/brm.sim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Functions for the Beta Item Response Model — brm-Methods","text":"Gruen, B., Kosmidis, ., & Zeileis, . (2012). Extended Beta regression R: Shaken, stirred, mixed, partitioned. Journal Statistical Software, 48(11), 1-25. doi:10.18637/jss.v048.i11 Noel, Y., & Dauvier, B. (2007). beta item response model continuous bounded responses. Applied Psychological Measurement, 31(1), 47-73. doi:10.1177/0146621605287691 Smithson, M., & Verkuilen, J. (2006). better lemon squeezer? Maximum-likelihood regression beta-distributed dependent variables. Psychological Methods, 11(1), 54-71. doi: 10.1037/1082-989X.11.1.54","code":""},{"path":[]},{"path":"/reference/brm.sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Functions for the Beta Item Response Model — brm-Methods","text":"","code":"############################################################################# # EXAMPLE 1: Simulated data beta response model #############################################################################  #*** (1) Simulation of the beta response model # Table 3 (p. 65) of Noel and Dauvier (2007) delta <- c( -.942, -.649, -.603, -.398, -.379, .523, .649, .781, .907 ) tau <- c( .382, .166, 1.799, .615, 2.092, 1.988, 1.899, 1.439, 1.057 ) K <- 5        # number of categories for discretization N <- 500        # number of persons I <- length(delta) # number of items  set.seed(865) theta <- stats::rnorm( N ) dat <- sirt::brm.sim( theta=theta, delta=delta, tau=tau, K=K) psych::describe(dat)  #*** (2) some preliminaries for estimation of the model in mirt #*** define a mirt function library(mirt) Theta <- matrix( seq( -4, 4, len=21), ncol=1 )  # compute item response function ii <- 1     # item ii=1 b1 <- sirt::brm.irf( Theta=Theta, delta=delta[ii], tau=tau[ii],  ncat=K ) # plot item response functions graphics::matplot( Theta[,1], b1, type=\"l\" )  #*** defining the beta item response function for estimation in mirt par <- c( 0, 1,  1) names(par) <- c( \"delta\", \"tau\",\"thdim\") est <- c( TRUE, TRUE, FALSE ) names(est) <- names(par) brm.icc <- function( par, Theta, ncat ){      delta <- par[1]      tau <- par[2]      thdim <- par[3]      probs <- sirt::brm.irf( Theta=Theta, delta=delta, tau=tau,  ncat=ncat,             thdim=thdim)      return(probs)             } name <- \"brm\" # create item response function brm.itemfct <- mirt::createItem(name, par=par, est=est, P=brm.icc) #*** define model in mirt mirtmodel <- mirt::mirt.model(\"            F1=1-9             \" ) itemtype <- rep(\"brm\", I ) customItems <- list(\"brm\"=brm.itemfct)  # define parameters to be estimated mod1.pars <- mirt::mirt(dat, mirtmodel, itemtype=itemtype,                    customItems=customItems, pars=\"values\")  if (FALSE) { #*** (3) estimate beta item response model in mirt mod1 <- mirt::mirt(dat,mirtmodel, itemtype=itemtype, customItems=customItems,                pars=mod1.pars, verbose=TRUE  ) # model summaries print(mod1) summary(mod1) coef(mod1) # estimated coefficients and comparison with simulated data cbind( sirt::mirt.wrapper.coef( mod1 )$coef, delta, tau ) mirt.wrapper.itemplot(mod1,ask=TRUE)  #--------------------------- # estimate beta item response model in TAM library(TAM)  # define the skill space: standard normal distribution TP <- 21                   # number of theta points theta.k <- diag(TP) theta.vec <-  seq( -6,6, len=TP) d1 <- stats::dnorm(theta.vec) d1 <- d1 / sum(d1) delta.designmatrix <- matrix( log(d1), ncol=1 ) delta.fixed <- cbind( 1, 1, 1 )  # define design matrix E E <- array(0, dim=c(I,K,TP,2*I + 1) ) dimnames(E)[[1]] <- items <- colnames(dat) dimnames(E)[[4]] <- c( paste0( rep( items, each=2 ),         rep( c(\"_a\",\"_b\" ), I) ), \"one\" ) for (ii in 1:I){     for (kk in 1:K){       for (tt in 1:TP){         qk <- (2*(kk-1)+1)/(2*K)         gammap <- exp( theta.vec[tt] / 2 )         E[ii, kk, tt, 2*(ii-1) + 1 ] <- gammap * log( qk )         E[ii, kk, tt, 2*(ii-1) + 2 ] <- 1 / gammap * log( 1 - qk )         E[ii, kk, tt, 2*I+1 ] <- - log(qk) - log( 1 - qk )                     }             }         } gammaslope.fixed <- cbind( 2*I+1, 1 ) gammaslope <- exp( rep(0,2*I+1) )  # estimate model in TAM mod2 <- TAM::tam.mml.3pl(resp=dat, E=E,control=list(maxiter=100),               skillspace=\"discrete\", delta.designmatrix=delta.designmatrix,               delta.fixed=delta.fixed, theta.k=theta.k, gammaslope=gammaslope,               gammaslope.fixed=gammaslope.fixed, notA=TRUE ) summary(mod2)  # extract original tau and delta parameters m1 <- matrix( mod2$gammaslope[1:(2*I) ], ncol=2, byrow=TRUE ) m1 <- as.data.frame(m1) colnames(m1) <- c(\"a\",\"b\") m1$delta.TAM <- log( m1$b / m1$a) m1$tau.TAM <- log( m1$a * m1$b )  # compare estimated parameter m2 <- cbind( sirt::mirt.wrapper.coef( mod1 )$coef, delta, tau )[,-1] colnames(m2) <- c(  \"delta.mirt\", \"tau.mirt\", \"thdim\",\"delta.true\",\"tau.true\"   ) m2 <- cbind(m1,m2) round( m2, 3 ) }"},{"path":"/reference/btm.html","id":null,"dir":"Reference","previous_headings":"","what":"Extended Bradley-Terry Model — btm","title":"Extended Bradley-Terry Model — btm","text":"function btm estimates extended Bradley-Terry model (Hunter, 2004; see Details). Parameter estimation uses bias corrected joint maximum likelihood estimation method based \\(\\varepsilon\\)-adjustment (see Bertoli-Barsotti, Lando & Punzo, 2014). See Details algorithm. function btm_sim simulated data extended Bradley-Terry model.","code":""},{"path":"/reference/btm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extended Bradley-Terry Model — btm","text":"","code":"btm(data, judge=NULL, ignore.ties=FALSE, fix.eta=NULL, fix.delta=NULL, fix.theta=NULL,        maxiter=100, conv=1e-04, eps=0.3, wgt.ties=.5)  # S3 method for btm summary(object, file=NULL, digits=4,...)  # S3 method for btm predict(object, data=NULL, ...)  btm_sim(theta, eta=0, delta=-99, repeated=FALSE)"},{"path":"/reference/btm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extended Bradley-Terry Model — btm","text":"data Data frame three columns. first two columns contain labels units pair comparison. third column contains result comparison. \"1\" means first units wins, \"0\" means second unit wins \"0.5\" means draw (tie). judge Optional vector judge identifiers (multiple judges available) ignore.ties Logical indicating whether ties ignored. fix.eta Numeric value fixed \\(\\eta\\) value fix.delta Numeric value fixed \\(\\delta\\) value fix.theta vector entries fixed theta values. maxiter Maximum number iterations conv Convergence criterion eps \\(\\varepsilon\\) parameter \\(\\varepsilon\\)-adjustment method (see Bertoli-Barsotti, Lando & Punzo, 2014) reduces bias ability estimates. case \\(\\varepsilon=0\\), persons extreme scores removed pairwise comparison. wgt.ties Weighting parameter ties, see formula Details. default .5 object Object class btm file Optional file name sinking summary digits Number digits decimal print ... arguments passed. theta Vector abilities eta Value \\(\\eta\\) parameter delta Value \\(\\delta\\) parameter repeated Logical indicating whether repeated ratings dyads (home advantage effect) simulated","code":""},{"path":"/reference/btm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extended Bradley-Terry Model — btm","text":"extended Bradley-Terry model comparison individuals \\(\\) \\(j\\) defined $$P(X_{ij}=1 ) \\propto \\exp( \\eta + \\theta_i ) $$ $$P(X_{ij}=0 ) \\propto \\exp(  \\theta_j ) $$ $$P(X_{ij}=0.5) \\propto \\exp( \\delta + w_T ( \\eta  + \\theta_i +\\theta_j ) ) $$ parameters \\(\\theta_i\\) denote abilities, \\(\\delta\\) tendency occurrence ties \\(\\eta\\) home-advantage effect. weighting parameter \\(w_T\\) governs importance ties can chosen argument wgt.ties. joint maximum likelihood (JML) estimation applied simulataneous estimation \\(\\eta\\), \\(\\delta\\) \\(\\theta_i\\) parameters. Rasch model, shown JML can result biased parameter estimates. \\(\\varepsilon\\)-adjustment approach proposed reduce bias parameter estimates (Bertoli-Bersotti, Lando & Punzo, 2014). estimation approach adapted Bradley-Terry model btm function. end, likelihood function modified purpose bias reduction. can easily shown exist sufficient statistics \\(\\eta\\), \\(\\delta\\) \\(\\theta_i\\) parameters. \\(\\varepsilon\\)-adjustment approach, sufficient statistic \\(\\theta_i\\) parameter modified. JML estimation Bradley-Terry model, \\(S_i=\\sum_{j \\ne } ( x_{ij} + x_{ji} )\\) sufficient statistic \\(\\theta_i\\). Let \\(M_i\\) maximum score person \\(\\) number \\(x_{ij}\\) terms appearing \\(S_i\\). \\(\\varepsilon\\)-adjustment approach, sufficient statistic \\(S_i\\) modified $$S_{, \\varepsilon}=\\varepsilon + \\frac{M_i - 2 \\varepsilon}{M_i} S_i $$ \\(S_{, \\varepsilon}\\) instead \\(S_{}\\) used JML estimation. Hence, original scores \\(S_i\\) linearly transformed persons \\(\\).","code":""},{"path":"/reference/btm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extended Bradley-Terry Model — btm","text":"List following entries pars Parameter summary \\(\\eta\\) \\(\\delta\\) effects Parameter estimates \\(\\theta\\)       outfit infit statistics summary.effects Summary \\(\\theta\\) parameter estimates mle.rel MLE reliability, also known separation reliability sepG Separation index \\(G\\) probs Estimated probabilities data Used dataset integer identifiers fit_judges Fit statistics (outfit infit) judges judge    provided. addition, average agreement rating mode    ratings calculated judge (least three ratings per dyad    available computing agreement). residuals Unstandardized standardized residuals observation","code":""},{"path":"/reference/btm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extended Bradley-Terry Model — btm","text":"Bertoli-Barsotti, L., Lando, T., & Punzo, . (2014). Estimating Rasch Model via fuzzy empirical probability functions. D. Vicari, . Okada, G. Ragozini & C. Weihs (Eds.). Analysis Modeling Complex Data Behavioral Social Sciences. Springer. doi:10.1007/978-3-319-06692-9_4 Hunter, D. R. (2004). MM algorithms generalized Bradley-Terry models. Annals Statistics, 32, 384-406. doi: 10.1214/aos/1079120141","code":""},{"path":[]},{"path":[]},{"path":"/reference/categorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Categorize and Decategorize Variables in a Data Frame — categorize","title":"Categorize and Decategorize Variables in a Data Frame — categorize","text":"function categorize defines categories variables data frame, starting user-defined index (e.g. 0 1). Continuous variables can categorized defining categories discretizing variables different quantile groups. function decategorize reverse operation.","code":""},{"path":"/reference/categorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Categorize and Decategorize Variables in a Data Frame — categorize","text":"","code":"categorize(dat, categorical=NULL, quant=NULL, lowest=0)  decategorize(dat, categ_design=NULL)"},{"path":"/reference/categorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Categorize and Decategorize Variables in a Data Frame — categorize","text":"dat Data frame categorical Vector variable names converted categories, beginning integer lowest quant Vector number classes variables.     Variables categorized among quantiles. vector must names containing variable names. lowest Lowest category index. Default 0. categ_design Data frame containing informations categorization output categorize.","code":""},{"path":"/reference/categorize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Categorize and Decategorize Variables in a Data Frame — categorize","text":"categorize, list entries data Converted data frame categ_design Data frame containing informations     categorization decategorize data frame.","code":""},{"path":"/reference/categorize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Categorize and Decategorize Variables in a Data Frame — categorize","text":"","code":"if (FALSE) { library(mice) library(miceadds)  ############################################################################# # EXAMPLE 1: Categorize questionnaire data #############################################################################  data(data.smallscale, package=\"miceadds\") dat <- data.smallscale  # (0) select dataset dat <- dat[, 9:20 ] summary(dat) categorical <- colnames(dat)[2:6]  # (1) categorize data res <- sirt::categorize( dat, categorical=categorical )  # (2) multiple imputation using the mice package dat2 <- res$data VV <- ncol(dat2) impMethod <- rep( \"sample\", VV )    # define random sampling imputation method names(impMethod) <- colnames(dat2) imp <- mice::mice( as.matrix(dat2), impMethod=impMethod, maxit=1, m=1 ) dat3 <- mice::complete(imp,action=1)  # (3) decategorize dataset dat3a <- sirt::decategorize( dat3, categ_design=res$categ_design )  ############################################################################# # EXAMPLE 2: Categorize ordinal and continuous data #############################################################################  data(data.ma01,package=\"miceadds\") dat <- data.ma01 summary(dat[,-c(1:2)] )  # define variables to be categorized categorical <- c(\"books\", \"paredu\" ) # define quantiles quant <-  c(6,5,11) names(quant) <- c(\"math\", \"read\", \"hisei\")  # categorize data res <- sirt::categorize( dat, categorical=categorical, quant=quant) str(res) }"},{"path":"/reference/ccov.np.html","id":null,"dir":"Reference","previous_headings":"","what":"Nonparametric Estimation of Conditional Covariances of Item Pairs — ccov.np","title":"Nonparametric Estimation of Conditional Covariances of Item Pairs — ccov.np","text":"function estimates conditional covariances itempairs (Stout, Habing, Douglas & Kim, 1996; Zhang & Stout, 1999a). function used estimation DETECT index. ccov.np function (default) option smooth item response functions (argument smooth) computation conditional covariances (Douglas, Kim, Habing, & Gao, 1998).","code":""},{"path":"/reference/ccov.np.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nonparametric Estimation of Conditional Covariances of Item Pairs — ccov.np","text":"","code":"ccov.np(data, score, bwscale=1.1, thetagrid=seq(-3, 3, len=200),     progress=TRUE, scale_score=TRUE, adjust_thetagrid=TRUE, smooth=TRUE,     use_sum_score=FALSE, bias_corr=TRUE)"},{"path":"/reference/ccov.np.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nonparametric Estimation of Conditional Covariances of Item Pairs — ccov.np","text":"data \\(N \\times \\) data frame dichotomous responses. Missing responses allowed. score ability estimate, e.g. WLE bwscale Bandwidth factor calculation conditional covariance. bandwidth used estimation bwscale times \\(N^{-1/5}\\). thetagrid vector contains theta values conditional covariances evaluated. progress Display progress? scale_score Logical indicating whether score z standardized advance calculation conditional covariances adjust_thetagrid Logical indicating whether thetagrid adjusted observed values score outside thetagrid. smooth Logical indicating whether smoothing applied conditional covariance estimation use_sum_score Logical indicating whether sum score used. option, bias corrected conditional covariance Zhang Stout (1999) used. bias_corr Logical indicating whether bias correction (Zhang & Stout, 1999) utilized use_sum_score=TRUE.","code":""},{"path":"/reference/ccov.np.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nonparametric Estimation of Conditional Covariances of Item Pairs — ccov.np","text":"Douglas, J., Kim, H. R., Habing, B., & Gao, F. (1998). Investigating local dependence conditional covariance functions. Journal Educational Behavioral Statistics, 23(2), 129-151. doi:10.3102/10769986023002129 Stout, W., Habing, B., Douglas, J., & Kim, H. R. (1996). Conditional covariance-based nonparametric multidimensionality assessment. Applied Psychological Measurement, 20(4), 331-354. doi:10.1177/014662169602000403 Zhang, J., & Stout, W. (1999). Conditional covariance structure generalized compensatory multidimensional items. Psychometrika, 64(2), 129-152. doi:10.1007/BF02294532","code":""},{"path":"/reference/ccov.np.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Nonparametric Estimation of Conditional Covariances of Item Pairs — ccov.np","text":"function used conf.detect expl.detect.","code":""},{"path":"/reference/ccov.np.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nonparametric Estimation of Conditional Covariances of Item Pairs — ccov.np","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: data.read | different settings for computing conditional covariance #############################################################################  data(data.read, package=\"sirt\") dat <- data.read  #* fit Rasch model mod <- sirt::rasch.mml2(dat) score <- sirt::wle.rasch(dat=dat, b=mod$item$b)$theta  #* ccov with smoothing cmod1 <- sirt::ccov.np(data=dat, score=score, bwscale=1.1) #* ccov without smoothing cmod2 <- sirt::ccov.np(data=dat, score=score, smooth=FALSE)  #- compare results 100*cbind( cmod1$ccov.table[1:6, \"ccov\"], cmod2$ccov.table[1:6, \"ccov\"]) }"},{"path":"/reference/cfa_meas_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of a Unidimensional Factor Model under Full and Partial\r\nMeasurement Invariance — cfa_meas_inv","title":"Estimation of a Unidimensional Factor Model under Full and Partial\r\nMeasurement Invariance — cfa_meas_inv","text":"Estimates unidimensional factor model based normal distribution fitting function full partial measurement invariance. Item loadings item intercepts successively freed based largest modification index chosen significance level alpha.","code":""},{"path":"/reference/cfa_meas_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of a Unidimensional Factor Model under Full and Partial\r\nMeasurement Invariance — cfa_meas_inv","text":"","code":"cfa_meas_inv(dat, group, weights=NULL, alpha=0.01, verbose=FALSE, op=c(\"~1\",\"=~\"))"},{"path":"/reference/cfa_meas_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of a Unidimensional Factor Model under Full and Partial\r\nMeasurement Invariance — cfa_meas_inv","text":"dat Data frame containing items group Vector group identifiers weights Optional vector sampling weights alpha Significance level verbose Logical indicating whether progress shown op Operators (intercepts loadings) estimation freed","code":""},{"path":"/reference/cfa_meas_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of a Unidimensional Factor Model under Full and Partial\r\nMeasurement Invariance — cfa_meas_inv","text":"List several entries pars_mi Model parameters full invariance pars_pi Model parameters partial invariance mod_mi Fitted model full invariance mod_pi Fitted model partial invariance ... output","code":""},{"path":[]},{"path":"/reference/cfa_meas_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of a Unidimensional Factor Model under Full and Partial\r\nMeasurement Invariance — cfa_meas_inv","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Factor model under full and partial invariance #############################################################################  #--- data simulation  set.seed(65) G <- 3  # number of groups I <- 5  # number of items # define lambda and nu parameters lambda <- matrix(1, nrow=G, ncol=I) nu <- matrix(0, nrow=G, ncol=I) err_var <- matrix(1, nrow=G, ncol=I)  # define size of noninvariance dif <- 1 #- 1st group: N(0,1) lambda[1,3] <- 1+dif*.4; nu[1,5] <- dif*.5 #- 2nd group: N(0.3,1.5) gg <- 2 ; lambda[gg,5] <- 1-.5*dif; nu[gg,1] <- -.5*dif #- 3nd group: N(.8,1.2) gg <- 3 lambda[gg,4] <- 1-.7*dif; nu[gg,2] <- -.5*dif #- define distributions of groups mu <- c(0,.3,.8) sigma <- sqrt(c(1,1.5,1.2)) N <- rep(1000,3) # sample sizes per group  #* use simulation function dat <- sirt::invariance_alignment_simulate(nu, lambda, err_var, mu, sigma, N,                 exact=TRUE)  #--- estimate CFA mod <- sirt::cfa_meas_inv(dat=dat[,-1], group=dat$group, verbose=TRUE, alpha=0.05) mod$pars_mi mod$pars_pi }"},{"path":"/reference/class.accuracy.rasch.html","id":null,"dir":"Reference","previous_headings":"","what":"Classification Accuracy in the Rasch Model — class.accuracy.rasch","title":"Classification Accuracy in the Rasch Model — class.accuracy.rasch","text":"function computes classification accuracy Rasch model maximum likelihood (person parameter) estimate according method Rudner (2001).","code":""},{"path":"/reference/class.accuracy.rasch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classification Accuracy in the Rasch Model — class.accuracy.rasch","text":"","code":"class.accuracy.rasch(cutscores, b, meantheta, sdtheta, theta.l, n.sims=0)"},{"path":"/reference/class.accuracy.rasch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classification Accuracy in the Rasch Model — class.accuracy.rasch","text":"cutscores Vector cut scores b Vector item difficulties meantheta Mean trait distribution sdtheta Standard deviation trait distribution theta.l Discretized theta distribution n.sims Number simulated persons data set. default 0 means simulation performed.","code":""},{"path":"/reference/class.accuracy.rasch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classification Accuracy in the Rasch Model — class.accuracy.rasch","text":"list following entries: class.stats Data frame containing classification accuracy statistics.   column agree0 refers absolute agreement, agree1   agreement difference one level. class.prob Probability table classification","code":""},{"path":"/reference/class.accuracy.rasch.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Classification Accuracy in the Rasch Model — class.accuracy.rasch","text":"Rudner, L.M. (2001). Computing expected proportions misclassified examinees. Practical Assessment, Research & Evaluation, 7(14).","code":""},{"path":[]},{"path":"/reference/class.accuracy.rasch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classification Accuracy in the Rasch Model — class.accuracy.rasch","text":"","code":"############################################################################# # EXAMPLE 1: Reading dataset ############################################################################# data( data.read, package=\"sirt\") dat <- data.read  # estimate the Rasch model mod <- sirt::rasch.mml2( dat )  # estimate classification accuracy (3 levels) cutscores <- c( -1, .3 )    # cut scores at theta=-1 and theta=.3 sirt::class.accuracy.rasch( cutscores=cutscores, b=mod$item$b,            meantheta=0,  sdtheta=mod$sd.trait,            theta.l=seq(-4,4,len=200), n.sims=3000)   ##   Cut Scores   ##   [1] -1.0  0.3   ##   ##   WLE reliability (by simulation)=0.671   ##   WLE consistency (correlation between two parallel forms)=0.649   ##   ##   Classification accuracy and consistency   ##              agree0 agree1 kappa consistency   ##   analytical   0.68  0.990 0.492          NA   ##   simulated    0.70  0.997 0.489       0.599   ##   ##   Probability classification table   ##               Est_Class1 Est_Class2 Est_Class3   ##   True_Class1      0.136      0.041      0.001   ##   True_Class2      0.081      0.249      0.093   ##   True_Class3      0.009      0.095      0.294"},{"path":"/reference/conf.detect.html","id":null,"dir":"Reference","previous_headings":"","what":"Confirmatory DETECT and polyDETECT Analysis — conf.detect","title":"Confirmatory DETECT and polyDETECT Analysis — conf.detect","text":"function computes DETECT statistics dichotomous item responses polyDETECT statistic polytomous item responses confirmatory specification item clusters (Stout, Habing, Douglas & Kim, 1996; Zhang & Stout, 1999a, 1999b; Zhang, 2007; Bonifay, Reise, Scheines, & Meijer, 2015). Item responses multi-matrix design allowed (Zhang, 2013). exploratory DETECT analysis can conducted using expl.detect function.","code":""},{"path":"/reference/conf.detect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confirmatory DETECT and polyDETECT Analysis — conf.detect","text":"","code":"conf.detect(data, score, itemcluster, bwscale=1.1, progress=TRUE,         thetagrid=seq(-3, 3, len=200), smooth=TRUE, use_sum_score=FALSE, bias_corr=TRUE)  # S3 method for conf.detect summary(object, digits=3, file=NULL, ...)"},{"path":"/reference/conf.detect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confirmatory DETECT and polyDETECT Analysis — conf.detect","text":"data \\(N \\times \\) data frame dichotomous polytomous responses. Missing responses allowed. score ability estimate, e.g. WLE, sum score mean score itemcluster Item cluster item. order entries must correspond columns data. bwscale Bandwidth factor calculation conditional covariance (see ccov.np) progress Display progress? smooth Logical indicating whether smoothing applied conditional covariance estimation thetagrid vector contains theta values conditional covariances evaluated. use_sum_score Logical indicating whether sum score used. option, bias corrected conditional covariance Zhang Stout (1999) used. bias_corr Logical indicating whether bias correction (Zhang & Stout, 1999) utilized use_sum_score=TRUE. object Object class conf.detect digits Number digits rounding summary file Optional file name sunk summary ... arguments passed","code":""},{"path":"/reference/conf.detect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Confirmatory DETECT and polyDETECT Analysis — conf.detect","text":"result DETECT indices DETECT, ASSI RATIO (see Zhang 2007 details) calculated options unweighted weighted. option unweighted means conditional covariances item pairs equally weighted, weighted means covariances weighted sample size item pairs. case multi matrix item designs, types indices can differ. classification scheme indices follows (Jang & Roussos, 2007; Zhang, 2007): Note expected value conditional covariance item pair negative unidimensional model holds. consequence, DETECT index can become negative unidimensional data (see Example 3). can also seen statistic MCOV100 value detect.","code":""},{"path":"/reference/conf.detect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confirmatory DETECT and polyDETECT Analysis — conf.detect","text":"list following entries: detect Data frame statistics DETECT, ASSI, RATIO, MADCOV100 MCOV100 ccovtable Individual contributions conditional covariance ccov.matrix Evaluated conditional covariance","code":""},{"path":"/reference/conf.detect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Confirmatory DETECT and polyDETECT Analysis — conf.detect","text":"Bonifay, W. E., Reise, S. P., Scheines, R., & Meijer, R. R. (2015). multidimensional data unidimensional enough structural equation modeling? evaluation DETECT multidimensionality index. Structural Equation Modeling, 22(4), 504-516. doi:10.1080/10705511.2014.938596 Jang, E. E., & Roussos, L. (2007). investigation dimensionality TOEFL using conditional covariance-based nonparametric approach. Journal Educational Measurement, 44(1), 1-21. doi:10.1111/j.1745-3984.2007.00024.x Stout, W., Habing, B., Douglas, J., & Kim, H. R. (1996). Conditional covariance-based nonparametric multidimensionality assessment. Applied Psychological Measurement, 20(4), 331-354. doi:10.1177/014662169602000403 Zhang, J. (2007). Conditional covariance theory DETECT polytomous items. Psychometrika, 72(1), 69-91. doi:10.1007/s11336-004-1257-7 Zhang, J. (2013). procedure dimensionality analyses response data various test designs. Psychometrika, 78(1), 37-58. doi:10.1007/s11336-012-9287-z Zhang, J., & Stout, W. (1999a). Conditional covariance structure generalized compensatory multidimensional items. Psychometrika, 64(2), 129-152. doi:10.1007/BF02294532 Zhang, J., & Stout, W. (1999b). theoretical DETECT index dimensionality application approximate simple structure. Psychometrika, 64(2), 213-249. doi:10.1007/BF02294536","code":""},{"path":[]},{"path":[]},{"path":"/reference/data.activity.itempars.html","id":null,"dir":"Reference","previous_headings":"","what":"Item Parameters Cultural Activities — data.activity.itempars","title":"Item Parameters Cultural Activities — data.activity.itempars","text":"List item parameters cultural activities Austrian students 9 Austrian countries.","code":""},{"path":"/reference/data.activity.itempars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Item Parameters Cultural Activities — data.activity.itempars","text":"","code":"data(data.activity.itempars)"},{"path":"/reference/data.activity.itempars.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Item Parameters Cultural Activities — data.activity.itempars","text":"format list number students per group (N), item loadings (lambda) item intercepts (nu): List 3  $ N     : 'table' int [1:9(1d)] 2580 5279 15131 14692 5525 11005 7080 ...   ..- attr(*, \"dimnames\")=List 1   .. ..$ : chr [1:9] \"1\" \"2\" \"3\" \"4\" ...  $ lambda: num [1:9, 1:5] 0.423 0.485 0.455 0.437 0.502 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : chr [1:9] \"country1\" \"country2\" \"country3\" \"country4\" ...   .. ..$ : chr [1:5] \"act1\" \"act2\" \"act3\" \"act4\" ...  $ nu    : num [1:9, 1:5] 1.65 1.53 1.7 1.59 1.7 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : chr [1:9] \"country1\" \"country2\" \"country3\" \"country4\" ...   .. ..$ : chr [1:5] \"act1\" \"act2\" \"act3\" \"act4\" ...","code":""},{"path":"/reference/data.befki.html","id":null,"dir":"Reference","previous_headings":"","what":"BEFKI Dataset (Schroeders, Schipolowski, & Wilhelm, 2015) — data.befki","title":"BEFKI Dataset (Schroeders, Schipolowski, & Wilhelm, 2015) — data.befki","text":"synthetic dataset based standardization sample Berlin Test Fluid Crystallized Intelligence (BEFKI, Wilhelm, Schroeders, & Schipolowski, 2014). underlying sample consists N=11,756 students German federal states (except smallest one) school types general educational system attending Grades 5 12. detailed description study, sample, measure given Schroeders, Schipolowski, Wilhelm (2015).","code":""},{"path":"/reference/data.befki.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BEFKI Dataset (Schroeders, Schipolowski, & Wilhelm, 2015) — data.befki","text":"","code":"data(data.befki) data(data.befki_resp)"},{"path":"/reference/data.befki.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BEFKI Dataset (Schroeders, Schipolowski, & Wilhelm, 2015) — data.befki","text":"dataset data.befki contains 11756 students, nested within 581 classes. 'data.frame':   11756 obs.  12 variables:  $ idclass: int  1276 1276 1276 1276 1276 1276 1276 1276 1276 1276 ...  $ idstud : int  127601 127602 127603 127604 127605 127606 127607 127608 127609 127610 ...  $ grade  : int  5 5 5 5 5 5 5 5 5 5 ...  $ gym    : int  0 0 0 0 0 0 0 0 0 0 ...  $ female : int  0 1 0 0 0 0 1 0 0 0 ...  $ age    : num  12.2 11.8 11.5 10.8 10.9 ...  $ sci    : num  -3.14 -3.44 -2.62 -2.16 -1.01 -1.91 -1.01 -4.13 -2.16 -3.44 ...  $ hum    : num  -1.71 -1.29 -2.29 -2.48 -0.65 -0.92 -1.71 -2.31 -1.99 -2.48 ...  $ soc    : num  -2.87 -3.35 -3.81 -2.35 -1.32 -1.11 -1.68 -2.96 -2.69 -3.35 ...  $ gfv    : num  -2.25 -2.19 -2.25 -1.17 -2.19 -3.05 -1.7 -2.19 -3.05 -1.7 ...  $ gfn    : num  -2.2 -1.85 -1.85 -1.85 -1.85 -0.27 -1.37 -2.58 -1.85 -3.13 ...  $ gff    : num  -0.91 -0.43 -1.17 -1.45 -0.61 -1.78 -1.17 -1.78 -1.78 -3.87 ... dataset data.befki_resp contains response indicators observed data points dataset data.befki. num [1:11756, 1:12] 1 1 1 1 1 1 1 1 1 1 ...  - attr(*, \"dimnames\")=List 2   ..$ : NULL   ..$ : chr [1:12] \"idclass\" \"idstud\" \"grade\" \"gym\" ...","code":""},{"path":"/reference/data.befki.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BEFKI Dataset (Schroeders, Schipolowski, & Wilhelm, 2015) — data.befki","text":"procedure generating dataset based factorization joint distribution. variables simulated unidimensional conditional parametric regression models including several interaction quadratic terms. multilevel structure approximated including cluster means predictors regression models.","code":""},{"path":"/reference/data.befki.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"BEFKI Dataset (Schroeders, Schipolowski, & Wilhelm, 2015) — data.befki","text":"Synthetic dataset","code":""},{"path":"/reference/data.befki.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"BEFKI Dataset (Schroeders, Schipolowski, & Wilhelm, 2015) — data.befki","text":"Schroeders, U., Schipolowski, S., & Wilhelm, O. (2015). Age-related changes mean covariance structure fluid crystallized intelligence childhood adolescence. Intelligence, 48, 15-29. doi:10.1016/j.intell.2014.10.006 Wilhelm, O., Schroeders, U., & Schipolowski, S. (2014). Berliner Test zur Erfassung fluider und kristalliner Intelligenz fuer die 8. bis 10. Jahrgangsstufe [Berlin test fluid crystallized intelligence grades 8-10]. Goettingen: Hogrefe.","code":""},{"path":"/reference/data.big5.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset Big 5 from qgraph Package — data.big5","title":"Dataset Big 5 from qgraph Package — data.big5","text":"Big 5 dataset qgraph package (Dolan, Oorts, Stoel, Wicherts, 2009). contains 500 subjects 240 items.","code":""},{"path":"/reference/data.big5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset Big 5 from qgraph Package — data.big5","text":"","code":"data(data.big5) data(data.big5.qgraph)"},{"path":"/reference/data.big5.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset Big 5 from qgraph Package — data.big5","text":"format data.big5 :  num [1:500, 1:240] 1 0 0 0 0 1 1 2 0 1 ...  - attr(*, \"dimnames\")=List 2   ..$ : NULL   ..$ : chr [1:240] \"N1\" \"E2\" \"O3\" \"A4\" ... format data.big5.qgraph : num [1:500, 1:240] 2 3 4 4 5 2 2 1 4 2 ...  - attr(*, \"dimnames\")=List 2   ..$ : NULL   ..$ : chr [1:240] \"N1\" \"E2\" \"O3\" \"A4\" ...","code":""},{"path":"/reference/data.big5.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dataset Big 5 from qgraph Package — data.big5","text":"datasets, exist 48 items dimension. Big 5 dimensions Neuroticism (N), Extraversion (E), Openness (O), Agreeableness () Conscientiousness (C). Note data.big5 differs data.big5.qgraph way original items recoded three categories 0,1 2.","code":""},{"path":"/reference/data.big5.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dataset Big 5 from qgraph Package — data.big5","text":"See big5 qgraph package.","code":""},{"path":"/reference/data.big5.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dataset Big 5 from qgraph Package — data.big5","text":"Dolan, C. V., Oort, F. J., Stoel, R. D., & Wicherts, J. M. (2009). Testing measurement invariance target rotates multigroup exploratory factor model. Structural Equation Modeling, 16, 295-314.","code":""},{"path":[]},{"path":"/reference/data.bs.html","id":null,"dir":"Reference","previous_headings":"","what":"Datasets from Borg and Staufenbiel (2007) — data.bs","title":"Datasets from Borg and Staufenbiel (2007) — data.bs","text":"Datasets book Borg Staufenbiel (2007) Lehrbuch Theorien Methoden der Skalierung.","code":""},{"path":"/reference/data.bs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Datasets from Borg and Staufenbiel (2007) — data.bs","text":"","code":"data(data.bs07a)"},{"path":"/reference/data.bs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Datasets from Borg and Staufenbiel (2007) — data.bs","text":"dataset data.bs07a contains data Gefechtsangst (p. 130) contains 8 original 9 items. items symptoms anxiety engagement. GF1: starkes Herzklopfen, GF2: flaues Gefuehl der Magengegend, GF3: Schwaechegefuehl, GF4: Uebelkeitsgefuehl, GF5: Erbrechen, GF6: Schuettelfrost, GF7: die Hose urinieren/einkoten, GF9: Gefuehl der Gelaehmtheit format 'data.frame':   100 obs.  9 variables:  $ idpatt: int  44 29 1 3 28 50 50 36 37 25 ...  $ GF1   : int  1 1 1 1 1 0 0 1 1 1 ...  $ GF2   : int  0 1 1 1 1 0 0 1 1 1 ...  $ GF3   : int  0 0 1 1 0 0 0 0 0 1 ...  $ GF4   : int  0 0 1 1 0 0 0 1 0 1 ...  $ GF5   : int  0 0 1 1 0 0 0 0 0 0 ...  $ GF6   : int  1 1 1 1 1 0 0 0 0 0 ...  $ GF7   : num  0 0 1 1 0 0 0 0 0 0 ...  $ GF9   : int  0 0 1 1 1 0 0 0 0 0 ... DATASETS","code":""},{"path":"/reference/data.bs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Datasets from Borg and Staufenbiel (2007) — data.bs","text":"Borg, ., & Staufenbiel, T. (2007). Lehrbuch Theorie und Methoden der Skalierung. Bern: Hogrefe.","code":""},{"path":"/reference/data.bs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Datasets from Borg and Staufenbiel (2007) — data.bs","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 07a: Dataset Gefechtsangst #############################################################################  data(data.bs07a) dat <- data.bs07a items <- grep( \"GF\", colnames(dat), value=TRUE )  #************************ # Model 1: Rasch model mod1 <- TAM::tam.mml(dat[,items] ) summary(mod1) IRT.WrightMap(mod1)  #************************ # Model 2: 2PL model mod2 <- TAM::tam.mml.2pl(dat[,items] ) summary(mod2)  #************************ # Model 3: Latent class analysis (LCA) with two classes tammodel <- \" ANALYSIS:   TYPE=LCA;   NCLASSES(2)   NSTARTS(5,10) LAVAAN MODEL:   F=~ GF1__GF9   \" mod3 <- TAM::tamaan( tammodel, dat ) summary(mod3)  #************************ # Model 4: LCA with three classes tammodel <- \" ANALYSIS:   TYPE=LCA;   NCLASSES(3)   NSTARTS(5,10) LAVAAN MODEL:   F=~ GF1__GF9   \" mod4 <- TAM::tamaan( tammodel, dat ) summary(mod4)  #************************ # Model 5: Located latent class model (LOCLCA) with two classes tammodel <- \" ANALYSIS:   TYPE=LOCLCA;   NCLASSES(2)   NSTARTS(5,10) LAVAAN MODEL:   F=~ GF1__GF9   \" mod5 <- TAM::tamaan( tammodel, dat ) summary(mod5)  #************************ # Model 6: Located latent class model with three classes tammodel <- \" ANALYSIS:   TYPE=LOCLCA;   NCLASSES(3)   NSTARTS(5,10) LAVAAN MODEL:   F=~ GF1__GF9   \" mod6 <- TAM::tamaan( tammodel, dat ) summary(mod6)  #************************ # Model 7: Probabilistic Guttman model mod7 <- sirt::prob.guttman( dat[,items] ) summary(mod7)  #-- model comparison IRT.compareModels( mod1, mod2, mod3, mod4, mod5, mod6, mod7 ) }"},{"path":"/reference/data.eid.html","id":null,"dir":"Reference","previous_headings":"","what":"Examples with Datasets from Eid and Schmidt (2014) — data.eid","title":"Examples with Datasets from Eid and Schmidt (2014) — data.eid","text":"Examples datasets Eid Schmidt (2014), illustrations several R packages. examples follow closely online material Hosoya (2014). datasets completely synthetic datasets resimulated originally available data.","code":""},{"path":"/reference/data.eid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Examples with Datasets from Eid and Schmidt (2014) — data.eid","text":"","code":"data(data.eid.kap4) data(data.eid.kap5) data(data.eid.kap6) data(data.eid.kap7)"},{"path":"/reference/data.eid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Examples with Datasets from Eid and Schmidt (2014) — data.eid","text":"data.eid.kap4 dataset Chapter 4. 'data.frame':   193 obs.  11 variables:  $ sex     : int  0 0 0 0 0 0 1 0 0 1 ...  $ Freude_1: int  1 1 1 0 1 1 1 1 1 1 ...  $ Wut_1   : int  1 1 1 0 1 1 1 1 1 1 ...  $ Angst_1 : int  1 0 0 0 1 1 1 0 1 0 ...  $ Trauer_1: int  1 1 1 0 1 1 1 1 1 1 ...  $ Ueber_1 : int  1 1 1 0 1 1 0 1 1 1 ...  $ Trauer_2: int  0 1 1 1 1 1 1 1 1 0 ...  $ Angst_2 : int  0 0 1 0 0 1 0 0 0 0 ...  $ Wut_2   : int  1 1 1 1 1 1 1 1 1 1 ...  $ Ueber_2 : int  1 0 1 0 1 1 1 0 1 1 ...  $ Freude_2: int  1 1 1 0 1 1 1 1 1 1 ... data.eid.kap5 dataset Chapter 5. 'data.frame':   499 obs.  7 variables:  $ sex   : int  0 0 0 0 1 1 1 0 0 0 ...  $ item_1: int  2 3 3 2 4 1 0 0 0 2 ...  $ item_2: int  1 1 4 1 3 3 2 1 2 3 ...  $ item_3: int  1 3 3 2 3 3 0 0 0 1 ...  $ item_4: int  2 4 3 4 3 3 3 2 0 2 ...  $ item_5: int  1 3 2 2 0 0 0 0 1 2 ...  $ item_6: int  4 3 4 3 4 3 2 1 1 3 ... data.eid.kap6 dataset Chapter 6. 'data.frame':   238 obs.  7 variables:  $ geschl: int  1 1 0 0 0 1 0 1 1 0 ...  $ item_1: int  3 3 3 3 2 0 1 4 3 3 ...  $ item_2: int  2 2 2 2 2 0 2 3 1 3 ...  $ item_3: int  2 2 1 3 2 0 0 3 1 3 ...  $ item_4: int  2 3 3 3 3 0 2 4 3 4 ...  $ item_5: int  1 2 1 2 2 0 1 2 2 2 ...  $ item_6: int  2 2 2 2 2 0 1 2 1 2 ... data.eid.kap7 dataset Emotionale Klarheit Chapter 7. 'data.frame':   238 obs.  9 variables:  $ geschl : int  1 0 1 1 0 1 0 1 0 1 ...  $ reakt_1: num  2.13 1.78 1.28 1.82 1.9 1.63 1.73 1.49 1.43 1.27 ...  $ reakt_2: num  1.2 1.73 0.95 1.5 1.99 1.75 1.58 1.71 1.41 0.96 ...  $ reakt_3: num  1.77 1.42 0.76 1.54 2.36 1.84 2.06 1.21 1.75 0.92 ...  $ reakt_4: num  2.18 1.28 1.39 1.82 2.09 2.15 2.1 1.13 1.71 0.78 ...  $ reakt_5: num  1.47 1.7 1.08 1.77 1.49 1.73 1.96 1.76 1.88 1.1 ...  $ reakt_6: num  1.63 0.9 0.82 1.63 1.79 1.37 1.79 1.11 1.27 1.06 ...  $ kla_th1: int  8 11 11 8 10 11 12 5 6 12 ...  $ kla_th2: int  7 11 12 8 10 11 12 5 8 11 ...","code":""},{"path":"/reference/data.eid.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Examples with Datasets from Eid and Schmidt (2014) — data.eid","text":"material original datasets can downloaded http://www.hogrefe.de/buecher/lehrbuecher/psychlehrbuchplus/lehrbuecher/ testtheorie-und-testkonstruktion/zusatzmaterial/.","code":""},{"path":"/reference/data.eid.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Examples with Datasets from Eid and Schmidt (2014) — data.eid","text":"Eid, M., & Schmidt, K. (2014). Testtheorie und Testkonstruktion. Goettingen, Hogrefe. Hosoya, G. (2014). Einfuehrung die Analyse testtheoretischer Modelle mit R. Available http://www.hogrefe.de/buecher/lehrbuecher/psychlehrbuchplus/lehrbuecher/testtheorie-und-testkonstruktion/zusatzmaterial/.","code":""},{"path":"/reference/data.eid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Examples with Datasets from Eid and Schmidt (2014) — data.eid","text":"","code":"if (FALSE) { miceadds::library_install(\"foreign\") #---- load some IRT packages in R miceadds::library_install(\"TAM\")        # package (a) miceadds::library_install(\"mirt\")       # package (b) miceadds::library_install(\"sirt\")       # package (c) miceadds::library_install(\"eRm\")        # package (d) miceadds::library_install(\"ltm\")        # package (e) miceadds::library_install(\"psychomix\")  # package (f)  ############################################################################# # EXAMPLES Ch. 4: Unidimensional IRT models | dichotomous data #############################################################################  data(data.eid.kap4) data0 <- data.eid.kap4  # load data data0 <- foreign::read.spss( linkname, to.data.frame=TRUE, use.value.labels=FALSE) # extract items dat <- data0[,2:11]  #********************************************************* # Model 1: Rasch model #*********************************************************  #----------- #-- 1a: estimation with TAM package  # estimation with tam.mml mod1a <- TAM::tam.mml(dat) summary(mod1a)  # person parameters in TAM pp1a <- TAM::tam.wle(mod1a)  # plot item response functions plot(mod1a,export=FALSE,ask=TRUE)  # Infit and outfit in TAM itemf1a <- TAM::tam.fit(mod1a) itemf1a  # model fit modf1a <- TAM::tam.modelfit(mod1a) summary(modf1a)  #----------- #-- 1b: estimation with mirt package  # estimation with mirt mod1b <- mirt::mirt( dat, 1, itemtype=\"Rasch\") summary(mod1b) print(mod1b)  # person parameters pp1b <- mirt::fscores(mod1b, method=\"WLE\")  # extract coefficients sirt::mirt.wrapper.coef(mod1b)  # plot item response functions plot(mod1b, type=\"trace\" ) par(mfrow=c(1,1))  # item fit itemf1b <- mirt::itemfit(mod1b) itemf1b  # model fit modf1b <- mirt::M2(mod1b) modf1b  #----------- #-- 1c: estimation with sirt package  # estimation with rasch.mml2 mod1c <- sirt::rasch.mml2(dat) summary(mod1c)  # person parameters (EAP) pp1c <- mod1c$person  # plot item response functions plot(mod1c, ask=TRUE )  # model fit modf1c <- sirt::modelfit.sirt(mod1c) summary(modf1c)  #----------- #-- 1d: estimation with eRm package  # estimation with RM mod1d <- eRm::RM(dat) summary(mod1d)  # estimation person parameters pp1d <- eRm::person.parameter(mod1d) summary(pp1d)  # plot item response functions eRm::plotICC(mod1d)  # person-item map eRm::plotPImap(mod1d)  # item fit itemf1d <- eRm::itemfit(pp1d)  # person fit persf1d <- eRm::personfit(pp1d)  #----------- #-- 1e: estimation with ltm package  # estimation with rasch mod1e <- ltm::rasch(dat) summary(mod1e)  # estimation person parameters pp1e <- ltm::factor.scores(mod1e)  # plot item response functions plot(mod1e)  # item fit itemf1e <- ltm::item.fit(mod1e)  # person fit persf1e <- ltm::person.fit(mod1e)  # goodness of fit with Bootstrap modf1e <- ltm::GoF.rasch(mod1e,B=20)    # use more bootstrap samples modf1e  #********************************************************* # Model 2: 2PL model #*********************************************************  #----------- #-- 2a: estimation with TAM package  # estimation mod2a <- TAM::tam.mml.2pl(dat) summary(mod2a)  # model fit modf2a <- TAM::tam.modelfit(mod2a) summary(modf2a)  # item response functions plot(mod2a, export=FALSE, ask=TRUE)  # model comparison anova(mod1a,mod2a)  #----------- #-- 2b: estimation with mirt package  # estimation mod2b <- mirt::mirt(dat,1,itemtype=\"2PL\") summary(mod2b) print(mod2b) sirt::mirt.wrapper.coef(mod2b)  # model fit modf2b <- mirt::M2(mod2b) modf2b  #----------- #-- 2c: estimation with sirt package  I <- ncol(dat) # estimation mod2c <- sirt::rasch.mml2(dat,est.a=1:I) summary(mod2c)  # model fit modf2c <- sirt::modelfit.sirt(mod2c) summary(modf2c)  #----------- #-- 2e: estimation with ltm package  # estimation mod2e <- ltm::ltm(dat ~ z1 ) summary(mod2e)  # item response functions plot(mod2e)  #********************************************************* # Model 3: Mixture Rasch model #*********************************************************  #----------- #-- 3a: estimation with TAM package  # avoid \"_\" in column names if the \"__\" operator is used in # the tamaan syntax dat1 <- dat colnames(dat1) <- gsub(\"_\", \"\", colnames(dat1) ) # define tamaan model tammodel <- \" ANALYSIS:   TYPE=MIXTURE ;   NCLASSES(2);   NSTARTS(20,25);   # 20 random starts with 25 initial iterations each LAVAAN MODEL:   F=~ Freude1__Freude2   F ~~ F ITEM TYPE:   ALL(Rasch);     \" mod3a <- TAM::tamaan( tammodel, resp=dat1 ) summary(mod3a) # extract item parameters ipars <- mod2$itempartable_MIXTURE[ 1:10, ] plot( 1:10, ipars[,3], type=\"o\", ylim=range( ipars[,3:4] ), pch=16,         xlab=\"Item\", ylab=\"Item difficulty\") lines( 1:10, ipars[,4], type=\"l\", col=2, lty=2) points( 1:10, ipars[,4],  col=2, pch=2)  #----------- #-- 3f: estimation with psychomix package  # estimation mod3f <- psychomix::raschmix( as.matrix(dat), k=2, scores=\"meanvar\") summary(mod3f) # plot class-specific item difficulties plot(mod3f)  ############################################################################# # EXAMPLES Ch. 5: Unidimensional IRT models | polytomous data #############################################################################  data(data.eid.kap5) data0 <- data.eid.kap5 # extract items dat <- data0[,2:7]  #********************************************************* # Model 1: Partial credit model #*********************************************************  #----------- #-- 1a: estimation with TAM package  # estimation with tam.mml mod1a <- TAM::tam.mml(dat) summary(mod1a)  # person parameters in TAM pp1a <- tam.wle(mod1a)  # plot item response functions plot(mod1a,export=FALSE,ask=TRUE)  # Infit and outfit in TAM itemf1a <- TAM::tam.fit(mod1a) itemf1a  # model fit modf1a <- TAM::tam.modelfit(mod1a) summary(modf1a)  #----------- #-- 1b: estimation with mirt package  # estimation with tam.mml mod1b <- mirt::mirt( dat, 1, itemtype=\"Rasch\") summary(mod1b) print(mod1b) sirt::mirt.wrapper.coef(mod1b)  # plot item response functions plot(mod1b, type=\"trace\" ) par(mfrow=c(1,1))  # item fit itemf1b <- mirt::itemfit(mod1b) itemf1b  #----------- #-- 1c: estimation with sirt package  # estimation with rm.facets mod1c <- sirt::rm.facets(dat) summary(mod1c) summary(mod1a)  #----------- #-- 1d: estimation with eRm package  # estimation mod1d <- eRm::PCM(dat) summary(mod1d)  # plot item response functions eRm::plotICC(mod1d)  # person-item map eRm::plotPImap(mod1d)  # item fit itemf1d <- eRm::itemfit(pp1d)  #----------- #-- 1e: estimation with ltm package  # estimation mod1e <- ltm::gpcm(dat, constraint=\"1PL\") summary(mod1e) # plot item response functions plot(mod1e)  #********************************************************* # Model 2: Generalized partial credit model #*********************************************************  #----------- #-- 2a: estimation with TAM package  # estimation with tam.mml mod2a <- TAM::tam.mml.2pl(dat, irtmodel=\"GPCM\") summary(mod2a)  # model fit modf2a <- TAM::tam.modelfit(mod2a) summary(modf2a)  #----------- #-- 2b: estimation with mirt package  # estimation mod2b <- mirt::mirt( dat, 1, itemtype=\"gpcm\") summary(mod2b) print(mod2b) sirt::mirt.wrapper.coef(mod2b)  #----------- #-- 2c: estimation with sirt package  # estimation with rm.facets mod2c <- sirt::rm.facets(dat, est.a.item=TRUE) summary(mod2c)  #----------- #-- 2e: estimation with ltm package  # estimation mod2e <- ltm::gpcm(dat) summary(mod2e) plot(mod2e) }"},{"path":"/reference/data.ess2005.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset European Social Survey 2005 — data.ess2005","title":"Dataset European Social Survey 2005 — data.ess2005","text":"dataset contains item loadings \\(\\lambda\\) intercepts \\(\\nu\\) 26 countries European Social Survey (ESS 2005; see Asparouhov & Muthen, 2014).","code":""},{"path":"/reference/data.ess2005.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset European Social Survey 2005 — data.ess2005","text":"","code":"data(data.ess2005)"},{"path":"/reference/data.ess2005.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset European Social Survey 2005 — data.ess2005","text":"format dataset : List 2  $ lambda: num [1:26, 1:4] 0.688 0.721 0.72 0.687 0.625 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:4] \"ipfrule\" \"ipmodst\" \"ipbhprp\" \"imptrad\"  $ nu    : num [1:26, 1:4] 3.26 2.52 3.41 2.84 2.79 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:4] \"ipfrule\" \"ipmodst\" \"ipbhprp\" \"imptrad\"","code":""},{"path":"/reference/data.ess2005.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dataset European Social Survey 2005 — data.ess2005","text":"Asparouhov, T., & Muthen, B. (2014). Multiple-group factor analysis alignment. Structural Equation Modeling, 21(4), 1-14. doi:10.1080/10705511.2014.919210","code":""},{"path":"/reference/data.g308.html","id":null,"dir":"Reference","previous_headings":"","what":"C-Test Datasets — data.g308","title":"C-Test Datasets — data.g308","text":"datasets C-tests provided. dataset data.g308 used Schroeders, Robitzsch Schipolowski (2014).","code":""},{"path":"/reference/data.g308.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"C-Test Datasets — data.g308","text":"","code":"data(data.g308)"},{"path":"/reference/data.g308.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"C-Test Datasets — data.g308","text":"dataset data.g308 C-test containing 20 items used Schroeders, Robitzsch Schipolowski (2014) following format 'data.frame':   747 obs.  21 variables:  $ id    : int  1 2 3 4 5 6 7 8 9 10 ...  $ G30801: int  1 1 1 1 1 0 0 1 1 1 ...  $ G30802: int  1 1 1 1 1 1 1 1 1 1 ...  $ G30803: int  1 1 1 1 1 1 1 1 1 1 ...  $ G30804: int  1 1 1 1 1 0 1 1 1 1 ... [...]  $ G30817: int  0 0 0 0 1 0 1 0 1 0 ...  $ G30818: int  0 0 1 0 0 0 0 1 1 0 ...  $ G30819: int  1 1 1 1 0 0 1 1 1 0 ...  $ G30820: int  1 1 1 1 0 0 0 1 1 0 ...","code":""},{"path":"/reference/data.g308.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"C-Test Datasets — data.g308","text":"Schroeders, U., Robitzsch, ., & Schipolowski, S. (2014). comparison different psychometric approaches modeling testlet structures: example C-tests. Journal Educational Measurement, 51(4), 400-418.","code":""},{"path":"/reference/data.g308.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"C-Test Datasets — data.g308","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Dataset G308 from Schroeders et al. (2014) #############################################################################  data(data.g308) dat <- data.g308  library(TAM) library(sirt)  # define testlets testlet <- c(1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4, 5, 5, 6, 6, 6)  #**************************************** #*** Model 1: Rasch model mod1 <- TAM::tam.mml(resp=dat, control=list(maxiter=300, snodes=1500)) summary(mod1)  #**************************************** #*** Model 2: Rasch testlet model  # testlets are dimensions, assign items to Q-matrix TT <- length(unique(testlet)) Q <- matrix(0, nrow=ncol(dat), ncol=TT + 1) Q[,1] <- 1 # First dimension constitutes g-factor for (tt in 1:TT){Q[testlet==tt, tt+1] <- 1}  # In a testlet model, all dimensions are uncorrelated among # each other, that is, all pairwise correlations are set to 0, # which can be accomplished with the \"variance.fixed\" command variance.fixed <- cbind(t( utils::combn(TT+1,2)), 0) mod2 <- TAM::tam.mml(resp=dat, Q=Q, variance.fixed=variance.fixed,             control=list(snodes=1500, maxiter=300)) summary(mod2)  #**************************************** #*** Model 3: Partial credit model  scores <- list() testlet.names <- NULL dat.pcm <- NULL for (tt in 1:max(testlet) ){    scores[[tt]] <- rowSums (dat[, testlet==tt, drop=FALSE])    dat.pcm <- c(dat.pcm, list(c(scores[[tt]])))    testlet.names <- append(testlet.names, paste0(\"testlet\",tt) )    } dat.pcm <- as.data.frame(dat.pcm) colnames(dat.pcm) <- testlet.names mod3 <- TAM::tam.mml(resp=dat.pcm, control=list(snodes=1500, maxiter=300) ) summary(mod3)  #**************************************** #*** Model 4: Copula model  mod4 <- sirt::rasch.copula2 (dat=dat, itemcluster=testlet) summary(mod4) }"},{"path":"/reference/data.inv4gr.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset for Invariance Testing with 4 Groups — data.inv4gr","title":"Dataset for Invariance Testing with 4 Groups — data.inv4gr","text":"Dataset invariance testing 4 groups.","code":""},{"path":"/reference/data.inv4gr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset for Invariance Testing with 4 Groups — data.inv4gr","text":"","code":"data(data.inv4gr)"},{"path":"/reference/data.inv4gr.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset for Invariance Testing with 4 Groups — data.inv4gr","text":"data frame 4000 observations following 12 variables.   first variable group identifier, variables items. group group identifier I01 numeric vector I02 numeric vector I03 numeric vector I04 numeric vector I05 numeric vector I06 numeric vector I07 numeric vector I08 numeric vector I09 numeric vector I10 numeric vector I11 numeric vector","code":""},{"path":"/reference/data.inv4gr.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dataset for Invariance Testing with 4 Groups — data.inv4gr","text":"Simulated dataset","code":""},{"path":"/reference/data.liking.science.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset 'Liking For Science' — data.liking.science","title":"Dataset 'Liking For Science' — data.liking.science","text":"Dataset 'Liking science' published Wright Masters (1982).","code":""},{"path":"/reference/data.liking.science.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset 'Liking For Science' — data.liking.science","text":"","code":"data(data.liking.science)"},{"path":"/reference/data.liking.science.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset 'Liking For Science' — data.liking.science","text":"format : num [1:75, 1:24] 1 2 2 1 1 1 2 2 0 2 ...  - attr(*, \"dimnames\")=List 2   ..$ : NULL   ..$ : chr [1:24] \"LS01\" \"LS02\" \"LS03\" \"LS04\" ...","code":""},{"path":"/reference/data.liking.science.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dataset 'Liking For Science' — data.liking.science","text":"Wright, B. D., & Masters, G. N. (1982). Rating scale analysis. Chicago: MESA Press.","code":""},{"path":"/reference/data.long.html","id":null,"dir":"Reference","previous_headings":"","what":"Longitudinal Dataset — data.long","title":"Longitudinal Dataset — data.long","text":"dataset contains 200 observations 12 items. 6 items (I1T1, ...,I6T1) administered measurement occasion T1 6 items T2 (I3T2, ..., I8T2). 4 anchor items presented time points. first column dataset contains student identifier.","code":""},{"path":"/reference/data.long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Longitudinal Dataset — data.long","text":"","code":"data(data.long)"},{"path":"/reference/data.long.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Longitudinal Dataset — data.long","text":"format dataset 'data.frame':   200 obs.  13 variables:  $ idstud: int  1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 ...  $ I1T1  : int  1 1 1 1 1 1 1 0 1 1 ...  $ I2T1  : int  0 0 1 1 1 1 0 1 1 1 ...  $ I3T1  : int  1 0 1 1 0 1 0 0 0 0 ...  $ I4T1  : int  1 0 0 1 0 0 0 0 1 1 ...  $ I5T1  : int  1 0 0 1 0 0 0 0 1 0 ...  $ I6T1  : int  1 0 0 0 0 0 0 0 0 0 ...  $ I3T2  : int  1 1 0 0 1 1 1 1 0 1 ...  $ I4T2  : int  1 1 0 0 1 1 0 0 0 1 ...  $ I5T2  : int  1 0 1 1 1 1 1 0 1 1 ...  $ I6T2  : int  1 1 0 0 0 0 0 0 0 1 ...  $ I7T2  : int  1 0 0 0 0 0 0 0 0 1 ...  $ I8T2  : int  0 0 0 0 1 0 0 0 0 0 ...","code":""},{"path":"/reference/data.long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Longitudinal Dataset — data.long","text":"","code":"if (FALSE) { data(data.long) dat <- data.long dat <- dat[,-1] I <- ncol(dat)  #************************************************* # Model 1: 2-dimensional Rasch model #************************************************* # define Q-matrix Q <- matrix(0,I,2) Q[1:6,1] <- 1 Q[7:12,2] <- 1 rownames(Q) <- colnames(dat) colnames(Q) <- c(\"T1\",\"T2\")  # vector with same items itemnr <- as.numeric( substring( colnames(dat),2,2) ) # fix mean at T2 to zero mu.fixed <- cbind( 2,0 )  #--- M1a: rasch.mml2 (in sirt) mod1a <- sirt::rasch.mml2(dat, Q=Q, est.b=itemnr, mu.fixed=mu.fixed) summary(mod1a)  #--- M1b: smirt (in sirt) mod1b <- sirt::smirt(dat, Qmatrix=Q, irtmodel=\"comp\", est.b=itemnr,                   mu.fixed=mu.fixed )  #--- M1c: tam.mml (in TAM)  # assume equal item difficulty of I3T1 and I3T2, I4T1 and I4T2, ... # create draft design matrix and modify it A <- TAM::designMatrices(resp=dat)$A dimnames(A)[[1]] <- colnames(dat)   ##   > str(A)   ##    num [1:12, 1:2, 1:12] 0 0 0 0 0 0 0 0 0 0 ...   ##    - attr(*, \"dimnames\")=List of 3   ##     ..$ : chr [1:12] \"Item01\" \"Item02\" \"Item03\" \"Item04\" ...   ##     ..$ : chr [1:2] \"Category0\" \"Category1\"   ##     ..$ : chr [1:12] \"I1T1\" \"I2T1\" \"I3T1\" \"I4T1\" ... A1 <- A[,, c(1:6, 11:12 ) ] A1[7,2,3] <- -1     # difficulty(I3T1)=difficulty(I3T2) A1[8,2,4] <- -1     # I4T1=I4T2 A1[9,2,5] <- A1[10,2,6] <- -1 dimnames(A1)[[3]] <- substring( dimnames(A1)[[3]],1,2)   ##   > A1[,2,]   ##        I1 I2 I3 I4 I5 I6 I7 I8   ##   I1T1 -1  0  0  0  0  0  0  0   ##   I2T1  0 -1  0  0  0  0  0  0   ##   I3T1  0  0 -1  0  0  0  0  0   ##   I4T1  0  0  0 -1  0  0  0  0   ##   I5T1  0  0  0  0 -1  0  0  0   ##   I6T1  0  0  0  0  0 -1  0  0   ##   I3T2  0  0 -1  0  0  0  0  0   ##   I4T2  0  0  0 -1  0  0  0  0   ##   I5T2  0  0  0  0 -1  0  0  0   ##   I6T2  0  0  0  0  0 -1  0  0   ##   I7T2  0  0  0  0  0  0 -1  0   ##   I8T2  0  0  0  0  0  0  0 -1  # estimate model # set intercept of second dimension (T2) to zero beta.fixed <- cbind( 1, 2, 0 ) mod1c <- TAM::tam.mml( resp=dat, Q=Q, A=A1, beta.fixed=beta.fixed) summary(mod1c)  #************************************************* # Model 2: 2-dimensional 2PL model #*************************************************  # set variance at T2 to 1 variance.fixed <- cbind(2,2,1)  # M2a: rasch.mml2 (in sirt) mod2a <- sirt::rasch.mml2(dat, Q=Q, est.b=itemnr, est.a=itemnr, mu.fixed=mu.fixed,              variance.fixed=variance.fixed, mmliter=100) summary(mod2a)  #************************************************* # Model 3: Concurrent calibration by assuming invariant item parameters #*************************************************  library(mirt)   # use mirt for concurrent calibration data(data.long) dat <- data.long[,-1] I <- ncol(dat)  # create user defined function for between item dimensionality 4PL model name <- \"4PLbw\" par <- c(\"low\"=0,\"upp\"=1,\"a\"=1,\"d\"=0,\"dimItem\"=1) est <- c(TRUE, TRUE,TRUE,TRUE,FALSE) # item response function irf <- function(par,Theta,ncat){      low <- par[1]      upp <- par[2]      a <- par[3]      d <- par[4]      dimItem <- par[5]      P1 <- low + ( upp - low ) * plogis( a*Theta[,dimItem] + d )      cbind(1-P1, P1) }  # create item response function fourPLbetw <- mirt::createItem(name, par=par, est=est, P=irf) head(dat)  # create mirt model (use variable names in mirt.model) mirtsyn <- \"      T1=I1T1,I2T1,I3T1,I4T1,I5T1,I6T1      T2=I3T2,I4T2,I5T2,I6T2,I7T2,I8T2      COV=T1*T2,,T2*T2      MEAN=T1      CONSTRAIN=(I3T1,I3T2,d),(I4T1,I4T2,d),(I5T1,I5T2,d),(I6T1,I6T2,d),                  (I3T1,I3T2,a),(I4T1,I4T2,a),(I5T1,I5T2,a),(I6T1,I6T2,a)         \" # create mirt model mirtmodel <- mirt::mirt.model( mirtsyn, itemnames=colnames(dat) ) # define parameters to be estimated mod3.pars <- mirt::mirt(dat, mirtmodel$model, rep( \"4PLbw\",I),                    customItems=list(\"4PLbw\"=fourPLbetw), pars=\"values\") # select dimensions ind <- intersect( grep(\"T2\",mod3.pars$item), which( mod3.pars$name==\"dimItem\" ) ) mod3.pars[ind,\"value\"] <- 2 # set item parameters low and upp to non-estimated ind <- which( mod3.pars$name %in% c(\"low\",\"upp\") ) mod3.pars[ind,\"est\"] <- FALSE  # estimate 2PL model mod3 <- mirt::mirt(dat, mirtmodel$model, itemtype=rep( \"4PLbw\",I),                 customItems=list(\"4PLbw\"=fourPLbetw), pars=mod3.pars, verbose=TRUE,                 technical=list(NCYCLES=50)  ) mirt.wrapper.coef(mod3)  #****** estimate model in lavaan library(lavaan)  # specify syntax lavmodel <- \"              #**** T1              F1=~ a1*I1T1+a2*I2T1+a3*I3T1+a4*I4T1+a5*I5T1+a6*I6T1              I1T1 | b1*t1 ; I2T1 | b2*t1 ; I3T1 | b3*t1 ; I4T1 | b4*t1              I5T1 | b5*t1 ; I6T1 | b6*t1              F1 ~~ 1*F1              #**** T2              F2=~ a3*I3T2+a4*I4T2+a5*I5T2+a6*I6T2+a7*I7T2+a8*I8T2              I3T2 | b3*t1 ; I4T2 | b4*t1 ; I5T2 | b5*t1 ; I6T2 | b6*t1              I7T2 | b7*t1 ; I8T2 | b8*t1              F2 ~~ NA*F2              F2 ~ 1              #*** covariance              F1 ~~ F2                 \" # estimate model using theta parameterization mod3lav <- lavaan::cfa( data=dat, model=lavmodel,             std.lv=TRUE, ordered=colnames(dat), parameterization=\"theta\") summary(mod3lav, standardized=TRUE, fit.measures=TRUE, rsquare=TRUE)  #************************************************* # Model 4: Linking with items of different item slope groups #*************************************************  data(data.long) dat <- data.long # dataset for T1 dat1 <- dat[, grep( \"T1\", colnames(dat) ) ] colnames(dat1) <- gsub(\"T1\",\"\", colnames(dat1) ) # dataset for T2 dat2 <- dat[, grep( \"T2\", colnames(dat) ) ] colnames(dat2) <- gsub(\"T2\",\"\", colnames(dat2) )  # 2PL model with slope groups T1 mod1 <- sirt::rasch.mml2( dat1, est.a=c( rep(1,2), rep(2,4) ) ) summary(mod1)  # 2PL model with slope groups T2 mod2 <- sirt::rasch.mml2( dat2, est.a=c( rep(1,4), rep(2,2) ) ) summary(mod2)  #------- Link 1: Haberman Linking # collect item parameters dfr1 <- data.frame( \"study1\", mod1$item$item, mod1$item$a, mod1$item$b ) dfr2 <- data.frame( \"study2\", mod2$item$item, mod2$item$a, mod2$item$b ) colnames(dfr2) <- colnames(dfr1) <- c(\"study\", \"item\", \"a\", \"b\" ) itempars <- rbind( dfr1, dfr2 ) # Linking link1 <- sirt::linking.haberman(itempars=itempars)  #------- Link 2: Invariance alignment method # create objects for invariance.alignment nu <- rbind( c(mod1$item$thresh,NA,NA), c(NA,NA,mod2$item$thresh) ) lambda <- rbind( c(mod1$item$a,NA,NA), c(NA,NA,mod2$item$a ) ) colnames(lambda) <- colnames(nu) <- paste0(\"I\",1:8) rownames(lambda) <- rownames(nu) <- c(\"T1\", \"T2\") # Linking link2a <- sirt::invariance.alignment( lambda, nu ) summary(link2a) }"},{"path":"/reference/data.lsem.html","id":null,"dir":"Reference","previous_headings":"","what":"Datasets for Local Structural Equation Models / Moderated Factor Analysis — data.lsem","title":"Datasets for Local Structural Equation Models / Moderated Factor Analysis — data.lsem","text":"Datasets local structural equation models moderated factor analysis.","code":""},{"path":"/reference/data.lsem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Datasets for Local Structural Equation Models / Moderated Factor Analysis — data.lsem","text":"","code":"data(data.lsem01) data(data.lsem02) data(data.lsem03)"},{"path":"/reference/data.lsem.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Datasets for Local Structural Equation Models / Moderated Factor Analysis — data.lsem","text":"dataset data.lsem01 following structure 'data.frame':   989 obs.  6 variables:  $ age: num  4 4 4 4 4 4 4 4 4 4 ...  $ v1 : num  1.83 2.38 1.85 4.53 -0.04 4.35 2.38 1.83 4.81 2.82 ...  $ v2 : num  6.06 9.08 7.41 8.24 6.18 7.4 6.54 4.28 6.43 7.6 ...  $ v3 : num  1.42 3.05 6.42 -1.05 -1.79 4.06 -0.17 -2.64 0.84 6.42 ...  $ v4 : num  3.84 4.24 3.24 3.36 2.31 6.07 4 5.93 4.4 3.49 ...  $ v5 : num  7.84 7.51 6.62 8.02 7.12 7.99 7.25 7.62 7.66 7.03 ... dataset data.lsem02 slightly perturbed dataset Woodcock-Johnson  III (WJ-III) Tests Cognitive Abilities used Hildebrandt et al. (2016) following structure 'data.frame':   1129 obs.  8 variables:  $ age : int  4 4 4 4 4 4 4 4 4 4 ...  $ gcw : num  -3.53 -3.73 -3.77 -3.84 -4.26 -4.6 -3.66 -4.31 -4.46 -3.64 ...  $ gvw : num  -1.98 -1.35 -1.66 -3.24 -1.17 -2.78 -2.97 -3.88 -3.22 -0.68 ...  $ gfw : num  -2.49 -2.41 -4.48 -4.17 -4.43 -5.06 -3.94 -3.66 -3.7 -2.74 ...  $ gsw : num  -4.85 -5.05 -5.66 -4.3 -5.23 -5.63 -4.91 -5.75 -6.29 -5.47 ...  $ gsmw: num  -2.99 -1.13 -4.21 -3.59 -3.79 -4.77 -2.98 -4.48 -2.99 -3.83 ...  $ glrw: num  -2.49 -2.91 -3.45 -2.91 -3.31 -3.78 -3.5 -3.96 -2.97 -3.14 ...  $ gaw : num  -3.22 -3.77 -3.54 -3.6 -3.22 -3.5 -1.27 -2.08 -2.23 -3.25 ... dataset data.lsem03 synthetic dataset SON-R application used Hueluer et al. (2011) following structure 'data.frame':   1027 obs.  10 variables:  $ id       : num  10001 10002 10003 10004 10005 ...  $ female   : int  0 0 0 0 0 0 0 0 0 0 ...  $ age      : num  2.62 2.65 2.66 2.67 2.68 2.68 2.68 2.69 2.71 2.71 ...  $ age_group: int  1 1 1 1 1 1 1 1 1 1 ...  $ p1       : num  -1.98 -1.98 -1.67 -2.29 -1.67 -1.98 -2.29 -1.98 -2.6 -1.67 ...  $ p2       : num  -1.51 -1.51 -0.55 -1.84 -1.51 -1.84 -2.16 -1.84 -2.48 -1.84 ...  $ p3       : num  -1.4 -2.31 -1.1 -2 -1.4 -1.7 -2.31 -1.4 -2.31 -0.79 ...  $ r1       : num  -1.46 -1.14 -0.49 -2.11 -1.46 -1.46 -2.11 -1.46 -2.75 -1.78 ...  $ r2       : num  -2.67 -1.74 0.74 -1.74 -0.81 -1.43 -2.05 -1.43 -1.74 -1.12 ...  $ r3       : num  -1.64 -1.64 -1.64 -0.9 -1.27 -3.11 -2.74 -1.64 -2.37 -1.27 ... subtests  Mosaics (p1), Puzzles (p1), Patterns (p3) constitute performance subscale; subtests Categories (r1), Analogies (r2), Situations (r3) constitute reasoning subscale.","code":""},{"path":"/reference/data.lsem.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Datasets for Local Structural Equation Models / Moderated Factor Analysis — data.lsem","text":"Hildebrandt, ., Luedtke, O., Robitzsch, ., Sommer, C., & Wilhelm, O. (2016). Exploring factor model parameters across continuous variables local structural equation models. Multivariate Behavioral Research, 51(2-3), 257-278. doi:10.1080/00273171.2016.1142856 Hueluer, G., Wilhelm, O., & Robitzsch, . (2011). Intelligence differentiation early childhood. Journal Individual Differences, 32(3), 170-179. doi:10.1027/1614-0001/a000049","code":""},{"path":"/reference/data.math.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset Mathematics — data.math","title":"Dataset Mathematics — data.math","text":"example dataset involving Mathematics items German fourth graders. Items classified several domains subdomains (see Section Format). dataset contains 664 students 30 items.","code":""},{"path":"/reference/data.math.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset Mathematics — data.math","text":"","code":"data(data.math)"},{"path":"/reference/data.math.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset Mathematics — data.math","text":"dataset list. list element data contains dataset demographic variables student ID (idstud) dummy variable female students (female). remaining variables (starting M name) mathematics items.  item metadata included list element item contains item name (item) testlet label (testlet). item included testlet indicated NA. item allocated one competence domain (domain). format : List 2  $ data:'data.frame':   ..$ idstud: int [1:664] 1001 1002 1003 ...   ..$ female: int [1:664] 1 1 0 0 1 1 1 0 0 1 ...   ..$ MA1   : int [1:664] 1 1 1 0 0 1 1 1 1 1 ...   ..$ MA2   : int [1:664] 1 1 1 1 1 0 0 0 0 1 ...   ..$ MA3   : int [1:664] 1 1 0 0 0 0 0 1 0 0 ...   ..$ MA4   : int [1:664] 0 1 1 1 0 0 1 0 0 0 ...   ..$ MB1   : int [1:664] 0 1 0 1 0 0 0 0 0 1 ...   ..$ MB2   : int [1:664] 1 1 1 1 0 1 0 1 0 0 ...   ..$ MB3   : int [1:664] 1 1 1 1 0 0 0 1 0 1 ...   [...]   ..$ MH3   : int [1:664] 1 1 0 1 0 0 1 0 1 0 ...   ..$ MH4   : int [1:664] 0 1 1 1 0 0 0 0 1 0 ...   ..$ MI1   : int [1:664] 1 1 0 1 0 1 0 0 1 0 ...   ..$ MI2   : int [1:664] 1 1 0 0 0 1 1 0 1 1 ...   ..$ MI3   : int [1:664] 0 1 0 1 0 0 0 0 0 0 ...  $ item:'data.frame':   ..$ item     : Factor w/ 30 levels \"MA1\",\"MA2\",\"MA3\",..: 1 2 3 4 5 ...   ..$ testlet  : Factor w/ 9 levels \"\",\"MA\",\"MB\",\"MC\",..: 2 2 2 2 3 3  ...   ..$ domain   : Factor w/ 3 levels \"arithmetic\",\"geometry\",..: 1 1 1  ...   ..$ subdomain: Factor w/ 9 levels \"\",\"addition\",..: 2 2 2 2 7 7  ...","code":""},{"path":"/reference/data.mcdonald.html","id":null,"dir":"Reference","previous_headings":"","what":"Some Datasets from McDonald's Test Theory Book — data.mcdonald","title":"Some Datasets from McDonald's Test Theory Book — data.mcdonald","text":"datasets McDonald (1999), especially related using NOHARM item response modeling. See Examples .","code":""},{"path":"/reference/data.mcdonald.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Some Datasets from McDonald's Test Theory Book — data.mcdonald","text":"","code":"data(data.mcdonald.act15) data(data.mcdonald.LSAT6) data(data.mcdonald.rape)"},{"path":"/reference/data.mcdonald.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Some Datasets from McDonald's Test Theory Book — data.mcdonald","text":"format ACT15 data data.mcdonald.act15 : num [1:15, 1:15] 0.49 0.44 0.38 0.3 0.29 0.13 0.23 0.16 0.16 0.23 ...  - attr(*, \"dimnames\")=List 2   ..$ : chr [1:15] \"A01\" \"A02\" \"A03\" \"A04\" ...   ..$ : chr [1:15] \"A01\" \"A02\" \"A03\" \"A04\" ... dataset (product-moment covariance matrix) obtained Ch. 12 McDonald (1999). format LSAT6 data data.mcdonald.LSAT6 : 'data.frame':   1004 obs.  5 variables:  $ L1: int  0 0 0 0 0 0 0 0 0 0 ...  $ L2: int  0 0 0 0 0 0 0 0 0 0 ...  $ L3: int  0 0 0 0 0 0 0 0 0 0 ...  $ L4: int  0 0 0 0 0 0 0 0 0 1 ...  $ L5: int  0 0 0 1 1 1 1 1 1 0 ... dataset obtained Ch. 6 McDonald (1999). format rape myth scale data  data.mcdonald.rape List 2  $ lambda: num [1:2, 1:19] 1.13 0.88 0.85 0.77 0.79 0.55 1.12 1.01 0.99 0.79 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : chr [1:2] \"male\" \"female\"   .. ..$ : chr [1:19] \"I1\" \"I2\" \"I3\" \"I4\" ...  $ nu    : num [1:2, 1:19] 2.88 1.87 3.12 2.32 2.13 1.43 3.79 2.6 3.01 2.11 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : chr [1:2] \"male\" \"female\"   .. ..$ : chr [1:19] \"I1\" \"I2\" \"I3\" \"I4\" ... dataset obtained Ch. 15 McDonald (1999).","code":""},{"path":"/reference/data.mcdonald.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Some Datasets from McDonald's Test Theory Book — data.mcdonald","text":"Tables McDonald (1999)","code":""},{"path":"/reference/data.mcdonald.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Some Datasets from McDonald's Test Theory Book — data.mcdonald","text":"McDonald, R. P. (1999). Test theory: unified treatment. Psychology Press.","code":""},{"path":"/reference/data.mcdonald.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Some Datasets from McDonald's Test Theory Book — data.mcdonald","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: LSAT6 data    | Chapter 12 McDonald (1999) ############################################################################# data(data.mcdonald.act15)  #************ # Model 1: 2-parameter normal ogive model  #++ NOHARM estimation I <- ncol(dat) # covariance structure P.pattern <- matrix( 0, ncol=1, nrow=1 ) P.init <- 1+0*P.pattern # fix all entries in the loading matrix to 1 F.pattern <- matrix( 1, nrow=I, ncol=1 ) F.init <- F.pattern # estimate model mod1a <- sirt::R2noharm( dat=dat, model.type=\"CFA\", F.pattern=F.pattern,              F.init=F.init, P.pattern=P.pattern, P.init=P.init,              writename=\"LSAT6__1dim_2pno\", noharm.path=noharm.path, dec=\",\" ) summary(mod1a, logfile=\"LSAT6__1dim_2pno__SUMMARY\")  #++ pairwise marginal maximum likelihood estimation using the probit link mod1b <- sirt::rasch.pml3( dat, est.a=1:I, est.sigma=FALSE)  #************ # Model 2: 1-parameter normal ogive model  #++ NOHARM estimation # covariance structure P.pattern <- matrix( 0, ncol=1, nrow=1 ) P.init <- 1+0*P.pattern # fix all entries in the loading matrix to 1 F.pattern <- matrix( 2, nrow=I, ncol=1 ) F.init <- 1+0*F.pattern # estimate model mod2a <- sirt::R2noharm( dat=dat, model.type=\"CFA\", F.pattern=F.pattern,                 F.init=F.init, P.pattern=P.pattern, P.init=P.init,                 writename=\"LSAT6__1dim_1pno\", noharm.path=noharm.path, dec=\",\" ) summary(mod2a, logfile=\"LSAT6__1dim_1pno__SUMMARY\")  # PMML estimation mod2b <- sirt::rasch.pml3( dat, est.a=rep(1,I), est.sigma=FALSE ) summary(mod2b)  #************ # Model 3: 3-parameter normal ogive model with fixed guessing parameters  #++ NOHARM estimation # covariance structure P.pattern <- matrix( 0, ncol=1, nrow=1 ) P.init <- 1+0*P.pattern # fix all entries in the loading matrix to 1 F.pattern <- matrix( 1, nrow=I, ncol=1 ) F.init <- 1+0*F.pattern # estimate model mod <- sirt::R2noharm( dat=dat, model.type=\"CFA\",  guesses=rep(.2,I),             F.pattern=F.pattern, F.init=F.init, P.pattern=P.pattern,             P.init=P.init, writename=\"LSAT6__1dim_3pno\",             noharm.path=noharm.path, dec=\",\" ) summary(mod, logfile=\"LSAT6__1dim_3pno__SUMMARY\")  #++ logistic link function employed in smirt function mod1d <- sirt::smirt(dat, Qmatrix=F.pattern, est.a=matrix(1:I,I,1), c.init=rep(.2,I)) summary(mod1d)  ############################################################################# # EXAMPLE 2: ACT15 data    | Chapter 6 McDonald (1999) ############################################################################# data(data.mcdonald.act15) pm <- data.mcdonald.act15  #************ # Model 1: 2-dimensional exploratory factor analysis mod1 <- sirt::R2noharm( pm=pm, n=1000, model.type=\"EFA\", dimensions=2,              writename=\"ACT15__efa_2dim\", noharm.path=noharm.path, dec=\",\" ) summary(mod1)  #************ # Model 2: 2-dimensional independent clusters basis solution P.pattern <- matrix(1,2,2) diag(P.pattern) <- 0 P.init <- 1+0*P.pattern F.pattern <- matrix(0,15,2) F.pattern[ c(1:5,11:15),1] <- 1 F.pattern[ c(6:10,11:15),2] <- 1 F.init <- F.pattern  # estimate model mod2 <- sirt::R2noharm( pm=pm, n=1000,  model.type=\"CFA\", F.pattern=F.pattern,             F.init=F.init, P.pattern=P.pattern,P.init=P.init,             writename=\"ACT15_indep_clusters\", noharm.path=noharm.path, dec=\",\" ) summary(mod2)  #************ # Model 3: Hierarchical model  P.pattern <- matrix(0,3,3) P.init <- P.pattern diag(P.init) <- 1 F.pattern <- matrix(0,15,3) F.pattern[,1] <- 1    # all items load on g factor F.pattern[ c(1:5,11:15),2] <- 1   # Items 1-5 and 11-15 load on first nested factor F.pattern[ c(6:10,11:15),3] <- 1  # Items 6-10 and 11-15 load on second nested factor F.init <- F.pattern  # estimate model mod3 <- sirt::R2noharm( pm=pm, n=1000,  model.type=\"CFA\", F.pattern=F.pattern,            F.init=F.init, P.pattern=P.pattern, P.init=P.init,            writename=\"ACT15_hierarch_model\", noharm.path=noharm.path, dec=\",\" ) summary(mod3)  ############################################################################# # EXAMPLE 3: Rape myth scale | Chapter 15 McDonald (1999) ############################################################################# data(data.mcdonald.rape) lambda <- data.mcdonald.rape$lambda nu <- data.mcdonald.rape$nu  # obtain multiplier for factor loadings (Formula 15.5) k <- sum( lambda[1,] * lambda[2,] ) / sum( lambda[2,]^2 )   ##   [1] 1.263243  # additive parameter (Formula 15.7) c <- sum( lambda[2,]*(nu[1,]-nu[2,]) ) / sum( lambda[2,]^2 )   ##   [1] 1.247697  # SD in the female group 1/k   ##   [1] 0.7916132  # M in the female group - c/k   ##   [1] -0.9876932  # Burt's coefficient of factorial congruence (Formula 15.10a) sum( lambda[1,] * lambda[2,] ) / sqrt( sum( lambda[1,]^2 ) * sum( lambda[2,]^2 ) )   ##   [1] 0.9727831  # congruence for mean parameters sum(  (nu[1,]-nu[2,]) * lambda[2,] ) / sqrt( sum( (nu[1,]-nu[2,])^2 ) * sum( lambda[2,]^2 ) )   ##   [1] 0.968176 }"},{"path":"/reference/data.mixed1.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset with Mixed Dichotomous and Polytomous Item Responses — data.mixed1","title":"Dataset with Mixed Dichotomous and Polytomous Item Responses — data.mixed1","text":"Dataset mixed dichotomous polytomous item responses.","code":""},{"path":"/reference/data.mixed1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset with Mixed Dichotomous and Polytomous Item Responses — data.mixed1","text":"","code":"data(data.mixed1)"},{"path":"/reference/data.mixed1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset with Mixed Dichotomous and Polytomous Item Responses — data.mixed1","text":"data frame 1000 observations following 37 variables. 'data.frame':   1000 obs.  37 variables:  $ I01: num  1 1 1 1 1 1 1 0 1 1 ...  $ I02: num  1 1 1 1 1 1 1 1 0 1 ...  [...]  $ I36: num  1 1 1 1 0 0 0 0 1 1 ...  $ I37: num  0 1 1 1 0 1 0 0 1 1 ...","code":""},{"path":"/reference/data.mixed1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dataset with Mixed Dichotomous and Polytomous Item Responses — data.mixed1","text":"","code":"data(data.mixed1) apply( data.mixed1, 2, max )   ##   I01 I02 I03 I04 I05 I06 I07 I08 I09 I10 I11 I12 I13 I14 I15 I16   ##     1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   ##   I17 I18 I19 I20 I21 I22 I23 I24 I25 I26 I27 I28 I29 I30 I31 I32   ##     1   1   1   1   4   4   1   1   1   1   1   1   1   1   1   1   ##   I33 I34 I35 I36 I37   ##     1   1   1   1   1"},{"path":"/reference/data.ml.html","id":null,"dir":"Reference","previous_headings":"","what":"Multilevel Datasets — data.ml","title":"Multilevel Datasets — data.ml","text":"Datasets conducting multilevel IRT analysis. dataset used examples function mcmc.2pno.ml.","code":""},{"path":"/reference/data.ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multilevel Datasets — data.ml","text":"","code":"data(data.ml1) data(data.ml2)"},{"path":"/reference/data.ml.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multilevel Datasets — data.ml","text":"data.ml1 data frame 2000 student observations 100 classes 17 variables.   first variable group contains class identifier.   remaining 16 variables dichotomous test items. 'data.frame':   2000 obs.  17 variables:  $ group: num  1001 1001 1001 1001 1001 ...  $ X1   : num  1 1 1 1 1 1 1 1 1 1 ...  $ X2   : num  1 1 1 0 1 1 1 1 1 1 ...  $ X3   : num  0 1 1 0 1 0 1 0 1 0 ...  $ X4   : num  1 1 1 0 0 1 1 1 1 1 ...  $ X5   : num  0 0 0 1 1 1 0 0 1 1 ... [...]  $ X16  : num  0 0 1 0 0 0 1 0 0 0 ... data.ml2 data frame 2000 student observations 100 classes 6 variables.   first variable group contains class identifier.   remaining 5 variables polytomous test items. 'data.frame':   2000 obs.  6 variables:  $ group: num  1 1 1 1 1 1 1 1 1 1 ...  $ X1   : num  2 3 4 3 3 3 1 4 4 3 ...  $ X2   : num  2 2 4 3 3 2 2 3 4 3 ...  $ X3   : num  3 4 5 4 2 3 3 4 4 2 ...  $ X4   : num  2 3 3 2 1 3 1 4 4 3 ...  $ X5   : num  2 3 3 2 3 3 1 3 2 2 ...","code":""},{"path":"/reference/data.noharm.html","id":null,"dir":"Reference","previous_headings":"","what":"Datasets for NOHARM Analysis — data.noharm","title":"Datasets for NOHARM Analysis — data.noharm","text":"Datasets analyses NOHARM (see R2noharm).","code":""},{"path":"/reference/data.noharm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Datasets for NOHARM Analysis — data.noharm","text":"","code":"data(data.noharmExC) data(data.noharm18)"},{"path":"/reference/data.noharm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Datasets for NOHARM Analysis — data.noharm","text":"data.noharmExC format dataset 'data.frame':   300 obs.  8 variables:  $ C1: int  1 1 1 1 1 0 1 1 1 1 ...  $ C2: int  1 1 1 1 0 1 1 1 1 1 ...  $ C3: int  1 1 1 1 1 0 0 0 1 1 ...  $ C4: int  0 0 1 1 1 1 1 0 1 0 ...  $ C5: int  1 1 1 1 1 0 0 1 1 0 ...  $ C6: int  1 0 0 0 1 0 1 1 0 1 ...  $ C7: int  1 1 0 0 1 1 0 0 0 1 ...  $ C8: int  1 0 1 0 1 0 1 0 1 1 ... data.noharm18 data frame 200 observations following 18 variables I01,   ..., I18. format 'data.frame':   200 obs.  18 variables:  $ I01: int  1 1 1 1 1 0 1 1 0 1 ...  $ I02: int  1 1 0 1 1 0 1 1 1 1 ...  $ I03: int  1 0 0 1 0 0 1 1 0 1 ...  $ I04: int  0 1 0 1 0 0 0 1 1 1 ...  $ I05: int  1 0 0 0 1 0 1 1 0 1 ...  $ I06: int  1 1 0 1 0 0 1 1 0 1 ...  $ I07: int  1 1 1 1 0 1 1 1 1 1 ...  $ I08: int  1 1 1 1 1 1 1 1 0 1 ...  $ I09: int  1 1 1 1 0 0 1 1 0 1 ...  $ I10: int  1 0 0 1 1 0 1 1 0 1 ...  $ I11: int  1 1 1 1 0 0 1 1 0 1 ...  $ I12: int  0 0 0 0 0 1 0 0 0 0 ...  $ I13: int  1 1 1 1 0 1 1 0 1 1 ...  $ I14: int  1 1 1 0 1 0 1 1 0 1 ...  $ I15: int  1 1 1 0 0 1 1 1 0 1 ...  $ I16: int  1 1 0 1 1 0 1 0 1 1 ...  $ I17: int  0 1 0 0 0 0 1 1 0 1 ...  $ I18: int  0 0 0 0 0 0 0 0 1 0 ...","code":""},{"path":"/reference/data.pars1.rasch.html","id":null,"dir":"Reference","previous_headings":"","what":"Item Parameters for Three Studies Obtained by 1PL and 2PL Estimation — data.pars1.rasch","title":"Item Parameters for Three Studies Obtained by 1PL and 2PL Estimation — data.pars1.rasch","text":"datasets contain item parameters prepared linking using function linking.haberman.","code":""},{"path":"/reference/data.pars1.rasch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Item Parameters for Three Studies Obtained by 1PL and 2PL Estimation — data.pars1.rasch","text":"","code":"data(data.pars1.rasch) data(data.pars1.2pl)"},{"path":"/reference/data.pars1.rasch.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Item Parameters for Three Studies Obtained by 1PL and 2PL Estimation — data.pars1.rasch","text":"format data.pars1.rasch : 'data.frame':   22 obs.  4 variables:  $ study: chr  \"study1\" \"study1\" \"study1\" \"study1\" ...  $ item : Factor w/ 12 levels \"M133\",\"M176\",..: 1 2 3 4 5 1 6 7 3 8 ...  $    : num  1 1 1 1 1 1 1 1 1 1 ...  $ b    : num  -1.5862 0.40762 1.78031 2.00382 0.00862 ... Item slopes fixed 1 1PL estimation. Item difficulties denoted b. format data.pars1.2pl : 'data.frame':   22 obs.  4 variables:  $ study: chr  \"study1\" \"study1\" \"study1\" \"study1\" ...  $ item : Factor w/ 12 levels \"M133\",\"M176\",..: 1 2 3 4 5 1 6 7 3 8 ...  $    : num  1.238 0.957 1.83 1.927 2.298 ...  $ b    : num  -1.16607 0.35844 1.06571 1.17159 0.00792 ...","code":""},{"path":"/reference/data.pirlsmissing.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset from PIRLS Study with Missing Responses — data.pirlsmissing","title":"Dataset from PIRLS Study with Missing Responses — data.pirlsmissing","text":"dataset PIRLS 2011 study 4th graders reading booklet 13 ('PIRLS reader') 4 countries (Austria, Germany, France, Netherlands). Missing responses (missing intention reached) coded 9.","code":""},{"path":"/reference/data.pirlsmissing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset from PIRLS Study with Missing Responses — data.pirlsmissing","text":"","code":"data(data.pirlsmissing)"},{"path":"/reference/data.pirlsmissing.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset from PIRLS Study with Missing Responses — data.pirlsmissing","text":"data frame 3480 observations following 38 variables. format : 'data.frame':   3480 obs.  38 variables:  $ idstud  : int  1000001 1000002 1000003 1000004 1000005 ...  $ country : Factor w/ 4 levels \"AUT\",\"DEU\",\"FRA\",..: 1 1 1 1 1 1 1 1 1 1 ...  $ studwgt : num  1.06 1.06 1.06 1.06 1.06 ...  $ R31G01M : int  1 1 1 1 1 1 0 1 1 0 ...  $ R31G02C : int  0 9 0 1 0 0 0 0 1 0 ...  $ R31G03M : int  1 1 1 1 0 1 0 0 1 1 ...  [...]  $ R31P15C : int  1 9 0 1 0 0 0 0 1 0 ...  $ R31P16C : int  0 0 0 0 0 0 0 9 0 1 ...","code":""},{"path":"/reference/data.pirlsmissing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dataset from PIRLS Study with Missing Responses — data.pirlsmissing","text":"","code":"data(data.pirlsmissing) # inspect missing rates round( colMeans( data.pirlsmissing==9 ), 3 )   ##    idstud  country  studwgt  R31G01M  R31G02C  R31G03M  R31G04C  R31G05M   ##     0.000    0.000    0.000    0.009    0.076    0.012    0.203    0.018   ##   R31G06M  R31G07M R31G08CZ R31G08CA R31G08CB  R31G09M  R31G10C  R31G11M   ##     0.010    0.020    0.189    0.225    0.252    0.019    0.126    0.023   ##   R31G12C R31G13CZ R31G13CA R31G13CB R31G13CC  R31G14M  R31P01M  R31P02C   ##     0.202    0.170    0.198    0.220    0.223    0.074    0.013    0.039   ##   R31P03C  R31P04M  R31P05C  R31P06C  R31P07C  R31P08M  R31P09C  R31P10M   ##     0.056    0.012    0.075    0.043    0.074    0.024    0.062    0.025   ##   R31P11M  R31P12M  R31P13M  R31P14C  R31P15C  R31P16C   ##     0.027    0.030    0.030    0.126    0.130    0.127"},{"path":"/reference/data.pisaMath.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset PISA Mathematics — data.pisaMath","title":"Dataset PISA Mathematics — data.pisaMath","text":"example PISA dataset reading items PISA 2009 study students Austria. dataset contains 565 students worked 11 mathematics items item cluster M3.","code":""},{"path":"/reference/data.pisaMath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset PISA Mathematics — data.pisaMath","text":"","code":"data(data.pisaMath)"},{"path":"/reference/data.pisaMath.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset PISA Mathematics — data.pisaMath","text":"dataset list. list element data contains dataset demographical variables student ID (idstud), school ID (idschool), dummy variable female students (female), socioeconomic status (hisei) migration background (migra). remaining variables (starting M name) mathematics items.  item metadata included list element item contains item name (item) testlet label (testlet). item included testlet indicated NA. format : List 2  $ data:'data.frame':   ..$ idstud  : num [1:565] 9e+10 9e+10 9e+10 9e+10 9e+10 ...   ..$ idschool: int [1:565] 900015 900015 900015 900015  ...   ..$ female  : int [1:565] 0 0 0 0 0 0 0 0 0 0 ...   ..$ hisei   : num [1:565] -1.16 -1.099 -1.588 -0.365 -1.588 ...   ..$ migra   : int [1:565] 0 0 0 0 0 0 0 0 0 1 ...   ..$ M192Q01 : int [1:565] 1 0 1 1 1 1 1 0 0 0 ...   ..$ M406Q01 : int [1:565] 1 1 1 0 1 0 0 0 1 0 ...   ..$ M406Q02 : int [1:565] 1 0 0 0 1 0 0 0 1 0 ...   ..$ M423Q01 : int [1:565] 0 1 0 1 1 1 1 1 1 0 ...   ..$ M496Q01 : int [1:565] 1 0 0 0 0 0 0 0 1 0 ...   ..$ M496Q02 : int [1:565] 1 0 0 1 0 1 0 1 1 0 ...   ..$ M564Q01 : int [1:565] 1 1 1 1 1 1 0 0 1 0 ...   ..$ M564Q02 : int [1:565] 1 0 1 1 1 0 0 0 0 0 ...   ..$ M571Q01 : int [1:565] 1 0 0 0 1 0 0 0 0 0 ...   ..$ M603Q01 : int [1:565] 1 0 0 0 1 0 0 0 0 0 ...   ..$ M603Q02 : int [1:565] 1 0 0 0 1 0 0 0 1 0 ...  $ item:'data.frame':   ..$ item   : Factor w/ 11 levels \"M192Q01\",\"M406Q01\",..: 1 2 3 4  ...   ..$ testlet: chr [1:11] NA \"M406\" \"M406\" NA ...","code":""},{"path":"/reference/data.pisaPars.html","id":null,"dir":"Reference","previous_headings":"","what":"Item Parameters from Two PISA Studies — data.pisaPars","title":"Item Parameters from Two PISA Studies — data.pisaPars","text":"data frame contains item parameters two PISA studies. Rasch model used, item difficulties considered.","code":""},{"path":"/reference/data.pisaPars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Item Parameters from Two PISA Studies — data.pisaPars","text":"","code":"data(data.pisaPars)"},{"path":"/reference/data.pisaPars.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Item Parameters from Two PISA Studies — data.pisaPars","text":"data frame 25 observations following 4 variables. item Item names testlet Items arranged corresponding testlets.         names located column. study1 Item difficulties study 1 study2 Item difficulties study 2","code":""},{"path":"/reference/data.pisaRead.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset PISA Reading — data.pisaRead","title":"Dataset PISA Reading — data.pisaRead","text":"example PISA dataset reading items PISA 2009 study students Austria. dataset contains 623 students worked 12 reading items item cluster R7.","code":""},{"path":"/reference/data.pisaRead.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset PISA Reading — data.pisaRead","text":"","code":"data(data.pisaRead)"},{"path":"/reference/data.pisaRead.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset PISA Reading — data.pisaRead","text":"dataset list. list element data contains dataset demographical variables student ID (idstud), school ID (idschool), dummy variable female students (female), socioeconomic status (hisei) migration background (migra). remaining variables (starting R name) reading items.  item metadata included list element item contains item name (item), testlet label (testlet), item format (ItemFormat), text type (TextType) text aspect (Aspect). format : List 2  $ data:'data.frame':   ..$ idstud  : num [1:623] 9e+10 9e+10 9e+10 9e+10 9e+10 ...   ..$ idschool: int [1:623] 900003 900003 900003 900003 ...   ..$ female  : int [1:623] 1 0 1 0 0 0 1 0 1 0 ...   ..$ hisei   : num [1:623] -1.16 -0.671 1.286 0.185 1.225 ...   ..$ migra   : int [1:623] 0 0 0 0 0 0 0 0 0 0 ...   ..$ R432Q01 : int [1:623] 1 1 1 1 1 1 1 1 1 1 ...   ..$ R432Q05 : int [1:623] 1 1 1 1 1 0 1 1 1 0 ...   ..$ R432Q06 : int [1:623] 0 0 0 0 0 0 0 0 0 0 ...   ..$ R456Q01 : int [1:623] 1 1 1 1 1 1 1 1 1 1 ...   ..$ R456Q02 : int [1:623] 1 1 1 1 1 1 1 1 1 1 ...   ..$ R456Q06 : int [1:623] 1 1 1 1 1 1 0 0 1 1 ...   ..$ R460Q01 : int [1:623] 1 1 0 0 0 0 0 1 1 1 ...   ..$ R460Q05 : int [1:623] 1 1 1 1 1 1 1 1 1 1 ...   ..$ R460Q06 : int [1:623] 0 1 1 1 1 1 0 0 1 1 ...   ..$ R466Q02 : int [1:623] 0 1 0 1 1 0 1 0 0 1 ...   ..$ R466Q03 : int [1:623] 0 0 0 1 0 0 0 1 0 1 ...   ..$ R466Q06 : int [1:623] 0 1 1 1 1 1 0 1 1 1 ...  $ item:'data.frame':   ..$ item      : Factor w/ 12 levels \"R432Q01\",\"R432Q05\",..: 1 2 3 4  ...   ..$ testlet   : Factor w/ 4 levels \"R432\",\"R456\",..: 1 1 1 2  ...   ..$ ItemFormat: Factor w/ 2 levels \"CR\",\"MC\": 1 1 2 2 1 1 1 2 2 1 ...   ..$ TextType  : Factor w/ 3 levels \"Argumentation\",..: 1 1 1 3  ...   ..$ Aspect    : Factor w/ 3 levels \"Access_and_retrieve\",..: 2 3 2 1 ...","code":""},{"path":"/reference/data.pw01.html","id":null,"dir":"Reference","previous_headings":"","what":"Datasets for Pairwise Comparisons — data.pw","title":"Datasets for Pairwise Comparisons — data.pw","text":"datasets pairwise comparisons.","code":""},{"path":"/reference/data.pw01.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Datasets for Pairwise Comparisons — data.pw","text":"","code":"data(data.pw01)"},{"path":"/reference/data.pw01.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Datasets for Pairwise Comparisons — data.pw","text":"dataset data.pw01 contains results German football league season 2000/01.","code":""},{"path":"/reference/data.ratings1.html","id":null,"dir":"Reference","previous_headings":"","what":"Rating Datasets — data.ratings","title":"Rating Datasets — data.ratings","text":"rating datasets.","code":""},{"path":"/reference/data.ratings1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rating Datasets — data.ratings","text":"","code":"data(data.ratings1) data(data.ratings2) data(data.ratings3)"},{"path":"/reference/data.ratings1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Rating Datasets — data.ratings","text":"Dataset data.ratings1: Data frame 274 observations containing 5 criteria (k1, ..., k5), 135 students 7 raters. 'data.frame':   274 obs.  7 variables:  $ idstud: int  100020106 100020106 100070101 100070101 100100109  ...  $ rater : Factor w/ 16 levels \"db01\",\"db02\",..: 3 15 5 10 2 1 5 4 1 5 ...  $ k1    : int  1 1 0 1 2 0 1 3 0 0 ...  $ k2    : int  1 1 1 1 1 0 0 3 0 0 ...  $ k3    : int  1 1 1 1 2 0 0 3 1 0 ...  $ k4    : int  1 1 1 2 1 0 0 2 0 1 ...  $ k5    : int  2 2 1 2 0 1 0 3 1 0 ... Data 2009 Austrian survey national educational standards 8th graders German language writing. Variables k1 k5 denote several rating criteria writing competency. Dataset data.ratings2: Data frame 615 observations containing 5 criteria (k1, ..., k5), 178 students 16 raters. 'data.frame':   615 obs.  7 variables:  $ idstud: num  1001 1001 1002 1002 1003 ...  $ rater : chr  \"R03\" \"R15\" \"R05\" \"R10\" ...  $ k1    : int  1 1 0 1 2 0 1 3 3 0 ...  $ k2    : int  1 1 1 1 1 0 0 3 3 0 ...  $ k3    : int  1 1 1 1 2 0 0 3 3 1 ...  $ k4    : int  1 1 1 2 1 0 0 2 2 0 ...  $ k5    : int  2 2 1 2 0 1 0 3 2 1 ... Dataset data.ratings3: Data frame 3169 observations containing 4 criteria (crit2, ..., crit6), 561 students 52 raters. 'data.frame':   3169 obs.  6 variables:  $ idstud: num  10001 10001 10002 10002 10003 ...  $ rater : num  840 838 842 808 830 845 813 849 809 802 ...  $ crit2 : int  1 3 3 1 2 2 2 2 3 3 ...  $ crit3 : int  2 2 2 2 2 2 2 2 3 3 ...  $ crit4 : int  1 2 2 2 1 1 1 2 2 2 ...  $ crit6 : num  4 4 4 3 4 4 4 4 4 4 ...","code":""},{"path":"/reference/data.raw1.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset with Raw Item Responses — data.raw1","title":"Dataset with Raw Item Responses — data.raw1","text":"Dataset raw item responses","code":""},{"path":"/reference/data.raw1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset with Raw Item Responses — data.raw1","text":"","code":"data(data.raw1)"},{"path":"/reference/data.raw1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset with Raw Item Responses — data.raw1","text":"data frame raw item responses 1200 persons following 77 items: 'data.frame':   1200 obs.  77 variables:  $ I101: num  0 0 0 2 0 0 0 0 0 0 ...  $ I102: int  NA NA 2 1 2 1 3 2 NA NA ...  $ I103: int  1 1 NA NA NA NA NA NA 1 1 ...  ...  $ I179: chr  \"E\" \"C\" \"D\" \"E\" ...","code":""},{"path":"/reference/data.read.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset Reading — data.read","title":"Dataset Reading — data.read","text":"dataset contains \\(N=328\\) students \\(=12\\) items measuring reading competence. 12 items arranged 3 testlets (items common text stimulus) labeled , B C. allocation items testlets indicated variable names.","code":""},{"path":"/reference/data.read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset Reading — data.read","text":"","code":"data(data.read)"},{"path":"/reference/data.read.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset Reading — data.read","text":"data frame 328 persons following 12 variables.   Rows correspond persons columns items. following items   included data.read: Testlet : A1, A2, A3, A4 Testlet B: B1, B2, B3, B4 Testlet C: C1, C2, C3, C4","code":""},{"path":[]},{"path":"/reference/data.reck.html","id":null,"dir":"Reference","previous_headings":"","what":"Datasets from Reckase' Book Multidimensional Item Response Theory — data.reck","title":"Datasets from Reckase' Book Multidimensional Item Response Theory — data.reck","text":"simulated datasets Reckase (2009).","code":""},{"path":"/reference/data.reck.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Datasets from Reckase' Book Multidimensional Item Response Theory — data.reck","text":"","code":"data(data.reck21) data(data.reck61DAT1) data(data.reck61DAT2) data(data.reck73C1a) data(data.reck73C1b) data(data.reck75C2) data(data.reck78ExA) data(data.reck79ExB)"},{"path":"/reference/data.reck.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Datasets from Reckase' Book Multidimensional Item Response Theory — data.reck","text":"format data.reck21 (Table 2.1, p. 45) : List 2  $ data: num [1:2500, 1:50] 0 0 0 1 1 0 0 0 1 0 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:50] \"I0001\" \"I0002\" \"I0003\" \"I0004\" ...  $ pars:'data.frame':   ..$ : num [1:50] 1.83 1.38 1.47 1.53 0.88 0.82 1.02 1.19 1.15 0.18 ...   ..$ b: num [1:50] 0.91 0.81 0.06 -0.8 0.24 0.99 1.23 -0.47 2.78 -3.85 ...   ..$ c: num [1:50] 0 0 0 0.25 0.21 0.29 0.26 0.19 0 0.21 ... format datasets data.reck61DAT1 data.reck61DAT2 (Table 6.1, p. 153) List 4  $ data : num [1:2500, 1:30] 1 0 0 1 1 0 0 1 1 0 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:30] \"A01\" \"A02\" \"A03\" \"A04\" ...  $ pars :'data.frame':   ..$ a1: num [1:30] 0.747 0.46 0.861 1.014 0.552 ...   ..$ a2: num [1:30] 0.025 0.0097 0.0067 0.008 0.0204 0.0064 0.0861 ...   ..$ a3: num [1:30] 0.1428 0.0692 0.404 0.047 0.1482 ...   ..$ d : num [1:30] 0.183 -0.192 -0.466 -0.434 -0.443 ...  $ mu   : num [1:3] -0.4 -0.7 0.1  $ sigma: num [1:3, 1:3] 1.21 0.297 1.232 0.297 0.81 ... dataset data.reck61DAT2 correlated dimensions data.reck61DAT1 uncorrelated dimensions. Datasets data.reck73C1a data.reck73C1b use item parameters Table 7.3 (p. 188). dataset C1a uncorrelated dimensions, C1b perfectly correlated dimensions. items sensitive 3 dimensions. format datasets List 4  $ data : num [1:2500, 1:30] 1 0 1 1 1 0 1 1 1 1 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:30] \"A01\" \"A02\" \"A03\" \"A04\" ...  $ pars :'data.frame':  30 obs.  4 variables:   ..$ a1: num [1:30] 0.747 0.46 0.861 1.014 0.552 ...   ..$ a2: num [1:30] 0.025 0.0097 0.0067 0.008 0.0204 0.0064 ...   ..$ a3: num [1:30] 0.1428 0.0692 0.404 0.047 0.1482 ...   ..$ d : num [1:30] 0.183 -0.192 -0.466 -0.434 -0.443 ...  $ mu   : num [1:3] 0 0 0  $ sigma: num [1:3, 1:3] 0.167 0.236 0.289 0.236 0.334 ... dataset data.reck75C2 simulated using item parameters Table 7.5 (p. 191). contains items sensitive one dimension individuals abilities three uncorrelated dimensions. format List 4  $ data : num [1:2500, 1:30] 0 0 1 1 1 0 0 1 1 1 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:30] \"A01\" \"A02\" \"A03\" \"A04\" ...  $ pars :'data.frame':  30 obs.  4 variables:   ..$ a1: num [1:30] 0.56 0.48 0.67 0.57 0.54 0.74 0.7 0.59 0.63 0.64 ...   ..$ a2: num [1:30] 0.62 0.53 0.63 0.69 0.58 0.69 0.75 0.63 0.64 0.64 ...   ..$ a3: num [1:30] 0.46 0.42 0.43 0.51 0.41 0.48 0.46 0.5 0.51 0.46 ...   ..$ d : num [1:30] 0.1 0.06 -0.38 0.46 0.14 0.31 0.06 -1.23 0.47 1.06 ...  $ mu   : num [1:3] 0 0 0  $ sigma: num [1:3, 1:3] 1 0 0 0 1 0 0 0 1 dataset data.reck78ExA contains simulated item responses Table 7.8 (p. 204 ff.). three item clusters two ability dimensions. format List 4  $ data : num [1:2500, 1:50] 0 1 1 0 1 0 0 0 0 0 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:50] \"A01\" \"A02\" \"A03\" \"A04\" ...  $ pars :'data.frame':  50 obs.  3 variables:   ..$ a1: num [1:50] 0.889 1.057 1.047 1.178 1.029 ...   ..$ a2: num [1:50] 0.1399 0.0432 0.016 0.0231 0.2347 ...   ..$ d : num [1:50] 0.2724 1.2335 -0.0918 -0.2372 0.8471 ...  $ mu   : num [1:2] 0 0  $ sigma: num [1:2, 1:2] 1 0 0 1 dataset data.reck79ExB contains simulated item responses Table 7.9 (p. 207 ff.). three item clusters three ability dimensions. format List 4  $ data : num [1:2500, 1:50] 1 1 0 1 0 0 0 1 1 0 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:50] \"A01\" \"A02\" \"A03\" \"A04\" ...  $ pars :'data.frame':  50 obs.  4 variables:   ..$ a1: num [1:50] 0.895 1.032 1.036 1.163 1.022 ...   ..$ a2: num [1:50] 0.052 0.132 0.144 0.13 0.165 ...   ..$ a3: num [1:50] 0.0722 0.1923 0.0482 0.1321 0.204 ...   ..$ d : num [1:50] 0.2724 1.2335 -0.0918 -0.2372 0.8471 ...  $ mu   : num [1:3] 0 0 0  $ sigma: num [1:3, 1:3] 1 0 0 0 1 0 0 0 1","code":""},{"path":"/reference/data.reck.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Datasets from Reckase' Book Multidimensional Item Response Theory — data.reck","text":"Simulated datasets","code":""},{"path":"/reference/data.reck.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Datasets from Reckase' Book Multidimensional Item Response Theory — data.reck","text":"Reckase, M. (2009). Multidimensional item response theory. New York: Springer. doi:10.1007/978-0-387-89976-3","code":""},{"path":"/reference/data.reck.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Datasets from Reckase' Book Multidimensional Item Response Theory — data.reck","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: data.reck21 dataset, Table 2.1, p. 45 ############################################################################# data(data.reck21)  dat <- data.reck21$dat      # extract dataset  # items with zero guessing parameters guess0 <- c( 1, 2, 3, 9,11,27,30,35,45,49,50 ) I <- ncol(dat)  #*** # Model 1: 3PL estimation using rasch.mml2 est.c <- est.a <- 1:I est.c[ guess0 ] <- 0 mod1 <- sirt::rasch.mml2( dat, est.a=est.a, est.c=est.c, mmliter=300 ) summary(mod1)  #*** # Model 2: 3PL estimation using smirt Q <- matrix(1,I,1) mod2 <- sirt::smirt( dat, Qmatrix=Q, est.a=\"2PL\", est.c=est.c, increment.factor=1.01) summary(mod2)  #*** # Model 3: estimation in mirt package library(mirt) itemtype <- rep(\"3PL\", I ) itemtype[ guess0 ] <- \"2PL\" mod3 <- mirt::mirt(dat, 1, itemtype=itemtype, verbose=TRUE) summary(mod3)  c3 <- unlist( coef(mod3) )[ 1:(4*I) ] c3 <- matrix( c3, I, 4, byrow=TRUE ) # compare estimates of rasch.mml2, smirt and true parameters round( cbind( mod1$item$c, mod2$item$c,c3[,3],data.reck21$pars$c ), 2 ) round( cbind( mod1$item$a, mod2$item$a.Dim1,c3[,1], data.reck21$pars$a ), 2 ) round( cbind( mod1$item$b, mod2$item$b.Dim1 / mod2$item$a.Dim1, - c3[,2] / c3[,1],             data.reck21$pars$b ), 2 )  ############################################################################# # EXAMPLE 2: data.reck61 dataset, Table 6.1, p. 153 #############################################################################  data(data.reck61DAT1) dat <- data.reck61DAT1$data  #*** # Model 1: Exploratory factor analysis  #-- Model 1a: tam.fa in TAM library(TAM) mod1a <- TAM::tam.fa( dat, irtmodel=\"efa\", nfactors=3 ) # varimax rotation varimax(mod1a$B.stand)  # Model 1b: EFA in NOHARM (Promax rotation) mod1b <- sirt::R2noharm( dat=dat, model.type=\"EFA\",  dimensions=3,               writename=\"reck61__3dim_efa\", noharm.path=\"c:/NOHARM\",dec=\",\") summary(mod1b)  # Model 1c: EFA with noharm.sirt mod1c <- sirt::noharm.sirt( dat=dat, dimensions=3  ) summary(mod1c) plot(mod1c)  # Model 1d: EFA with 2 dimensions in noharm.sirt mod1d <- sirt::noharm.sirt( dat=dat, dimensions=2  ) summary(mod1d) plot(mod1d, efa.load.min=.2)   # plot loadings of at least .20  #*** # Model 2: Confirmatory factor analysis  #-- Model 2a: tam.fa in TAM dims <- c( rep(1,10), rep(3,10), rep(2,10)  ) Qmatrix <- matrix( 0, nrow=30, ncol=3 ) Qmatrix[ cbind( 1:30, dims) ] <- 1 mod2a <- TAM::tam.mml.2pl( dat,Q=Qmatrix,             control=list( snodes=1000, QMC=TRUE, maxiter=200) ) summary(mod2a)  #-- Model 2b: smirt in sirt mod2b <- sirt::smirt( dat,Qmatrix=Qmatrix, est.a=\"2PL\", maxiter=20, qmcnodes=1000 ) summary(mod2b)  #-- Model 2c: rasch.mml2 in sirt mod2c <- sirt::rasch.mml2( dat,Qmatrix=Qmatrix, est.a=1:30,                 mmliter=200, theta.k=seq(-5,5,len=11) ) summary(mod2c)  #-- Model 2d: mirt in mirt cmodel <- mirt::mirt.model(\"      F1=1-10      F2=21-30      F3=11-20      COV=F1*F2, F1*F3, F2*F3 \" ) mod2d <- mirt::mirt(dat, cmodel, verbose=TRUE) summary(mod2d) coef(mod2d)  #-- Model 2e: CFA in NOHARM # specify covariance pattern P.pattern <- matrix( 1, ncol=3, nrow=3 ) P.init <- .4*P.pattern diag(P.pattern) <- 0 diag(P.init) <- 1 # fix all entries in the loading matrix to 1 F.pattern <- matrix( 0, nrow=30, ncol=3 ) F.pattern[1:10,1] <- 1 F.pattern[21:30,2] <- 1 F.pattern[11:20,3] <- 1 F.init <- F.pattern # estimate model mod2e <- sirt::R2noharm( dat=dat, model.type=\"CFA\", P.pattern=P.pattern,             P.init=P.init, F.pattern=F.pattern, F.init=F.init,             writename=\"reck61__3dim_cfa\", noharm.path=\"c:/NOHARM\",dec=\",\") summary(mod2e)  #-- Model 2f: CFA with noharm.sirt mod2f <- sirt::noharm.sirt( dat=dat, Fval=F.init, Fpatt=F.pattern,                  Pval=P.init, Ppatt=P.pattern ) summary(mod2f)  ############################################################################# # EXAMPLE 3: DETECT analysis data.reck78ExA and data.reck79ExB #############################################################################  data(data.reck78ExA) data(data.reck79ExB)  #************************ # Example A dat <- data.reck78ExA$data #- estimate person score score <- stats::qnorm( ( rowMeans( dat )+.5 )  / ( ncol(dat) + 1 ) ) #- extract item cluster itemcluster <- substring( colnames(dat), 1, 1 ) #- confirmatory DETECT Item cluster detectA <- sirt::conf.detect( data=dat, score=score, itemcluster=itemcluster )   ##          unweighted weighted   ##   DETECT      0.571    0.571   ##   ASSI        0.523    0.523   ##   RATIO       0.757    0.757  #- exploratory DETECT analysis detect_explA <- sirt::expl.detect(data=dat, score, nclusters=10, N.est=nrow(dat)/2  )   ##  Optimal Cluster Size is  5  (Maximum of DETECT Index)   ##     N.Cluster N.items N.est N.val         size.cluster DETECT.est ASSI.est   ##   1         2      50  1250  1250                31-19      0.531    0.404   ##   2         3      50  1250  1250             10-19-21      0.554    0.407   ##   3         4      50  1250  1250           10-19-14-7      0.630    0.509   ##   4         5      50  1250  1250         10-19-3-7-11      0.653    0.546   ##   5         6      50  1250  1250       10-12-7-3-7-11      0.593    0.458   ##   6         7      50  1250  1250      10-12-7-3-7-9-2      0.604    0.474   ##   7         8      50  1250  1250    10-12-7-3-3-9-4-2      0.608    0.481   ##   8         9      50  1250  1250  10-12-7-3-3-5-4-2-4      0.617    0.494   ##   9        10      50  1250  1250 10-5-7-7-3-3-5-4-2-4      0.592    0.460  # cluster membership cluster_membership <- detect_explA$itemcluster$cluster3 # Cluster 1: colnames(dat)[ cluster_membership==1 ]   ##   [1] \"A01\" \"A02\" \"A03\" \"A04\" \"A05\" \"A06\" \"A07\" \"A08\" \"A09\" \"A10\" # Cluster 2: colnames(dat)[ cluster_membership==2 ]   ##    [1] \"B11\" \"B12\" \"B13\" \"B14\" \"B15\" \"B16\" \"B17\" \"B18\" \"B19\" \"B20\" \"B21\" \"B22\"   ##   [13] \"B23\" \"B25\" \"B26\" \"B27\" \"B28\" \"B29\" \"B30\" # Cluster 3: colnames(dat)[ cluster_membership==3 ]   ##    [1] \"B24\" \"C31\" \"C32\" \"C33\" \"C34\" \"C35\" \"C36\" \"C37\" \"C38\" \"C39\" \"C40\" \"C41\"   ##   [13] \"C42\" \"C43\" \"C44\" \"C45\" \"C46\" \"C47\" \"C48\" \"C49\" \"C50\"  #************************ # Example B dat <- data.reck79ExB$data #- estimate person score score <- stats::qnorm( ( rowMeans( dat )+.5 )  / ( ncol(dat) + 1 ) ) #- extract item cluster itemcluster <- substring( colnames(dat), 1, 1 ) #- confirmatory DETECT Item cluster detectB <- sirt::conf.detect( data=dat, score=score, itemcluster=itemcluster )   ##          unweighted weighted   ##   DETECT      0.715    0.715   ##   ASSI        0.624    0.624   ##   RATIO       0.855    0.855  #- exploratory DETECT analysis detect_explB <- sirt::expl.detect(data=dat, score, nclusters=10, N.est=nrow(dat)/2  )   ##   Optimal Cluster Size is  4  (Maximum of DETECT Index)   ##   ##     N.Cluster N.items N.est N.val         size.cluster DETECT.est ASSI.est   ##   1         2      50  1250  1250                30-20      0.665    0.546   ##   2         3      50  1250  1250             10-20-20      0.686    0.585   ##   3         4      50  1250  1250           10-20-8-12      0.728    0.644   ##   4         5      50  1250  1250         10-6-14-8-12      0.654    0.553   ##   5         6      50  1250  1250       10-6-14-3-12-5      0.659    0.561   ##   6         7      50  1250  1250      10-6-14-3-7-5-5      0.664    0.576   ##   7         8      50  1250  1250     10-6-7-7-3-7-5-5      0.616    0.518   ##   8         9      50  1250  1250   10-6-7-7-3-5-5-5-2      0.612    0.512   ##   9        10      50  1250  1250 10-6-7-7-3-5-3-5-2-2      0.613    0.512 }"},{"path":"/reference/data.si.html","id":null,"dir":"Reference","previous_headings":"","what":"Some Example Datasets for the sirt Package — data.sirt","title":"Some Example Datasets for the sirt Package — data.sirt","text":"example datasets sirt package.","code":""},{"path":"/reference/data.si.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Some Example Datasets for the sirt Package — data.sirt","text":"","code":"data(data.si01) data(data.si02) data(data.si03) data(data.si04) data(data.si05) data(data.si06) data(data.si07) data(data.si08) data(data.si09) data(data.si10)"},{"path":"/reference/data.si.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Some Example Datasets for the sirt Package — data.sirt","text":"format dataset data.si01 : 'data.frame':   1857 obs.  3 variables:  $ idgroup: int  1 1 1 1 1 1 1 1 1 1 ...  $ item1  : int  NA NA NA NA NA NA NA NA NA NA ...  $ item2  : int  4 4 4 4 4 4 4 2 4 4 ... dataset data.si02 Stouffer-Toby-dataset published Lindsay, Clogg Grego (1991; Table 1, p.97, Cross-classification ): List 2  $ data   : num [1:16, 1:4] 1 0 1 0 1 0 1 0 1 0 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:4] \"I1\" \"I2\" \"I3\" \"I4\"  $ weights: num [1:16] 42 1 6 2 6 1 7 2 23 4 ... format dataset data.si03 (containing item parameters two studies) : 'data.frame':   27 obs.  3 variables:  $ item    : Factor w/ 27 levels \"M1\",\"M10\",\"M11\",..: 1 12 21 22 ...  $ b_study1: num  0.297 1.163 0.151 -0.855 -1.653 ...  $ b_study2: num  0.72 1.118 0.351 -0.861 -1.593 ... dataset data.si04 adapted Bartolucci, Montanari Pandolfi (2012; Table 4, Table 7). data contains 4999 persons, 79 items 5 dimensions. See rasch.mirtlc using data analysis. List 3  $ data        : num [1:4999, 1:79] 0 1 1 0 1 1 0 0 1 1 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:79] \"A01\" \"A02\" \"A03\" \"A04\" ...  $ itempars    :'data.frame':   79 obs.  4 variables:   ..$ item      : Factor w/ 79 levels \"A01\",\"A02\",\"A03\",..: 1 2 3 4 5 6 7 8 9 10 ...   ..$ dim       : num [1:79] 1 1 1 1 1 1 1 1 1 1 ...   ..$ gamma     : num [1:79] 1 1 1 1 1 1 1 1 1 1 ...   ..$ gamma.beta: num [1:79] -0.189 0.25 0.758 1.695 1.022 ...  $ distribution: num [1:9, 1:7] 1 2 3 4 5 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:7] \"class\" \"\" \"B\" \"C\" ... dataset data.si05 contains double ratings two exchangeable raters three items Ex1, Ex2 Ex3, respectively. List 3  $ Ex1:'data.frame':    199 obs.  2 variables:   ..$ C7040: num [1:199] NA 1 0 1 1 0 0 0 1 0 ...   ..$ C7041: num [1:199] 1 1 0 0 0 0 0 0 1 0 ...  $ Ex2:'data.frame':    2000 obs.  2 variables:   ..$ rater1: num [1:2000] 2 0 3 1 2 2 0 0 0 0 ...   ..$ rater2: num [1:2000] 4 1 3 2 1 0 0 0 0 2 ...  $ Ex3:'data.frame':    2000 obs.  2 variables:   ..$ rater1: num [1:2000] 5 1 6 2 3 3 0 0 0 0 ...   ..$ rater2: num [1:2000] 7 2 6 3 2 1 0 1 0 3 ... dataset data.si06 contains multiple choice item responses. correct alternative denoted 0, distractors indicated codes 1, 2 3. 'data.frame':   4441 obs.  14 variables:  $ WV01: num  0 0 0 0 0 0 0 0 0 3 ...  $ WV02: num  0 0 0 3 0 0 0 0 0 1 ...  $ WV03: num  0 1 0 0 0 0 0 0 0 0 ...  $ WV04: num  0 0 0 0 0 0 0 0 0 1 ...  $ WV05: num  3 1 1 1 0 0 1 1 0 2 ...  $ WV06: num  0 1 3 0 0 0 2 0 0 1 ...  $ WV07: num  0 0 0 0 0 0 0 0 0 0 ...  $ WV08: num  0 1 1 0 0 0 0 0 0 0 ...  $ WV09: num  0 0 0 0 0 0 0 0 0 2 ...  $ WV10: num  1 1 3 0 0 2 0 0 0 0 ...  $ WV11: num  0 0 0 0 0 0 0 0 0 0 ...  $ WV12: num  0 0 0 2 0 0 2 0 0 0 ...  $ WV13: num  3 1 1 3 0 0 3 0 0 0 ...  $ WV14: num  3 1 2 3 0 3 1 3 3 0 ... dataset data.si07 contains parameters empirical illustration DeCarlo (2020). simulation function sim_fun can used simulating data IRSDT model (see DeCarlo, 2020) List 3  $ pars   :'data.frame':        16 obs.  3 variables:   ..$ item: Factor w/ 16 levels \"I01\",\"I02\",\"I03\",..: 1 2 3 4 5 6 7 8 9 10 ...   ..$ b   : num [1:16] -1.1 -0.18 1.44 1.78 -1.19 0.45 -1.12 0.33 0.82 -0.43 ...   ..$ d   : num [1:16] 2.69 4.6 6.1 3.11 3.2 ...  $ trait  :'data.frame':        20 obs.  2 variables:   ..$ x   : num [1:20] 0.025 0.075 0.125 0.175 0.225 0.275 0.325 0.375 0.425 0.475 ...   ..$ prob: num [1:20] 0.0238 0.1267 0.105 0.0594 0.0548 ...  $ sim_fun:function (lambda, b, d, items) dataset data.si08 contains 5 items respect knowledge lung cancer kind information acquisition (Goodman, 1970; see also Rasch, Kubinger & Yanagida, 2011). L1: reading newspapers, L2: listening radio, L3: reading books magazines, L4: attending talks, L5: knowledge lung cancer 'data.frame':   32 obs.  6 variables:  $ L1 : num  1 1 1 1 1 1 1 1 1 1 ...  $ L2 : num  1 1 1 1 1 1 1 1 0 0 ...  $ L3 : num  1 1 1 1 0 0 0 0 1 1 ...  $ L4 : num  1 1 0 0 1 1 0 0 1 1 ...  $ L5 : num  1 0 1 0 1 0 1 0 1 0 ...  $ wgt: num  23 8 102 67 8 4 35 59 27 18 ... dataset data.si09 used Fischer Karl (2019) asked employees eight countries, report whether typically help employees (helping behavior, seven items, help) whether make suggestions improve work conditions products (voice behavior, five items, voice). Individuals responded items 1-7 Likert-type scale. dataset downloaded https://osf.io/wkx8c/. 'data.frame':   5201 obs.  13 variables:  $ country: Factor w/ 8 levels \"BRA\",\"CAN\",\"KEN\",..: 5 5 5 5 5 5 5 5 5 5 ...  $ help1  : int  6 6 5 5 5 6 6 6 4 6 ...  $ help2  : int  3 6 5 6 6 6 6 6 6 7 ...  $ help3  : int  5 6 6 7 7 6 5 6 6 7 ...  $ help4  : int  7 6 5 6 6 7 7 6 6 7 ...  $ help5  : int  5 5 5 6 6 6 6 6 6 7 ...  $ help6  : int  3 4 5 6 6 7 7 6 6 5 ...  $ help7  : int  5 4 4 5 5 7 7 6 6 6 ...  $ voice1 : int  3 6 5 6 4 7 6 6 5 7 ...  $ voice2 : int  3 6 4 7 6 5 6 6 4 7 ...  $ voice3 : int  6 6 5 7 6 5 6 6 6 5 ...  $ voice4 : int  6 6 6 5 5 7 5 6 6 6 ...  $ voice5 : int  6 7 4 7 6 6 6 6 5 7 ... dataset data.si10 contains votes 435 members U.S. House Representatives, 267 Democrates 168 Republicans. dataset used Fop Murphy (2017). 'data.frame':   435 obs.  17 variables:  $ party : Factor w/ 2 levels \"democrat\",\"republican\": 2 2 1 1 1 1 1 2 2 1 ...  $ vote01: num  0 0 NA 0 1 0 0 0 0 1 ...  $ vote02: num  1 1 1 1 1 1 1 1 1 1 ...  $ vote03: num  0 0 1 1 1 1 0 0 0 1 ...  $ vote04: num  1 1 NA 0 0 0 1 1 1 0 ...  $ vote05: num  1 1 1 NA 1 1 1 1 1 0 ...  $ vote06: num  1 1 1 1 1 1 1 1 1 0 ...  $ vote07: num  0 0 0 0 0 0 0 0 0 1 ...  $ vote08: num  0 0 0 0 0 0 0 0 0 1 ...  $ vote09: num  0 0 0 0 0 0 0 0 0 1 ...  $ vote10: num  1 0 0 0 0 0 0 0 0 0 ...  $ vote11: num  NA 0 1 1 1 0 0 0 0 0 ...  $ vote12: num  1 1 0 0 NA 0 0 0 1 0 ...  $ vote13: num  1 1 1 1 1 1 NA 1 1 0 ...  $ vote14: num  1 1 1 0 1 1 1 1 1 0 ...  $ vote15: num  0 0 0 0 1 1 1 NA 0 NA ...  $ vote16: num  1 NA 0 1 1 1 1 1 1 NA ...","code":""},{"path":[]},{"path":"/reference/data.si.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Some Example Datasets for the sirt Package — data.sirt","text":"Bartolucci, F., Montanari, G. E., & Pandolfi, S. (2012). Dimensionality latent structure item selection via latent class multidimensional IRT models. Psychometrika, 77(4), 782-802. doi:10.1007/s11336-012-9278-0 DeCarlo, L. T. (2020). item response model true-false exams based signal detection theory. Applied Psychological Measurement, 34(3). 234-248. doi:10.1177/0146621619843823 Fischer, R., & Karl, J. . (2019). primer (cross-cultural) multi-group invariance testing possibilities R. Frontiers Psychology | Cultural Psychology, 10:1507. doi:10.3389/fpsyg.2019.01507 Fop, M., & Murphy, T. B. (2018). Variable selection methods model-based clustering. Statistics Surveys, 12, 18-65. https://doi.org/10.1214/18-SS119 Goodman, L. . (1970). multivariate analysis qualitative data: Interactions among multiple classifications. Journal American Statistical Association, 65(329), 226-256. doi:10.1080/01621459.1970.10481076 Lindsay, B., Clogg, C. C., & Grego, J. (1991). Semiparametric estimation Rasch model related exponential response models, including simple latent class model item analysis. Journal American Statistical Association, 86(413), 96-107. doi:10.1080/01621459.1991.10475008 Rasch, D., Kubinger, K. D., & Yanagida, T. (2011). Statistics psychology using R SPSS. New York: Wiley. doi:10.1002/9781119979630","code":""},{"path":"/reference/data.si.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Some Example Datasets for the sirt Package — data.sirt","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Nested logit model multiple choice dataset data.si06 #############################################################################  data(data.si06, package=\"sirt\") dat <- data.si06  #** estimate 2PL nested logit model library(mirt) mod1 <- mirt::mirt( dat, model=1, itemtype=\"2PLNRM\", key=rep(0,ncol(dat) ),             verbose=TRUE  ) summary(mod1) cmod1 <- sirt::mirt.wrapper.coef(mod1)$coef cmod1[,-1] <- round( cmod1[,-1], 3)  #** normalize item parameters according Suh and Bolt (2010) cmod2 <- cmod1  # slope parameters ind <-  grep(\"ak\",colnames(cmod2)) h1 <- cmod2[,ind ] cmod2[,ind] <- t( apply( h1, 1, FUN=function(ll){ ll - mean(ll) } ) ) # item intercepts ind <-  paste0( \"d\", 0:9 ) ind <- which( colnames(cmod2) %in% ind ) h1 <- cmod2[,ind ] cmod2[,ind] <- t( apply( h1, 1, FUN=function(ll){ ll - mean(ll) } ) ) cmod2[,-1] <- round( cmod2[,-1], 3)  ############################################################################# # EXAMPLE 2: Item response modle based on signal detection theory (IRSDT model) #############################################################################  data(data.si07, package=\"sirt\") data <- data.si07  #-- simulate data set.seed(98) N <- 2000 # define sample size # generate membership scores lambda <- sample(size=N, x=data$trait$x, prob=data$trait$prob, replace=TRUE) b <- data$pars$b d <- data$pars$d items <- data$pars$item dat <- data$sim_fun(lambda=lambda, b=b, d=d, items=items)  #- estimate IRSDT model as a grade of membership model with two classes problevels <- seq( 0.025, 0.975, length=20 ) mod1 <- sirt::gom.em( dat, K=2, problevels=problevels ) summary(mod1) }"},{"path":"/reference/data.timss.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset TIMSS Mathematics — data.timss","title":"Dataset TIMSS Mathematics — data.timss","text":"datasets contains TIMSS mathematics data 345 students 25 items.","code":""},{"path":"/reference/data.timss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset TIMSS Mathematics — data.timss","text":"","code":"data(data.timss)"},{"path":"/reference/data.timss.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset TIMSS Mathematics — data.timss","text":"dataset list. data dataset containing student ID (idstud), dummy variable female (girl) student age (age). following variables (starting M variable name items. format : List 2  $ data:'data.frame':   ..$ idstud  : num [1:345] 4e+09 4e+09 4e+09 4e+09 4e+09 ...   ..$ girl    : int [1:345] 0 0 0 0 0 0 0 0 1 0 ...   ..$ age     : num [1:345] 10.5 10 10.25 10.25 9.92 ...   ..$ M031286 : int [1:345] 0 0 0 1 1 0 1 0 1 0 ...   ..$ M031106 : int [1:345] 0 0 0 1 1 0 1 1 0 0 ...   ..$ M031282 : int [1:345] 0 0 0 1 1 0 1 1 0 0 ...   ..$ M031227 : int [1:345] 0 0 0 0 1 0 0 0 0 0 ...     [...]   ..$ M041203 : int [1:345] 0 0 0 1 1 0 0 0 0 1 ...  $ item:'data.frame':   ..$ item            : Factor w/ 25 levels \"M031045\",\"M031068\",..: ...   ..$ Block           : Factor w/ 2 levels \"M01\",\"M02\": 1 1 1 1 1 1 ..   ..$ Format          : Factor w/ 2 levels \"CR\",\"MC\": 1 1 1 1 2  ...   ..$ Content.Domain  : Factor w/ 3 levels \"Data Display\",..: 3 3 3 3  ...   ..$ Cognitive.Domain: Factor w/ 3 levels \"Applying\",\"Knowing\",..: 2 3 3 ..","code":""},{"path":"/reference/data.timss07.G8.RUS.html","id":null,"dir":"Reference","previous_headings":"","what":"TIMSS 2007 Grade 8 Mathematics and Science Russia — data.timss07.G8.RUS","title":"TIMSS 2007 Grade 8 Mathematics and Science Russia — data.timss07.G8.RUS","text":"TIMSS 2007 dataset contains item responses 4472 eigth grade Russian students Mathematics Science.","code":""},{"path":"/reference/data.timss07.G8.RUS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TIMSS 2007 Grade 8 Mathematics and Science Russia — data.timss07.G8.RUS","text":"","code":"data(data.timss07.G8.RUS)"},{"path":"/reference/data.timss07.G8.RUS.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"TIMSS 2007 Grade 8 Mathematics and Science Russia — data.timss07.G8.RUS","text":"datasets contains raw responses (raw), scored responses (scored) item informations (iteminfo). format dataset : List 3  $ raw     :'data.frame':   ..$ idstud  : num [1:4472] 3010101 3010102 3010104 3010105 3010106 ...   ..$ M022043 : atomic [1:4472] NA 1 4 NA NA NA NA NA NA NA ...   .. ..- attr(*, \"value.labels\")=Named num [1:7] 9 6 5 4 3 2 1   .. .. ..- attr(*, \"names\")=chr [1:7] \"OMITTED\" \"REACHED\" \"E\" \"D*\" ...   [...]   ..$ M032698 : atomic [1:4472] NA NA NA NA NA NA NA 2 1 NA ...   .. ..- attr(*, \"value.labels\")=Named num [1:6] 9 6 4 3 2 1   .. .. ..- attr(*, \"names\")=chr [1:6] \"OMITTED\" \"REACHED\" \"D\" \"C\" ...   ..$ M032097 : atomic [1:4472] NA NA NA NA NA NA NA 2 3 NA ...   .. ..- attr(*, \"value.labels\")=Named num [1:6] 9 6 4 3 2 1   .. .. ..- attr(*, \"names\")=chr [1:6] \"OMITTED\" \"REACHED\" \"D\" \"C*\" ...   .. [list output truncated]  $ scored  : num [1:4472, 1:443] 3010101 3010102 3010104 3010105 3010106 ...   ..- attr(*, \"dimnames\")=List 2   .. ..$ : NULL   .. ..$ : chr [1:443] \"idstud\" \"M022043\" \"M022046\" \"M022049\" ...  $ iteminfo:'data.frame':   ..$ item      : Factor w/ 442 levels \"M022043\",\"M022046\",..: 1 2 3 4 5 6 21 7 8 17 ...   ..$ content   : Factor w/ 8 levels \"Algebra\",\"Biology\",..: 7 7 6 1 6 7 4 6 7 7 ...   ..$ topic     : Factor w/ 49 levels \"Algebraic Expression\",..: 32 32 41 29  ...   ..$ cognitive : Factor w/ 3 levels \"Applying\",\"Knowing\",..: 2 1 3 2 1 1 1 1 2 1 ...   ..$ item.type : Factor w/ 2 levels \"CR\",\"MC\": 2 1 2 2 1 2 2 2 2 1 ...   ..$ N.options : Factor w/ 4 levels \"-\",\" -\",\"4\",\"5\": 4 1 3 4 1 4 4 4 3 1 ...   ..$ key       : Factor w/ 7 levels \"-\",\" -\",\"\",\"B\",..: 6 1 6 7 1 5 5 4 6 1 ...   ..$ max.points: int [1:442] 1 1 1 1 1 1 1 1 1 2 ...   ..$ item.label: Factor w/ 432 levels \"1 teacher every 12 students \",..: 58 351 ...","code":""},{"path":"/reference/data.timss07.G8.RUS.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"TIMSS 2007 Grade 8 Mathematics and Science Russia — data.timss07.G8.RUS","text":"TIMSS 2007 8th Grade, Russian Sample","code":""},{"path":"/reference/data.trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset Used in Stoyan, Pommerening and Wuensche (2018) — data.trees","title":"Dataset Used in Stoyan, Pommerening and Wuensche (2018) — data.trees","text":"Dataset used Stoyan, Pommerening Wuensche (2018; see also Pommerening et al., 2018). dataset, 15 forest managers classify 387 trees either trees maintained trees removed. assign tree marks, either 0 1, mark 1 means remove.","code":""},{"path":"/reference/data.trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset Used in Stoyan, Pommerening and Wuensche (2018) — data.trees","text":"","code":"data(data.trees)"},{"path":"/reference/data.trees.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset Used in Stoyan, Pommerening and Wuensche (2018) — data.trees","text":"dataset following structure. 'data.frame':   387 obs.  16 variables:  $ Number: int  142 184 9 300 374 42 382 108 125 201 ...  $ FM1   : int  1 1 1 1 1 1 1 1 1 0 ...  $ FM2   : int  1 1 1 0 1 1 1 1 1 1 ...  $ FM3   : int  1 0 1 1 1 1 1 1 1 1 ...  $ FM4   : int  1 1 1 1 1 1 0 1 1 1 ...  $ FM5   : int  1 1 1 1 1 1 0 0 0 1 ...  $ FM6   : int  1 1 1 1 0 1 1 1 1 0 ...  $ FM7   : int  1 0 1 1 0 0 1 0 1 1 ...  $ FM8   : int  1 1 1 1 1 0 0 1 0 1 ...  $ FM9   : int  1 1 0 1 1 1 1 0 1 1 ...  $ FM10  : int  0 1 1 0 1 1 1 1 0 0 ...  $ FM11  : int  1 1 1 1 0 1 1 0 1 0 ...  $ FM12  : int  1 1 1 1 1 1 0 1 0 0 ...  $ FM13  : int  0 1 0 0 1 1 1 1 1 1 ...  $ FM14  : int  1 1 1 1 1 0 1 1 1 1 ...  $ FM15  : int  1 1 0 1 1 0 1 0 0 1 ...","code":""},{"path":"/reference/data.trees.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Dataset Used in Stoyan, Pommerening and Wuensche (2018) — data.trees","text":"https://www.pommerening.org/wiki/images/d/dc/CoedyBreninSortedforPublication.txt","code":""},{"path":"/reference/data.trees.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Dataset Used in Stoyan, Pommerening and Wuensche (2018) — data.trees","text":"Pommerening, ., Ramos, C. P., Kedziora, W., Haufe, J., & Stoyan, D. (2018). Rating experiments forestry: much agreement tree marking? PloS ONE, 13(3), e0194747. doi:10.1371/journal.pone.0194747 Stoyan, D., Pommerening, ., & Wuensche, . (2018). Rater classification means set-theoretic methods applied forestry data. Journal Environmental Statistics, 8(2), 1-17.","code":""},{"path":"/reference/data.trees.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dataset Used in Stoyan, Pommerening and Wuensche (2018) — data.trees","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Latent class models, latent trait models, mixed membership models #############################################################################  data(data.trees, package=\"sirt\") dat <- data.trees[,-1] I <- ncol(dat)  #** latent class models with 2, 3, and 4 classes problevels <- seq( 0, 1, len=2 ) mod02 <- sirt::gom.em(dat, K=2, problevels, model=\"GOM\") mod03 <- sirt::gom.em(dat, K=3, problevels, model=\"GOM\") mod04 <- sirt::gom.em(dat, K=4, problevels, model=\"GOM\")  #** grade of membership models mod11 <- sirt::gom.em(dat, K=2, theta0.k=10*seq(-1,1,len=11), model=\"GOMnormal\") problevels <- seq( 0, 1, len=3 ) mod12 <- sirt::gom.em(dat, K=2, problevels, model=\"GOM\") mod13 <- sirt::gom.em(dat, K=3, problevels, model=\"GOM\") mod14 <- sirt::gom.em(dat, K=4, problevels, model=\"GOM\") problevels <- seq( 0, 1, len=4 ) mod22 <- sirt::gom.em(dat, K=2, problevels, model=\"GOM\") mod23 <- sirt::gom.em(dat, K=3, problevels, model=\"GOM\") mod24 <- sirt::gom.em(dat, K=4, problevels, model=\"GOM\")  #** latent trait models #- 1PL mod31 <- sirt::rasch.mml2(dat) #- 2PL mod32 <- sirt::rasch.mml2(dat, est.a=1:I)  #- model comparison IRT.compareModels(mod02, mod03, mod04, mod11, mod12, mod13, mod14,                      mod22, mod23, mod24, mod31, mod32)  #-- inspect model results summary(mod12) round( cbind( mod12$theta.k, mod12$pi.k ),3)  summary(mod13) round(cbind( mod13$theta.k, mod13$pi.k ),3) }"},{"path":"/reference/data.wide2long.html","id":null,"dir":"Reference","previous_headings":"","what":"Converting a Data Frame from Wide Format in a Long Format — data.wide2long","title":"Converting a Data Frame from Wide Format in a Long Format — data.wide2long","text":"Converts data frame wide format long format.","code":""},{"path":"/reference/data.wide2long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converting a Data Frame from Wide Format in a Long Format — data.wide2long","text":"","code":"data.wide2long(dat, id=NULL, X=NULL, Q=NULL)"},{"path":"/reference/data.wide2long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converting a Data Frame from Wide Format in a Long Format — data.wide2long","text":"dat Data frame item responses person identifier id !=NULL. id optional string variable name person identifier. X Data frame person covariates inclusion         data frame long format Q Data frame item predictors. Item labels must included         column named \"item\".","code":""},{"path":"/reference/data.wide2long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converting a Data Frame from Wide Format in a Long Format — data.wide2long","text":"Data frame long format","code":""},{"path":"/reference/data.wide2long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converting a Data Frame from Wide Format in a Long Format — data.wide2long","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: data.pisaRead ############################################################################# miceadds::library_install(\"lme4\")  data(data.pisaRead) dat <- data.pisaRead$data Q <- data.pisaRead$item   # item predictors  # define items items <- colnames(dat)[ substring( colnames(dat), 1, 1 )==\"R\" ] dat1 <- dat[, c( \"idstud\", items ) ] # matrix with person predictors X <- dat[, c(\"idschool\", \"hisei\", \"female\", \"migra\") ]  # create dataset in long format dat.long <- sirt::data.wide2long( dat=dat1, id=\"idstud\", X=X, Q=Q )  #*** # Model 1: Rasch model mod1 <- lme4::glmer( resp ~ 0 + ( 1 | idstud ) + as.factor(item), data=dat.long,             family=\"binomial\", verbose=TRUE) summary(mod1)  #*** # Model 2: Rasch model and inclusion of person predictors mod2 <- lme4::glmer( resp ~ 0 + ( 1 | idstud ) + as.factor(item) + female + hisei + migra,            data=dat.long, family=\"binomial\", verbose=TRUE) summary(mod2)  #*** # Model 3: LLTM mod3 <- lme4::glmer(resp ~ (1|idstud) + as.factor(ItemFormat) + as.factor(TextType),             data=dat.long, family=\"binomial\", verbose=TRUE) summary(mod3)  ############################################################################# # EXAMPLE 2: Rasch model in lme4 #############################################################################  set.seed(765) N <- 1000  # number of persons I <- 10    # number of items b <- seq(-2,2,length=I) dat <- sirt::sim.raschtype( stats::rnorm(N,sd=1.2), b=b ) dat.long <- sirt::data.wide2long( dat=dat ) #*** # estimate Rasch model with lmer library(lme4) mod1 <- lme4::glmer( resp ~ 0 + as.factor( item ) + ( 1 | id_index), data=dat.long,              verbose=TRUE, family=\"binomial\") summary(mod1)   ##   Random effects:   ##    Groups   Name        Variance Std.Dev.   ##    id_index (Intercept) 1.454    1.206   ##   Number of obs: 10000, groups: id_index, 1000   ##   ##   Fixed effects:   ##                        Estimate Std. Error z value Pr(>|z|)   ##   as.factor(item)I0001  2.16365    0.10541  20.527  < 2e-16 ***   ##   as.factor(item)I0002  1.66437    0.09400  17.706  < 2e-16 ***   ##   as.factor(item)I0003  1.21816    0.08700  14.002  < 2e-16 ***   ##   as.factor(item)I0004  0.68611    0.08184   8.383  < 2e-16 ***   ##   [...] }"},{"path":"/reference/detect.index.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculation of the DETECT and polyDETECT Index — detect.index","title":"Calculation of the DETECT and polyDETECT Index — detect.index","text":"function calculated DETECT polyDETECT index (Stout, Habing, Douglas & Kim, 1996; Zhang & Stout, 1999a; Zhang, 2007). first, conditional covariances estimated using ccov.np function.","code":""},{"path":"/reference/detect.index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculation of the DETECT and polyDETECT Index — detect.index","text":"","code":"detect.index(ccovtable, itemcluster)"},{"path":"/reference/detect.index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculation of the DETECT and polyDETECT Index — detect.index","text":"ccovtable value ccov.np. itemcluster Item cluster item. order entries must correspond columns data (submitted ccov.np).","code":""},{"path":"/reference/detect.index.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculation of the DETECT and polyDETECT Index — detect.index","text":"Stout, W., Habing, B., Douglas, J., & Kim, H. R. (1996). Conditional covariance-based nonparametric multidimensionality assessment. Applied Psychological Measurement, 20, 331-354. Zhang, J., & Stout, W. (1999a). Conditional covariance structure generalized compensatory multidimensional items. Psychometrika, 64, 129-152. Zhang, J., & Stout, W. (1999b). theoretical DETECT index dimensionality application approximate simple structure. Psychometrika, 64, 213-249. Zhang, J. (2007). Conditional covariance theory DETECT polytomous items. Psychometrika, 72, 69-91.","code":""},{"path":[]},{"path":"/reference/dif.logistic.regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","title":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","text":"function assesses differential item functioning using logistic regression analysis (Zumbo, 1999).","code":""},{"path":"/reference/dif.logistic.regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","text":"","code":"dif.logistic.regression(dat, group, score,quant=1.645)"},{"path":"/reference/dif.logistic.regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","text":"dat Data frame dichotomous item responses group Group identifier score Ability estimate, e.g. WLE. quant Used quantile normal distribution assessing statistical significance","code":""},{"path":"/reference/dif.logistic.regression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","text":"Items classified (negligible DIF), B (moderate DIF) C (large DIF) levels according ETS classification system (Longford, Holland & Thayer, 1993, p. 175). See also Monahan, McHorney, Stump Perkins (2007) DIF effect size classifications.","code":""},{"path":"/reference/dif.logistic.regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","text":"data frame following variables: itemnr Numeric index item sortDIFindex Rank item respect uniform DIF     (negative positive values) item Item name N Sample size per item R Value group variable reference group F Value group variable focal group nR Sample size per item reference group nF Sample size per item focal group p Item \\(p\\) value pR Item \\(p\\) value reference group pF Item \\(p\\) value focal group pdiff Item \\(p\\) value differences pdiff.adj Adjusted \\(p\\) value difference uniformDIF Uniform DIF estimate se.uniformDIF Standard error uniform DIF t.uniformDIF \\(t\\) value uniform DIF sig.uniformDIF Significance label uniform DIF DIF.ETS DIF classification according ETS classification     system (see Details) uniform.EBDIF Empirical Bayes estimate uniform DIF (Longford,     Holland & Thayer, 1993) takes degree DIF standard error         account DIF.SD Value DIF standard deviation nonuniformDIF Nonuniform DIF estimate se.nonuniformDIF Standard error nonuniform DIF t.nonuniformDIF \\(t\\) value nonuniform DIF sig.nonuniformDIF Significance label nonuniform DIF","code":""},{"path":"/reference/dif.logistic.regression.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","text":"Longford, N. T., Holland, P. W., & Thayer, D. T. (1993). Stability MH D-DIF statistics across populations. P. W. Holland & H. Wainer (Eds.). Differential Item Functioning (pp. 171-196). Hillsdale, NJ: Erlbaum. Magis, D., Beland, S., Tuerlinckx, F., & De Boeck, P. (2010). general framework R package detection dichotomous differential item functioning. Behavior Research Methods, 42(3), 847-862. doi:10.3758/BRM.42.3.847 Monahan, P. O., McHorney, C. ., Stump, T. E., & Perkins, . J. (2007). Odds ratio, delta, ETS classification, standardization measures DIF magnitude binary logistic regression. Journal Educational Behavioral Statistics, 32(1), 92-109. doi:10.3102/1076998606298035 Zumbo, B. D. (1999). handbook theory methods differential item functioning (DIF): Logistic regression modeling unitary framework binary Likert-type (ordinal) item scores. Ottawa : Directorate Human Resources Research Evaluation, Department National Defense.","code":""},{"path":[]},{"path":"/reference/dif.logistic.regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Differential Item Functioning using Logistic Regression Analysis — dif.logistic.regression","text":"","code":"############################################################################# # EXAMPLE 1: Mathematics data | Gender DIF #############################################################################  data( data.math ) dat <- data.math$data items <- grep( \"M\", colnames(dat))  # estimate item parameters and WLEs mod <- sirt::rasch.mml2( dat[,items] ) wle <- sirt::wle.rasch( dat[,items], b=mod$item$b )$theta  # assess DIF by logistic regression mod1 <- sirt::dif.logistic.regression( dat=dat[,items], score=wle, group=dat$female)  # calculate DIF variance dif1 <- sirt::dif.variance( dif=mod1$uniformDIF, se.dif=mod1$se.uniformDIF ) dif1$unweighted.DIFSD   ## > dif1$unweighted.DIFSD   ## [1] 0.1963958  # calculate stratified DIF variance # stratification based on domains dif2 <- sirt::dif.strata.variance( dif=mod1$uniformDIF, se.dif=mod1$se.uniformDIF,               itemcluster=data.math$item$domain )   ## $unweighted.DIFSD   ## [1] 0.1455916  if (FALSE) { #**** # Likelihood ratio test and graphical model test in eRm package miceadds::library_install(\"eRm\") # estimate Rasch model res <- eRm::RM( dat[,items] ) summary(res) # LR-test with respect to female lrres <- eRm::LRtest(res, splitcr=dat$female) summary(lrres) # graphical model test eRm::plotGOF(lrres)  ############################################################################# # EXAMPLE 2: Comparison with Mantel-Haenszel test #############################################################################  library(TAM) library(difR)  #*** (1) simulate data set.seed(776) N <- 1500   # number of persons per group I <- 12     # number of items mu2 <- .5   # impact (group difference) sd2 <- 1.3  # standard deviation group 2  # define item difficulties b <- seq( -1.5, 1.5, length=I) # simulate DIF effects bdif <- scale( stats::rnorm(I, sd=.6 ), scale=FALSE )[,1] # item difficulties per group b1 <- b + 1/2 * bdif b2 <- b - 1/2 * bdif # simulate item responses dat1 <- sirt::sim.raschtype( theta=stats::rnorm(N, mean=0, sd=1 ), b=b1 ) dat2 <- sirt::sim.raschtype( theta=stats::rnorm(N, mean=mu2, sd=sd2 ), b=b2 ) dat <- rbind( dat1, dat2 ) group <- rep( c(1,2), each=N ) # define group indicator  #*** (2) scale data mod <- TAM::tam.mml( dat, group=group ) summary(mod)  #*** (3) extract person parameter estimates mod_eap <- mod$person$EAP mod_wle <- tam.wle( mod )$theta  #********************************* # (4) techniques for assessing differential item functioning  # Model 1: assess DIF by logistic regression and WLEs dif1 <- sirt::dif.logistic.regression( dat=dat, score=mod_wle, group=group) # Model 2: assess DIF by logistic regression and EAPs dif2 <- sirt::dif.logistic.regression( dat=dat, score=mod_eap, group=group) # Model 3: assess DIF by Mantel-Haenszel statistic dif3 <- difR::difMH(Data=dat, group=group, focal.name=\"1\",  purify=FALSE ) print(dif3)   ##  Mantel-Haenszel Chi-square statistic:   ##   ##        Stat.    P-value   ##  I0001  14.5655   0.0001 ***   ##  I0002 300.3225   0.0000 ***   ##  I0003   2.7160   0.0993 .   ##  I0004 191.6925   0.0000 ***   ##  I0005   0.0011   0.9740   ##  [...]   ##  Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1   ##  Detection threshold: 3.8415 (significance level: 0.05)   ##   ##  Effect size (ETS Delta scale):   ##   ##  Effect size code:   ##   'A': negligible effect   ##   'B': moderate effect   ##   'C': large effect   ##   ##        alphaMH deltaMH   ##  I0001  1.3908 -0.7752 A   ##  I0002  0.2339  3.4147 C   ##  I0003  1.1407 -0.3093 A   ##  I0004  2.8515 -2.4625 C   ##  I0005  1.0050 -0.0118 A   ##  [...]   ##   ##  Effect size codes: 0 'A' 1.0 'B' 1.5 'C'   ##   (for absolute values of 'deltaMH')  # recompute DIF parameter from alphaMH uniformDIF3 <- log(dif3$alphaMH)  # compare different DIF statistics dfr <- data.frame( \"bdif\"=bdif, \"LR_wle\"=dif1$uniformDIF,         \"LR_eap\"=dif2$uniformDIF, \"MH\"=uniformDIF3 ) round( dfr, 3 )   ##       bdif LR_wle LR_eap     MH   ##  1   0.236  0.319  0.278  0.330   ##  2  -1.149 -1.473 -1.523 -1.453   ##  3   0.140  0.122  0.038  0.132   ##  4   0.957  1.048  0.938  1.048   ##  [...] colMeans( abs( dfr[,-1] - bdif ))   ##      LR_wle     LR_eap         MH   ##  0.07759187 0.19085743 0.07501708 }"},{"path":"/reference/dif.strata.variance.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratified DIF Variance — dif.strata.variance","title":"Stratified DIF Variance — dif.strata.variance","text":"Calculation stratified DIF variance","code":""},{"path":"/reference/dif.strata.variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratified DIF Variance — dif.strata.variance","text":"","code":"dif.strata.variance(dif, se.dif, itemcluster)"},{"path":"/reference/dif.strata.variance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratified DIF Variance — dif.strata.variance","text":"dif Vector uniform DIF effects se.dif Standard error uniform DIF effects itemcluster Vector item strata","code":""},{"path":"/reference/dif.strata.variance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stratified DIF Variance — dif.strata.variance","text":"list following entries: stratadif Summary statistics DIF effects within item strata weighted.DIFSD Weighted DIF standard deviation unweigted.DIFSD DIF standard deviation","code":""},{"path":"/reference/dif.strata.variance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stratified DIF Variance — dif.strata.variance","text":"Longford, N. T., Holland, P. W., & Thayer, D. T. (1993). Stability MH D-DIF statistics across populations. P. W. Holland & H. Wainer (Eds.). Differential Item Functioning (pp. 171-196). Hillsdale, NJ: Erlbaum.","code":""},{"path":[]},{"path":"/reference/dif.variance.html","id":null,"dir":"Reference","previous_headings":"","what":"DIF Variance — dif.variance","title":"DIF Variance — dif.variance","text":"function calculates variance DIF effects, called DIF variance (Longford, Holland & Thayer, 1993).","code":""},{"path":"/reference/dif.variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DIF Variance — dif.variance","text":"","code":"dif.variance(dif, se.dif, items=paste(\"item\", 1:length(dif), sep=\"\") )"},{"path":"/reference/dif.variance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DIF Variance — dif.variance","text":"dif Vector uniform DIF effects se.dif Standard error uniform DIF effects items Optional vector item names","code":""},{"path":"/reference/dif.variance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DIF Variance — dif.variance","text":"list following entries weighted.DIFSD Weighted DIF standard deviation unweigted.DIFSD DIF standard deviation mean.se.dif Mean standard errors DIF effects eb.dif Empirical Bayes estimates DIF effects","code":""},{"path":"/reference/dif.variance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"DIF Variance — dif.variance","text":"Longford, N. T., Holland, P. W., & Thayer, D. T. (1993). Stability MH D-DIF statistics across populations. P. W. Holland & H. Wainer (Eds.). Differential Item Functioning (pp. 171-196). Hillsdale, NJ: Erlbaum.","code":""},{"path":[]},{"path":"/reference/dirichlet.mle.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Likelihood Estimation of the Dirichlet Distribution — dirichlet.mle","title":"Maximum Likelihood Estimation of the Dirichlet Distribution — dirichlet.mle","text":"Maximum likelihood estimation parameters Dirichlet distribution","code":""},{"path":"/reference/dirichlet.mle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Likelihood Estimation of the Dirichlet Distribution — dirichlet.mle","text":"","code":"dirichlet.mle(x, weights=NULL, eps=10^(-5), convcrit=1e-05, maxit=1000,      oldfac=.3, progress=FALSE)"},{"path":"/reference/dirichlet.mle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Likelihood Estimation of the Dirichlet Distribution — dirichlet.mle","text":"x Data frame \\(N\\) observations \\(K\\) variables Dirichlet distribution weights Optional vector frequency weights eps Tolerance number added prevent logarithms zero convcrit Convergence criterion maxit Maximum number iterations oldfac Convergence acceleration factor. must parameter 0 1. progress Display iteration progress?","code":""},{"path":"/reference/dirichlet.mle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Likelihood Estimation of the Dirichlet Distribution — dirichlet.mle","text":"list following entries alpha Vector \\(\\alpha\\) parameters alpha0 concentration parameter \\(\\alpha_0=\\sum_k \\alpha_k\\) xsi Vector proportions \\(\\xi_k=\\alpha_k / \\alpha_0\\)","code":""},{"path":"/reference/dirichlet.mle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Maximum Likelihood Estimation of the Dirichlet Distribution — dirichlet.mle","text":"Minka, T. P. (2012). Estimating Dirichlet distribution. Technical Report.","code":""},{"path":[]},{"path":[]},{"path":"/reference/dirichlet.simul.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation of a Dirichlet Distributed Vectors — dirichlet.simul","title":"Simulation of a Dirichlet Distributed Vectors — dirichlet.simul","text":"function makes random draws Dirichlet distribution.","code":""},{"path":"/reference/dirichlet.simul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation of a Dirichlet Distributed Vectors — dirichlet.simul","text":"","code":"dirichlet.simul(alpha)"},{"path":"/reference/dirichlet.simul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation of a Dirichlet Distributed Vectors — dirichlet.simul","text":"alpha matrix \\(\\bold{\\alpha}\\) parameters Dirichlet distribution","code":""},{"path":"/reference/dirichlet.simul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulation of a Dirichlet Distributed Vectors — dirichlet.simul","text":"data frame Dirichlet distributed responses","code":""},{"path":"/reference/dirichlet.simul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation of a Dirichlet Distributed Vectors — dirichlet.simul","text":"","code":"############################################################################# # EXAMPLE 1: Simulation with two components #############################################################################  set.seed(789) N <- 2000 probs <- c(.7, .3)    # define (extremal) class probabilities  #*** alpha0=.2  -> nearly crisp latent classes alpha0 <- .2 alpha <- alpha0*probs alpha <- matrix( alpha, nrow=N, ncol=length(alpha), byrow=TRUE  ) x <- sirt::dirichlet.simul( alpha ) htitle <- expression(paste( alpha[0], \"=.2, \", p[1], \"=.7\"   ) ) hist( x[,1], breaks=seq(0,1,len=20), main=htitle)  #*** alpha0=3 -> strong deviation from crisp membership alpha0 <- 3 alpha <- alpha0*probs alpha <- matrix( alpha, nrow=N, ncol=length(alpha), byrow=TRUE  ) x <- sirt::dirichlet.simul( alpha ) htitle <- expression(paste( alpha[0], \"=3, \", p[1], \"=.7\"   ) ) hist( x[,1], breaks=seq(0,1,len=20), main=htitle)  if (FALSE) { ############################################################################# # EXAMPLE 2: Simulation with three components #############################################################################  set.seed(986) N <- 2000 probs <- c( .5, .35, .15 )  #*** alpha0=.2 alpha0 <- .2 alpha <- alpha0*probs alpha <- matrix( alpha, nrow=N, ncol=length(alpha), byrow=TRUE  ) x <- sirt::dirichlet.simul( alpha ) htitle <- expression(paste( alpha[0], \"=.2, \", p[1], \"=.7\"   ) ) miceadds::library_install(\"ade4\") ade4::triangle.plot(x, label=NULL, clabel=1)  #*** alpha0=3 alpha0 <- 3 alpha <- alpha0*probs alpha <- matrix( alpha, nrow=N, ncol=length(alpha), byrow=TRUE  ) x <- sirt::dirichlet.simul( alpha ) htitle <- expression(paste( alpha[0], \"=3, \", p[1], \"=.7\"   ) ) ade4::triangle.plot(x, label=NULL, clabel=1) }"},{"path":"/reference/dmlavaan.html","id":null,"dir":"Reference","previous_headings":"","what":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","title":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","text":"function dmlavaan compares model parameters different lavaan models fitted dataset. leads dependent coefficients. Statistical inference either conducted M-estimation (.e., robust sandwich method; method=\"bootstrap\") bootstrap (method=\"bootstrap\"). See Mize et al. (2019) Weesie (1999) details.","code":""},{"path":"/reference/dmlavaan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","text":"","code":"dmlavaan(fun1, args1, fun2, args2, method=\"sandwich\", R=50)"},{"path":"/reference/dmlavaan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","text":"fun1 lavaan function first model (e.g., \"lavaan\", \"cfa\", \"sem\") args1 arguments lavaan function first model fun2 lavaan function second model (e.g., \"lavaan\", \"cfa\", \"sem\") args2 arguments lavaan function second model method estimation method standard errors R Number bootstrap samples","code":""},{"path":"/reference/dmlavaan.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","text":"bootstrap estimation, normal approximation applied computation confidence intervals. Hence, R chosen relatively small.  (yet implemented):","code":""},{"path":"/reference/dmlavaan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","text":"list following entries coef Model parameters models vcov Covariance matrix model parameters models partable Parameter table containing univariate model parameters ... entries","code":""},{"path":"/reference/dmlavaan.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","text":"Mize, T.D., Doan, L., & Long, J.S. (2019). general framework comparing predictions marginal effects across models. Sociological Methodology, 49(1), 152-189. doi:10.1177/0081175019852763 Weesie, J. (1999) Seemingly unrelated estimation cluster-adjusted sandwich estimator. Stata Technical Bulletin, 9, 231-248.","code":""},{"path":"/reference/dmlavaan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comparing Regression Parameters of Different lavaan Models Fitted to the\r\nSame Dataset — dmlavaan","text":"","code":"if (FALSE) { ############################################################################ # EXAMPLE 1: Confirmatory factor analysis with and without fourth item #############################################################################  #**** simulate data N <- 200  # number of persons I <- 4    # number of items  # loadings and error correlations lam <- seq(.7,.4, len=I) PSI <- diag( 1-lam^2 )  # define some model misspecification sd_error <- .1 S1 <- matrix( c( -1.84, 0.39,-0.68, 0.13,   0.39,-1.31,-0.07,-0.27,  -0.68,-0.07, 0.90, 1.91,   0.13,-0.27, 1.91,-0.56 ), nrow=4, ncol=4, byrow=TRUE) S1 <- ( S1 - mean(S1) ) / sd(S1) * sd_error  Sigma <- lam %*% t(lam) + PSI + S1 dat <- MASS::mvrnorm(n=N, mu=rep(0,I), Sigma=Sigma) colnames(dat) <- paste0(\"X\",1:4) dat <- as.data.frame(dat) rownames(Sigma) <- colnames(Sigma) <- colnames(dat)   #*** define two lavaan models lavmodel1 <- \"F=~ X1 + X2 + X3 + X4\" lavmodel2 <- \"F=~ X1 + X2 + X3\"  #*** define lavaan estimation arguments and functions fun2 <- fun1 <- \"cfa\" args1 <- list( model=lavmodel1, data=dat, std.lv=TRUE, estimator=\"MLR\") args2 <- args1 args2$model <- lavmodel2  #* run model comparison res1 <- sirt::dmlavaan( fun1=fun1, args1=args1, fun2=fun2, args2=args2)  # inspect results sirt:::print_digits(res1$partable, digits=3) }"},{"path":"/reference/eigenvalues.manymatrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Computation of Eigenvalues of Many Symmetric Matrices — eigenvalues.manymatrices","title":"Computation of Eigenvalues of Many Symmetric Matrices — eigenvalues.manymatrices","text":"function computes eigenvalue decomposition \\(N\\) symmetric positive definite matrices. eigenvalues computed Rayleigh quotient method (Lange, 2010, p. 120). addition, inverse matrix can calculated.","code":""},{"path":"/reference/eigenvalues.manymatrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computation of Eigenvalues of Many Symmetric Matrices — eigenvalues.manymatrices","text":"","code":"eigenvalues.manymatrices(Sigma.all, itermax=10, maxconv=0.001,     inverse=FALSE )"},{"path":"/reference/eigenvalues.manymatrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computation of Eigenvalues of Many Symmetric Matrices — eigenvalues.manymatrices","text":"Sigma.\\(N \\times D^2\\) matrix containing \\(D^2\\) entries \\(N\\) symmetric matrices dimension \\(D \\times D\\) itermax Maximum number iterations maxconv Convergence criterion convergence eigenvectors inverse logical indicates inverse matrix     shall calculated","code":""},{"path":"/reference/eigenvalues.manymatrices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computation of Eigenvalues of Many Symmetric Matrices — eigenvalues.manymatrices","text":"list following entries lambda Matrix eigenvalues U \\(N \\times D^2\\) Matrix orthonormal eigenvectors logdet Vector logarithm determinants det Vector determinants Sigma.inv Inverse matrix inverse=TRUE.","code":""},{"path":"/reference/eigenvalues.manymatrices.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Computation of Eigenvalues of Many Symmetric Matrices — eigenvalues.manymatrices","text":"Lange, K. (2010). Numerical Analysis Statisticians. New York: Springer.","code":""},{"path":"/reference/eigenvalues.manymatrices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computation of Eigenvalues of Many Symmetric Matrices — eigenvalues.manymatrices","text":"","code":"# define matrices Sigma <- diag(1,3) Sigma[ lower.tri(Sigma) ] <- Sigma[ upper.tri(Sigma) ] <- c(.4,.6,.8 ) Sigma1 <- Sigma  Sigma <- diag(1,3) Sigma[ lower.tri(Sigma) ] <- Sigma[ upper.tri(Sigma) ] <- c(.2,.1,.99 ) Sigma2 <- Sigma  # collect matrices in a \"super-matrix\" Sigma.all <- rbind( matrix( Sigma1, nrow=1, byrow=TRUE),                 matrix( Sigma2, nrow=1, byrow=TRUE) ) Sigma.all <- Sigma.all[ c(1,1,2,2,1 ), ]  # eigenvalue decomposition m1 <- sirt::eigenvalues.manymatrices( Sigma.all ) m1  # eigenvalue decomposition for Sigma1 s1 <- svd(Sigma1) s1"},{"path":"/reference/equating.rasch.html","id":null,"dir":"Reference","previous_headings":"","what":"Equating in the Generalized Logistic Rasch Model — equating.rasch","title":"Equating in the Generalized Logistic Rasch Model — equating.rasch","text":"function linking generalized logistic item response model. item difficulties (\\(b\\) item parameters) allowed. Mean-mean linking methods Haebara Stocking-Lord implemented (Kolen & Brennan, 2004).","code":""},{"path":"/reference/equating.rasch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Equating in the Generalized Logistic Rasch Model — equating.rasch","text":"","code":"equating.rasch(x, y, theta=seq(-4, 4, len=100),        alpha1=0, alpha2=0)"},{"path":"/reference/equating.rasch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Equating in the Generalized Logistic Rasch Model — equating.rasch","text":"x Matrix two columns: First column items, second column item difficulties y Matrix two columns: First columns item, second column item difficulties theta Vector theta values linking functions evaluated. weighting according prespecified normal distribution \\(N( \\mu,\\sigma^2)\\) aimed, choose theta=stats::qnorm( seq(.001, .999, len=100), mean=mu, sd=sigma) alpha1 Fixed \\(\\alpha_1\\) parameter generalized item response model alpha2 Fixed \\(\\alpha_2\\) parameter generalized item response model","code":""},{"path":"/reference/equating.rasch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Equating in the Generalized Logistic Rasch Model — equating.rasch","text":"B.est Estimated linking constants according methods Mean.Mean (Mean-mean linking), Haebara (Haebara method) Stocking.Lord (Stocking-Lord method). descriptives Descriptives linking. linking error (linkerror) calculated assumption simple random sampling items anchor Original transformed item parameters anchor items transf.par Original transformed item parameters items","code":""},{"path":"/reference/equating.rasch.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Equating in the Generalized Logistic Rasch Model — equating.rasch","text":"Kolen, M. J., & Brennan, R. L. (2004). Test Equating, Scaling, Linking: Methods Practices. New York: Springer.","code":""},{"path":[]},{"path":"/reference/equating.rasch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Equating in the Generalized Logistic Rasch Model — equating.rasch","text":"","code":"############################################################################# # EXAMPLE 1: Linking item parameters of the PISA study #############################################################################  data(data.pisaPars) pars <- data.pisaPars  # linking the two studies with the Rasch model mod <- sirt::equating.rasch(x=pars[,c(\"item\",\"study1\")], y=pars[,c(\"item\",\"study2\")])   ##   Mean.Mean    Haebara Stocking.Lord   ## 1   0.08828 0.08896269    0.09292838  if (FALSE) { #*** linking using the plink package # The plink package is not available on CRAN anymore. # You can download the package with # utils::install.packages(\"plink\", repos=\"http://www2.uaem.mx/r-mirror\") library(plink) I <- nrow(pars) pm <- plink::as.poly.mod(I) # linking parameters plink.pars1 <- list( \"study1\"=data.frame( 1, pars$study1, 0 ),                      \"study2\"=data.frame( 1, pars$study2, 0 ) )       # the parameters are arranged in the columns:       # Discrimination, Difficulty, Guessing Parameter # common items common.items <- cbind(\"study1\"=1:I,\"study2\"=1:I) # number of categories per item cats.item <- list( \"study1\"=rep(2,I), \"study2\"=rep(2,I)) # convert into plink object x <- plink::as.irt.pars( plink.pars1, common.items, cat=cats.item,           poly.mod=list(pm,pm)) # linking using plink: first group is reference group out <- plink::plink(x, rescale=\"MS\", base.grp=1, D=1.7) # summary for linking summary(out)   ##   -------  group2/group1*  -------   ##   Linking Constants   ##   ##                        A         B   ##   Mean/Mean     1.000000 -0.088280   ##   Mean/Sigma    1.000000 -0.088280   ##   Haebara       1.000000 -0.088515   ##   Stocking-Lord 1.000000 -0.096610 # extract linked parameters pars.out <- plink::link.pars(out) }"},{"path":"/reference/equating.rasch.jackknife.html","id":null,"dir":"Reference","previous_headings":"","what":"Jackknife Equating Error in Generalized Logistic Rasch Model — equating.rasch.jackknife","title":"Jackknife Equating Error in Generalized Logistic Rasch Model — equating.rasch.jackknife","text":"function estimates linking error linking based Jackknife (Monseur & Berezner, 2007).","code":""},{"path":"/reference/equating.rasch.jackknife.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jackknife Equating Error in Generalized Logistic Rasch Model — equating.rasch.jackknife","text":"","code":"equating.rasch.jackknife(pars.data, display=TRUE,    se.linkerror=FALSE, alpha1=0, alpha2=0)"},{"path":"/reference/equating.rasch.jackknife.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jackknife Equating Error in Generalized Logistic Rasch Model — equating.rasch.jackknife","text":"pars.data Data frame four columns: jackknife unit (1st column), item parameter study 1 (2nd column), item parameter study 2 (3rd column), item (4th column) display Display progress? se.linkerror Compute standard error linking error alpha1 Fixed \\(\\alpha_1\\) parameter generalized item response model alpha2 Fixed \\(\\alpha_2\\) parameter generalized item response model","code":""},{"path":"/reference/equating.rasch.jackknife.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jackknife Equating Error in Generalized Logistic Rasch Model — equating.rasch.jackknife","text":"list following entries: pars.data Used item parameters itemunits Used units jackknife descriptives Descriptives Jackknife. linkingerror.jackknife estimated linking error.","code":""},{"path":"/reference/equating.rasch.jackknife.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Jackknife Equating Error in Generalized Logistic Rasch Model — equating.rasch.jackknife","text":"Monseur, C., & Berezner, . (2007). computation equating errors international surveys education. Journal Applied Measurement, 8, 323-335.","code":""},{"path":[]},{"path":"/reference/equating.rasch.jackknife.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jackknife Equating Error in Generalized Logistic Rasch Model — equating.rasch.jackknife","text":"","code":"############################################################################# # EXAMPLE 1: Linking errors PISA study #############################################################################  data(data.pisaPars) pars <- data.pisaPars  # Linking error: Jackknife unit is the testlet vars <- c(\"testlet\",\"study1\",\"study2\",\"item\") res1 <- sirt::equating.rasch.jackknife(pars[, vars]) res1$descriptives   ##   N.items N.units      shift        SD linkerror.jackknife SE.SD.jackknife   ## 1      25       8 0.09292838 0.1487387          0.04491197      0.03466309  # Linking error: Jackknife unit is the item res2 <- sirt::equating.rasch.jackknife(pars[, vars ] ) res2$descriptives   ##   N.items N.units      shift        SD linkerror.jackknife SE.SD.jackknife   ## 1      25      25 0.09292838 0.1487387          0.02682839      0.02533327"},{"path":"/reference/expl.detect.html","id":null,"dir":"Reference","previous_headings":"","what":"Exploratory DETECT Analysis — expl.detect","title":"Exploratory DETECT Analysis — expl.detect","text":"function estimates DETECT index (Stout, Habing, Douglas & Kim, 1996; Zhang & Stout, 1999a, 1999b) exploratory way. Conditional covariances itempairs transformed distance matrix items clustered hierarchical Ward algorithm (Roussos, Stout & Marden, 1998). Note function provide output original DETECT software.","code":""},{"path":"/reference/expl.detect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exploratory DETECT Analysis — expl.detect","text":"","code":"expl.detect(data, score, nclusters, N.est=NULL, seed=NULL, bwscale=1.1,     smooth=TRUE, use_sum_score=FALSE, hclust_method=\"ward.D\", estsample=NULL)"},{"path":"/reference/expl.detect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exploratory DETECT Analysis — expl.detect","text":"data \\(N \\times \\) data frame dichotomous polytomous responses. Missing responses allowed. score ability estimate, e.g. WLE, sum score mean score nclusters Maximum number clusters used exploratory analysis N.est Number students (possible) validation DETECT index. N.est students drawn random data. seed Random seed bwscale Bandwidth scale factor smooth Logical indicating whether smoothing applied conditional covariance estimation use_sum_score Logical indicating whether sum score used. option, bias corrected conditional covariance Zhang Stout (1999) used. hclust_method Clustering method used argument method stats::hclust. estsample Optional vector subject indices defines estimation sample","code":""},{"path":"/reference/expl.detect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exploratory DETECT Analysis — expl.detect","text":"list following entries detect.unweighted Unweighted DETECT statistics detect.weighted Weighted DETECT statistics. Weighting done proportionally sample sizes item pairs. clusterfit Fit cluster method itemcluster Cluster allocations use_sum_score","code":""},{"path":"/reference/expl.detect.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Exploratory DETECT Analysis — expl.detect","text":"Roussos, L. ., Stout, W. F., & Marden, J. . (1998). Using new proximity measures hierarchical cluster analysis detect multidimensionality. Journal Educational Measurement, 35, 1-30. Stout, W., Habing, B., Douglas, J., & Kim, H. R. (1996). Conditional covariance-based nonparametric multidimensionality assessment. Applied Psychological Measurement, 20, 331-354. Zhang, J., & Stout, W. (1999a). Conditional covariance structure generalized compensatory multidimensional items, Psychometrika, 64, 129-152. Zhang, J., & Stout, W. (1999b). theoretical DETECT index dimensionality application approximate simple structure, Psychometrika, 64, 213-249.","code":""},{"path":[]},{"path":"/reference/f1d.irt.html","id":null,"dir":"Reference","previous_headings":"","what":"Functional Unidimensional Item Response Model — f1d.irt","title":"Functional Unidimensional Item Response Model — f1d.irt","text":"Estimates functional unidimensional item response model dichotomous data (Ip, Molenberghs, Chen, Goegebeur & De Boeck, 2013). Either IRT model estimated using probit link employing tetrachoric correlations item discriminations intercepts pre-estimated multidimensional IRT model provided input.","code":""},{"path":"/reference/f1d.irt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functional Unidimensional Item Response Model — f1d.irt","text":"","code":"f1d.irt(dat=NULL, nnormal=1000, nfactors=3, A=NULL, intercept=NULL,     mu=NULL, Sigma=NULL, maxiter=100, conv=10^(-5), progress=TRUE)"},{"path":"/reference/f1d.irt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Functional Unidimensional Item Response Model — f1d.irt","text":"dat Data frame dichotomous item responses nnormal Number \\(\\theta_p\\) grid points approximating normal distribution nfactors Number dimensions estimated Matrix item discriminations (IRT model already estimated) intercept Vector item intercepts (IRT model already estimated) mu Vector estimated means. default assumed      means zero. Sigma Estimated covariance matrix. default identity matrix. maxiter Maximum number iterations conv Convergence criterion progress Display progress? default TRUE.","code":""},{"path":"/reference/f1d.irt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Functional Unidimensional Item Response Model — f1d.irt","text":"functional unidimensional item response model (F1D model) dichotomous item responses based multidimensional model link function \\(g\\) (probit logit): $$ P( X_{pi}=1 | \\bold{\\theta}_p )= g( \\sum_d a_{id} \\theta_{pd} - d_i ) $$ assumed \\(\\bold{\\theta}_p\\) multivariate normally distribution zero mean vector identity covariance matrix. F1D model estimates unidimensional item response functions $$ P( X_{pi}=1 | \\theta_p^\\ast ) \\approx g \\left( a_{}^\\ast \\theta_{p}^\\ast - d_i^\\ast \\right) $$ optimization function \\(F\\) minimizes deviations approximation equations $$ a_{}^\\ast \\theta_{p}^\\ast - d_i^\\ast \\approx \\sum_d a_{id} \\theta_{pd} - d_i $$ optimization function \\(F\\) defined $$ F( \\{ a_i^\\ast, d_i^\\ast \\}_i, \\{ \\theta_p^\\ast \\}_p )=     \\sum_p \\sum_i w_p ( a_{id} \\theta_{pd} - d_i- a_{}^\\ast \\theta_{p}^\\ast + d_i^\\ast )^2 \\rightarrow Min! $$ items \\(\\) equally weighted whereas ability distribution persons \\(p\\) weighted according multivariate normal distribution (using weights \\(w_p\\)). estimation conducted using alternating least squares algorithm (see Ip et al. 2013 different algorithm). ability distribution \\(\\theta_p^\\ast\\) functional unidimensional model assumed standardized, .e. zero mean standard deviation one.","code":""},{"path":"/reference/f1d.irt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Functional Unidimensional Item Response Model — f1d.irt","text":"list following entries: item Data frame estimated item parameters: Item intercepts     functional unidimensional \\(a_{}^\\ast\\) (ai.ast)     ('ordinary') unidimensional (ai0) item response     model. holds item intercepts \\(d_{}^\\ast\\) (di.ast     di0 respectively). person Data frame estimated \\(\\theta_p^\\ast\\)   distribution. Locations theta.ast corresponding   probabilities wgt. Estimated provided item discriminations intercept Estimated provided intercepts dat Used dataset tetra Object generated tetrachoric2 dat     specified input. list entry useful applying     greenyang.reliability.","code":""},{"path":"/reference/f1d.irt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Functional Unidimensional Item Response Model — f1d.irt","text":"Ip, E. H., Molenberghs, G., Chen, S. H., Goegebeur, Y., & De Boeck, P. (2013). Functionally unidimensional item response models multivariate binary data. Multivariate Behavioral Research, 48, 534-562.","code":""},{"path":[]},{"path":"/reference/f1d.irt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Functional Unidimensional Item Response Model — f1d.irt","text":"","code":"############################################################################# # EXAMPLE 1: Dataset Mathematics data.math | Exploratory multidimensional model ############################################################################# data(data.math) dat <- ( data.math$data )[, -c(1,2) ] # select Mathematics items  #**** # Model 1: Functional unidimensional model based on original data  #++ (1) estimate model with 3 factors mod1 <- sirt::f1d.irt( dat=dat, nfactors=3)  #++ (2) plot results      par(mfrow=c(1,2)) # Intercepts plot( mod1$item$di0, mod1$item$di.ast, pch=16, main=\"Item Intercepts\",         xlab=expression( paste( d[i], \" (Unidimensional Model)\" )),         ylab=expression( paste( d[i], \" (Functional Unidimensional Model)\" ))) abline( lm(mod1$item$di.ast ~ mod1$item$di0), col=2, lty=2 ) # Discriminations plot( mod1$item$ai0, mod1$item$ai.ast, pch=16, main=\"Item Discriminations\",         xlab=expression( paste( a[i], \" (Unidimensional Model)\" )),         ylab=expression( paste( a[i], \" (Functional Unidimensional Model)\" ))) abline( lm(mod1$item$ai.ast ~ mod1$item$ai0), col=2, lty=2 )      par(mfrow=c(1,1))  #++ (3) estimate bifactor model and Green-Yang reliability gy1 <- sirt::greenyang.reliability( mod1$tetra, nfactors=3 )  if (FALSE) { #**** # Model 2: Functional unidimensional model based on estimated multidimensional #          item response model  #++ (1) estimate 2-dimensional exploratory factor analysis with 'smirt' I <- ncol(dat) Q <- matrix( 1, I,2 ) Q[1,2] <- 0 variance.fixed <- cbind( 1,2,0 ) mod2a <- sirt::smirt( dat, Qmatrix=Q, irtmodel=\"comp\", est.a=\"2PL\",                 variance.fixed=variance.fixed, maxiter=50) #++ (2) input estimated discriminations and intercepts for #       functional unidimensional model mod2b <- sirt::f1d.irt( A=mod2a$a, intercept=mod2a$b )  ############################################################################# # EXAMPLE 2: Dataset Mathematics data.math | Confirmatory multidimensional model #############################################################################  data(data.math) library(TAM)  # dataset dat <- data.math$data dat <- dat[, grep(\"M\", colnames(dat) ) ] # extract item informations iteminfo <- data.math$item I <- ncol(dat) # define Q-matrix Q <- matrix( 0, nrow=I, ncol=3 ) Q[ grep( \"arith\", iteminfo$domain ), 1 ] <- 1 Q[ grep( \"Meas\", iteminfo$domain ), 2 ] <- 1 Q[ grep( \"geom\", iteminfo$domain ), 3 ] <- 1  # fit three-dimensional model in TAM mod1 <- TAM::tam.mml.2pl(  dat, Q=Q, control=list(maxiter=40, snodes=1000) ) summary(mod1)  # specify functional unidimensional model intercept <- mod1$xsi[, c(\"xsi\") ] names(intercept) <- rownames(mod1$xsi) fumod1 <- sirt::f1d.irt( A=mod1$B[,2,], intercept=intercept, Sigma=mod1$variance) fumod1$item }"},{"path":"/reference/fit.isop.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"Fit isotonic probabilistic model (ISOP; Scheiblechner, 1995) additive isotonic probabilistic model (ADISOP; Scheiblechner, 1999).","code":""},{"path":"/reference/fit.isop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"","code":"fit.isop(freq.correct, wgt, conv=1e-04, maxit=100,       progress=TRUE, calc.ll=TRUE)  fit.adisop(freq.correct, wgt, conv=1e-04, maxit=100,       epsilon=0.01, progress=TRUE, calc.ll=TRUE)"},{"path":"/reference/fit.isop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"freq.correct Frequency table wgt Weights frequency table (number persons cell) conv Convergence criterion maxit Maximum number iterations epsilon Additive constant handle cell frequencies 0 1 fit.adisop progress Display progress? calc.ll Calculate log-likelihood values? default TRUE.","code":""},{"path":"/reference/fit.isop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"See isop.dich details ISOP ADISOP model.","code":""},{"path":"/reference/fit.isop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"list following entries fX Fitted frequency table ResX Residual frequency table fit Fit statistic: weighted least squares   deviations observed expected frequencies item.sc Estimated item parameters person.sc Estimated person parameters ll Log-likelihood model freq.fitted Fitted frequencies long data frame","code":""},{"path":"/reference/fit.isop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"Scheiblechner, H. (1995). Isotonic ordinal probabilistic models (ISOP). Psychometrika, 60, 281-304. Scheiblechner, H. (1999). Additive conjoint isotonic probabilistic models (ADISOP). Psychometrika, 64, 295-316.","code":""},{"path":"/reference/fit.isop.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"fitting ADISOP model recommended first fit ISOP model proceed fitted frequency table ISOP (see Examples).","code":""},{"path":[]},{"path":"/reference/fit.isop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fitting the ISOP and ADISOP Model for Frequency Tables — fit.isop","text":"","code":"############################################################################# # EXAMPLE 1: Dataset Reading #############################################################################  data(data.read) dat <- as.matrix( data.read) dat.resp <- 1 - is.na(dat) # response indicator matrix I <- ncol(dat)  #*** # (1) Data preparation #     actually only freq.correct and wgt are needed #     but these matrices must be computed in advance.  # different scores of students stud.p <- rowMeans( dat, na.rm=TRUE ) # different item p values item.p <- colMeans( dat, na.rm=TRUE ) item.ps <- sort( item.p, index.return=TRUE) dat <- dat[,  item.ps$ix ] # define score groups students scores <- sort( unique( stud.p ) ) SC <- length(scores) # create table freq.correct <- matrix( NA, SC, I ) wgt <- freq.correct # percent correct a1 <- stats::aggregate( dat==1, list( stud.p ), mean, na.rm=TRUE ) freq.correct <- a1[,-1] # weights a1 <- stats::aggregate( dat.resp, list( stud.p ), sum, na.rm=TRUE ) wgt <- a1[,-1]  #*** # (2) Fit ISOP model res.isop <- sirt::fit.isop( freq.correct, wgt ) # fitted frequency table res.isop$fX  #*** # (3) Fit ADISOP model # use monotonely smoothed frequency table from ISOP model res.adisop <- sirt::fit.adisop( freq.correct=res.isop$fX, wgt ) # fitted frequency table res.adisop$fX"},{"path":"/reference/fuzcluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Clustering for Continuous Fuzzy Data — fuzcluster","title":"Clustering for Continuous Fuzzy Data — fuzcluster","text":"function performs clustering continuous fuzzy data membership functions assumed Gaussian (Denoeux, 2013). mixture also assumed Gaussian (conditionally cluster membership) independent.","code":""},{"path":"/reference/fuzcluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clustering for Continuous Fuzzy Data — fuzcluster","text":"","code":"fuzcluster(dat_m, dat_s, K=2, nstarts=7, seed=NULL, maxiter=100,      parmconv=0.001, fac.oldxsi=0.75, progress=TRUE)  # S3 method for fuzcluster summary(object,...)"},{"path":"/reference/fuzcluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clustering for Continuous Fuzzy Data — fuzcluster","text":"dat_m Centers individual item specific membership functions dat_s Standard deviations individual item specific membership functions K Number latent classes nstarts Number random starts. default 7 random starts. seed Simulation seed. one value provided, one start performed. maxiter Maximum number iterations parmconv Maximum absolute change parameters fac.oldxsi Convergence acceleration factor take values 0 1. default 0.75. progress optional logical indicating whether iteration progress displayed. object Object class fuzcluster ... arguments passed","code":""},{"path":"/reference/fuzcluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clustering for Continuous Fuzzy Data — fuzcluster","text":"list following entries deviance Deviance iter Number iterations pi_est Estimated class probabilities mu_est Cluster means sd_est Cluster standard deviations posterior Individual posterior distributions cluster membership seed Simulation seed cluster solution ic Information criteria","code":""},{"path":"/reference/fuzcluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Clustering for Continuous Fuzzy Data — fuzcluster","text":"Denoeux, T. (2013). Maximum likelihood estimation uncertain data belief function framework. IEEE Transactions Knowledge Data Engineering, 25, 119-130.","code":""},{"path":[]},{"path":"/reference/fuzcluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clustering for Continuous Fuzzy Data — fuzcluster","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: 2 classes and 3 items #############################################################################  #*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*- # simulate data (2 classes and 3 items) set.seed(876) library(mvtnorm) Ntot <- 1000  # number of subjects # define SDs for simulating uncertainty sd_uncertain <- c( .2, 1, 2 )  dat_m <- NULL   # data frame containing mean of membership function dat_s <- NULL   # data frame containing SD of membership function  # *** Class 1 pi_class <- .6 Nclass <- Ntot * pi_class mu <- c(3,1,0) Sigma <- diag(3) # simulate data dat_m1 <- mvtnorm::rmvnorm( Nclass, mean=mu, sigma=Sigma ) dat_s1 <- matrix( stats::runif( Nclass * 3 ), nrow=Nclass ) for ( ii in 1:3){ dat_s1[,ii] <- dat_s1[,ii] * sd_uncertain[ii] } dat_m <- rbind( dat_m, dat_m1 ) dat_s <- rbind( dat_s, dat_s1 )  # *** Class 2 pi_class <- .4 Nclass <- Ntot * pi_class mu <- c(0,-2,0.4) Sigma <- diag(c(0.5, 2, 2 ) ) # simulate data dat_m1 <- mvtnorm::rmvnorm( Nclass, mean=mu, sigma=Sigma ) dat_s1 <- matrix( stats::runif( Nclass * 3 ), nrow=Nclass ) for ( ii in 1:3){ dat_s1[,ii] <- dat_s1[,ii] * sd_uncertain[ii] } dat_m <- rbind( dat_m, dat_m1 ) dat_s <- rbind( dat_s, dat_s1 ) colnames(dat_s) <- colnames(dat_m) <- paste0(\"I\", 1:3 )  #*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*- # estimation  #*** Model 1: Clustering with 8 random starts res1 <- sirt::fuzcluster(K=2,dat_m, dat_s, nstarts=8, maxiter=25) summary(res1)   ##  Number of iterations=22 (Seed=5090 )   ##  ---------------------------------------------------   ##  Class probabilities (2 Classes)   ##  [1] 0.4083 0.5917   ##   ##  Means   ##           I1      I2     I3   ##  [1,] 0.0595 -1.9070 0.4011   ##  [2,] 3.0682  1.0233 0.0359   ##   ##  Standard deviations   ##         [,1]   [,2]   [,3]   ##  [1,] 0.7238 1.3712 1.2647   ##  [2,] 0.9740 0.8500 0.7523  #*** Model 2: Clustering with one start with seed 4550 res2 <- sirt::fuzcluster(K=2,dat_m, dat_s, nstarts=1, seed=5090 ) summary(res2)  #*** Model 3: Clustering for crisp data #             (assuming no uncertainty, i.e. dat_s=0) res3 <- sirt::fuzcluster(K=2,dat_m, dat_s=0*dat_s, nstarts=30, maxiter=25) summary(res3)   ##  Class probabilities (2 Classes)   ##  [1] 0.3645 0.6355   ##   ##  Means   ##           I1      I2      I3   ##  [1,] 0.0463 -1.9221  0.4481   ##  [2,] 3.0527  1.0241 -0.0008   ##   ##  Standard deviations   ##         [,1]   [,2]   [,3]   ##  [1,] 0.7261 1.4541 1.4586   ##  [2,] 0.9933 0.9592 0.9535  #*** Model 4: kmeans cluster analysis res4 <- stats::kmeans( dat_m, centers=2 )   ##   K-means clustering with 2 clusters of sizes 607, 393   ##   Cluster means:   ##             I1        I2          I3   ##   1 3.01550780  1.035848 -0.01662275   ##   2 0.03448309 -2.008209  0.48295067 }"},{"path":"/reference/fuzdiscr.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","title":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","text":"function estimates discrete distribution uncertain data based belief function framework (Denoeux, 2013; see Details).","code":""},{"path":"/reference/fuzdiscr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","text":"","code":"fuzdiscr(X, theta0=NULL, maxiter=200, conv=1e-04)"},{"path":"/reference/fuzdiscr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","text":"X Matrix fuzzy data. Rows corresponds subjects columns values membership function theta0 Initial vector parameter estimates maxiter Maximum number iterations conv Convergence criterion","code":""},{"path":"/reference/fuzdiscr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","text":"\\(n\\) subjects, membership functions \\(m_n(k)\\) observed indicate belief data \\(X_n=k\\). membership function interpreted epistemic uncertainty (Denoeux, 2011). However, associated parameters statistical models crisp means models formulated basis precise (crisp) data observed. present estimation problem discrete distribution, parameters interest category probabilities \\(\\theta_k=P( X=k)\\). parameter estimation follows evidential EM algorithm (Denoeux, 2013).","code":""},{"path":"/reference/fuzdiscr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","text":"Vector probabilities discrete distribution","code":""},{"path":"/reference/fuzdiscr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","text":"Denoeux, T. (2011). Maximum likelihood estimation fuzzy data using EM algorithm. Fuzzy Sets Systems, 183, 72-91. Denoeux, T. (2013). Maximum likelihood estimation uncertain data belief function framework. IEEE Transactions Knowledge Data Engineering, 25, 119-130.","code":""},{"path":"/reference/fuzdiscr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of a Discrete Distribution for Fuzzy Data (Data in Belief Function\r\nFramework) — fuzdiscr","text":"","code":"############################################################################# # EXAMPLE 1: Binomial distribution Denoeux Example 4.3 (2013) #############################################################################  #*** define uncertain data X_alpha <- function( alpha ){     Q <- matrix( 0, 6, 2 )     Q[5:6,2] <- Q[1:3,1] <- 1     Q[4,] <- c( alpha, 1 - alpha )     return(Q)         }  # define data for alpha=0.5 X <- X_alpha( alpha=.5 )   ##   > X   ##        [,1] [,2]   ##   [1,]  1.0  0.0   ##   [2,]  1.0  0.0   ##   [3,]  1.0  0.0   ##   [4,]  0.5  0.5   ##   [5,]  0.0  1.0   ##   [6,]  0.0  1.0    ## The fourth observation has equal plausibility for the first and the   ## second category.  # parameter estimate uncertain data fuzdiscr( X )   ##   > sirt::fuzdiscr( X )   ##   [1] 0.5999871 0.4000129  # parameter estimate pseudo likelihood colMeans( X )   ##   > colMeans( X )   ##   [1] 0.5833333 0.4166667 ##-> Observations are weighted according to belief function values.  #***** # plot parameter estimates as function of alpha alpha <- seq( 0, 1, len=100 ) res <- sapply( alpha, FUN=function(aa){              X <- X_alpha( alpha=aa )              c( sirt::fuzdiscr( X )[1], colMeans( X )[1] )                     } ) # plot plot( alpha, res[1,], xlab=expression(alpha), ylab=expression( theta[alpha] ), type=\"l\",         main=\"Comparison Belief Function and Pseudo-Likelihood (Example 1)\") lines( alpha, res[2,], lty=2, col=2) legend( 0, .67, c(\"Belief Function\", \"Pseudo-Likelihood\" ), col=c(1,2), lty=c(1,2) )  ############################################################################# # EXAMPLE 2: Binomial distribution (extends Example 1) #############################################################################  X_alpha <- function( alpha ){     Q <- matrix( 0, 6, 2 )     Q[6,2] <- Q[1:2,1] <- 1     Q[3:5,] <- matrix( c( alpha, 1 - alpha ), 3, 2, byrow=TRUE)     return(Q)         }  X <- X_alpha( alpha=.5 ) alpha <- seq( 0, 1, len=100 ) res <- sapply( alpha, FUN=function(aa){            X <- X_alpha( alpha=aa )            c( sirt::fuzdiscr( X )[1], colMeans( X )[1] )                     } ) # plot plot( alpha, res[1,], xlab=expression(alpha), ylab=expression( theta[alpha] ), type=\"l\",         main=\"Comparison Belief Function and Pseudo-Likelihood (Example 2)\") lines( alpha, res[2,], lty=2, col=2) legend( 0, .67, c(\"Belief Function\", \"Pseudo-Likelihood\" ), col=c(1,2), lty=c(1,2) )  ############################################################################# # EXAMPLE 3: Multinomial distribution with three categories #############################################################################  # define uncertain data X <- matrix( c( 1,0,0, 1,0,0,   0,1,0, 0,0,1, .7, .2, .1,          .4, .6, 0 ), 6, 3, byrow=TRUE )   ##   > X   ##        [,1] [,2] [,3]   ##   [1,]  1.0  0.0  0.0   ##   [2,]  1.0  0.0  0.0   ##   [3,]  0.0  1.0  0.0   ##   [4,]  0.0  0.0  1.0   ##   [5,]  0.7  0.2  0.1   ##   [6,]  0.4  0.6  0.0  ##->  Only the first four observations are crisp.  #*** estimation for uncertain data fuzdiscr( X )   ##   > sirt::fuzdiscr( X )   ##   [1] 0.5772305 0.2499931 0.1727764  #*** estimation pseudo-likelihood colMeans(X)   ##   > colMeans(X)   ##   [1] 0.5166667 0.3000000 0.1833333  ##-> Obviously, the treatment uncertainty is different in belief function ##   and in pseudo-likelihood framework."},{"path":"/reference/gom.em.html","id":null,"dir":"Reference","previous_headings":"","what":"Discrete (Rasch) Grade of Membership Model — gom.em","title":"Discrete (Rasch) Grade of Membership Model — gom.em","text":"function estimates grade membership model (Erosheva, Fienberg & Joutard, 2007; also called mixed membership model) EM algorithm assuming discrete membership score distribution. function restricted dichotomous item responses.","code":""},{"path":"/reference/gom.em.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Discrete (Rasch) Grade of Membership Model — gom.em","text":"","code":"gom.em(dat, K=NULL, problevels=NULL, weights=NULL, model=\"GOM\", theta0.k=seq(-5,5,len=15),     xsi0.k=exp(seq(-6, 3, len=15)), max.increment=0.3, numdiff.parm=1e-4,     maxdevchange=1e-6, globconv=1e-4, maxiter=1000, msteps=4, mstepconv=0.001,     theta_adjust=FALSE, lambda.inits=NULL, lambda.index=NULL, pi.k.inits=NULL,     newton_raphson=TRUE, optimizer=\"nlminb\", progress=TRUE)  # S3 method for gom summary(object, file=NULL, ...)  # S3 method for gom anova(object,...)  # S3 method for gom logLik(object,...)  # S3 method for gom IRT.irfprob(object,...)  # S3 method for gom IRT.likelihood(object,...)  # S3 method for gom IRT.posterior(object,...)  # S3 method for gom IRT.modelfit(object,...)  # S3 method for IRT.modelfit.gom summary(object,...)"},{"path":"/reference/gom.em.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Discrete (Rasch) Grade of Membership Model — gom.em","text":"dat Data frame dichotomous responses K Number classes (applies model=\"GOM\") problevels Vector containing probability levels membership functions (applies model=\"GOM\"). specific space probability levels estimated, matrix can supplied (see Example 1, Model 2a). weights Optional vector sampling weights model type grade membership model. default \"GOM\" nonparametric grade membership model. parametric multivariate normal representation can requested \"GOMnormal\". probabilities membership functions specifications described Details called via \"GOMRasch\". theta0.k Vector \\(\\tilde{\\theta}_k\\) grid (applies model=\"GOMRasch\") xsi0.k Vector \\(\\xi_p\\) grid (applies model=\"GOMRasch\") max.increment Maximum increment numdiff.parm Numerical differentiation parameter maxdevchange Convergence criterion change relative deviance globconv Global convergence criterion parameter change maxiter Maximum number iterations msteps Number iterations within M step mstepconv Convergence criterion within M step theta_adjust Logical indicating whether multivariate normal distribution adaptively chosen EM algorithm. lambda.inits Initial values item parameters lambda.index Optional integer matrix integers indicating equality constraints among \\(\\lambda\\) item parameters pi.k.inits Initial values distribution parameters newton_raphson Logical indicating whether Newton-Raphson used final iterations optimizer Type optimizer. Can \"optim\" \"nlminb\". progress Display iteration progress? Default TRUE. object Object class gom file Optional file name summary output ... arguments passed","code":""},{"path":"/reference/gom.em.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Discrete (Rasch) Grade of Membership Model — gom.em","text":"item response model grade membership model (Erosheva, Fienberg & Junker, 2002; Erosheva, Fienberg & Joutard, 2007) \\(K\\) classes dichotomous correct responses \\(X_{pi}\\) person \\(p\\) item \\(\\) follows (model=\"GOM\") $$     P(X_{pi}=1 | g_{p1}, \\ldots, g_{pK} )=\\sum_k \\lambda_{ik} g_{pk} \\quad, \\quad \\sum_{k=1}^K g_{pk}=1 \\quad, \\quad 0 \\leq g_{pk} \\leq 1                 $$ applications (e.g. Erosheva et al., 2007), grade membership function \\(\\{g_{pk}\\}\\) assumed follow Dirichlet distribution. gom.em implementation membership function assumed discretely represented grid \\(u=(u_1, \\ldots, u_L)\\) entries 0 1 (e.g. seq(0,1,length=5) \\(L=5\\)). values \\(g_{pk}\\) membership function can take values \\(\\{ u_1, \\ldots, u_L \\}\\) restriction \\(\\sum_k g_{pk} \\sum_l \\bold{1}(g_{pk}=u_l )=1\\). grid \\(u\\) specified using argument problevels. Rasch grade membership model (model=\"GOMRasch\") poses constraints probabilities \\(\\lambda_{ik}\\) membership functions \\(g_{pk}\\). membership function person \\(p\\) parameterized location parameter \\(\\theta_p\\) variability parameter \\(\\xi_p\\). class \\(k\\) represented location parameter \\(\\tilde{\\theta}_k\\). membership function defined $$ g_{pk} \\propto \\exp \\left[ - \\frac{ (\\theta_p - \\tilde{\\theta}_k)^2 }{2 \\xi_p^2 } \\right] $$ person parameter \\(\\theta_p\\) indicates usual 'ability', \\(\\xi_p\\) describes individual tendency change classes \\(1,\\ldots,K\\) corresponding locations \\(\\tilde{\\theta}_1, \\ldots,\\tilde{\\theta}_K\\). extremal class probabilities \\(\\lambda_{ik}\\) follow Rasch model $$ \\lambda_{ik}=invlogit( \\tilde{\\theta}_k - b_i  )= \\frac{ \\exp( \\tilde{\\theta}_k - b_i ) }{ 1 + \\exp( \\tilde{\\theta}_k - b_i ) }$$ Putting assumptions together leads model equation $$     P(X_{pi}=1 | g_{p1}, \\ldots, g_{pK} )=     P(X_{pi}=1 | \\theta_p, \\xi_p  )=         \\sum_k \\frac{ \\exp( \\tilde{\\theta}_k - b_i ) }{ 1 + \\exp(\\tilde{\\theta}_k - b_i ) }         \\cdot \\exp \\left[ - \\frac{ (\\theta_p - \\tilde{\\theta}_k)^2 }{2 \\xi_p^2 } \\right]                 $$ extreme case small \\(\\xi_p=\\varepsilon > 0\\) \\(\\theta_p=\\theta_0\\), Rasch model obtained $$     P(X_{pi}=1 | \\theta_p, \\xi_p  )=     P(X_{pi}=1 | \\theta_0, \\varepsilon  )=         \\frac{ \\exp( \\theta_0 - b_i ) }{ 1 + \\exp( \\theta_0 - b_i ) }                 $$ See Erosheva et al. (2002), Erosheva (2005, 2006) Galyart (2015) comparison grade membership models latent trait models latent class models. grade membership model also published name Bernoulli aspect model, see Bingham, Kaban Fortelius (2009).","code":""},{"path":"/reference/gom.em.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Discrete (Rasch) Grade of Membership Model — gom.em","text":"list following entries: deviance Deviance ic Information criteria item Data frame item parameters person Data frame person parameters EAP.rel EAP reliability (applies model=\"GOMRasch\") MAP Maximum aposteriori estimate membership function EAP EAP estimate individual membership scores classdesc Descriptives class membership lambda Estimated response probabilities \\(\\lambda_{ik}\\) se.lambda Standard error estimated response probabilities \\(\\lambda_{ik}\\) mu Mean distribution \\((\\theta_p, \\xi_p)\\)     (applies model=\"GOMRasch\") Sigma Covariance matrix \\((\\theta_p, \\xi_p)\\)     (applies model=\"GOMRasch\") b Estimated item difficulties (applies model=\"GOMRasch\") se.b Standard error estimated difficulties (applies model=\"GOMRasch\") f.yi.qk Individual likelihood f.qk.yi Individual posterior probs Array response probabilities n.ik Expected counts iter Number iterations Number items K Number classes TP Number discrete integration points \\((g_{p1},...,g_{pK})\\) theta.k Used grid membership functions ... values","code":""},{"path":"/reference/gom.em.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Discrete (Rasch) Grade of Membership Model — gom.em","text":"Bingham, E., Kaban, ., & Fortelius, M. (2009). aspect Bernoulli model: multiple causes presences absences. Pattern Analysis Applications, 12(1), 55-78. Erosheva, E. . (2005). Comparing latent structures grade membership, Rasch, latent class models. Psychometrika, 70, 619-628. Erosheva, E. . (2006). Latent class representation grade membership model. Seattle: University Washington. Erosheva, E. ., Fienberg, S. E., & Junker, B. W. (2002). Alternative statistical models representations large sparse multi-dimensional contingency tables. Annales-Faculte Des Sciences Toulouse Mathematiques, 11, 485-505. Erosheva, E. ., Fienberg, S. E., & Joutard, C. (2007). Describing disability individual-level mixture models multivariate binary data. Annals Applied Statistics, 1, 502-537. Galyardt, . (2015). Interpreting mixed membership models: Implications Erosheva's representation theorem. E. M. Airoldi, D. Blei, E. . Erosheva, & S. E. Fienberg (Eds.). Handbook Mixed Membership Models (pp. 39-65). Chapman & Hall.","code":""},{"path":[]},{"path":[]},{"path":"/reference/gom.jml.html","id":null,"dir":"Reference","previous_headings":"","what":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","title":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","text":"function estimates grade membership model employing joint maximum likelihood estimation method (Erosheva, 2002; p. 23ff.).","code":""},{"path":"/reference/gom.jml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","text":"","code":"gom.jml(dat, K=2, seed=NULL, globconv=0.001, maxdevchange=0.001,         maxiter=600, min.lambda=0.001, min.g=0.001)"},{"path":"/reference/gom.jml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","text":"dat Data frame dichotomous item responses K Number classes seed Seed value random number generator. Deterministic starting values     used default value NULL. globconv Global parameter convergence criterion maxdevchange Maximum change relative deviance maxiter Maximum number iterations min.lambda Minimum \\(\\lambda_{ik}\\) parameter estimated min.g Minimum \\(g_{pk}\\) parameter estimated","code":""},{"path":"/reference/gom.jml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","text":"item response model grade membership model \\(K\\) classes dichotomous correct responses \\(X_{pi}\\) person \\(p\\) item \\(\\) $$     P(X_{pi}=1 | g_{p1}, \\ldots, g_{pK} )=\\sum_k \\lambda_{ik} g_{pk} \\quad, \\quad \\sum_k g_{pk}=1                 $$","code":""},{"path":"/reference/gom.jml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","text":"list following entries: lambda Data frame item parameters \\(\\lambda_{ik}\\) g Data frame individual membership scores \\(g_{pk}\\) g.mean Mean membership scores gcut Discretized membership scores gcut.distr Distribution discretized membership scores K Number classes deviance Deviance ic Information criteria N Number students score Person score iter Number iterations datproc List processed data (recoded data, starting values, ...) ... values","code":""},{"path":"/reference/gom.jml.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","text":"Erosheva, E. . (2002). Grade membership latent structure models application disability survey data. PhD thesis, Carnegie Mellon University, Department Statistics.","code":""},{"path":[]},{"path":"/reference/gom.jml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Grade of Membership Model (Joint Maximum Likelihood Estimation) — gom.jml","text":"","code":"############################################################################# # EXAMPLE 1: TIMSS data #############################################################################  data( data.timss) dat <- data.timss$data[, grep(\"M\", colnames(data.timss$data) ) ]  # 2 Classes (deterministic starting values) m2 <- sirt::gom.jml(dat,K=2, maxiter=10 ) summary(m2)  if (FALSE) { # 3 Classes with fixed seed and maximum number of iterations m3 <- sirt::gom.jml(dat,K=3, maxiter=50,seed=89) summary(m3) }"},{"path":"/reference/greenyang.reliability.html","id":null,"dir":"Reference","previous_headings":"","what":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","title":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","text":"function estimates model-based reliability dichotomous data using Green & Yang (2009) method. underlying factor model \\(D\\)-dimensional dimension \\(D\\) specified argument nfactors. factor solution subject application Schmid-Leiman transformation (see Reise, 2012; Reise, Bonifay, & Haviland, 2013; Reise, Moore, & Haviland, 2010).","code":""},{"path":"/reference/greenyang.reliability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","text":"","code":"greenyang.reliability(object.tetra, nfactors)"},{"path":"/reference/greenyang.reliability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","text":"object.tetra Object output function tetrachoric, fa.parallel.poly psych package tetrachoric2 function (sirt). object can also created list user tetrachoric correlation must must list entry rho thresholds must list entry thresh. nfactors Number factors (dimensions)","code":""},{"path":"/reference/greenyang.reliability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","text":"data frame columns: coefficient Name reliability measure. omega_1 (Omega) reliability estimate total score dichotomous data based one-factor model, omega_t (Omega Total) estimate \\(D\\)-dimensional model. nested factor model, omega_h (Omega Asymptotic) reliability general factor model, omega_ha (Omega Hierarchical Asymptotic) eliminates item-specific variance. explained common variance (ECV) explained common factor based \\(D\\)-dimensional take item thresholds account. amount explained variance ExplVar defined quotient first eigenvalue tetrachoric correlation matrix sum eigenvalues. statistic EigenvalRatio ratio first second eigenvalue. dimensions Number dimensions estimate Reliability estimate","code":""},{"path":"/reference/greenyang.reliability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","text":"Green, S. B., & Yang, Y. (2009). Reliability summed item scores using structural equation modeling: alternative coefficient alpha. Psychometrika, 74, 155-167. Reise, S. P. (2012). rediscovery bifactor measurement models. Multivariate Behavioral Research, 47, 667-696. Reise, S. P., Bonifay, W. E., & Haviland, M. G. (2013). Scoring modeling psychological measures presence multidimensionality. Journal Personality Assessment, 95, 129-140. Reise, S. P., Moore, T. M., & Haviland, M. G.  (2010). Bifactor models rotations: Exploring extent multidimensional data yield univocal scale scores, Journal Personality Assessment, 92, 544-559.","code":""},{"path":"/reference/greenyang.reliability.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","text":"function needs psych package.","code":""},{"path":[]},{"path":"/reference/greenyang.reliability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reliability for Dichotomous Item Response Data\r\nUsing the Method of Green and Yang (2009) — greenyang.reliability","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Reliability estimation of Reading dataset data.read ############################################################################# miceadds::library_install(\"psych\") set.seed(789) data( data.read ) dat <- data.read  # calculate matrix of tetrachoric correlations dat.tetra <- psych::tetrachoric(dat)      # using tetrachoric from psych package dat.tetra2 <- sirt::tetrachoric2(dat)       # using tetrachoric2 from sirt package  # perform parallel factor analysis fap <- psych::fa.parallel.poly(dat, n.iter=1 )   ##   Parallel analysis suggests that the number of factors=3   ##   and the number of components=2  # parallel factor analysis based on tetrachoric correlation matrix ##       (tetrachoric2) fap2 <- psych::fa.parallel(dat.tetra2$rho, n.obs=nrow(dat),  n.iter=1 )   ## Parallel analysis suggests that the number of factors=6   ## and the number of components=2   ## Note that in this analysis, uncertainty with respect to thresholds is ignored.  # calculate reliability using a model with 4 factors greenyang.reliability( object.tetra=dat.tetra, nfactors=4 )   ##                                            coefficient dimensions estimate   ## Omega Total (1D)                               omega_1          1    0.771   ## Omega Total (4D)                               omega_t          4    0.844   ## Omega Hierarchical (4D)                        omega_h          4    0.360   ## Omega Hierarchical Asymptotic (4D)            omega_ha          4    0.427   ## Explained Common Variance (4D)                     ECV          4    0.489   ## Explained Variance (First Eigenvalue)          ExplVar         NA   35.145   ## Eigenvalue Ratio (1st to 2nd Eigenvalue) EigenvalRatio         NA    2.121  # calculation of Green-Yang-Reliability based on tetrachoric correlations #   obtained by tetrachoric2 greenyang.reliability( object.tetra=dat.tetra2, nfactors=4 )  # The same result will be obtained by using fap as the input greenyang.reliability( object.tetra=fap, nfactors=4 ) }"},{"path":"/reference/invariance.alignment.html","id":null,"dir":"Reference","previous_headings":"","what":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","title":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","text":"function invariance.alignment performs alignment approximate invariance \\(G\\) groups \\(\\) items (Asparouhov & Muthen, 2014; Byrne & van de Vijver, 2017; DeMars, 2020; Finch, 2016; Fischer & Karl, 2019; Flake & McCoach, 2018; Kim et al., 2017; Marsh et al., 2018; Muthen & Asparouhov, 2014, 2018; Pokropek, Davidov & Schmidt, 2019). assumed item loadings intercepts previously estimated unidimensional factor model assumption factor zero mean variance one. function invariance_alignment_constraints postprocesses output invariance.alignment function estimates item parameters equality constraints prespecified absolute values parameter tolerance. function invariance_alignment_simulate simulates one-factor model multiple groups given matrices \\(\\nu\\) \\(\\lambda\\) parameters item intercepts item slopes (see Example 6). function invariance_alignment_cfa_config estimates one-factor models separately group preliminary step invariance alignment (see Example 6). Sampling weights accommodated argument weights.  computed variance matrix vcov function can used obtain standard errors invariance.alignment function supplied argument vcov.","code":""},{"path":"/reference/invariance.alignment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","text":"","code":"invariance.alignment(lambda, nu, wgt=NULL, align.scale=c(1, 1),     align.pow=c(.5, .5), eps=1e-3, psi0.init=NULL, alpha0.init=NULL, center=FALSE,     optimizer=\"optim\", fixed=NULL, meth=1, vcov=NULL, eps_grid=seq(0,-10, by=-.5),     num_deriv=FALSE, ...)  # S3 method for invariance.alignment summary(object, digits=3, file=NULL, ...)  invariance_alignment_constraints(model, lambda_parm_tol, nu_parm_tol )  # S3 method for invariance_alignment_constraints summary(object, digits=3, file=NULL, ...)  invariance_alignment_simulate(nu, lambda, err_var, mu, sigma, N, output=\"data\",      groupwise=FALSE, exact=FALSE)  invariance_alignment_cfa_config(dat, group, weights=NULL, model=\"2PM\", verbose=FALSE, ...)"},{"path":"/reference/invariance.alignment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","text":"lambda \\(G \\times \\) matrix item loadings nu \\(G \\times \\) matrix item intercepts wgt \\(G \\times \\) matrix weighing groups item align.scale vector length two containing scale parameter \\(a_\\lambda\\) \\(a_\\nu\\) (see Details) align.pow vector length two containing power \\(p_\\lambda\\) \\(p_\\nu\\) (see Details) eps parameter optimization function psi0.init optional vector initial \\(\\psi_0\\) parameters alpha0.init optional vector initial \\(\\alpha_0\\) parameters center Logical indicating whether estimated means standard deviations centered. optimizer Name optimizer chosen alignment. Options    \"optim\" (using stats::optim)    \"nlminb\" (using stats::nlminb). fixed Logical indicating whether SD first group fixed one. fixed=FALSE, product SDs set one. NULL, fixed automatically chosen default. many groups, fixed=FALSE chosen. meth Type method used optimization function. meth=1 default optimization function used Mplus. meth=2 uses logarithmized item loadings alignment. choice meth=4 uses constraint \\(\\prod_g \\psi_g=1\\) adds penalty \\(\\lambda \\sum_g \\alpha_g^2\\) fixed value \\(\\lambda\\) depends weights wgt (similar Mplus' free method). choice meth=3 uses constraint \\(\\prod_g \\psi_g=1\\) (similar Mplus' FIXED method). vcov Variance matrix produced invariance_alignment_cfa_config standard error computation. matrix provided, standard errors computed. eps_grid Grid logarithmized epsilon values optimization num_deriv Logical indicating whether numerical derivatives used object Object class invariance.alignment digits Number digits used rounding file Optional file name summary sunk ... optional arguments passed model Model class invariance.alignment. invariance_alignment_cfa_config: Model type: \"2PM\" two-parameter model unequal loadings \"1PM\" equal loadings equal residual variances lambda_parm_tol Parameter tolerance \\(\\lambda\\) parameters nu_parm_tol Parameter tolerance \\(\\nu\\) parameters err_var Error variance mu Vector means sigma Vector standard deviations N Vector sample sizes per group output Specifies output type: \"data\" dataset \"suffstat\" sufficient statistics (.e., means covariance matrices) groupwise Logical indicating whether group-wise output requested exact Logical indicating whether distributions exactly preserved simulated data dat Dataset items list containing sufficient statistics group Vector containing group indicators weights Optional vector sampling weights verbose Logical indicating whether progress printed","code":""},{"path":"/reference/invariance.alignment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","text":"\\(G\\) groups \\(\\) items, item loadings \\(\\lambda_{ig0}\\) intercepts \\(\\nu_{ig0}\\) available estimated 1-dimensional factor analysis assuming standardized factor. alignment procedure searches means \\(\\alpha_{g0}\\) standard deviations \\(\\psi_{g0}\\) using alignment optimization function \\(F\\). function defined $$F=\\sum_i \\sum_{ g_1 < g_2} w_{,g1} w_{,g2}     f_\\lambda( \\lambda_{g_1,1} - \\lambda_{g_2,1} )     + \\sum_i \\sum_{ g_1 < g_2} w_{,g1} w_{,g2} f_\\nu( \\nu_{g_1,1} - \\nu_{g_2,1} ) $$ aligned item parameters \\(\\lambda_{g,1}\\) \\(\\nu_{g,1}\\) defined $$ \\lambda_{g,1}=\\lambda_{g 0} / \\psi_{g0}     \\qquad \\mbox{} \\qquad     \\nu_{g,1}=\\nu_{g 0} -  \\alpha_{g0} \\lambda_{ig0} / \\psi_{g0}             $$ optimization functions defined $$ f_\\lambda (x)=| x/ a_\\lambda | ^{p_\\lambda} \\approx [ ( x/ a_\\lambda )^2 + \\varepsilon ]^{p_\\lambda / 2}     \\qquad \\mbox{} \\qquad     f_\\nu (x)=|  x/ a_\\nu ]^{p_\\nu}     \\approx [ ( x/ a_\\nu )^2 + \\varepsilon ]^{p_\\nu / 2}             $$ using small \\( \\varepsilon > 0\\) (e.g. .001) obtain differentiable optimization function. \\(p_\\nu=0\\) \\(p_\\lambda=0\\), optimization function essentially counts number different parameter mimicks \\(L_0\\) penalty zero iff argument zero one otherwise. approximated $$f(x)=x^2 (x^2 + \\varepsilon )^{-1} $$ (O'Neill & Burke, 2023). identification reasons, product \\(\\Pi_g \\psi_{g0}\\) (meth=0,0.5) group standard deviations \\(\\psi_1\\) (meth=1,2) set one. mean \\(\\alpha_{g0}\\) first group set zero (meth=0.5,1,2) penalty function added linking function (meth=0). Note Asparouhov Muthen (2014) use \\(a_\\lambda=a_\\nu=1\\) (can modified align.scale) \\(p_\\lambda=p_\\nu=0.5\\) (can modified align.pow). case \\(p_\\lambda=2\\), penalty approximately \\(f_\\lambda(x)=x^2 \\), case \\(p_\\lambda=0.5\\) approximately \\(f_\\lambda(x)=\\sqrt{|x|} \\). Note sirt used different parametrization versions 3.5. \\(p\\) parameters halved consistency previous versions (e.g., Asparouhov & Muthen parametrization corresponds \\(p=.25\\); see also Fischer & Karl, 2019, application previous parametrization). Effect sizes approximate invariance based \\(R^2\\) proposed Asparouhov Muthen (2014). calculated separately item loading intercepts, resulting \\(R^2_\\lambda\\) \\(R^2_\\nu\\) measures included output es.invariance. addition, average correlation aligned item parameters among groups (rbar) reported. Metric invariance means aligned item loadings \\(\\lambda_{ig,1}\\) equal across groups therefore \\(R^2_\\lambda=1\\). Scalar invariance means aligned item loadings \\(\\lambda_{ig,1}\\) aligned item intercepts \\(\\nu_{ig,1}\\) equal across groups therefore \\(R^2_\\lambda=1\\) \\(R^2_\\nu=1\\) (see Vandenberg & Lance, 2000).","code":""},{"path":"/reference/invariance.alignment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","text":"list following entries pars Aligned distribution parameters itempars.aligned Aligned item parameters groups es.invariance Effect sizes approximate invariance lambda.aligned Aligned \\( \\lambda_{g,1}\\) parameters lambda.resid Residuals \\( \\lambda_{g,1}\\) parameters nu.aligned Aligned \\( \\nu_{g,1}\\) parameters nu.resid Residuals \\( \\nu_{g,1}\\) parameters Niter Number iterations \\(f_\\lambda\\) \\(f_\\nu\\) optimization functions fopt Minimum optimization value align.scale Used alignment scale parameters align.pow Used alignment power parameters vcov Estimated variance matrix aligned means standard deviations","code":""},{"path":"/reference/invariance.alignment.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","text":"Asparouhov, T., & Muthen, B. (2014). Multiple-group factor analysis alignment. Structural Equation Modeling, 21(4), 1-14. doi:10.1080/10705511.2014.919210 Byrne, B. M., & van de Vijver, F. J. R. (2017). maximum likelihood alignment approach testing approximate measurement invariance: paradigmatic cross-cultural application. Psicothema, 29(4), 539-551. doi:10.7334/psicothema2017.178 DeMars, C. E. (2020). Alignment alternative anchor purification DIF analyses. Structural Equation Modeling, 27(1), 56-72. doi:10.1080/10705511.2019.1617151 Finch, W. H. (2016). Detection differential item functioning two groups: Monte Carlo comparison methods. Applied Measurement Education, 29,(1), 30-45, doi:10.1080/08957347.2015.1102916 Fischer, R., & Karl, J. . (2019). primer (cross-cultural) multi-group invariance testing possibilities R. Frontiers Psychology | Cultural Psychology, 10:1507. doi:10.3389/fpsyg.2019.01507 Flake, J. K., & McCoach, D. B. (2018). investigation alignment method polytomous indicators conditions partial measurement invariance. Structural Equation Modeling, 25(1), 56-70. doi:10.1080/10705511.2017.1374187 Kim, E. S., Cao, C., Wang, Y., & Nguyen, D. T. (2017). Measurement invariance testing many groups: comparison five approaches. Structural Equation Modeling, 24(4), 524-544. doi:10.1080/10705511.2017.1304822 Marsh, H. W., Guo, J., Parker, P. D., Nagengast, B., Asparouhov, T., Muthen, B., & Dicke, T. (2018). scalar invariance fails: extended alignment method multi-group factor analysis comparison latent means across many groups. Psychological Methods, 23(3), 524-545. doi: 10.1037/met0000113 Muthen, B., & Asparouhov, T. (2014). IRT studies many groups: alignment method. Frontiers Psychology | Quantitative Psychology Measurement, 5:978. doi:10.3389/fpsyg.2014.00978 Muthen, B., & Asparouhov, T. (2018). Recent methods study measurement invariance many groups: Alignment random effects. Sociological Methods & Research, 47(4), 637-664. doi:10.1177/0049124117701488 O'Neill, M., & Burke, K. (2023). Variable selection using smooth information criterion distributional regression models. Statistics Computing, 33(3), 71. doi:10.1007/s11222-023-10204-8 Pokropek, ., Davidov, E., & Schmidt, P. (2019). Monte Carlo simulation study assess appropriateness traditional newer approaches test measurement invariance. Structural Equation Modeling, 26(5), 724-744. doi:10.1080/10705511.2018.1561293 Vandenberg, R. J., & Lance, C. E. (2000). review synthesis measurement invariance literature: Suggestions, practices, recommendations organizational research. Organizational Research Methods, 3, 4-70. doi:10.1177/109442810031002 s","code":""},{"path":[]},{"path":"/reference/invariance.alignment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Alignment Procedure for Linking under Approximate Invariance — invariance.alignment","text":"","code":"############################################################################# # EXAMPLE 1: Item parameters cultural activities #############################################################################  data(data.activity.itempars, package=\"sirt\") lambda <- data.activity.itempars$lambda nu <- data.activity.itempars$nu Ng <-  data.activity.itempars$N wgt <- matrix( sqrt(Ng), length(Ng), ncol(nu) )  #*** # Model 1: Alignment using a quadratic loss function mod1 <- sirt::invariance.alignment( lambda, nu, wgt, align.pow=c(2,2) ) summary(mod1)  #**** # Model 2: Different powers for alignment mod2 <- sirt::invariance.alignment( lambda, nu, wgt,  align.pow=c(.5,1),               align.scale=c(.95,.95)) summary(mod2)  # compare means from Models 1 and 2 plot( mod1$pars$alpha0, mod2$pars$alpha0, pch=16,     xlab=\"M (Model 1)\", ylab=\"M (Model 2)\", xlim=c(-.3,.3), ylim=c(-.3,.3) ) lines( c(-1,1), c(-1,1), col=\"gray\") round( cbind( mod1$pars$alpha0, mod2$pars$alpha0 ), 3 ) round( mod1$nu.resid, 3) round( mod2$nu.resid,3 )  # L0 penalty mod2b <- sirt::invariance.alignment( lambda, nu, wgt,  align.pow=c(0,0),               align.scale=c(.3,.3)) summary(mod2b)  #**** # Model 3: Low powers for alignment of scale and power # Note that setting increment.factor larger than 1 seems necessary mod3 <- sirt::invariance.alignment( lambda, nu, wgt, align.pow=c(.5,.75),             align.scale=c(.55,.55), psi0.init=mod1$psi0, alpha0.init=mod1$alpha0 ) summary(mod3)  # compare mean and SD estimates of Models 1 and 3 plot( mod1$pars$alpha0, mod3$pars$alpha0, pch=16) plot( mod1$pars$psi0, mod3$pars$psi0, pch=16)  # compare residuals for Models 1 and 3 # plot lambda plot( abs(as.vector(mod1$lambda.resid)), abs(as.vector(mod3$lambda.resid)),       pch=16, xlab=\"Residuals lambda (Model 1)\",       ylab=\"Residuals lambda (Model 3)\", xlim=c(0,.1), ylim=c(0,.1)) lines( c(-3,3),c(-3,3), col=\"gray\") # plot nu plot( abs(as.vector(mod1$nu.resid)), abs(as.vector(mod3$nu.resid)),       pch=16, xlab=\"Residuals nu (Model 1)\", ylab=\"Residuals nu (Model 3)\",       xlim=c(0,.4),ylim=c(0,.4)) lines( c(-3,3),c(-3,3), col=\"gray\")  if (FALSE) { ############################################################################# # EXAMPLE 2: Comparison 4 groups | data.inv4gr #############################################################################  data(data.inv4gr) dat <- data.inv4gr miceadds::library_install(\"semTools\")  model1 <- \"     F=~ I01 + I02 + I03 + I04 + I05 + I06 + I07 + I08 + I09 + I10 + I11     F ~~ 1*F     \"  res <- semTools::measurementInvariance(model1, std.lv=TRUE, data=dat, group=\"group\")   ##   Measurement invariance tests:   ##   ##   Model 1: configural invariance:   ##       chisq        df    pvalue       cfi     rmsea       bic   ##     162.084   176.000     0.766     1.000     0.000 95428.025   ##   ##   Model 2: weak invariance (equal loadings):   ##       chisq        df    pvalue       cfi     rmsea       bic   ##     519.598   209.000     0.000     0.973     0.039 95511.835   ##   ##   [Model 1 versus model 2]   ##     delta.chisq      delta.df delta.p.value     delta.cfi   ##         357.514        33.000         0.000         0.027   ##   ##   Model 3: strong invariance (equal loadings + intercepts):   ##       chisq        df    pvalue       cfi     rmsea       bic   ##    2197.260   239.000     0.000     0.828     0.091 96940.676   ##   ##   [Model 1 versus model 3]   ##     delta.chisq      delta.df delta.p.value     delta.cfi   ##        2035.176        63.000         0.000         0.172   ##   ##   [Model 2 versus model 3]   ##     delta.chisq      delta.df delta.p.value     delta.cfi   ##        1677.662        30.000         0.000         0.144   ##  # extract item parameters separate group analyses ipars <- lavaan::parameterEstimates(res$fit.configural) # extract lambda's: groups are in rows, items in columns lambda <- matrix( ipars[ ipars$op==\"=~\", \"est\"], nrow=4,  byrow=TRUE) colnames(lambda) <- colnames(dat)[-1] # extract nu's nu <- matrix( ipars[ ipars$op==\"~1\"  & ipars$se !=0, \"est\" ], nrow=4,  byrow=TRUE) colnames(nu) <- colnames(dat)[-1]  # Model 1: least squares optimization mod1 <- sirt::invariance.alignment( lambda=lambda, nu=nu ) summary(mod1)   ##   Effect Sizes of Approximate Invariance   ##          loadings intercepts   ##   R2       0.9826     0.9972   ##   sqrtU2   0.1319     0.0526   ##   rbar     0.6237     0.7821   ##   -----------------------------------------------------------------   ##   Group Means and Standard Deviations   ##     alpha0  psi0   ##   1  0.000 0.965   ##   2 -0.105 1.098   ##   3 -0.081 1.011   ##   4  0.171 0.935  # Model 2: sparse target function mod2 <- sirt::invariance.alignment( lambda=lambda, nu=nu, align.pow=c(.5,.5) ) summary(mod2)   ##   Effect Sizes of Approximate Invariance   ##          loadings intercepts   ##   R2       0.9824     0.9972   ##   sqrtU2   0.1327     0.0529   ##   rbar     0.6237     0.7856   ##   -----------------------------------------------------------------   ##   Group Means and Standard Deviations   ##     alpha0  psi0   ##   1 -0.002 0.965   ##   2 -0.107 1.098   ##   3 -0.083 1.011   ##   4  0.170 0.935  ############################################################################# # EXAMPLE 3: European Social Survey data.ess2005 #############################################################################  data(data.ess2005) lambda <- data.ess2005$lambda nu <- data.ess2005$nu  # Model 1: least squares optimization mod1 <- sirt::invariance.alignment( lambda=lambda, nu=nu, align.pow=c(2,2) ) summary(mod1)  # Model 2: sparse target function and definition of scales mod2 <- sirt::invariance.alignment( lambda=lambda, nu=nu, control=list(trace=2) ) summary(mod2)  ############################################################################# # EXAMPLE 4: Linking with item parameters containing outliers #############################################################################  # see Help file in linking.robust  # simulate some item difficulties in the Rasch model I <- 38 set.seed(18785) itempars <- data.frame(\"item\"=paste0(\"I\",1:I) ) itempars$study1 <- stats::rnorm( I, mean=.3, sd=1.4 ) # simulate DIF effects plus some outliers bdif <- stats::rnorm(I, mean=.4, sd=.09) +              (stats::runif(I)>.9 )*rep( 1*c(-1,1)+.4, each=I/2 ) itempars$study2 <- itempars$study1 + bdif # create input for function invariance.alignment nu <- t( itempars[,2:3] ) colnames(nu) <- itempars$item lambda <- 1+0*nu  # linking using least squares optimization mod1 <- sirt::invariance.alignment( lambda=lambda, nu=nu ) summary(mod1)   ##   Group Means and Standard Deviations   ##          alpha0 psi0   ##   study1 -0.286    1   ##   study2  0.286    1  # linking using powers of .5 mod2 <- sirt::invariance.alignment( lambda=lambda, nu=nu, align.pow=c(1,1) ) summary(mod2)   ##   Group Means and Standard Deviations   ##          alpha0 psi0   ##   study1 -0.213    1   ##   study2  0.213    1  # linking using powers of .25 mod3 <- sirt::invariance.alignment( lambda=lambda, nu=nu, align.pow=c(.5,.5) ) summary(mod3)   ##   Group Means and Standard Deviations   ##          alpha0 psi0   ##   study1 -0.207    1   ##   study2  0.207    1  ############################################################################# # EXAMPLE 5: Linking gender groups with data.math #############################################################################  data(data.math) dat <- data.math$data dat.male <- dat[ dat$female==0, substring( colnames(dat),1,1)==\"M\"  ] dat.female <- dat[ dat$female==1, substring( colnames(dat),1,1)==\"M\"  ]  #************************* # Model 1: Linking using the Rasch model mod1m <- sirt::rasch.mml2( dat.male ) mod1f <- sirt::rasch.mml2( dat.female )  # create objects for invariance.alignment nu <- rbind( mod1m$item$thresh, mod1f$item$thresh ) colnames(nu) <- mod1m$item$item rownames(nu) <- c(\"male\", \"female\") lambda <- 1+0*nu  # mean of item difficulties round( rowMeans(nu), 3 )  # Linking using least squares optimization res1a <- sirt::invariance.alignment( lambda, nu, align.scale=c( .3, .5 ) ) summary(res1a)  # Linking using optimization with absolute value function (pow=.5) res1b <- sirt::invariance.alignment( lambda, nu, align.scale=c( .3, .5 ),                 align.pow=c(1,1) ) summary(res1b)  #-- compare results with Haberman linking I <- ncol(dat.male) itempartable <- data.frame( \"study\"=rep( c(\"male\", \"female\"), each=I ) ) itempartable$item <- c( paste0(mod1m$item$item),  paste0(mod1f$item$item) ) itempartable$a <- 1 itempartable$b <- c( mod1m$item$b, mod1f$item$b ) # estimate linking parameters res1c <- sirt::linking.haberman( itempars=itempartable )  #-- results of sirt::equating.rasch x <- itempartable[ 1:I, c(\"item\", \"b\") ] y <- itempartable[ I + 1:I, c(\"item\", \"b\") ] res1d <- sirt::equating.rasch( x, y ) round( res1d$B.est, 3 )   ##     Mean.Mean Haebara Stocking.Lord   ##   1     0.032   0.032         0.029  #************************* # Model 2: Linking using the 2PL model I <- ncol(dat.male) mod2m <- sirt::rasch.mml2( dat.male, est.a=1:I) mod2f <- sirt::rasch.mml2( dat.female, est.a=1:I)  # create objects for invariance.alignment nu <- rbind( mod2m$item$thresh, mod2f$item$thresh ) colnames(nu) <- mod2m$item$item rownames(nu) <- c(\"male\", \"female\") lambda <- rbind( mod2m$item$a, mod2f$item$a ) colnames(lambda) <- mod2m$item$item rownames(lambda) <- c(\"male\", \"female\")  res2a <- sirt::invariance.alignment( lambda, nu, align.scale=c( .3, .5 ) ) summary(res2a)  res2b <- sirt::invariance.alignment( lambda, nu, align.scale=c( .3, .5 ),                 align.pow=c(1,1) ) summary(res2b)  # compare results with Haberman linking I <- ncol(dat.male) itempartable <- data.frame( \"study\"=rep( c(\"male\", \"female\"), each=I ) ) itempartable$item <- c( paste0(mod2m$item$item),  paste0(mod2f$item$item ) ) itempartable$a <- c( mod2m$item$a, mod2f$item$a ) itempartable$b <- c( mod2m$item$b, mod2f$item$b ) # estimate linking parameters res2c <- sirt::linking.haberman( itempars=itempartable )  ############################################################################# # EXAMPLE 6: Data from Asparouhov & Muthen (2014) simulation study #############################################################################  G <- 3  # number of groups I <- 5  # number of items # define lambda and nu parameters lambda <- matrix(1, nrow=G, ncol=I) nu <- matrix(0, nrow=G, ncol=I)  # define size of noninvariance dif <- 1  #- 1st group: N(0,1) lambda[1,3] <- 1+dif*.4; nu[1,5] <- dif*.5  #- 2nd group: N(0.3,1.5) gg <- 2 ; mu <- .3; sigma <- sqrt(1.5) lambda[gg,5] <- 1-.5*dif; nu[gg,1] <- -.5*dif nu[gg,] <- nu[gg,] + mu*lambda[gg,] lambda[gg,] <- lambda[gg,] * sigma  #- 3nd group: N(.8,1.2) gg <- 3 ; mu <- .8; sigma <- sqrt(1.2) lambda[gg,4] <- 1-.7*dif; nu[gg,2] <- -.5*dif nu[gg,] <- nu[gg,] + mu*lambda[gg,] lambda[gg,] <- lambda[gg,] * sigma  # define alignment scale align.scale <- c(.2,.4)   # Asparouhov and Muthen use c(1,1) # define alignment powers align.pow <- c(.5,.5)   # as in Asparouhov and Muthen  #*** estimate alignment parameters mod1 <- sirt::invariance.alignment( lambda, nu, eps=.01, optimizer=\"optim\",             align.scale=align.scale, align.pow=align.pow, center=FALSE ) summary(mod1)  #--- find parameter constraints for prespecified tolerance cmod1 <- sirt::invariance_alignment_constraints(model=mod1, nu_parm_tol=.4,             lambda_parm_tol=.2 ) summary(cmod1)  ############################################################################# # EXAMPLE 7: Similar to Example 6, but with data simulation and CFA estimation #############################################################################  #--- data simulation  set.seed(65) G <- 3  # number of groups I <- 5  # number of items # define lambda and nu parameters lambda <- matrix(1, nrow=G, ncol=I) nu <- matrix(0, nrow=G, ncol=I) err_var <- matrix(1, nrow=G, ncol=I)  # define size of noninvariance dif <- 1 #- 1st group: N(0,1) lambda[1,3] <- 1+dif*.4; nu[1,5] <- dif*.5 #- 2nd group: N(0.3,1.5) gg <- 2 ; lambda[gg,5] <- 1-.5*dif; nu[gg,1] <- -.5*dif #- 3nd group: N(.8,1.2) gg <- 3 lambda[gg,4] <- 1-.7*dif; nu[gg,2] <- -.5*dif #- define distributions of groups mu <- c(0,.3,.8) sigma <- sqrt(c(1,1.5,1.2)) N <- rep(1000,3) # sample sizes per group  #* simulate data dat <- sirt::invariance_alignment_simulate(nu, lambda, err_var, mu, sigma, N) head(dat)  #--- estimate CFA models pars <- sirt::invariance_alignment_cfa_config(dat[,-1], group=dat$group) print(pars)  #--- invariance alignment # define alignment scale align.scale <- c(.2,.4) # define alignment powers align.pow <- c(.5,.5) mod1 <- sirt::invariance.alignment( lambda=pars$lambda, nu=pars$nu, eps=.01,             optimizer=\"optim\", align.scale=align.scale, align.pow=align.pow, center=FALSE) #* find parameter constraints for prespecified tolerance cmod1 <- sirt::invariance_alignment_constraints(model=mod1, nu_parm_tol=.4,             lambda_parm_tol=.2 ) summary(cmod1)  #--- estimate CFA models with sampling weights  #* simulate weights weights <- stats::runif(sum(N), 0, 2) #* estimate models pars2 <- sirt::invariance_alignment_cfa_config(dat[,-1], group=dat$group, weights=weights) print(pars2$nu) print(pars$nu)  #--- estimate one-parameter model pars <- sirt::invariance_alignment_cfa_config(dat[,-1], group=dat$group, model=\"1PM\") print(pars)  ############################################################################# # EXAMPLE 8: Computation of standard errors #############################################################################  G <- 3  # number of groups I <- 5  # number of items # define lambda and nu parameters lambda <- matrix(1, nrow=G, ncol=I) nu <- matrix(0, nrow=G, ncol=I)  # define size of noninvariance dif <- 1  mu1 <- c(0,.3,.8) sigma1 <- c(1,1.25,1.1)  #- 1st group lambda[1,3] <- 1+dif*.4; nu[1,5] <- dif*.5  #- 2nd group gg <- 2 lambda[gg,5] <- 1-.5*dif; nu[gg,1] <- -.5*dif  #- 3nd group gg <- 3 lambda[gg,4] <- 1-.7*dif; nu[gg,2] <- -.5*dif  dat <- sirt::invariance_alignment_simulate(nu=nu, lambda=lambda, err_var=1+0*lambda,                 mu=mu1, sigma=sigma1, N=500, output=\"data\", exact=TRUE)  #* estimate CFA res <- sirt::invariance_alignment_cfa_config(dat=dat[,-1], group=dat$group )  #- perform invariance alignment eps <- .001 align.pow <- 0.5*rep(1,2) lambda <- res$lambda nu <- res$nu mod1 <- sirt::invariance.alignment( lambda=lambda, nu=nu, eps=eps, optimizer=\"optim\",              align.pow=align.pow, meth=meth, vcov=res$vcov) # variance matrix and standard errors mod1$vcov sqrt(diag(mod1$vcov))  ############################################################################# # EXAMPLE 9: Comparison 2 groups for dichotomous data | data.pisaMath #############################################################################  data(data.pisaMath) dat <- data.pisaMath$data library(\"lavaan\")  model1 <- \"     F=~ M192Q01 + M406Q01 + M406Q02 + M423Q01 + M496Q01 + M496Q02 + M564Q01 +          M564Q02 + M571Q01 + M603Q01 + M603Q02     \"  fit.configural <- lavaan::cfa(model1, data=dat, group=\"female\",                   ordered=TRUE, std.lv=TRUE, parameterization=\"theta\") lavaan::summary(fit.configural, standardized=TRUE)  # extract item parameters separate group analyses ipars <- lavaan::parameterEstimates(fit.configural) # extract lambda's: groups are in rows, items in columns lambda <- matrix( ipars[ ipars$op==\"=~\", \"est\"], nrow=2,  byrow=TRUE) colnames(lambda) <- colnames(dat)[6:16] # extract nu's nu <- matrix( ipars[ ipars$op==\"|\" & ipars$se !=0, \"est\" ], nrow=2,  byrow=TRUE) colnames(nu) <- colnames(dat)[6:16]  # Model 1: apply invariance alignment mod1 <- sirt::invariance.alignment( lambda=lambda, nu=nu ) summary(mod1) }"},{"path":"/reference/IRT.mle.html","id":null,"dir":"Reference","previous_headings":"","what":"Person Parameter Estimation — IRT.mle","title":"Person Parameter Estimation — IRT.mle","text":"Computes maximum likelihood estimate (MLE), weighted likelihood estimate (WLE) maximum aposterior estimate (MAP) ability unidimensional item response models (Penfield & Bergeron, 2005; Warm, 1989). Item response functions can defined user.","code":""},{"path":"/reference/IRT.mle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Person Parameter Estimation — IRT.mle","text":"","code":"IRT.mle(data, irffct, arg.list, theta=rep(0,nrow(data)), type=\"MLE\",      mu=0, sigma=1, maxiter=20, maxincr=3, h=0.001, convP=1e-04,      maxval=9, progress=TRUE)"},{"path":"/reference/IRT.mle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Person Parameter Estimation — IRT.mle","text":"data Data frame item responses irffct User defined item response (see Examples). Arguments must specified arg.list. function must contain theta ii (item index) arguments. theta Initial ability estimate arg.list List arguments irffct. type Type ability estimate. can \"MLE\" (default),         \"WLE\" \"MAP\". mu Mean normal prior distribution (type=\"MAP\") sigma Standard deviation normal prior distribution (type=\"MAP\") maxiter Maximum number iterations maxincr Maximum increment h Numerical differentiation parameter convP Convergence criterion maxval Maximum ability value estimated progress Logical indicating whether iteration progress displayed","code":""},{"path":"/reference/IRT.mle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Person Parameter Estimation — IRT.mle","text":"Data frame estimated abilities (est) standard error (se).","code":""},{"path":"/reference/IRT.mle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Person Parameter Estimation — IRT.mle","text":"Penfield, R. D., & Bergeron, J. M. (2005). Applying weighted maximum likelihood latent trait estimator generalized partial credit model. Applied Psychological Measurement, 29, 218-233. Warm, T. . (1989). Weighted likelihood estimation ability item response theory. Psychometrika, 54, 427-450.","code":""},{"path":[]},{"path":"/reference/IRT.mle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Person Parameter Estimation — IRT.mle","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Generalized partial credit model #############################################################################  data(data.ratings1) dat <- data.ratings1  # estimate model mod1 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater,              pid=dat$idstud, maxiter=15) # extract dataset and item parameters data <- mod1$procdata$dat2.NA a <- mod1$ipars.dat2$a b <- mod1$ipars.dat2$b theta0 <- mod1$person$EAP # define item response function for item ii calc.pcm <- function( theta, a, b, ii ){     K <- ncol(b)     N <- length(theta)     matrK <- matrix( 0:K, nrow=N, ncol=K+1, byrow=TRUE)     eta <- a[ii] * theta * matrK - matrix( c(0,b[ii,]), nrow=N, ncol=K+1, byrow=TRUE)     eta <- exp(eta)     probs <- eta / rowSums(eta, na.rm=TRUE)     return(probs) } arg.list <- list(\"a\"=a, \"b\"=b )  # MLE abil1 <- sirt::IRT.mle( data, irffct=calc.pcm, theta=theta0, arg.list=arg.list ) str(abil1) # WLE abil2 <- sirt::IRT.mle( data, irffct=calc.pcm, theta=theta0, arg.list=arg.list, type=\"WLE\") str(abil2) # MAP with prior distribution N(.2, 1.3) abil3 <- sirt::IRT.mle( data, irffct=calc.pcm, theta=theta0, arg.list=arg.list,               type=\"MAP\", mu=.2, sigma=1.3 ) str(abil3)  ############################################################################# # EXAMPLE 2: Rasch model #############################################################################  data(data.read) dat <- data.read I <- ncol(dat)  # estimate Rasch model mod1 <- sirt::rasch.mml2( dat ) summary(mod1)  # define item response function irffct <- function( theta, b, ii){     eta <- exp( theta - b[ii] )     probs <- eta / ( 1 + eta )     probs <- cbind( 1 - probs, probs )     return(probs) } # initial person parameters and item parameters theta0 <- mod1$person$EAP arg.list <- list( \"b\"=mod1$item$b  )  # estimate WLE abil <- sirt::IRT.mle( data=dat, irffct=irffct, arg.list=arg.list,             theta=theta0, type=\"WLE\") # compare with wle.rasch function theta <- sirt::wle.rasch( dat, b=mod1$item$b ) cbind( abil[,1], theta$theta, abil[,2], theta$se.theta )  ############################################################################# # EXAMPLE 3: Ramsay quotient model #############################################################################  data(data.read) dat <- data.read I <- ncol(dat)  # estimate Ramsay model mod1 <- sirt::rasch.mml2( dat, irtmodel=\"ramsay.qm\" ) summary(mod1) # define item response function irffct <- function( theta, b, K, ii){     eta <- exp( theta / b[ii] )     probs <- eta / ( K[ii] + eta )     probs <- cbind( 1 - probs, probs )     return(probs) } # initial person parameters and item parameters theta0 <- exp( mod1$person$EAP ) arg.list <- list( \"b\"=mod1$item2$b, \"K\"=mod1$item2$K ) # estimate MLE res <- sirt::IRT.mle( data=dat, irffct=irffct, arg.list=arg.list, theta=theta0,             maxval=20, maxiter=50) }"},{"path":"/reference/isop.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","title":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","text":"Fit unidimensional isotonic probabilistic model (ISOP; Scheiblechner, 1995, 2007) additive istotonic probabilistic model (ADISOP; Scheiblechner, 1999). isop.dich function can used dichotomous data isop.poly function can applied polytomous data. Note applying ISOP model polytomous data necessary items number categories.","code":""},{"path":"/reference/isop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","text":"","code":"isop.dich(dat, score.breaks=NULL, merge.extreme=TRUE,      conv=.0001, maxit=1000, epsilon=.025, progress=TRUE)  isop.poly( dat, score.breaks=seq(0,1,len=10 ),      conv=.0001, maxit=1000, epsilon=.025, progress=TRUE )  # S3 method for isop summary(object,...)  # S3 method for isop plot(x,ask=TRUE,...)"},{"path":"/reference/isop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","text":"dat Data frame dichotomous polytomous item responses score.breaks Vector breaks define score groups. dichotomous data, person score grouping applied mean person score, polytomous data applied modified percentile score. merge.extreme Merge extreme groups zero maximum score succeeding score categories? default TRUE. conv Convergence criterion maxit Maximum number iterations epsilon Additive constant handle cell frequencies 0 1 fit.adisop progress Display progress? object Object class isop (generated     isop.dich isop.poly) x Object class isop (generated     isop.dich isop.poly) ask Ask new plot? ... arguments passed","code":""},{"path":"/reference/isop.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","text":"ISOP model dichotomous data firstly proposed Irtel Schmalhofer (1982). Consider person groups \\(p\\) (ordered low high scores) items \\(\\) (ordered difficult easy items). , \\(F(p,)\\) denotes proportion correct item \\(\\)  score group \\(p\\), \\(n_{pi}\\) denotes number persons group \\(p\\) item \\(\\). isotonic probabilistic model (Scheiblechner, 1995) monotonically smooths distribution function \\(F\\) $$ P( X_{pi}=1 | p, )=F^\\ast( p, ) $$ two-dimensional distribution function \\(F^\\ast\\) isotonic \\(p\\) \\(\\). Model fit assessed square root weighted squares deviations $$Fit=\\sqrt{ \\frac{1}{} \\sum_{p,} w_{pi} \\left(  F(p, ) -     F^\\ast(p,) \\right )^2 }$$ frequency weights \\(w_{pi}\\) \\(\\sum_p w_{pi}=1\\) every item \\(\\). additive isotonic model (ADISOP; Scheiblechner, 1999) assumes existence person parameters \\(\\theta_p\\) item parameters \\(\\delta_i\\) $$ P( X_{pi}=1 | p )=g( \\theta_p + \\delta_i )$$ \\(g\\) nonparametrically estimated isotonic function. functions isop.dich isop.poly uses \\(F^\\ast\\) ISOP models estimates person item parameters ADISOP model. comparison, isop.dich also fits model logistic function \\(g\\) results Rasch model. polytomous data, starting point empirical distribution function $$ P( X_i \\le k | p  )=F( k ; p, )  $$ increasing argument \\(k\\) (item categories). ISOP model defined antitonic \\(p\\) \\(\\) items ordered respect item P-scores persons ordered according modified percentile scores (Scheiblechner, 2007). estimated ISOP model results distribution function \\(F^\\ast\\). Using function, additive isotonic probabilistic model (ADISOP) aims estimating distribution function $$P( X_i \\le k ; p  )=F^{\\ast \\ast} ( k ; p, )=F^{ \\ast \\ast }     ( k, \\theta_p + \\delta_i ) $$ antitonic \\(k\\) \\(\\theta_p + \\delta_i\\). Due additive relation, ADISOP scale values claimed measured interval scale level (Scheiblechner, 1999). ADISOP model compared graded response model defined response equation $$P( X_i \\le k ; p  )=g( \\theta_p + \\delta_i + \\gamma_k ) $$ \\(g\\) denotes logistic function. Estimated parameters value fit.grm: person parameters \\(\\theta_p\\) (person.sc), item parameters \\(\\delta_i\\) (item.sc) category parameters \\(\\gamma_k\\) (cat.sc). calculation person item scores explained isop.scoring. application ISOP ADISOP model see Scheiblechner Lutz (2009).","code":""},{"path":"/reference/isop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","text":"list following entries: freq.correct Used frequency table (distribution function)    dichotomous polytomous data wgt Used weights (frequencies) prob.saturated Frequencies saturated model prob.isop Fitted frequencies ISOP model prob.adisop Fitted frequencies ADISOP model prob.logistic Fitted frequencies logistic model     (isop.dich) prob.grm Fitted frequencies graded response model     (isop.poly) ll List log-likelihood values fit Vector fit statistics person Data frame person parameters item Data frame item parameters p.itemcat Frequencies every item category score.itemcat Scoring points every item category fit.isop Values fitting ISOP model (see fit.isop) fit.isop Values fitting ADISOP model (see fit.adisop) fit.logistic Values fitting logistic model  (isop.dich) fit.grm Values fitting graded response model  (isop.poly) ... values","code":""},{"path":"/reference/isop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","text":"Irtel, H., & Schmalhofer, F. (1982). Psychodiagnostik auf Ordinalskalenniveau: Messtheoretische Grundlagen, Modelltest und Parameterschaetzung. Archiv fuer Psychologie, 134, 197-218. Scheiblechner, H. (1995). Isotonic ordinal probabilistic models (ISOP). Psychometrika, 60, 281-304. Scheiblechner, H. (1999). Additive conjoint isotonic probabilistic models (ADISOP). Psychometrika, 64, 295-316. Scheiblechner, H. (2007). unified nonparametric IRT model d-dimensional psychological test data (d-ISOP). Psychometrika, 72, 43-67. Scheiblechner, H., & Lutz, R. (2009). Die Konstruktion eines optimalen eindimensionalen Tests mittels nichtparametrischer Testtheorie (NIRT) Beispiel des MR SOC. Diagnostica, 55, 41-54.","code":""},{"path":[]},{"path":"/reference/isop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Unidimensional ISOP and ADISOP Model to Dichotomous\r\nand Polytomous Item Responses — isop","text":"","code":"############################################################################# # EXAMPLE 1: Dataset Reading (dichotomous items) #############################################################################  data(data.read) dat <- as.matrix( data.read) I <- ncol(dat)  # Model 1: ISOP Model (11 score groups) mod1 <- sirt::isop.dich( dat ) summary(mod1) plot(mod1)  if (FALSE) { # Model 2: ISOP Model (5 score groups) score.breaks <- seq( -.005, 1.005, len=5+1 ) mod2 <- sirt::isop.dich( dat, score.breaks=score.breaks) summary(mod2)  ############################################################################# # EXAMPLE 2: Dataset PISA mathematics (dichotomous items) #############################################################################  data(data.pisaMath) dat <- data.pisaMath$data dat <- dat[, grep(\"M\", colnames(dat) ) ]  # fit ISOP model # Note that for this model many iterations are needed #   to reach convergence for ADISOP mod1 <- sirt::isop.dich( dat, maxit=4000) summary(mod1) }  ############################################################################# # EXAMPLE 3: Dataset Students (polytomous items) #############################################################################  # Dataset students: scale cultural activities library(CDM) data(data.Students, package=\"CDM\") dat <- stats::na.omit( data.Students[, paste0(\"act\",1:4) ] )  # fit models mod1 <- sirt::isop.poly( dat ) summary(mod1) plot(mod1)"},{"path":"/reference/isop.scoring.html","id":null,"dir":"Reference","previous_headings":"","what":"Scoring Persons and Items in the ISOP Model — isop.scoring","title":"Scoring Persons and Items in the ISOP Model — isop.scoring","text":"function scoring isotonic probabilistic model (Scheiblechner, 1995, 2003, 2007). Person parameters ordinally scaled ISOP model also allows specific objective (ordinal) comparisons persons (Scheiblechner, 1995).","code":""},{"path":"/reference/isop.scoring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scoring Persons and Items in the ISOP Model — isop.scoring","text":"","code":"isop.scoring(dat,score.itemcat=NULL)"},{"path":"/reference/isop.scoring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scoring Persons and Items in the ISOP Model — isop.scoring","text":"dat Data frame dichotomous polytomous item responses score.itemcat Optional data frame scoring points every item every category (see Example 2).","code":""},{"path":"/reference/isop.scoring.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scoring Persons and Items in the ISOP Model — isop.scoring","text":"function extracts scoring rule ISOP model (score.itemcat !=NULL) calculates modified percentile score every person. score \\(s_{ik}\\) item \\(\\) category \\(k\\) calculated $$ s_{ik}=\\sum_{j=0}^{k-1} f_{ij} - \\sum_{j=k+1}^K f_{ij}=P( X_i < k  ) - P( X_i > k ) $$ \\(f_{ik}\\) relative frequency item \\(\\) category \\(k\\) \\(K\\) maximum category. modified percentile score \\(\\rho_p\\) subject \\(p\\) (mpsc person) defined $$ \\rho_p=\\frac{1}{} \\sum_{=1}^        \\sum_{j=0}^K s_{ik} \\mathbf{1}( X_{pi}=k ) $$ Note dichotomous items, sum score sufficient statistic \\(\\rho_p\\) case polytomous items. modified percentile score \\(\\rho_p\\) ranges -1 1. modified item P-score \\(\\rho_i\\) (Scheiblechner, 2007, p. 52) defined $$ \\rho_i=\\frac{1}{-1} \\cdot \\sum_j \\left[ P( X_j < X_i )         - P( X_j > X_i ) \\right ] $$","code":""},{"path":"/reference/isop.scoring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scoring Persons and Items in the ISOP Model — isop.scoring","text":"list following entries: person data frame person parameters. modified   percentile score \\(\\rho_p\\) denoted mpsc. item Item statistics scoring parameters.     item P-scores \\(\\rho_i\\)    labeled pscore. p.itemcat Frequencies every item category score.itemcat Scoring points every item category distr.fct Empirical distribution function","code":""},{"path":"/reference/isop.scoring.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Scoring Persons and Items in the ISOP Model — isop.scoring","text":"Scheiblechner, H. (1995). Isotonic ordinal probabilistic models (ISOP). Psychometrika, 60, 281-304. Scheiblechner, H. (2003). Nonparametric IRT: Scoring functions ordinal parameter estimation isotonic probabilistic models (ISOP). Technical Report, Philipps-Universitaet Marburg. Scheiblechner, H. (2007). unified nonparametric IRT model d-dimensional psychological test data (d-ISOP). Psychometrika, 72, 43-67.","code":""},{"path":[]},{"path":"/reference/isop.scoring.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scoring Persons and Items in the ISOP Model — isop.scoring","text":"","code":"############################################################################# # EXAMPLE 1: Dataset Reading #############################################################################  data( data.read ) dat <- data.read  # Scoring according to the ISOP model msc <- sirt::isop.scoring( dat ) # plot student scores boxplot( msc$person$mpsc ~ msc$person$score )  ############################################################################# # EXAMPLE 2: Dataset students from CDM package | polytomous items #############################################################################  library(\"CDM\") data( data.Students, package=\"CDM\") dat <- stats::na.omit(data.Students[, -c(1:2) ])  # Scoring according to the ISOP model msc <- sirt::isop.scoring( dat ) # plot student scores boxplot( msc$person$mpsc ~ msc$person$score )  # scoring with known scoring rule for activity items items <- paste0( \"act\", 1:5 ) score.itemcat <- msc$score.itemcat score.itemcat <- score.itemcat[ items, ] msc2 <- sirt::isop.scoring( dat[,items], score.itemcat=score.itemcat )"},{"path":"/reference/isop.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Testing the ISOP Model — isop.test","title":"Testing the ISOP Model — isop.test","text":"function performs tests W1 axiom ISOP model (Scheiblechner, 2003). Standard errors corresponding \\(W1_i\\) statistics obtained Jackknife.","code":""},{"path":"/reference/isop.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Testing the ISOP Model — isop.test","text":"","code":"isop.test(data, jackunits=20, weights=rep(1, nrow(data)))  # S3 method for isop.test summary(object,...)"},{"path":"/reference/isop.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Testing the ISOP Model — isop.test","text":"data Data frame item responses jackunits number Jackknife units (integer provided argument value) vector Jackknife units already defined. weights Optional vector sampling weights object Object class isop.test ... arguments passed","code":""},{"path":"/reference/isop.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Testing the ISOP Model — isop.test","text":"list following entries itemstat Data frame test item statistics W1 axiom.   \\(W1_i\\) statistic denoted est se   corresponding standard error statistic.   sample size per item N M denotes item mean. Es Number concordances per item Ed Number disconcordances per item \\(W1_i\\) statistics printed summary method.","code":""},{"path":"/reference/isop.test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Testing the ISOP Model — isop.test","text":"Scheiblechner, H. (2003). Nonparametric IRT: Testing bi-isotonicity isotonic probabilistic models (ISOP). Psychometrika, 68, 79-96.","code":""},{"path":[]},{"path":"/reference/isop.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Testing the ISOP Model — isop.test","text":"","code":"############################################################################# # EXAMPLE 1: ISOP model data.Students #############################################################################  data(data.Students, package=\"CDM\") dat <- data.Students[, paste0(\"act\",1:5) ] dat <- dat[1:300, ]    # select first 300 students  # perform the ISOP test mod <- sirt::isop.test(dat) summary(mod)   ## -> W1i statistics   ##     parm   N     M   est    se      t   ##   1 test 300    NA 0.430 0.036 11.869   ##   2 act1 278 0.601 0.451 0.048  9.384   ##   3 act2 275 0.473 0.473 0.035 13.571   ##   4 act3 274 0.277 0.352 0.098  3.596   ##   5 act4 291 1.320 0.381 0.054  7.103   ##   6 act5 276 0.460 0.475 0.042 11.184"},{"path":"/reference/latent.regression.em.raschtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"function estimates unidimensional latent regression model likelihood specified, parameters generalized item response model (Stukel, 1988) mean standard error estimate individual scores provided input. Item parameters treated fixed estimation.","code":""},{"path":"/reference/latent.regression.em.raschtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"","code":"latent.regression.em.raschtype(data=NULL, f.yi.qk=NULL, X,     weights=rep(1, nrow(X)), beta.init=rep(0,ncol(X)),     sigma.init=1, b=rep(0,ncol(X)), a=rep(1,length(b)),     c=rep(0, length(b)), d=rep(1, length(b)), alpha1=0, alpha2=0,     max.parchange=1e-04, theta.list=seq(-5, 5, len=20),     maxiter=300, progress=TRUE )  latent.regression.em.normal(y, X, sig.e, weights=rep(1, nrow(X)),     beta.init=rep(0, ncol(X)), sigma.init=1, max.parchange=1e-04,     maxiter=300, progress=TRUE)  # S3 method for latent.regression summary(object,...)"},{"path":"/reference/latent.regression.em.raschtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"data \\(N \\times \\) data frame dichotomous item responses.   data frame supplied, user can input individual   likelihood f.yi.qk. f.yi.qk optional matrix contains individual likelihood.   matrix produced rasch.mml2   rasch.copula2. use argument allows   estimation latent regression model independent   parameters used item response model. X \\(N \\times K\\) matrix \\(K\\) covariates latent     regression model. Note intercept (.e. vector ones)     must included X. weights Student weights (optional). beta.init Initial regression coefficients (optional). sigma.init Initial residual standard deviation (optional). b Item difficulties (optional). must provided likelihood f.yi.qk given input. Item discriminations (optional). c Guessing parameter (lower asymptotes) (optional). d One minus slipping parameter (upper asymptotes) (optional). alpha1 Upper tail parameter \\(\\alpha_1\\) generalized logistic item response model. Default 0. alpha2 Lower tail parameter \\(\\alpha_2\\) parameter generalized logistic item response model. Default 0. max.parchange Maximum change regression parameters theta.list Grid person ability theta evaluated maxiter Maximum number iterations progress optional logical indicating whether computation progress displayed. y Individual scores sig.e Standard errors individual scores object Object class latent.regression ... arguments passed","code":""},{"path":"/reference/latent.regression.em.raschtype.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"output Regression Parameters fraction missing information (fmi) reported increase variance regression parameter estimates ability defined latent variable. effective sample size pseudoN.latent corresponds sample size ability available reliability one.","code":""},{"path":"/reference/latent.regression.em.raschtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"list following entries iterations Number iterations needed maxiter Maximal number iterations max.parchange Maximum change parameter estimates coef Coefficients summary.coef Summary regression coefficients sigma Estimate residual standard deviation vcov.simple Covariance parameters estimated parameters       (simplified version) vcov.latent Covariance parameters estimated parameters                         accounts latent ability post Individual posterior distribution EAP Individual EAP estimates SE.EAP Standard error estimates EAP explvar Explained variance latent regression totalvar Total variance latent regression rsquared Explained variance \\(R^2\\) latent regression","code":""},{"path":"/reference/latent.regression.em.raschtype.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"Adams, R., & Wu. M. (2007). mixed-coefficients multinomial logit model: generalized form Rasch model. M. von Davier & C. H. Carstensen (Eds.). Multivariate mixture distribution Rasch models: Extensions applications (pp. 57-76). New York: Springer. doi:10.1007/978-0-387-49839-3_4 Mislevy, R. J. (1991). Randomization-based inference latent variables complex samples. Psychometrika, 56(2), 177-196. doi:10.1007/BF02294457 Stukel, T. . (1988). Generalized logistic models. Journal American Statistical Association, 83(402), 426-431. doi:10.1080/01621459.1988.10478613","code":""},{"path":"/reference/latent.regression.em.raschtype.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"Using defaults , c, d, alpha1 alpha2 corresponds Rasch model.","code":""},{"path":[]},{"path":"/reference/latent.regression.em.raschtype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Latent Regression Model for the Generalized\r\nLogistic Item Response Model and the Linear Model for Normal Responses — latent.regression.em.raschtype","text":"","code":"############################################################################# #  EXAMPLE 1: PISA Reading | Rasch model for dichotomous data #############################################################################  data(data.pisaRead, package=\"sirt\") dat <- data.pisaRead$data items <- grep(\"R\", colnames(dat)) # define matrix of covariates X <- cbind( 1, dat[, c(\"female\",\"hisei\",\"migra\" ) ] )  #*** # Model 1: Latent regression model in the Rasch model # estimate Rasch model mod1 <- sirt::rasch.mml2( dat[,items] ) # latent regression model lm1 <- sirt::latent.regression.em.raschtype( data=dat[,items ], X=X, b=mod1$item$b )  if (FALSE) { #*** # Model 2: Latent regression with generalized link function # estimate alpha parameters for link function mod2 <- sirt::rasch.mml2( dat[,items], est.alpha=TRUE) # use model estimated likelihood for latent regression model lm2 <- sirt::latent.regression.em.raschtype( f.yi.qk=mod2$f.yi.qk,             X=X, theta.list=mod2$theta.k)  #*** # Model 3: Latent regression model based on Rasch copula model testlets <- paste( data.pisaRead$item$testlet) itemclusters <- match( testlets, unique(testlets) ) # estimate Rasch copula model mod3 <- sirt::rasch.copula2( dat[,items], itemcluster=itemclusters ) # use model estimated likelihood for latent regression model lm3 <- sirt::latent.regression.em.raschtype( f.yi.qk=mod3$f.yi.qk,                 X=X, theta.list=mod3$theta.k)  ############################################################################# # EXAMPLE 2: Simulated data according to the Rasch model #############################################################################  set.seed(899) I <- 21     # number of items b <- seq(-2,2, len=I)   # item difficulties n <- 2000       # number of students  # simulate theta and covariates theta <- stats::rnorm( n ) x <- .7 * theta + stats::rnorm( n, .5 ) y <- .2 * x+ .3*theta + stats::rnorm( n, .4 ) dfr <- data.frame( theta, 1, x, y )  # simulate Rasch model dat1 <- sirt::sim.raschtype( theta=theta, b=b )  # estimate latent regression mod <- sirt::latent.regression.em.raschtype( data=dat1, X=dfr[,-1], b=b )   ## Regression Parameters   ##   ##        est se.simple     se        t p   beta    fmi N.simple pseudoN.latent   ## X1 -0.2554    0.0208 0.0248 -10.2853 0 0.0000 0.2972     2000       1411.322   ## x   0.4113    0.0161 0.0193  21.3037 0 0.4956 0.3052     2000       1411.322   ## y   0.1715    0.0179 0.0213   8.0438 0 0.1860 0.2972     2000       1411.322   ##   ## Residual Variance=0.685   ## Explained Variance=0.3639   ## Total Variance=1.049   ##                 R2=0.3469  # compare with linear model (based on true scores) summary( stats::lm( theta  ~ x + y, data=dfr ) )   ## Coefficients:   ##             Estimate Std. Error t value Pr(>|t|)   ## (Intercept) -0.27821    0.01984  -14.02   <2e-16 ***   ## x            0.40747    0.01534   26.56   <2e-16 ***   ## y            0.18189    0.01704   10.67   <2e-16 ***   ## ---   ##   ## Residual standard error: 0.789 on 1997 degrees of freedom   ## Multiple R-squared: 0.3713,     Adjusted R-squared: 0.3707  #*********** # define guessing parameters (lower asymptotes) and # upper asymptotes ( 1 minus slipping parameters) cI <- rep(.2, I)        # all items get a guessing parameter of .2 cI[ c(7,9) ] <- .25     # 7th and 9th get a guessing parameter of .25 dI <- rep( .95, I )    # upper asymptote of .95 dI[ c(7,11) ] <- 1        # 7th and 9th item have an asymptote of 1  # latent regression model mod1 <- sirt::latent.regression.em.raschtype( data=dat1, X=dfr[,-1],            b=b, c=cI, d=dI    )   ## Regression Parameters   ##   ##        est se.simple     se        t p   beta    fmi N.simple pseudoN.latent   ## X1 -0.7929    0.0243 0.0315 -25.1818 0 0.0000 0.4044     2000       1247.306   ## x   0.5025    0.0188 0.0241  20.8273 0 0.5093 0.3936     2000       1247.306   ## y   0.2149    0.0209 0.0266   8.0850 0 0.1960 0.3831     2000       1247.306   ##   ## Residual Variance=0.9338   ## Explained Variance=0.5487   ## Total Variance=1.4825   ##                 R2=0.3701  ############################################################################# # EXAMPLE 3: Measurement error in dependent variable #############################################################################  set.seed(8766) N <- 4000       # number of persons X <- stats::rnorm(N)           # independent variable Z <- stats::rnorm(N)           # independent variable y <- .45 * X + .25 * Z + stats::rnorm(N)   # dependent variable true score sig.e <- stats::runif( N, .5, .6 )       # measurement error standard deviation yast <- y + stats::rnorm( N, sd=sig.e ) # dependent variable measured with error  #**** # Model 1: Estimation with latent.regression.em.raschtype using #          individual likelihood # define theta grid for evaluation of density theta.list <- mean(yast) + stats::sd(yast) * seq( - 5, 5, length=21) # compute individual likelihood f.yi.qk <- stats::dnorm( outer( yast, theta.list, \"-\" ) / sig.e ) f.yi.qk <- f.yi.qk / rowSums(f.yi.qk) # define predictor matrix X1 <- as.matrix(data.frame( \"intercept\"=1, \"X\"=X, \"Z\"=Z ))  # latent regression model res <- sirt::latent.regression.em.raschtype( f.yi.qk=f.yi.qk,                     X=X1, theta.list=theta.list)   ##   Regression Parameters   ##   ##                est se.simple     se       t      p   beta    fmi N.simple pseudoN.latent   ##   intercept 0.0112    0.0157 0.0180  0.6225 0.5336 0.0000 0.2345     4000       3061.998   ##   X         0.4275    0.0157 0.0180 23.7926 0.0000 0.3868 0.2350     4000       3061.998   ##   Z         0.2314    0.0156 0.0178 12.9868 0.0000 0.2111 0.2349     4000       3061.998   ##   ##   Residual Variance=0.9877   ##   Explained Variance=0.2343   ##   Total Variance=1.222   ##                   R2=0.1917  #**** # Model 2: Estimation with latent.regression.em.normal res2 <- sirt::latent.regression.em.normal( y=yast, sig.e=sig.e, X=X1)   ##   Regression Parameters   ##   ##                est se.simple     se       t      p   beta    fmi N.simple pseudoN.latent   ##   intercept 0.0112    0.0157 0.0180  0.6225 0.5336 0.0000 0.2345     4000       3062.041   ##   X         0.4275    0.0157 0.0180 23.7927 0.0000 0.3868 0.2350     4000       3062.041   ##   Z         0.2314    0.0156 0.0178 12.9870 0.0000 0.2111 0.2349     4000       3062.041   ##   ##   Residual Variance=0.9877   ##   Explained Variance=0.2343   ##   Total Variance=1.222   ##                   R2=0.1917    ## -> Results between Model 1 and Model 2 are identical because they use   ##    the same input.  #*** # Model 3: Regression model based on true scores y mod3 <- stats::lm( y ~ X + Z ) summary(mod3)   ##   Coefficients:   ##               Estimate Std. Error t value Pr(>|t|)   ##   (Intercept)  0.02364    0.01569   1.506    0.132   ##   X            0.42401    0.01570  27.016   <2e-16 ***   ##   Z            0.23804    0.01556  15.294   <2e-16 ***   ##   Residual standard error: 0.9925 on 3997 degrees of freedom   ##   Multiple R-squared:  0.1923,    Adjusted R-squared:  0.1919   ##   F-statistic: 475.9 on 2 and 3997 DF,  p-value: < 2.2e-16  #*** # Model 4: Regression model based on observed scores yast mod4 <- stats::lm( yast ~ X + Z ) summary(mod4)   ##   Coefficients:   ##               Estimate Std. Error t value Pr(>|t|)   ##   (Intercept)  0.01101    0.01797   0.613     0.54   ##   X            0.42716    0.01797  23.764   <2e-16 ***   ##   Z            0.23174    0.01783  13.001   <2e-16 ***   ##   Residual standard error: 1.137 on 3997 degrees of freedom   ##   Multiple R-squared:  0.1535,    Adjusted R-squared:  0.1531   ##   F-statistic: 362.4 on 2 and 3997 DF,  p-value: < 2.2e-16 }"},{"path":"/reference/lavaan2mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Converting a lavaan Model into a mirt Model — lavaan2mirt","title":"Converting a lavaan Model into a mirt Model — lavaan2mirt","text":"Converts lavaan model mirt model. Optionally, model can estimated mirt::mirt function (est.mirt=TRUE) just mirt syntax generated (est.mirt=FALSE). Extensions lavaan syntax include guessing slipping parameters (operators ?=g1 ?=s1) shortage operator item groups (see __). See TAM::lavaanify.IRT details.","code":""},{"path":"/reference/lavaan2mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converting a lavaan Model into a mirt Model — lavaan2mirt","text":"","code":"lavaan2mirt(dat, lavmodel, est.mirt=TRUE, poly.itemtype=\"gpcm\", ...)"},{"path":"/reference/lavaan2mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converting a lavaan Model into a mirt Model — lavaan2mirt","text":"dat Dataset item responses lavmodel Model specified lavaan syntax (see lavaan::lavaanify) est.mirt optional logical indicating whether model estimated mirt::mirt poly.itemtype Item type polytomous data. can     gpcm generalized partial credit model       graded graded response model. ... arguments passed estimation mirt","code":""},{"path":"/reference/lavaan2mirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Converting a lavaan Model into a mirt Model — lavaan2mirt","text":"function uses lavaan::lavaanify (lavaan) function. single group models supported (now).","code":""},{"path":"/reference/lavaan2mirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converting a lavaan Model into a mirt Model — lavaan2mirt","text":"list following entries mirt Object generated mirt function est.mirt=TRUE mirt.model Generated mirt model mirt.syntax Generated mirt syntax mirt.pars Generated parameter specifications    mirt lavaan.model Used lavaan model transformed lavaanify function dat Used dataset. necessary, items used model included dataset.","code":""},{"path":[]},{"path":"/reference/lavaan2mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converting a lavaan Model into a mirt Model — lavaan2mirt","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Convert some lavaan syntax to mirt syntax for data.read #############################################################################  library(mirt) data(data.read) dat <- data.read  #****************** #*** Model 1: Single factor model lavmodel <- \"      # omit item C3      F=~ A1+A2+A3+A4 + C1+C2+C4 + B1+B2+B3+B4      F ~~ 1*F             \"  # convert syntax and estimate model res <- sirt::lavaan2mirt( dat,  lavmodel, verbose=TRUE, technical=list(NCYCLES=3) ) # inspect coefficients coef(res$mirt) mirt.wrapper.coef(res$mirt) # converted mirt model and parameter table cat(res$mirt.syntax) res$mirt.pars  #****************** #*** Model 2: Rasch Model with first six items lavmodel <- \"      F=~ a*A1+a*A2+a*A3+a*A4+a*B1+a*B2      F ~~ 1*F             \" # convert syntax and estimate model res <- sirt::lavaan2mirt( dat,  lavmodel, est.mirt=FALSE) # converted mirt model cat(res$mirt.syntax) # mirt parameter table res$mirt.pars # estimate model using generated objects res2 <- mirt::mirt( res$dat, res$mirt.model, pars=res$mirt.pars ) mirt.wrapper.coef(res2)     # parameter estimates  #****************** #*** Model 3: Bifactor model lavmodel <- \"      G=~ A1+A2+A3+A4 + B1+B2+B3+B4  + C1+C2+C3+C4      A=~ A1+A2+A3+A4      B=~ B1+B2+B3+B4      C=~ C1+C2+C3+C4      G ~~ 1*G      A ~~ 1*A      B ~~ 1*B      C ~~ 1*C             \" res <- sirt::lavaan2mirt( dat,  lavmodel, est.mirt=FALSE ) # mirt syntax and mirt model cat(res$mirt.syntax) res$mirt.model res$mirt.pars  #****************** #*** Model 4: 3-dimensional model with some parameter constraints lavmodel <- \"      # some equality constraints among loadings      A=~ a*A1+a*A2+a2*A3+a2*A4      B=~ B1+B2+b3*B3+B4      C=~ c*C1+c*C2+c*C3+c*C4      # some equality constraints among thresholds      A1 | da*t1      A3 | da*t1      B3 | da*t1      C3 | dg*t1      C4 | dg*t1      # standardized latent variables      A ~~ 1*A      B ~~ 1*B      C ~~ 1*C      # estimate Cov(A,B) and Cov(A,C)      A ~~ B      A ~~ C      # estimate mean of B      B ~ 1             \" res <- sirt::lavaan2mirt( dat,  lavmodel, verbose=TRUE, technical=list(NCYCLES=3) ) # estimated parameters mirt.wrapper.coef(res$mirt) # generated mirt syntax cat(res$mirt.syntax) # mirt parameter table mirt::mod2values(res$mirt)  #****************** #*** Model 5: 3-dimensional model with some parameter constraints and #             parameter fixings lavmodel <- \"      A=~ a*A1+a*A2+1.3*A3+A4  # set loading of A3 to 1.3      B=~ B1+1*B2+b3*B3+B4      C=~ c*C1+C2+c*C3+C4      A1 | da*t1      A3 | da*t1      C4 | dg*t1      B1 | 0*t1      B3 | -1.4*t1   # fix item threshold of B3 to -1.4      A ~~ 1*A      B ~~ B         # estimate variance of B freely      C ~~ 1*C      A ~~ B         # estimate covariance between A and B      A ~~ .6 * C    # fix covariance to .6      A ~ .5*1       # set mean of A to .5      B ~ 1          # estimate mean of B             \" res <- sirt::lavaan2mirt( dat,  lavmodel, verbose=TRUE, technical=list(NCYCLES=3) ) mirt.wrapper.coef(res$mirt)  #****************** #*** Model 6: 1-dimensional model with guessing and slipping parameters #******************  lavmodel <- \"      F=~ c*A1+c*A2+1*A3+1.3*A4 + C1__C4 + a*B1+b*B2+b*B3+B4      # guessing parameters      A1+A2 ?=guess1*g1      A3 ?=.25*g1      B1+C1 ?=g1      B2__B4 ?=0.10*g1      # slipping parameters      A1+A2+C3 ?=slip1*s1      A3 ?=.02*s1      # fix item intercepts      A1 | 0*t1      A2 | -.4*t1      F ~ 1    # estimate mean of F      F ~~ 1*F   # fix variance of F             \" # convert syntax and estimate model res <- sirt::lavaan2mirt( dat,  lavmodel, verbose=TRUE, technical=list(NCYCLES=3) ) # coefficients mirt.wrapper.coef(res$mirt) # converted mirt model cat(res$mirt.syntax)  ############################################################################# # EXAMPLE 2: Convert some lavaan syntax to mirt syntax for #            longitudinal data data.long #############################################################################  data(data.long) dat <- data.long[,-1]  #****************** #*** Model 1: Rasch model for T1 lavmodel <- \"      F=~ 1*I1T1 +1*I2T1+1*I3T1+1*I4T1+1*I5T1+1*I6T1      F ~~ F             \" # convert syntax and estimate model res <- sirt::lavaan2mirt( dat,  lavmodel, verbose=TRUE, technical=list(NCYCLES=20) ) # inspect coefficients mirt.wrapper.coef(res$mirt) # converted mirt model cat(res$mirt.syntax)  #****************** #*** Model 2: Rasch model for two time points lavmodel <- \"      F1=~ 1*I1T1 +1*I2T1+1*I3T1+1*I4T1+1*I5T1+1*I6T1      F2=~ 1*I3T2 +1*I4T2+1*I5T2+1*I6T2+1*I7T2+1*I8T2      F1 ~~ F1      F1 ~~ F2      F2 ~~ F2      # equal item difficulties of same items      I3T1 | i3*t1      I3T2 | i3*t1      I4T1 | i4*t1      I4T2 | i4*t1      I5T1 | i5*t1      I5T2 | i5*t1      I6T1 | i6*t1      I6T2 | i6*t1      # estimate mean of F1, but fix mean of F2      F1 ~ 1      F2 ~ 0*1             \" # convert syntax and estimate model res <- sirt::lavaan2mirt( dat,  lavmodel, verbose=TRUE, technical=list(NCYCLES=20) ) # inspect coefficients mirt.wrapper.coef(res$mirt) # converted mirt model cat(res$mirt.syntax)  #-- compare estimation with smirt function # define Q-matrix I <- ncol(dat) Q <- matrix(0,I,2) Q[1:6,1] <- 1 Q[7:12,2] <- 1 rownames(Q) <- colnames(dat) colnames(Q) <- c(\"T1\",\"T2\") # vector with same items itemnr <- as.numeric( substring( colnames(dat),2,2) ) # fix mean at T2 to zero mu.fixed <- cbind( 2,0 ) # estimate model in smirt mod1 <- sirt::smirt(dat, Qmatrix=Q, irtmodel=\"comp\", est.b=itemnr, mu.fixed=mu.fixed ) summary(mod1)  ############################################################################# # EXAMPLE 3: Converting lavaan syntax for polytomous data #############################################################################  data(data.big5) # select some items items <- c( grep( \"O\", colnames(data.big5), value=TRUE )[1:6],             grep( \"N\", colnames(data.big5), value=TRUE )[1:4] ) #  O3  O8  O13 O18 O23 O28 N1  N6  N11 N16 dat <- data.big5[, items ] library(psych) psych::describe(dat)  #****************** #*** Model 1: Partial credit model lavmodel <- \"       O=~ 1*O3+1*O8+1*O13+1*O18+1*O23+1*O28       O ~~ O          \" # estimate model in mirt res <- sirt::lavaan2mirt( dat, lavmodel, technical=list(NCYCLES=20), verbose=TRUE) # estimated mirt model mres <- res$mirt # mirt syntax cat(res$mirt.syntax)   ##   O=1,2,3,4,5,6   ##   COV=O*O # estimated parameters mirt.wrapper.coef(mres) # some plots mirt::itemplot( mres, 3 )   # third item plot(mres)   # item information plot(mres,type=\"trace\")  # item category functions  # graded response model with equal slopes res1 <- sirt::lavaan2mirt( dat, lavmodel, poly.itemtype=\"graded\", technical=list(NCYCLES=20),               verbose=TRUE ) mirt.wrapper.coef(res1$mirt)  #****************** #*** Model 2: Generalized partial credit model with some constraints lavmodel <- \"       O=~ O3+O8+O13+a*O18+a*O23+1.2*O28       O ~ 1   # estimate mean       O ~~ O  # estimate variance       # some constraints among thresholds       O3  | d1*t1       O13 | d1*t1       O3  | d2*t2       O8  | d3*t2       O28 | (-0.5)*t1          \" # estimate model in mirt res <- sirt::lavaan2mirt( dat, lavmodel, technical=list(NCYCLES=5), verbose=TRUE) # estimated mirt model mres <- res$mirt # estimated parameters mirt.wrapper.coef(mres)  #*** generate syntax for mirt for this model and estimate it in mirt package # Items: O3  O8  O13 O18 O23 O28 mirtmodel <- mirt::mirt.model( \"              O=1-6              # a(O18)=a(O23), t1(O3)=t1(O18), t2(O3)=t2(O8)              CONSTRAIN=(4,5,a1), (1,3,d1), (1,2,d2)              MEAN=O              COV=O*O                \") # initial table of parameters in mirt mirt.pars <- mirt::mirt( dat[,1:6], mirtmodel, itemtype=\"gpcm\", pars=\"values\") # fix slope of item O28 to 1.2 ind <- which( ( mirt.pars$item==\"O28\" ) & ( mirt.pars$name==\"a1\") ) mirt.pars[ ind, \"est\"] <- FALSE mirt.pars[ ind, \"value\"] <- 1.2 # fix d1 of item O28 to -0.5 ind <- which( ( mirt.pars$item==\"O28\" ) & ( mirt.pars$name==\"d1\") ) mirt.pars[ ind, \"est\"] <- FALSE mirt.pars[ ind, \"value\"] <- -0.5 # estimate model res2 <- mirt::mirt( dat[,1:6], mirtmodel, pars=mirt.pars,              verbose=TRUE, technical=list(NCYCLES=4) ) mirt.wrapper.coef(res2) plot(res2, type=\"trace\") }"},{"path":"/reference/lc.2raters.html","id":null,"dir":"Reference","previous_headings":"","what":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","title":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","text":"function computes latent class model ratings item based exchangeable raters (Uebersax & Grove, 1990). Additionally, several measures rater agreement computed (see e.g. Gwet, 2010).","code":""},{"path":"/reference/lc.2raters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","text":"","code":"lc.2raters(data, conv=0.001, maxiter=1000, progress=TRUE)  # S3 method for lc.2raters summary(object,...)"},{"path":"/reference/lc.2raters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","text":"data Data frame item responses (must ordered 0 \\(K\\)) two columns correspond ratings two (exchangeable) raters. conv Convergence criterion maxiter Maximum number iterations progress optional logical indicating whether iteration progress displayed. object Object class lc.2raters ... arguments passed","code":""},{"path":"/reference/lc.2raters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","text":"two exchangeable raters provide ratings item, latent class model \\(K+1\\) classes (\\(K+1\\) item categories \\(0,...,K\\)) defined. \\(P(X=x, Y=y | c)\\) denotes probability first rating \\(x\\) second rating \\(y\\) given true unknown item category (class) \\(c\\). Ratings assumed locally independent, .e. $$ P(X=x, Y=y | c )=P( X=x | c) \\cdot P(Y=y | c )=p_{x|c} \\cdot p_{y|c}$$ Note \\(P(X=x|c)=P(Y=x|c)=p_{x|c}\\) holds due exchangeability raters. latent class model estimates true class proportions \\(\\pi_c\\) conditional item probabilities \\(p_{x|c}\\).","code":""},{"path":"/reference/lc.2raters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","text":"list following entries classprob.1rater.like Classification probability \\(P(c|x)\\) latent category \\(c\\) given manifest rating \\(x\\) (estimated maximum likelihood) classprob.1rater.post Classification probability \\(P(c|x)\\) latent category \\(c\\) given manifest rating \\(x\\) (estimated posterior distribution) classprob.2rater.like Classification probability \\(P(c|(x,y))\\) latent category \\(c\\) given two manifest ratings \\(x\\) \\(y\\) (estimated maximum likelihood) classprob.2rater.post Classification probability \\(P(c|(x,y))\\) latent category \\(c\\) given two manifest ratings \\(x\\) \\(y\\) (estimated posterior distribution) f.yi.qk Likelihood pair ratings f.qk.yi Posterior pair ratings probs Item response probabilities \\(p_{x|c}\\) pi.k Estimated class proportions \\(\\pi_c\\) pi.k.obs Observed manifest class proportions freq.long Frequency table ratings long format freq.table Symmetrized frequency table ratings agree.stats Measures rater agreement. measures include percentage agreement (agree0, agree1), Cohen's kappa weighted Cohen's kappa (kappa, wtd.kappa.linear), Gwet's AC1 agreement measures (AC1; Gwet, 2008, 2010) Aickin's alpha (alpha.aickin; Aickin, 1990). data Used dataset N.categ Number categories","code":""},{"path":"/reference/lc.2raters.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","text":"Aickin, M. (1990). Maximum likelihood estimation agreement constant predictive probability model, relation Cohen's kappa. Biometrics, 46, 293-302. Gwet, K. L. (2008). Computing inter-rater reliability variance presence high agreement. British Journal Mathematical Statistical Psychology, 61, 29-48. Gwet, K. L. (2010). Handbook Inter-Rater Reliability. Advanced Analytics, Gaithersburg. http://www.agreestat.com/ Uebersax, J. S., & Grove, W. M. (1990). Latent class analysis diagnostic agreement. Statistics Medicine, 9, 559-572.","code":""},{"path":[]},{"path":"/reference/lc.2raters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Latent Class Model for Two Exchangeable Raters and One Item — lc.2raters","text":"","code":"############################################################################# # EXAMPLE 1: Latent class models for rating datasets data.si05 #############################################################################  data(data.si05)  #*** Model 1: one item with two categories mod1 <- sirt::lc.2raters( data.si05$Ex1) summary(mod1)  #*** Model 2: one item with five categories mod2 <- sirt::lc.2raters( data.si05$Ex2) summary(mod2)  #*** Model 3: one item with eight categories mod3 <- sirt::lc.2raters( data.si05$Ex3) summary(mod3)"},{"path":"/reference/likelihood.adjustment.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjustment and Approximation of Individual Likelihood Functions — likelihood.adjustment","title":"Adjustment and Approximation of Individual Likelihood Functions — likelihood.adjustment","text":"Approximates individual likelihood functions \\(L(\\bold{X}_p | \\theta)\\) normal distributions (see Mislevy, 1990). Extreme response patterns handled adding pseudo-observations items extreme item difficulties (see argument extreme.item. individual standard deviations likelihood, used normal approximation, can modified individual adjustment factors specified adjfac. addition, reliability adjusted likelihood can specified target.EAP.rel.","code":""},{"path":"/reference/likelihood.adjustment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjustment and Approximation of Individual Likelihood Functions — likelihood.adjustment","text":"","code":"likelihood.adjustment(likelihood, theta=NULL, prob.theta=NULL,      adjfac=rep(1, nrow(likelihood)), extreme.item=5, target.EAP.rel=NULL,      min_tuning=0.2, max_tuning=3, maxiter=100, conv=1e-04,      trait.normal=TRUE)"},{"path":"/reference/likelihood.adjustment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjustment and Approximation of Individual Likelihood Functions — likelihood.adjustment","text":"likelihood matrix containing individual likelihood \\(L(\\bold{X}_p | \\theta)\\) object class IRT.likelihood. theta Optional vector (unidimensional) \\(\\theta\\) values prob.theta Optional vector probabilities \\(\\theta\\) trait distribution adjfac Vector individual adjustment factors standard deviations likelihood extreme.item Item difficulties two extreme pseudo items added additional observed data likelihood. large number (e.g. extreme.item=15) leaves likelihood almost unaffected. See also Mislevy (1990). target.EAP.rel Target EAP reliability. additional tuning parameter estimated adjusts likelihood obtain pre-specified reliability. min_tuning Minimum value tuning parameter (! .null(target.EAP.rel) ) max_tuning Maximum value tuning parameter (! .null(target.EAP.rel) ) maxiter Maximum number iterations (! .null(target.EAP.rel) ) conv Convergence criterion (! .null(target.EAP.rel) ) trait.normal Optional logical indicating whether trait distribution normally distributed (! .null(target.EAP.rel) ).","code":""},{"path":"/reference/likelihood.adjustment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjustment and Approximation of Individual Likelihood Functions — likelihood.adjustment","text":"Object class IRT.likelihood.","code":""},{"path":"/reference/likelihood.adjustment.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adjustment and Approximation of Individual Likelihood Functions — likelihood.adjustment","text":"Mislevy, R. (1990). Scaling procedures. E. Johnson & R. Zwick (Eds.), Focusing new design: NAEP 1988 technical report (ETS RR 19-20). Princeton, NJ: Educational Testing Service.","code":""},{"path":[]},{"path":"/reference/likelihood.adjustment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjustment and Approximation of Individual Likelihood Functions — likelihood.adjustment","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Adjustment of the likelihood | data.read #############################################################################  library(CDM) library(TAM) data(data.read) dat <- data.read  # define theta grid theta.k <- seq(-6,6,len=41)  #*** Model 1: fit Rasch model in TAM mod1 <- TAM::tam.mml( dat, control=list( nodes=theta.k) ) summary(mod1)  #*** Model 2: fit Rasch copula model testlets <- substring( colnames(dat), 1, 1 ) mod2 <- sirt::rasch.copula2( dat, itemcluster=testlets, theta.k=theta.k) summary(mod2)  # model comparison IRT.compareModels( mod1, mod2 )  # extract EAP reliabilities rel1 <- mod1$EAP.rel rel2 <- mod2$EAP.Rel # variance inflation factor vif <- (1-rel2) / (1-rel1)   ##  > vif   ##  [1] 1.211644  # extract individual likelihood like1 <- IRT.likelihood( mod1 ) # adjust likelihood from Model 1 to obtain a target EAP reliability of .599 like1b <- sirt::likelihood.adjustment( like1, target.EAP.rel=.599 )  # compare estimated latent regressions lmod1a <- TAM::tam.latreg( like1, Y=NULL ) lmod1b <- TAM::tam.latreg( like1b, Y=NULL ) summary(lmod1a) summary(lmod1b) }"},{"path":"/reference/linking.haberman.html","id":null,"dir":"Reference","previous_headings":"","what":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","title":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","text":"function linking several studies calibrated using 2PL generalized item response model according Haberman (2009). method generalization log-mean-mean linking one study several studies. default a_log=TRUE logarithmizes item slopes linking otherwise additive regression model assumed original item loadings (see Details; Battauz, 2017)","code":""},{"path":"/reference/linking.haberman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","text":"","code":"linking.haberman(itempars, personpars, estimation=\"OLS\", a_trim=Inf, b_trim=Inf,     lts_prop=.5, a_log=TRUE, conv=1e-05, maxiter=1000, progress=TRUE,     adjust_main_effects=TRUE, vcov=TRUE)  # S3 method for linking.haberman summary(object, digits=3, file=NULL, ...)  linking.haberman.lq(itempars, pow=2, eps=1e-3, a_log=TRUE, use_nu=FALSE,       est_pow=FALSE, lower_pow=.1, upper_pow=3)  # S3 method for linking.haberman.lq summary(object, digits=3, file=NULL, ...)  ## prepare 'itempars' argument for linking.haberman() linking_haberman_itempars_prepare(b, a=NULL, wgt=NULL)  ## conversion of different parameterizations of item parameters linking_haberman_itempars_convert(itempars=NULL, lambda=NULL, nu=NULL, a=NULL, b=NULL)  ## L0 polish precedure minimizing number of interactions in two-way table L0_polish(x, tol, conv=0.01, maxiter=30, type=1, verbose=TRUE)"},{"path":"/reference/linking.haberman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","text":"itempars data frame four five columns. first four columns contain order: study name, item name, \\(\\) parameter, \\(b\\) parameter. fifth column optional weight every item every study. personpars list vectors (e.g. EAPs WLEs) data frames     (e.g. plausible values) containing person parameters     transformed. data frame list entry se SE (standard error) column name, corresponding column multiplied \\(A_t\\). column labeled pid (person ID), left untransformed. estimation Estimation method. Can \"OLS\" (ordinary least squares), \"BSQ\" (bisquare weighted regression), \"HUB\" (regression using Huber weights), \"MED\" (median regression), \"LTS\" (trimmed least squares), \"L1\" (median polish), \"L0\" (minimizing number interactions) a_trim Trimming parameter item slopes \\(a_{}\\) bisquare regression (see Details). b_trim Trimming parameter item slopes \\(b_{}\\) bisquare regression (see Details). lts_prop Proportion retained observations \"LTS\" regression estimation a_log Logical indicating whether item slopes logarithmized linking. conv Convergence criterion. maxiter Maximum number iterations. progress optional logical indicating whether computational progress displayed. adjust_main_effects Logical indicating whether elements vector main effects simultaneously adjusted vcov Optional indicating whether covariance matrix linking errors computed pow Power \\(q\\) eps Epsilon value used differentiable approximating function use_nu Logical indicating whether item intercepts instead item difficulties used linking est_pow Logical indicating whether power values estimated lower_pow Lower bound estimated power upper_pow Upper bound estimated power lambda Matrix containing item loadings nu Matrix containing item intercepts object Object class linking.haberman. digits Number digits decimals rounding summary. file Optional file name summary sunk file. ... arguments passed b Matrix item intercepts (items \\(times\\) studies) Matrix item slopes wgt Matrix weights x Matrix tol Tolerance value type Can 1 (using Tukey's median polish) 2 (alternating median regression). verbose Logical indicating whether iteration progress displayed","code":""},{"path":"/reference/linking.haberman.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","text":"\\(t=1,\\ldots,T\\) studies, item difficulties \\(b_{}\\) item slopes \\(a_{}\\) available. dichotomous responses, parameters defined 2PL response equation $$ logit P(X_{pi}=1| \\theta_p )=a_i ( \\theta_p - b_i ) $$ polytomous responses generalized partial credit model holds $$ log \\frac{P(X_{pi}=k| \\theta_p )}{P(X_{pi}=k-1| \\theta_p )} =a_i ( \\theta_p - b_i + d_{ik} ) $$ parameters \\( \\{ a_{}, b_{} \\}\\) items studies linearly transformed using equations \\(a_{} \\approx a_i / A_t\\) (a_log=TRUE) \\(a_{} \\approx a_i + A_t\\) (a_log=FALSE) \\(b_{} \\cdot A_t \\approx B_t + b_i\\). identification reasons, define \\(A_1=1\\) \\(B_1\\)=0. optimization function (least squares criterion; see Haberman, 2009) seeks transformation parameters \\(A_t\\) \\(B_t\\) alternating least squares method (estimation=\"OLS\"). Note every item \\(\\) every study \\(t\\) can weighted (specified fifth column itempars). Alternatively, robust regression method based bisquare weighting (Fox, 2015) can employed linking using argument estimation=\"BSQ\". example, case item loadings, bisquare weighting applied residuals \\(e_{}=a_{} - a_i - A_t \\) (logarithmized non-logarithmized item loadings employed) forming weights \\(w_{}=[ 1 - ( e_{} / k )^2 ]^2\\) \\(e_{} <k\\) 0 \\(e_{} \\ge k\\) \\(k\\) trimming constant can estimated fixed estimation using arguments a_trim b_trim. Items studies large residuals (.e., presence differential item functioning) effectively set zero linking procedure. Alternatively, Huber weights (estimation=\"HUB\") downweight large residuals applying \\(w_{}=k / | e_{} |\\) residuals \\(|e_{}|>k\\).  method estimation=\"LTS\" employs trimmed least squares proportion data retained specified lts_prop default set .50. method estimation=\"MED\" estimates item parameters linking constants based alternating median regression. similar approach median polish procedure Tukey (Tukey, 1977, p. 362ff.; Maronna, Martin & Yohai, 2006, p. 104; see also stats::medpolish) implemented estimation=\"L1\" aims minimize \\(\\sum_{,t} | e_{} |\\). pre-specified tolerance value \\(t\\) (a_trim b_trim), approach estimation=\"L0\" minimizes number interactions (.e., DIF effects) \\(e_{}\\) effects. detail, minimizes  \\(\\sum_{,t} \\# \\{ | e_{} | > t \\} \\) computationally conducted  repeatedly applying median polish procedure one cell omitted (Davies, 2012; Terbeck & Davies, 1998). Effect sizes invariance calculated R-squared measures explained item slopes intercepts linking comparison item parameters across groups (Asparouhov & Muthen, 2014). function \\(linking.haberman.lq\\) uses loss function \\(\\rho(x)=|x|^q\\). originally proposed Haberman linking can obtained pow=2 (\\(q=2\\)). powers can also estimated (argument est_pow=TRUE).","code":""},{"path":"/reference/linking.haberman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","text":"list following entries transf.pars Data frame transformation parameters \\(A_t\\) \\(B_t\\) transf.personpars Data frame linear transformation functions   person parameters joint.itempars Estimated joint item parameters \\(a_i\\) \\(b_i\\) .trans Transformed \\(a_{}\\) parameters b.trans Transformed \\(b_{}\\) parameters .orig Original \\(a_{}\\) parameters b.orig Original \\(b_{}\\) parameters .resid Residual \\(a_{}\\) parameters (DIF parameters) b.resid Residual \\(b_{}\\) parameters (DIF parameters) personpars Transformed person parameters es.invariance Effect size measures invariance,         separately item slopes intercepts.         rows, \\(R^2\\) \\(\\sqrt{1-R^2}\\) reported. es.robust Effect size measures invariance based   robust estimation (used). selitems Indices items present one   study.","code":""},{"path":"/reference/linking.haberman.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","text":"Asparouhov, T., & Muthen, B. (2014). Multiple-group factor analysis alignment. Structural Equation Modeling, 21(4), 1-14. doi:10.1080/10705511.2014.919210 Battauz, M. (2017). Multiple equating separate IRT calibrations. Psychometrika, 82(3), 610-636. doi:10.1007/s11336-016-9517-x Davies, P. L. (2012). Interactions analysis variance. Journal American Statistical Association, 107(500), 1502-1509. doi:10.1080/01621459.2012.726895 Fox, J. (2015). Applied regression analysis generalized linear models. Thousand Oaks: Sage. Haberman, S. J. (2009). Linking parameter estimates derived item response model separate calibrations. ETS Research Report ETS RR-09-40. Princeton, ETS. doi:10.1002/j.2333-8504.2009.tb02197.x Kolen, M. J., & Brennan, R. L. (2014). Test equating, scaling, linking: Methods practices. New York: Springer. doi:10.1007/978-1-4939-0317-7 Magis, D., & De Boeck, P. (2012). robust outlier approach prevent type error inflation differential item functioning. Educational Psychological Measurement, 72(2), 291-311. doi:10.1177/0013164411416975 Maronna, R. ., Martin, R. D., & Yohai, V. J. (2006). Robust statistics. West Sussex: Wiley. doi:10.1002/0470010940 Terbeck, W., & Davies, P. L. (1998). Interactions outliers two-way analysis variance. Annals Statistics, 26(4), 1279-1305. doi: 10.1214/aos/1024691243 Tukey, J. W. (1977). Exploratory data analysis. Addison-Wesley. Weeks, J. P. (2010). plink: R package linking mixed-format tests using IRT-based methods. Journal Statistical Software, 35(12), 1-33. doi:10.18637/jss.v035.i12","code":""},{"path":[]},{"path":"/reference/linking.haberman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linking in the 2PL/Generalized Partial Credit Model — linking.haberman","text":"","code":"############################################################################# # EXAMPLE 1: Item parameters data.pars1.rasch and data.pars1.2pl #############################################################################  # Model 1: Linking three studies calibrated by the Rasch model data(data.pars1.rasch) mod1 <- sirt::linking.haberman( itempars=data.pars1.rasch ) summary(mod1)  # Model 1b: Linking these studies but weigh these studies by #     proportion weights 3 : 0.5 : 1 (see below). #     All weights are the same for each item but they could also #     be item specific. itempars <- data.pars1.rasch itempars$wgt <- 1 itempars[ itempars$study==\"study1\",\"wgt\"] <- 3 itempars[ itempars$study==\"study2\",\"wgt\"] <- .5 mod1b <- sirt::linking.haberman( itempars=itempars ) summary(mod1b)  # Model 2: Linking three studies calibrated by the 2PL model data(data.pars1.2pl) mod2 <- sirt::linking.haberman( itempars=data.pars1.2pl ) summary(mod2)  # additive model instead of logarithmic model for item slopes mod2b <- sirt::linking.haberman( itempars=data.pars1.2pl, a_log=FALSE ) summary(mod2b)  if (FALSE) { ############################################################################# # EXAMPLE 2: Linking longitudinal data ############################################################################# data(data.long)  #****** # Model 1: Scaling with the 1PL model  # scaling at T1 dat1 <- data.long[, grep(\"T1\", colnames(data.long) ) ] resT1 <- sirt::rasch.mml2( dat1 ) itempartable1 <- data.frame( \"study\"=\"T1\", resT1$item[, c(\"item\", \"a\", \"b\" ) ] ) # scaling at T2 dat2 <- data.long[, grep(\"T2\", colnames(data.long) ) ] resT2 <- sirt::rasch.mml2( dat2 ) summary(resT2) itempartable2 <- data.frame( \"study\"=\"T2\", resT2$item[, c(\"item\", \"a\", \"b\" ) ] ) itempartable <- rbind( itempartable1, itempartable2 ) itempartable[,2] <- substring( itempartable[,2], 1, 2 ) # estimate linking parameters mod1 <- sirt::linking.haberman( itempars=itempartable )  #****** # Model 2: Scaling with the 2PL model  # scaling at T1 dat1 <- data.long[, grep(\"T1\", colnames(data.long) ) ] resT1 <- sirt::rasch.mml2( dat1, est.a=1:6) itempartable1 <- data.frame( \"study\"=\"T1\", resT1$item[, c(\"item\", \"a\", \"b\" ) ] )  # scaling at T2 dat2 <- data.long[, grep(\"T2\", colnames(data.long) ) ] resT2 <- sirt::rasch.mml2( dat2, est.a=1:6) summary(resT2) itempartable2 <- data.frame( \"study\"=\"T2\", resT2$item[, c(\"item\", \"a\", \"b\" ) ] ) itempartable <- rbind( itempartable1, itempartable2 ) itempartable[,2] <- substring( itempartable[,2], 1, 2 ) # estimate linking parameters mod2 <- sirt::linking.haberman( itempars=itempartable )  ############################################################################# # EXAMPLE 3: 2 Studies - 1PL and 2PL linking ############################################################################# set.seed(789) I <- 20        # number of items N <- 2000       # number of persons # define item parameters b <- seq( -1.5, 1.5, length=I ) # simulate data dat1 <- sirt::sim.raschtype( stats::rnorm( N, mean=0,sd=1 ), b=b ) dat2 <- sirt::sim.raschtype( stats::rnorm( N, mean=0.5,sd=1.50 ), b=b )  #*** Model 1: 1PL # 1PL Study 1 mod1 <- sirt::rasch.mml2( dat1, est.a=rep(1,I) ) summary(mod1) # 1PL Study 2 mod2 <- sirt::rasch.mml2( dat2, est.a=rep(1,I) ) summary(mod2)  # collect item parameters dfr1 <- data.frame( \"study1\", mod1$item$item, mod1$item$a, mod1$item$b ) dfr2 <- data.frame( \"study2\", mod2$item$item, mod2$item$a, mod2$item$b ) colnames(dfr2) <- colnames(dfr1) <- c(\"study\", \"item\", \"a\", \"b\" ) itempars <- rbind( dfr1, dfr2 )  # Haberman linking linkhab1 <- sirt::linking.haberman(itempars=itempars)   ## Transformation parameters (Haberman linking)   ##    study    At     Bt   ## 1 study1 1.000  0.000   ## 2 study2 1.465 -0.512   ##   ## Linear transformation for item parameters a and b   ##    study   A_a   A_b    B_b   ## 1 study1 1.000 1.000  0.000   ## 2 study2 0.682 1.465 -0.512   ##   ## Linear transformation for person parameters theta   ##    study A_theta B_theta   ## 1 study1   1.000   0.000   ## 2 study2   1.465   0.512   ##   ## R-Squared Measures of Invariance   ##        slopes intercepts   ## R2          1     0.9979   ## sqrtU2      0     0.0456  #*** Model 2: 2PL # 2PL Study 1 mod1 <- sirt::rasch.mml2( dat1, est.a=1:I ) summary(mod1) # 2PL Study 2 mod2 <- sirt::rasch.mml2( dat2, est.a=1:I ) summary(mod2)  # collect item parameters dfr1 <- data.frame( \"study1\", mod1$item$item, mod1$item$a, mod1$item$b ) dfr2 <- data.frame( \"study2\", mod2$item$item, mod2$item$a, mod2$item$b ) colnames(dfr2) <- colnames(dfr1) <- c(\"study\", \"item\", \"a\", \"b\" ) itempars <- rbind( dfr1, dfr2 )  # Haberman linking linkhab2 <- sirt::linking.haberman(itempars=itempars)   ## Transformation parameters (Haberman linking)   ##    study    At     Bt   ## 1 study1 1.000  0.000   ## 2 study2 1.468 -0.515   ##   ## Linear transformation for item parameters a and b   ##    study   A_a   A_b    B_b   ## 1 study1 1.000 1.000  0.000   ## 2 study2 0.681 1.468 -0.515   ##   ## Linear transformation for person parameters theta   ##    study A_theta B_theta   ## 1 study1   1.000   0.000   ## 2 study2   1.468   0.515   ##   ## R-Squared Measures of Invariance   ##        slopes intercepts   ## R2     0.9984     0.9980   ## sqrtU2 0.0397     0.0443  ############################################################################# # EXAMPLE 4: 3 Studies - 1PL and 2PL linking ############################################################################# set.seed(789) I <- 20         # number of items N <- 1500       # number of persons # define item parameters b <- seq( -1.5, 1.5, length=I ) # simulate data dat1 <- sirt::sim.raschtype( stats::rnorm( N, mean=0, sd=1), b=b ) dat2 <- sirt::sim.raschtype( stats::rnorm( N, mean=0.5, sd=1.50), b=b ) dat3 <- sirt::sim.raschtype( stats::rnorm( N, mean=-0.2, sd=0.8), b=b ) # set some items to non-administered dat3 <- dat3[, -c(1,4) ] dat2 <- dat2[, -c(1,2,3) ]  #*** Model 1: 1PL in sirt # 1PL Study 1 mod1 <- sirt::rasch.mml2( dat1, est.a=rep(1,ncol(dat1)) ) summary(mod1) # 1PL Study 2 mod2 <- sirt::rasch.mml2( dat2, est.a=rep(1,ncol(dat2)) ) summary(mod2) # 1PL Study 3 mod3 <- sirt::rasch.mml2( dat3, est.a=rep(1,ncol(dat3)) ) summary(mod3)  # collect item parameters dfr1 <- data.frame( \"study1\", mod1$item$item, mod1$item$a, mod1$item$b ) dfr2 <- data.frame( \"study2\", mod2$item$item, mod2$item$a, mod2$item$b ) dfr3 <- data.frame( \"study3\", mod3$item$item, mod3$item$a, mod3$item$b ) colnames(dfr3) <- colnames(dfr2) <- colnames(dfr1) <- c(\"study\", \"item\", \"a\", \"b\" ) itempars <- rbind( dfr1, dfr2, dfr3 )  # use person parameters personpars <- list( mod1$person[, c(\"EAP\",\"SE.EAP\") ], mod2$person[, c(\"EAP\",\"SE.EAP\") ],     mod3$person[, c(\"EAP\",\"SE.EAP\") ] )  # Haberman linking linkhab1 <- sirt::linking.haberman(itempars=itempars, personpars=personpars) # compare item parameters round( cbind( linkhab1$joint.itempars[,-1], linkhab1$b.trans )[1:5,], 3 )   ##            aj     bj study1 study2 study3   ##   I0001 0.998 -1.427 -1.427     NA     NA   ##   I0002 0.998 -1.290 -1.324     NA -1.256   ##   I0003 0.998 -1.140 -1.068     NA -1.212   ##   I0004 0.998 -0.986 -1.003 -0.969     NA   ##   I0005 0.998 -0.869 -0.809 -0.872 -0.926  # summary of person parameters of second study round( psych::describe( linkhab1$personpars[[2]] ), 2 )   ##   var    n mean   sd median trimmed  mad   min  max range  skew kurtosis   ## EAP      1 1500 0.45 1.36   0.41    0.47 1.52 -2.61 3.25  5.86 -0.08    -0.62   ## SE.EAP   2 1500 0.57 0.09   0.53    0.56 0.04  0.49 0.84  0.35  1.47     1.56   ##          se   ## EAP    0.04   ## SE.EAP 0.00  #*** Model 2: 2PL in TAM library(TAM) # 2PL Study 1 mod1 <- TAM::tam.mml.2pl( resp=dat1, irtmodel=\"2PL\" ) pvmod1 <- TAM::tam.pv(mod1, ntheta=300, normal.approx=TRUE) # draw plausible values summary(mod1) # 2PL Study 2 mod2 <- TAM::tam.mml.2pl( resp=dat2, irtmodel=\"2PL\" ) pvmod2 <- TAM::tam.pv(mod2, ntheta=300, normal.approx=TRUE) summary(mod2) # 2PL Study 3 mod3 <- TAM::tam.mml.2pl( resp=dat3, irtmodel=\"2PL\" ) pvmod3 <- TAM::tam.pv(mod3, ntheta=300, normal.approx=TRUE) summary(mod3)  # collect item parameters #!!  Note that in TAM the parametrization is a*theta - b while linking.haberman #!!  needs the parametrization a*(theta-b) dfr1 <- data.frame( \"study1\", mod1$item$item, mod1$B[,2,1], mod1$xsi$xsi / mod1$B[,2,1] ) dfr2 <- data.frame( \"study2\", mod2$item$item, mod2$B[,2,1], mod2$xsi$xsi / mod2$B[,2,1] ) dfr3 <- data.frame( \"study3\", mod3$item$item, mod3$B[,2,1], mod3$xsi$xsi / mod3$B[,2,1] ) colnames(dfr3) <- colnames(dfr2) <- colnames(dfr1) <- c(\"study\", \"item\", \"a\", \"b\" ) itempars <- rbind( dfr1, dfr2, dfr3 )  # define list containing person parameters personpars <- list(  pvmod1$pv[,-1], pvmod2$pv[,-1], pvmod3$pv[,-1] )  # Haberman linking linkhab2 <- sirt::linking.haberman(itempars=itempars,personpars=personpars)   ##   Linear transformation for person parameters theta   ##      study A_theta B_theta   ##   1 study1   1.000   0.000   ##   2 study2   1.485   0.465   ##   3 study3   0.786  -0.192  # extract transformed person parameters personpars.trans <- linkhab2$personpars  ############################################################################# # EXAMPLE 5: Linking with simulated item parameters containing outliers #############################################################################  # simulate some parameters I <- 38 set.seed(18785) b <- stats::rnorm( I, mean=.3, sd=1.4 ) # simulate DIF effects plus some outliers bdif <- stats::rnorm(I,mean=.4,sd=.09)+( stats::runif(I)>.9 )* rep( 1*c(-1,1)+.4, each=I/2 ) # create item parameter table itempars <- data.frame( \"study\"=paste0(\"study\",rep(1:2, each=I)),                 \"item\"=paste0( \"I\", 100 + rep(1:I,2) ), \"a\"=1,                  \"b\"=c( b, b + bdif  )  )  #*** Model 1: Haberman linking with least squares regression mod1 <- sirt::linking.haberman( itempars=itempars ) summary(mod1)  #*** Model 2: Haberman linking with robust bisquare regression with fixed trimming value mod2 <- sirt::linking.haberman( itempars=itempars, estimation=\"BSQ\", b_trim=.4) summary(mod2)  #*** Model 2: Haberman linking with robust bisquare regression with estimated trimming value mod3 <- sirt::linking.haberman( itempars=itempars, estimation=\"BSQ\") summary(mod3)  ## see also Example 3 of ?sirt::robust.linking  ############################################################################# # EXAMPLE 6: Toy example of Magis and De Boeck (2012) #############################################################################  # define item parameters from Magis & De Boeck (20212, p. 293) b1 <- c(1,1,1,1) b2 <- c(1,1,1,2) itempars <- data.frame(study=rep(1:2, each=4), item=rep(1:4,2), a=1, b=c(b1,b2) )  #- Least squares regression mod1 <- sirt::linking.haberman( itempars=itempars, estimation=\"OLS\") summary(mod1)  #- Bisquare regression with estimated and fixed trimming factors mod2 <- sirt::linking.haberman( itempars=itempars, estimation=\"BSQ\") mod2a <- sirt::linking.haberman( itempars=itempars, estimation=\"BSQ\", b_trim=.4) mod2b <- sirt::linking.haberman( itempars=itempars, estimation=\"BSQ\", b_trim=1.2) summary(mod2) summary(mod2a) summary(mod2b)  #- Least squares trimmed regression mod3 <- sirt::linking.haberman( itempars=itempars, estimation=\"LTS\") summary(mod3)  #- median regression mod4 <- sirt::linking.haberman( itempars=itempars, estimation=\"MED\") summary(mod4)  ############################################################################# # EXAMPLE 7: Simulated example with directional DIF #############################################################################  set.seed(98) I <- 8 mu <- c(-.5, 0, .5) b <- sample(seq(-1.5,1.5, len=I)) sd_dif <- 0.001 pars <- outer(b, mu, \"+\") + stats::rnorm(I*3, sd=sd_dif) ind <- c(1,2); pars[ind,1] <- pars[ind,1] + c(.5,.5) ind <- c(3,4); pars[ind,2] <- pars[ind,2] + (-1)*c(.6,.6) ind <- c(5,6); pars[ind,3] <- pars[ind,3] + (-1)*c(1,1)  # median polish (=stats::medpolish()) tmod1 <- sirt:::L1_polish(x=pars) # L0 polish with tolerance criterion of .3 tmod2 <- sirt::L0_polish(x=pars, tol=.3)  #- prepare itempars input itempars <- sirt::linking_haberman_itempars_prepare(b=pars)  #- compare different estimation functions for Haberman linking mod01 <- sirt::linking.haberman(itempars, estimation=\"L1\") mod02 <- sirt::linking.haberman(itempars, estimation=\"L0\", b_trim=.3) mod1 <- sirt::linking.haberman(itempars, estimation=\"OLS\") mod2 <- sirt::linking.haberman(itempars, estimation=\"BSQ\") mod2a <- sirt::linking.haberman(itempars, estimation=\"BSQ\", b_trim=.4) mod3 <- sirt::linking.haberman(itempars, estimation=\"MED\") mod4 <- sirt::linking.haberman(itempars, estimation=\"LTS\") mod5 <- sirt::linking.haberman(itempars, estimation=\"HUB\") mod01$transf.pars mod02$transf.pars mod1$transf.pars mod2$transf.pars mod2a$transf.pars mod3$transf.pars mod4$transf.pars mod5$transf.pars  ############################################################################# # EXAMPLE 8: Many studies and directional DIF #############################################################################  ## dataset 2 set.seed(98) I <- 10 # number of items S <- 7  # number of studies mu <- round( seq(0, 1, len=S)) b <- sample(seq(-1.5,1.5, len=I)) sd_dif <- 0.001 pars0 <- pars <- outer(b, mu, \"+\") + stats::rnorm(I*S, sd=sd_dif)  # select n_dif items at random per group and set it to dif or -dif n_dif <- 2 dif <- .6 for (ss in 1:S){     ind <- sample( 1:I, n_dif )     pars[ind,ss] <- pars[ind,ss] + dif*sign( runif(1) - .5 ) }  # check DIF pars - pars0  #* estimate models itempars <- sirt::linking_haberman_itempars_prepare(b=pars) mod0 <- sirt::linking.haberman(itempars, estimation=\"L0\", b_trim=.2) mod1 <- sirt::linking.haberman(itempars, estimation=\"OLS\") mod2 <- sirt::linking.haberman(itempars, estimation=\"BSQ\") mod2a <- sirt::linking.haberman(itempars, estimation=\"BSQ\", b_trim=.4) mod3 <- sirt::linking.haberman(itempars, estimation=\"MED\") mod3a <- sirt::linking.haberman(itempars, estimation=\"L1\") mod4 <- sirt::linking.haberman(itempars, estimation=\"LTS\") mod5 <- sirt::linking.haberman(itempars, estimation=\"HUB\") mod0$transf.pars mod1$transf.pars mod2$transf.pars mod2a$transf.pars mod3$transf.pars mod3a$transf.pars mod4$transf.pars mod5$transf.pars  #* compare results with Haebara linking mod11 <- sirt::linking.haebara(itempars, dist=\"L2\") mod12 <- sirt::linking.haebara(itempars, dist=\"L1\") summary(mod11) summary(mod12) }"},{"path":"/reference/linking.haebara.html","id":null,"dir":"Reference","previous_headings":"","what":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","title":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","text":"function linking.haebara generalization Haebara linking 2PL model multiple groups (multiple studies; see Battauz, 2017, similar approach). optimization estimates transformation parameters means standard deviations groups joint item parameters. function allows two different distance functions dist=\"L2\" dist=\"L1\" latter robustified version Haebara linking (see Details; , Cui, & Osterlind, 2015; & Cui, 2020; Hu, Rogers, & Vukmirovic, 2008).","code":""},{"path":"/reference/linking.haebara.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","text":"","code":"linking.haebara(itempars, dist=\"L2\", theta=seq(-4,4, length=61),         optimizer=\"optim\", center=FALSE, eps=1e-3, par_init=NULL, use_rcpp=TRUE,         pow=2, use_der=TRUE, ...)  # S3 method for linking.haebara summary(object, digits=3, file=NULL, ...)"},{"path":"/reference/linking.haebara.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","text":"itempars data frame four five columns. first four columns contain order: study name, item name, \\(\\) parameter, \\(b\\) parameter. fifth column optional weight every item every study. See linking.haberman function uses argument. dist Distance function. Options \"L2\" squared loss \"L1\" absolute value loss. theta Grid theta points 2PL item response functions optimizer Name optimizer chosen alignment. Options    \"optim\" (using stats::optim)    \"nlminb\" (using stats::nlminb). center Logical indicating whether means standard deviations centered estimation eps Small value smooth approximation absolute value function par_init Optional vector initial parameter estimates use_rcpp Logical indicating whether Rcpp used computation pow Power method dist=\"Lq\" use_der Logical indicating whether analytical derivative used object Object class linking.haabara. digits Number digits decimals rounding summary. file Optional file name summary sunk file. ... arguments passed","code":""},{"path":"/reference/linking.haebara.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","text":"\\(t=1,\\ldots,T\\) studies, item difficulties \\(b_{}\\) item slopes \\(a_{}\\) available. 2PL item response functions given $$ logit P(X_{pi}=1| \\theta_p )=a_i ( \\theta_p - b_i ) $$ Haebara linking compares observed item response functions \\(P_{}\\) based equation logits \\(a_{}(\\theta - b_{})\\) expected item response functions \\(P_{}^\\ast\\) based equation logits \\(a_i^\\ast \\sigma_t ( \\theta - ( b_i - \\mu_t)/\\sigma_t )\\) joint item parameters \\(a_i\\) \\(b_i\\) means \\(\\mu_t\\) standard deviations \\(\\sigma_t\\) estimated. Two loss functions implemented. quadratic loss Haebara linking (dist=\"L2\") minimizes $$f_{opt, L2}=\\sum_t \\sum_i \\int ( P_{} (\\theta ) - P_{}^\\ast (\\theta ) )^2 w(\\theta)$$ originally proposed Haebara. robustified version (dist=\"L1\") uses optimization function (et al., 2015) $$f_{opt, L1}=\\sum_t \\sum_i \\int | P_{} (\\theta ) - P_{}^\\ast (\\theta ) |  w(\\theta)$$ generalization, follwing distance function (dist=\"Lp\") can minimized: $$f_{opt, Lp}=\\sum_t \\sum_i \\int | P_{} (\\theta ) - P_{}^\\ast (\\theta ) |^p  w(\\theta)$$","code":""},{"path":"/reference/linking.haebara.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","text":"list following entries pars Estimated means standard deviations (transformation parameters) item Estimated joint item parameters .orig Original \\(a_{}\\) parameters b.orig Original \\(b_{}\\) parameters .resid Residual \\(a_{}\\) parameters (DIF parameters) b.resid Residual \\(b_{}\\) parameters (DIF parameters) res_optim Value optimization routine","code":""},{"path":"/reference/linking.haebara.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","text":"Battauz, M. (2017). Multiple equating separate IRT calibrations. Psychometrika, 82, 610-636. doi:10.1007/s11336-016-9517-x , Y., Cui, Z., & Osterlind, S. J. (2015). New robust scale transformation methods presence outlying common items. Applied Psychological Measurement, 39(8), 613-626. doi:10.1177/0146621615587003 , Y., & Cui, Z. (2020). Evaluating robust scale transformation methods multiple outlying common items IRT true score equating. Applied Psychological Measurement, 44(4), 296-310. doi:10.1177/0146621619886050 Hu, H., Rogers, W. T., & Vukmirovic, Z. (2008). Investigation IRT-based equating methods presence outlier common items. Applied Psychological Measurement, 32(4), 311-333. doi:10.1177/0146621606292215","code":""},{"path":[]},{"path":"/reference/linking.haebara.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Haebara Linking of the 2PL Model for Multiple Studies — linking.haebara","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Robust linking methods in the presence of outliers #############################################################################  #** simulate data I <- 10 a <- seq(.9, 1.1, len=I) b <- seq(-2, 2, len=I)  #- define item parameters item_names <- paste0(\"I\",100+1:I) # th=SIG*TH+MU=> logit(p)=a*(SIG*TH+MU-b)=a*SIG*(TH-(-MU)/SIG-b/SIG) d1 <- data.frame( study=\"S1\", item=item_names, a=a, b=b ) mu <- .5; sigma <- 1.3 d2 <- data.frame( study=\"S2\", item=item_names, a=a*sigma, b=(b-mu)/sigma ) mu <- -.3; sigma <- .7 d3 <- data.frame( study=\"S3\", item=item_names, a=a*sigma, b=(b-mu)/sigma )  #- define DIF effect # dif <- 0  # no DIF effects dif <- 1 d2[4,\"a\"] <- d2[4,\"a\"] * (1-.8*dif) d3[5,\"b\"] <- d3[5,\"b\"] - 2*dif itempars <- rbind(d1, d2, d3)  #* Haebara linking non-robust mod1 <- sirt::linking.haebara( itempars, dist=\"L2\", control=list(trace=2) ) summary(mod1)  #* Haebara linking robust mod2 <- sirt::linking.haebara( itempars, dist=\"L1\", control=list(trace=2) ) summary(mod2)  #* using initial parameter estimates par_init <- mod1$res_optim$par mod2b <- sirt::linking.haebara( itempars, dist=\"L1\", par_init=par_init) summary(mod2b)  #* power p=.25 mod2c <- sirt::linking.haebara( itempars, dist=\"Lp\", pow=.25, par_init=par_init) summary(mod2c)  #* Haberman linking non-robust mod3 <- sirt::linking.haberman(itempars) summary(mod3)  #* Haberman linking robust mod4 <- sirt::linking.haberman(itempars, estimation=\"BSQ\", a_trim=.25, b_trim=.5) summary(mod4)  #* compare transformation parameters (means and standard deviations) mod1$pars mod2$pars mod3$transf.personpars mod4$transf.personpars }"},{"path":"/reference/linking.robust.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust Linking of Item Intercepts — linking.robust","title":"Robust Linking of Item Intercepts — linking.robust","text":"function implements robust alternative mean-mean linking employs trimmed means instead means. linking constant calculated varying trimming parameters \\(k\\). treatment differential item functioning outliers application robust statistics discussed Magis De Boeck (2011, 2012).","code":""},{"path":"/reference/linking.robust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust Linking of Item Intercepts — linking.robust","text":"","code":"linking.robust(itempars)  # S3 method for linking.robust summary(object,...)  # S3 method for linking.robust plot(x, ...)"},{"path":"/reference/linking.robust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust Linking of Item Intercepts — linking.robust","text":"itempars Data frame item parameters (item intercepts). first column contains item label, 2nd 3rd columns item parameters two studies. object Object class linking.robust x Object class linking.robust ... arguments passed","code":""},{"path":"/reference/linking.robust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust Linking of Item Intercepts — linking.robust","text":"list following entries ind.kopt Index optimal scale parameter kopt Optimal scale parameter meanpars.kopt Linking constant optimal scale parameter se.kopt Standard error linking constant obtained optimal scale parameter meanpars Linking constant dependent scale parameter se Standard error linking constant dependent scale parameter sd DIF standard deviation (non-robust estimate) mad DIF standard deviation (robust estimate using MAD measure) pars Original item parameters k.robust Used vector scale parameters Number items itempars Used data frame item parameters","code":""},{"path":"/reference/linking.robust.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Robust Linking of Item Intercepts — linking.robust","text":"Magis, D., & De Boeck, P. (2011). Identification differential item functioning multiple-group settings: multivariate outlier detection approach. Multivariate Behavioral Research, 46(5), 733-755. doi:10.1080/00273171.2011.606757 Magis, D., & De Boeck, P. (2012). robust outlier approach prevent type error inflation differential item functioning. Educational Psychological Measurement, 72(2), 291-311. doi:10.1177/0013164411416975","code":""},{"path":[]},{"path":"/reference/linking.robust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robust Linking of Item Intercepts — linking.robust","text":"","code":"############################################################################# # EXAMPLE 1: Linking data.si03 #############################################################################  data(data.si03) res1 <- sirt::linking.robust( itempars=data.si03 ) summary(res1)   ##   Number of items=27   ##   Optimal trimming parameter k=8 |  non-robust parameter k=0   ##   Linking constant=-0.0345 |  non-robust estimate=-0.056   ##   Standard error=0.0186 |  non-robust estimate=0.027   ##   DIF SD: MAD=0.0771 (robust) | SD=0.1405 (non-robust) plot(res1)  if (FALSE) { ############################################################################# # EXAMPLE 2: Linking PISA item parameters data.pisaPars #############################################################################  data(data.pisaPars)  # Linking with items res2 <- sirt::linking.robust( data.pisaPars[, c(1,3,4)] ) summary(res2)   ##   Optimal trimming parameter k=0 |  non-robust parameter k=0   ##   Linking constant=-0.0883 |  non-robust estimate=-0.0883   ##   Standard error=0.0297 |  non-robust estimate=0.0297   ##   DIF SD: MAD=0.1824 (robust) | SD=0.1487 (non-robust) ##  -> no trimming is necessary for reducing the standard error plot(res2)  ############################################################################# # EXAMPLE 3: Linking with simulated item parameters containing outliers #############################################################################  # simulate some parameters I <- 38 set.seed(18785) itempars <- data.frame(\"item\"=paste0(\"I\",1:I) ) itempars$study1 <- stats::rnorm( I, mean=.3, sd=1.4 ) # simulate DIF effects plus some outliers bdif <- stats::rnorm(I,mean=.4,sd=.09)+( stats::runif(I)>.9 )* rep( 1*c(-1,1)+.4, each=I/2 ) itempars$study2 <- itempars$study1 + bdif  # robust linking res <- sirt::linking.robust( itempars ) summary(res)   ##   Number of items=38   ##   Optimal trimming parameter k=12 |  non-robust parameter k=0   ##   Linking constant=-0.4285 |  non-robust estimate=-0.5727   ##   Standard error=0.0218 |  non-robust estimate=0.0913   ##   DIF SD: MAD=0.1186 (robust) | SD=0.5628 (non-robust) ## -> substantial differences of estimated linking constants in this case of ##    deviations from normality of item parameters plot(res) }"},{"path":"/reference/lq_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit of a \\(L_q\\) Regression Model — lq_fit","title":"Fit of a \\(L_q\\) Regression Model — lq_fit","text":"Fits regression model \\(L_q\\) norm (also labeled \\(L_p\\) norm). detail, optimization function \\( \\sum_i | y_i - x_i \\beta | ^p\\) optimized. nondifferentiable function approximated differentiable approximation, .e., use \\(|x| \\approx \\sqrt{x^2 + \\varepsilon } \\). power \\(p\\) can also estimated using est_pow=TRUE, see Giacalone, Panarello Mattera (2018). algorithm iterates estimating regression coefficients estimation power values. estimation power based vector residuals e can conducted using function lq_fit_estimate_power. Using \\(L_q\\) norm regression equivalent assuming expontial power function residuals (Giacalone et al., 2018). density function simulation function provided dexppow rexppow, respectively. See also normalp package.","code":""},{"path":"/reference/lq_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit of a \\(L_q\\) Regression Model — lq_fit","text":"","code":"lq_fit(y, X, w=NULL, pow=2, eps=0.001, beta_init=NULL, est_pow=FALSE, optimizer=\"optim\",     eps_vec=10^seq(0,-10, by=-.5), conv=1e-4, miter=20, lower_pow=.1, upper_pow=5)  lq_fit_estimate_power(e, pow_init=2, lower_pow=.1, upper_pow=10)  dexppow(x, mu=0, sigmap=1, pow=2, log=FALSE)  rexppow(n, mu=0, sigmap=1, pow=2, xbound=100, xdiff=.01)"},{"path":"/reference/lq_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit of a \\(L_q\\) Regression Model — lq_fit","text":"y Dependent variable X Design matrix w Optional vector weights pow Power \\(p\\) \\(L_q\\) norm est_pow Logical indicating whether power estimated eps Parameter governing differentiable approximation e Vector resiuals pow_init Initial value power beta_init Initial vector optimizer Can \"optim\" \"nlminb\". eps_vec Vector decreasing \\(\\varepsilon\\) values used optimization conv Convergence criterion miter Maximum number iterations lower_pow Lower bound estimated power upper_pow Upper bound estimated power x Vector mu Location parameter sigmap Scale parameter log Logical indicating whether logarithm provided n Sample size xbound Lower upper bound density approximation xdiff Grid width density approximation","code":""},{"path":"/reference/lq_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit of a \\(L_q\\) Regression Model — lq_fit","text":"List following several entries coefficients Vector coefficients res_optim Results optimization ... values","code":""},{"path":"/reference/lq_fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit of a \\(L_q\\) Regression Model — lq_fit","text":"Giacalone, M., Panarello, D., & Mattera, R. (2018). Multicollinearity regression: efficiency comparison $L_p$-norm least squares estimators. Quality & Quantity, 52(4), 1831-1859. doi:10.1007/s11135-017-0571-y","code":""},{"path":"/reference/lq_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit of a \\(L_q\\) Regression Model — lq_fit","text":"","code":"############################################################################# # EXAMPLE 1: Small simulated example with fixed power #############################################################################  set.seed(98) N <- 300 x1 <- stats::rnorm(N) x2 <- stats::rnorm(N) par1 <- c(1,.5,-.7) y <- par1[1]+par1[2]*x1+par1[3]*x2 + stats::rnorm(N) X <- cbind(1,x1,x2)  #- lm function in stats mod1 <- stats::lm.fit(y=y, x=X)  #- use lq_fit function mod2 <- sirt::lq_fit( y=y, X=X, pow=2, eps=1e-4) mod1$coefficients mod2$coefficients  if (FALSE) { ############################################################################# # EXAMPLE 2: Example with estimated power values #############################################################################  #*** simulate regression model with residuals from the exponential power distribution #*** using a power of .30 set.seed(918) N <- 2000 X <- cbind( 1, c(rep(1,N), rep(0,N)) ) e <- sirt::rexppow(n=2*N, pow=.3, xdiff=.01, xbound=200) y <- X %*% c(1,.5) + e  #*** estimate model mod <- sirt::lq_fit( y=y, X=X, est_pow=TRUE, lower_pow=.1) mod1 <- stats::lm( y ~ 0 + X ) mod$coefficients mod$pow mod1$coefficients }"},{"path":"/reference/lsdm.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares Distance Method of Cognitive Validation — lsdm","title":"Least Squares Distance Method of Cognitive Validation — lsdm","text":"function estimates least squares distance method cognitive validation (Dimitrov, 2007; Dimitrov & Atanasov, 2012) assumes multiplicative relationship attribute response probabilities explain item response probabilities. argument distance allows estimation squared loss function (distance=\"L2\") absolute value loss function (distance=\"L1\"). function also estimates classical linear logistic test model (LLTM; Fischer, 1973) assumes linear relationship item difficulties Rasch model.","code":""},{"path":"/reference/lsdm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares Distance Method of Cognitive Validation — lsdm","text":"","code":"lsdm(data, Qmatrix, theta=seq(-3,3,by=.5), wgt_theta=rep(1, length(theta)), distance=\"L2\",    quant.list=c(0.5,0.65,0.8), b=NULL, a=rep(1,nrow(Qmatrix)), c=rep(0,nrow(Qmatrix)) )  # S3 method for lsdm summary(object, file=NULL, digits=3, ...)  # S3 method for lsdm plot(x, ...)"},{"path":"/reference/lsdm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares Distance Method of Cognitive Validation — lsdm","text":"data \\(\\times L\\) matrix dichotomous item responses. data consists \\(\\) item response functions (parametrically nonparametrically estimated) evaluated discrete grid \\(L\\) theta values (person parameters) specified argument theta. Qmatrix \\(\\times K\\) matrix allocation items attributes coded. Values zero one values zero one permitted. must items zero Q-matrix entries row. theta discrete grid points \\(\\theta\\) item response functions evaluated LSDM method. wgt_theta Optional vector weights discrete \\(\\theta\\) points quant.list vector quantiles attribute response functions evaluated. distance Type distance function minimizing discrepancy observed expected item response functions. Options \"L2\" squared distance (proposed original LSDM formulation Dimitrov, 2007) absolute value distance \"L1\" (see Details). b optional vector item difficulties. specified, data input necessary. optional vector item discriminations. c optional vector guessing parameters. object Object class lsdm file Optional file name summary output digits Number digits aftert decimal summary ... arguments passed x Object class lsdm","code":""},{"path":"/reference/lsdm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Squares Distance Method of Cognitive Validation — lsdm","text":"least squares distance method (LSDM; Dimitrov 2007) based assumption estimated item response functions \\(P(X_i=1 | \\theta)\\) can decomposed multiplicative way (implemented conjunctive model): $$ P( X_i=1  | \\theta ) \\approx \\prod_{k=1}^K [ P( A_k=1 | \\theta ) ]^{q_{ik}} $$ \\(P( A_k=1 | \\theta )\\) attribute response functions \\(q_{ik}\\) entries Q-matrix. Note multiplicative form can rewritten taking logarithm $$ \\log P( X_i=1  | \\theta ) \\approx     \\sum_{k=1}^K q_{ik} \\log [ P( A_k=1 | \\theta ) ] $$ item attribute response functions evaluated grid \\(\\theta\\) values. Using definitions matrices \\(\\bold{L}=\\{ \\log P( X_i=1 ) | \\theta ) \\} \\), \\(\\bold{Q}=\\{ q_{ik} \\} \\) \\(\\bold{X}=\\{ \\log P( A_k=1  | \\theta ) \\} \\), estimation problem can formulated \\( \\bold{L} \\approx \\bold{Q} \\bold{X}\\). Two different loss functions minimizing discrepancy \\( \\bold{L}\\) \\(\\bold{Q} \\bold{X}\\) implemented. First, squared loss function computes weighted difference \\(|| \\bold{L} - \\bold{Q} \\bold{X}||_2=\\sum_i ( l_i - \\sum_t q_{} x_{})^2\\)  (distance=\"L2\") originally proposed Dimitrov (2007). Second, absolute value loss function \\(|| \\bold{L} - \\bold{Q} \\bold{X}||_1=\\sum_i | l_i - \\sum_t q_{} x_{} |\\) (distance=\"L1\") robust outliers (.e., items show misfit assumed multiplicative LSDM formulation). fitting attribute response functions, empirical item-attribute discriminations \\(w_{ik}\\) calculated approximation following equation $$ \\log P( X_i=1  | \\theta )= \\sum_{k=1}^K w_{ik} q_{ik} \\log [ P( A_k=1 | \\theta ) ] $$","code":""},{"path":"/reference/lsdm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares Distance Method of Cognitive Validation — lsdm","text":"list following entries mean.mad.lsdm0 Mean \\(MAD\\) statistics LSDM mean.mad.lltm Mean \\(MAD\\) statistics LLTM attr.curves Estimated attribute response curves evaluated theta attr.pars Estimated attribute parameters LSDM LLTM data.fitted LSDM-fitted item response functions evaluated theta theta Grid ability distributions functions evaluated item Item statistics (p value, \\(MAD\\), ...) data Estimated fixed item response functions evaluated theta Qmatrix Used Q-matrix lltm Model output LLTM (lm values) W Matrix empirical item-attribute discriminations","code":""},{"path":"/reference/lsdm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Least Squares Distance Method of Cognitive Validation — lsdm","text":"Al-Shamrani, ., & Dimitrov, D. M. (2016). Cognitive diagnostic analysis reading comprehension items: case English proficiency assessment Saudi Arabia. International Journal School Cognitive Psychology, 4(3). 1000196. http://dx.doi.org/10.4172/2469-9837.1000196 DiBello, L. V., Roussos, L. ., & Stout, W. F. (2007). Review cognitively diagnostic assessment summary psychometric models. C. R. Rao S. Sinharay (Eds.), Handbook Statistics, Vol. 26 (pp. 979-1030). Amsterdam: Elsevier. Dimitrov, D. M. (2007). Least squares distance method cognitive validation analysis binary items using item response theory parameters. Applied Psychological Measurement, 31, 367-387. http://dx.doi.org/10.1177/0146621606295199 Dimitrov, D. M., & Atanasov, D. V. (2012). Conjunctive disjunctive extensions least squares distance model cognitive diagnosis. Educational Psychological Measurement, 72, 120-138. http://dx.doi.org/10.1177/0013164411402324 Dimitrov, D. M., Gerganov, E. N., Greenberg, M., & Atanasov, D. V. (2008). Analysis cognitive attributes mathematics items framework Rasch measurement. AERA 2008, New York. Fischer, G. H. (1973). linear logistic test model instrument educational research. Acta Psychologica, 37, 359-374. http://dx.doi.org/10.1016/0001-6918(73)90003-6 Sonnleitner, P. (2008). Using LLTM evaluate item-generating system reading comprehension. Psychology Science, 50, 345-362.","code":""},{"path":[]},{"path":[]},{"path":"/reference/lsem.estimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Structural Equation Models (LSEM) — lsem.estimate","title":"Local Structural Equation Models (LSEM) — lsem.estimate","text":"Local structural equation models (LSEM) structural equation models (SEM) evaluated value pre-defined moderator variable (Hildebrandt et al., 2009, 2016). nonparametric regression models, observations near focal point - model evaluated - obtain higher weights, far distant observations obtain lower weights. LSEM can specified making use lavaan syntax. also possible specify discretized version LSEM values moderator grouped multiple group SEM specified. LSEM can tested employing permutation test, see lsem.permutationTest. function lsem.MGM.stepfunctions outputs stepwise functions multiple group model evaluated grid focal points moderator, specified moderator.grid. argument pseudo_weights provides ad hoc solution estimate LSEM model can fitted lavaan. also possible constrain parameters along values moderator joint estimation approach (est_joint=TRUE). Parameter names can specified assumed invariant (par_invariant). addition, linear quadratic constraints can imposed parameters (par_linear par_quadratic). Statistical inference case joint estimation (also separate estimation) can conducted via bootstrap using function lsem.bootstrap. Bootstrap level cluster identifier allowed (argument cluster).","code":""},{"path":"/reference/lsem.estimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Structural Equation Models (LSEM) — lsem.estimate","text":"","code":"lsem.estimate(data, moderator, moderator.grid, lavmodel, type=\"LSEM\", h=1.1, bw=NULL,     residualize=TRUE, fit_measures=c(\"rmsea\", \"cfi\", \"tli\", \"gfi\", \"srmr\"),     standardized=FALSE, standardized_type=\"std.all\", lavaan_fct=\"sem\",     sufficient_statistics=TRUE, pseudo_weights=0,     sampling_weights=NULL, loc_linear_smooth=TRUE, est_joint=FALSE, par_invariant=NULL,     par_linear=NULL, par_quadratic=NULL, partable_joint=NULL, pw_linear=1,     pw_quadratic=1, pd=TRUE, est_DIF=FALSE, se=NULL, kernel=\"gaussian\",     eps=1e-08, verbose=TRUE, ...)  # S3 method for lsem summary(object, file=NULL, digits=3, ...)  # S3 method for lsem plot(x, parindex=NULL, ask=TRUE, ci=TRUE, lintrend=TRUE,        parsummary=TRUE, ylim=NULL, xlab=NULL,  ylab=NULL, main=NULL,        digits=3, ...)  lsem.MGM.stepfunctions( object, moderator.grid )  # compute local weights lsem_local_weights(data.mod, moderator.grid, h, sampling_weights=NULL,  bw=NULL,      kernel=\"gaussian\")  lsem.bootstrap(object, R=100, verbose=TRUE, cluster=NULL,      repl_design=NULL, repl_factor=NULL, use_starting_values=TRUE,      n.core=1, cl.type=\"PSOCK\")"},{"path":"/reference/lsem.estimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Structural Equation Models (LSEM) — lsem.estimate","text":"data Data frame list imputed datasets moderator Variable name moderator moderator.grid Focal points LSEM evaluated. type=\"MGM\", breaks defined vector. lavmodel Specified SEM lavaan. type Type estimated model. default type=\"LSEM\" means     local structural equation model estimated.     multiple group model discretized moderator     grouping variable can estimated type=\"MGM\".     case, breaks must defined moderator.grid. h Bandwidth factor bw Optional bandwidth parameter h used residualize Logical indicating whether residualization     applied. fit_measures Vector names fit measures following labels lavaan standardized Optional logical indicating whether  standardized solution included parameters  output using lavaan::standardizedSolution function. Standardized parameters labeled std__. standardized_type Type standardization standardized=TRUE. types described lavaan::standardizedSolution. lavaan_fct String whether lavaan::lavaan (lavaan_fct=\"lavaan\"), lavaan::sem (lavaan_fct=\"sem\"), lavaan::cfa (lavaan_fct=\"cfa\") lavaan::growth (lavaan_fct=\"growth\") used. sufficient_statistics Logical whether sufficient statistics weighted means covariances used model fitting. option can set sufficient_statistics=FALSE data contain missing values. Note option sufficient_statistics=TRUE valid (approximate) missing completely random (MCAR) data. option can used continuous data. pseudo_weights Integer defining target sample size. Local weights multiplied factor rounded integers. approach referred pseudo weighting approach. example, using pseudo_weights=30000 implies sum local weights focal point 30000. sampling_weights Optional vector sampling weights loc_linear_smooth Logical indicating whether local linear smoothing used computing sufficient statistics means covariances. default FALSE. est_joint Logical indicating whether LSEM estimated joint estimation approach. options works wih continuous data sufficient statistics. par_invariant Vector invariant parameters par_linear Vector parameters linear function par_quadratic Vector parameters quadratic function partable_joint User-defined parameter table joint estimation used (est_joint=TRUE). pw_linear Number segments piecewise linear estimation parameters used pw_quadratic Number segments piecewise quadratic estimation parameters used pd Logical indicating whether nearest positive definite covariance matrix computed sufficient statistics used est_DIF Logical indicating whether parameters differential item functioning (DIF) additionally computed invariant item parameters se Type standard error used lavaan::lavaan. NULL, lavaan default used. kernel Type kernel function. Can \"gaussian\", \"uniform\" \"epanechnikov\". eps Minimum number weights verbose Optional logical printing information computation progress. object Object class lsem file file name summary output written. digits Number digits. x Object class lsem. parindex Vector indices parameters plot function. ask logical asks changing graphic parameter. ci Logical indicating whether confidence intervals plotted. lintrend Logical indicating whether linear trend plotted. parsummary Logical indicating whether parameter summary   displayed. ylim Plot parameter ylim. Can list, see Examples. xlab Plot parameter xlab. Can vector. ylab Plot parameter ylab. Can vector. main Plot parameter main. Can vector. ... arguments passed lavaan::sem lavaan::lavaan. data.mod Observed values moderator R Number bootstrap samples cluster Optional variable name bootstrap level cluster identifier repl_design Optional matrix containing replication weights computation standard errors. Note sampling weights already included repl_design. repl_factor Replication factor variance formula statistical inference, e.g., 0.05 PISA. use_starting_values Logical indicating whether starting values used original sample n.core scalar indicating number cores used. cl.type cluster type. Default value \"PSOCK\". Posix machines (Linux, Mac) generally benefit much faster cluster computation type set type=\"FORK\".","code":""},{"path":"/reference/lsem.estimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local Structural Equation Models (LSEM) — lsem.estimate","text":"List following entries parameters Data frame parameters estimated focal points     moderator. Bias-corrected estimates boostrap can found     column est_bc. weights Data frame weights focal point parameters_summary Summary table estimated parameters parametersM Estimated parameters matrix form. Parameters columns values grid moderator rows. bw Used bandwidth h Used bandwidth factor N Sample size moderator.density Estimated frequencies effective sample size     moderator focal points moderator.stat Descriptive statistics moderator moderator Variable name moderator moderator.grid Used grid focal points moderator moderator.grouped Data frame informations grouping moderator type=\"MGM\". residualized.intercepts Estimated intercept functions used residualization. lavmodel Used lavaan model data Used data frame, possibly residualized residualize=TRUE model_parameters Model parameters LSEM parameters_boot Parameter values bootstrap sample (lsem.bootstrap) fitstats_joint_boot Fit statistics bootstrap sample (lsem.bootstrap) dif_effects Estimated item parameters DIF","code":""},{"path":"/reference/lsem.estimate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Local Structural Equation Models (LSEM) — lsem.estimate","text":"Hildebrandt, ., Luedtke, O., Robitzsch, ., Sommer, C., & Wilhelm, O. (2016). Exploring factor model parameters across continuous variables local structural equation models. Multivariate Behavioral Research, 51(2-3), 257-278. doi:10.1080/00273171.2016.1142856 Hildebrandt, ., Wilhelm, O., & Robitzsch, . (2009). Complementary competing factor analytic approaches investigation measurement invariance. Review Psychology, 16, 87-102.","code":""},{"path":"/reference/lsem.estimate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Local Structural Equation Models (LSEM) — lsem.estimate","text":"Alexander Robitzsch, Oliver Luedtke, Andrea Hildebrandt","code":""},{"path":[]},{"path":"/reference/lsem.estimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Structural Equation Models (LSEM) — lsem.estimate","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: data.lsem01 | Age differentiation #############################################################################  data(data.lsem01, package=\"sirt\") dat <- data.lsem01  # specify lavaan model lavmodel <- \"         F=~ v1+v2+v3+v4+v5         F ~~ 1*F\"  # define grid of moderator variable age moderator.grid <- seq(4,23,1)  #******************************** #*** Model 1: estimate LSEM with bandwidth 2 mod1 <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, std.lv=TRUE) summary(mod1) plot(mod1, parindex=1:5)  # perform permutation test for Model 1 pmod1 <- sirt::lsem.permutationTest( mod1, B=10 )           # only for illustrative purposes the number of permutations B is set           # to a low number of 10 summary(pmod1) plot(pmod1, type=\"global\")  #* perform permutation test with parallel computation pmod1a <- sirt::lsem.permutationTest( mod1, B=10, n.core=3 ) summary(pmod1a)  #** estimate Model 1 based on pseudo weights mod1b <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, std.lv=TRUE, pseudo_weights=50 ) summary(mod1b)  #** estimation with sampling weights  # generate random sampling weights set.seed(987) weights <- stats::runif(nrow(dat), min=.4, max=3 ) mod1c <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, sampling_weights=weights) summary(mod1c)  #******************************** #*** Model 2: estimate multiple group model with 4 age groups  # define breaks for age groups moderator.grid <- seq( 3.5, 23.5, len=5) # 4 groups # estimate model mod2 <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,            lavmodel=lavmodel, type=\"MGM\", std.lv=TRUE) summary(mod2)  # output step functions smod2 <- sirt::lsem.MGM.stepfunctions( object=mod2, moderator.grid=seq(4,23,1) ) str(smod2)  #******************************** #*** Model 3: define standardized loadings as derived variables  # specify lavaan model lavmodel <- \"         F=~ a1*v1+a2*v2+a3*v3+a4*v4         v1 ~~ s1*v1         v2 ~~ s2*v2         v3 ~~ s3*v3         v4 ~~ s4*v4         F ~~ 1*F         # standardized loadings         l1 :=a1 / sqrt(a1^2 + s1 )         l2 :=a2 / sqrt(a2^2 + s2 )         l3 :=a3 / sqrt(a3^2 + s3 )         l4 :=a4 / sqrt(a4^2 + s4 )         \" # estimate model mod3 <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, std.lv=TRUE) summary(mod3) plot(mod3)  #******************************** #*** Model 4: estimate LSEM and automatically include standardized solutions  lavmodel <- \"         F=~ 1*v1+v2+v3+v4         F ~~ F\" mod4 <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, standardized=TRUE) summary(mod4) # permutation test (use only few permutations for testing purposes) pmod1 <- sirt::lsem.permutationTest( mod4, B=3 )  #**** compute LSEM local weights wgt <- sirt::lsem_local_weights(data.mod=dat$age, moderator.grid=moderator.grid,              h=2)$weights print(str(weights))  #******************************** #*** Model 5: invariance parameter constraints and other constraints  lavmodel <- \"         F=~ 1*v1+v2+v3+v4         F ~~ F\" moderator.grid <- seq(4,23,4)  #- estimate model without constraints mod5a <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, standardized=TRUE) summary(mod5a) # extract parameter names mod5a$model_parameters  #- invariance constraints on residual variances par_invariant <- c(\"F=~v2\",\"v2~~v2\") mod5b <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, standardized=TRUE, par_invariant=par_invariant) summary(mod5b)  #- bootstrap for statistical inference bmod5b <- sirt::lsem.bootstrap(mod5b, R=100) # inspect parameter values and standard errors bmod5b$parameters  #- bootstrap using parallel computing (i.e., multiple cores) bmod5ba <- sirt::lsem.bootstrap(mod5b, R=100, n.core=3)  #- user-defined replication design R <- 100    # bootstrap samples N <- nrow(dat) repl_design <- matrix(0, nrow=N, ncol=R) for (rr in 1:R){     indices <- sort( sample(1:N, replace=TRUE) )     repl_design[,rr] <- sapply(1:N, FUN=function(ii){ sum(indices==ii) } ) } head(repl_design) bmod5b1 <- sirt::lsem.bootstrap(mod5a, repl_design=repl_design, repl_factor=1/R)  #- compare model mod5b with joint estimation without constraints mod5c <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, standardized=TRUE, est_joint=TRUE) summary(mod5c)  #- linear and quadratic functions par_invariant <- c(\"F=~v1\",\"v2~~v2\") par_linear <- c(\"v1~~v1\") par_quadratic <- c(\"v4~~v4\")  mod5d <- sirt::lsem.estimate( dat1, moderator=\"age\", moderator.grid=moderator.grid,             lavmodel=lavmodel, h=2, par_invariant=par_invariant, par_linear=par_linear,             par_quadratic=par_quadratic) summary(mod5d)  #- user-defined constraints: step functions for parameters  # inspect parameter table (from lavaan) of fitted model pj <- mod5d$partable_joint #* modify parameter table for user-defined constraints # define step function for F=~v1 which is constant on intervals 1:4 and 5:7 pj2 <- pj[ pj$con==1, ] pj2[ c(5,6), \"lhs\" ] <- \"p1g5\" pj2 <- pj2[ -4, ] partable_joint <- rbind(pj1, pj2) # estimate model with constraints mod5e <- lsem::lsem.estimate( dat1, moderator=\"age\", moderator.grid=moderator.grid,              lavmodel=lavmodel, h=2, std.lv=TRUE, estimator=\"ML\",              partable_joint=partable_joint) summary(mod5e)  ############################################################################# # EXAMPLE 2: data.lsem01 | FIML with missing data #############################################################################  data(data.lsem01) dat <- data.lsem01 # induce artifical missing values set.seed(98) dat[ stats::runif(nrow(dat)) < .5, c(\"v1\")] <- NA dat[ stats::runif(nrow(dat)) < .25, c(\"v2\")] <- NA  # specify lavaan model lavmodel1 <- \"         F=~ v1+v2+v3+v4+v5         F ~~ 1*F\"  # define grid of moderator variable age moderator.grid <- seq(4,23,2)  #*** estimate LSEM with FIML mod1 <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                 lavmodel=lavmodel1, h=2, std.lv=TRUE, estimator=\"ML\", missing=\"fiml\") summary(mod1)  ############################################################################# # EXAMPLE 3: data.lsem01 | WLSMV estimation #############################################################################  data(data.lsem01) dat <- data.lsem01  # create artificial dichotomous data for (vv in 2:6){ dat[,vv] <- 1*(dat[,vv] > mean(dat[,vv])) }  # specify lavaan model lavmodel1 <- \"         F=~ v1+v2+v3+v4+v5         F ~~ 1*F         v1 | t1         v2 | t1         v3 | t1         v4 | t1         v5 | t1         \"  # define grid of moderator variable age moderator.grid <- seq(4,23,2)  #*** local WLSMV estimation mod1 <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,           lavmodel=lavmodel1, h=2, std.lv=TRUE, estimator=\"DWLS\", ordered=paste0(\"v\",1:5),           residualize=FALSE, pseudo_weights=10000, parameterization=\"THETA\" ) summary(mod1) }"},{"path":"/reference/lsem.permutationTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Permutation Test for a Local Structural Equation Model — lsem.permutationTest","title":"Permutation Test for a Local Structural Equation Model — lsem.permutationTest","text":"Performs permutation test testing hypothesis model parameter independent moderator variable (see Hildebrandt, Wilhelm, & Robitzsch, 2009; Hildebrandt, Luedtke, Robitzsch, Sommer, & Wilhelm, 2016).","code":""},{"path":"/reference/lsem.permutationTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permutation Test for a Local Structural Equation Model — lsem.permutationTest","text":"","code":"lsem.permutationTest(lsem.object, B=1000, residualize=TRUE, verbose=TRUE,      n.core=1, cl.type=\"PSOCK\")  # S3 method for lsem.permutationTest summary(object, file=NULL, digits=3, ...)  # S3 method for lsem.permutationTest plot(x, type=\"global\", stattype=\"SD\",     parindex=NULL, sig_add=TRUE, sig_level=0.05, sig_pch=17, nonsig_pch=2,     sig_cex=1, sig_lab=\"p value\",  stat_lab=\"Test statistic\",     moderator_lab=NULL, digits=3, title=NULL, parlabels=NULL,     ask=TRUE, ...)"},{"path":"/reference/lsem.permutationTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permutation Test for a Local Structural Equation Model — lsem.permutationTest","text":"lsem.object Fitted object class lsem lsem.estimate B Number permutation samples residualize Optional logical indicating whether residualization moderator performed permutation sample. verbose Optional logical printing information computation progress. n.core scalar indicating number cores used. cl.type cluster type. Default value \"PSOCK\". Posix machines (Linux, Mac) generally benefit much faster cluster computation type set type=\"FORK\". object Object class lsem file file name summary output written. digits Number digits. ... arguments passed. x Object class lsem type Type statistic plotted. type=\"global\", global test displayed. type=\"pointwise\" value focal point (defined moderator.grid) calculated. stattype Type test statistics. Can MAD (mean absolute deviation), SD (standard deviation) lin_slo (linear slope). parindex Vector indices selected parameters. sig_add Logical indicating whether significance values (p values) displayed. sig_level Significance level. sig_pch Point symbol significant values. nonsig_pch Point symbol non-significant values. sig_cex Point size graphic displaying p values sig_lab Label significance value (p value). stat_lab Label y axis graphic pointwise test statistic moderator_lab Label moderator. title Title plot. Can vector. parlabels Labels parameters. Can vector. ask logical asks changing graphic parameter.","code":""},{"path":"/reference/lsem.permutationTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Permutation Test for a Local Structural Equation Model — lsem.permutationTest","text":"List following entries teststat Data frame global test statistics. statistics SD, MAD lin_slo corresponding p values. parameters_pointwise_test Data frame pointwise test statistics. parameters Original parameters. parameters Parameters permutation samples. parameters_summary Original parameter summary. parameters_summary_M Mean parameter permutation sample. parameters_summary_SD Standard deviation (SD) statistic permutation slope. parameters_summary_MAD Mean absolute deviation (MAD)     statistic permutation sample. parameters_summary_MAD Linear slope parameter permutation sample. nonconverged_rate Percentage permuted dataset LSEM model converge","code":""},{"path":"/reference/lsem.permutationTest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Permutation Test for a Local Structural Equation Model — lsem.permutationTest","text":"Hildebrandt, ., Luedtke, O., Robitzsch, ., Sommer, C., & Wilhelm, O. (2016). Exploring factor model parameters across continuous variables local structural equation models. Multivariate Behavioral Research, 51(2-3), 257-278. doi:10.1080/00273171.2016.1142856 Hildebrandt, ., Wilhelm, O., & Robitzsch, . (2009). Complementary competing factor analytic approaches investigation measurement invariance. Review Psychology, 16, 87-102.","code":""},{"path":"/reference/lsem.permutationTest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Permutation Test for a Local Structural Equation Model — lsem.permutationTest","text":"Alexander Robitzsch, Oliver Luedtke, Andrea Hildebrandt","code":""},{"path":[]},{"path":"/reference/lsem.test.html","id":null,"dir":"Reference","previous_headings":"","what":"Test a Local Structural Equation Model Based on Bootstrap — lsem.test","title":"Test a Local Structural Equation Model Based on Bootstrap — lsem.test","text":"Performs global parameter tests fitted local structural equation model. LSEM must fitted bootstrap estimates LSEM model must available statistical inference. hypothesis constant parameter tested means Wald test. Moreover, regression functions can specified tested specified argument models.","code":""},{"path":"/reference/lsem.test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test a Local Structural Equation Model Based on Bootstrap — lsem.test","text":"","code":"lsem.test(mod, bmod, models=NULL)"},{"path":"/reference/lsem.test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test a Local Structural Equation Model Based on Bootstrap — lsem.test","text":"mod Fitted LSEM object bmod Fitted LSEM bootstrap object. argument bmod can also missing. models List model formulas named LSEM model parameters","code":""},{"path":"/reference/lsem.test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test a Local Structural Equation Model Based on Bootstrap — lsem.test","text":"List following entries wald_test_global Global Wald test model parameters test_models Output fitted regression models parameters Original model parameters fitting (.e., smoothing) particular parameter using regression model specified models. parameters_boot Bootstrapped model parameters fitting (.e., smoothing) particular parameter using regression model specified models.","code":""},{"path":[]},{"path":"/reference/lsem.test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test a Local Structural Equation Model Based on Bootstrap — lsem.test","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: data.lsem01 | Age differentiation and tested models #############################################################################  data(data.lsem01, package=\"sirt\") dat <- data.lsem01  # specify lavaan model lavmodel <- \"         F=~ v1+v2+v3+v4+v5         F ~~ 1*F     \"  # define grid of moderator variable age moderator.grid <- seq(4,23,1)  #-- estimate LSEM with bandwidth 2 mod <- sirt::lsem.estimate( dat, moderator=\"age\", moderator.grid=moderator.grid,                lavmodel=lavmodel, h=2, std.lv=TRUE) summary(mod1)  #-- bootstrap model bmod <- sirt::lsem.bootstrap(mod, R=200)  #-- test models models <- list( \"F=~v1\"=y ~ m + I(m^2),                 \"F=~v2\"=y ~ I( splines::bs(m, df=4) ) ) tmod <- sirt::lsem.test(mod=mod, bmod=bmod, models=models) str(tmod) sirt::print_digits(wald_test_global, 3) sirt::print_digits(test_models, 3) }"},{"path":"/reference/marginal.truescore.reliability.html","id":null,"dir":"Reference","previous_headings":"","what":"True-Score Reliability for Dichotomous Data — marginal.truescore.reliability","title":"True-Score Reliability for Dichotomous Data — marginal.truescore.reliability","text":"function computes marginal true-score reliability dichotomous data (Dimitrov, 2003; May & Nicewander, 1994) four-parameter logistic item response model (see rasch.mml2 details regarding IRT model).","code":""},{"path":"/reference/marginal.truescore.reliability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"True-Score Reliability for Dichotomous Data — marginal.truescore.reliability","text":"","code":"marginal.truescore.reliability(b, a=1+0*b,c=0*b,d=1+0*b,     mean.trait=0, sd.trait=1, theta.k=seq(-6,6,len=200) )"},{"path":"/reference/marginal.truescore.reliability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"True-Score Reliability for Dichotomous Data — marginal.truescore.reliability","text":"b Vector item difficulties Vector item discriminations c Vector guessing parameters d Vector upper asymptotes mean.trait Mean trait distribution sd.trait Standard deviation trait distribution theta.k Grid trait distribution evaluated","code":""},{"path":"/reference/marginal.truescore.reliability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"True-Score Reliability for Dichotomous Data — marginal.truescore.reliability","text":"list following entries: rel.test Reliability test item True score variance (sig2.true, error variance   (sig2.error) item reliability (rel.item).   Expected proportions correct column pi. pi Average proportion correct items persons sig2.tau True score variance \\(\\sigma^2_{\\tau}\\)   (calculated formula May & Nicewander, 1994) sig2.error Error variance \\(\\sigma^2_{e}\\)","code":""},{"path":"/reference/marginal.truescore.reliability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"True-Score Reliability for Dichotomous Data — marginal.truescore.reliability","text":"Dimitrov, D. (2003). Marginal true-score measures reliability binary items function IRT parameters. Applied Psychological Measurement, 27, 440-458. May, K., & Nicewander, W. . (1994). Reliability information functions percentile ranks. Journal Educational Measurement, 31, 313-325.","code":""},{"path":[]},{"path":"/reference/marginal.truescore.reliability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"True-Score Reliability for Dichotomous Data — marginal.truescore.reliability","text":"","code":"############################################################################# # EXAMPLE 1: Dimitrov (2003) Table 1 - 2PL model #############################################################################  # item discriminations a <- 1.7*c(0.449,0.402,0.232,0.240,0.610,0.551,0.371,0.321,0.403,0.434,0.459,     0.410,0.302,0.343,0.225,0.215,0.487,0.608,0.341,0.465) # item difficulties b <- c( -2.554,-2.161,-1.551,-1.226,-0.127,-0.855,-0.568,-0.277,-0.017,     0.294,0.532,0.773,1.004,1.250,1.562,1.385,2.312,2.650,2.712,3.000 )  marginal.truescore.reliability( b=b, a=a )   ##   Reliability=0.606  ############################################################################# # EXAMPLE 2: Dimitrov (2003) Table 2 #  3PL model: Poetry items (4 items) #############################################################################  # slopes, difficulties and guessing parameters a <- 1.7*c(1.169,0.724,0.554,0.706 ) b <- c(0.468,-1.541,-0.042,0.698 ) c <- c(0.159,0.211,0.197,0.177 )  res <- sirt::marginal.truescore.reliability( b=b, a=a, c=c)   ##   Reliability=0.403   ##   > round( res$item, 3 )   ##     item    pi sig2.tau sig2.error rel.item   ##   1    1 0.463    0.063      0.186    0.252   ##   2    2 0.855    0.017      0.107    0.135   ##   3    3 0.605    0.026      0.213    0.107   ##   4    4 0.459    0.032      0.216    0.130  ############################################################################# # EXAMPLE 3: Reading Data ############################################################################# data( data.read)  #*** # Model 1: 1PL mod <- sirt::rasch.mml2( data.read ) marginal.truescore.reliability( b=mod$item$b )   ##   Reliability=0.653  #*** # Model 2: 2PL mod <- sirt::rasch.mml2( data.read, est.a=1:12 ) marginal.truescore.reliability( b=mod$item$b, a=mod$item$a)   ##   Reliability=0.696  if (FALSE) { # compare results with Cronbach's alpha and McDonald's omega # posing a 'wrong model' for normally distributed data library(psych) psych::omega(dat, nfactors=1)     # 1 factor   ##  Omega_h for 1 factor is not meaningful, just omega_t   ##   Omega   ##   Call: omega(m=dat, nfactors=1)   ##   Alpha:                 0.69   ##   G.6:                   0.7   ##   Omega Hierarchical:    0.66   ##   Omega H asymptotic:    0.95   ##   Omega Total            0.69  ##! Note that alpha in psych is the standardized one. }"},{"path":"/reference/matrixfunctions.sirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Some Matrix Functions — matrixfunctions.sirt","title":"Some Matrix Functions — matrixfunctions.sirt","text":"matrix functions written Rcpp speed reasons.","code":""},{"path":"/reference/matrixfunctions.sirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Some Matrix Functions — matrixfunctions.sirt","text":"","code":"rowMaxs.sirt(matr)      # rowwise maximum  rowMins.sirt(matr)      # rowwise minimum  rowCumsums.sirt(matr)   # rowwise cumulative sum  colCumsums.sirt(matr)   # columnwise cumulative sum  rowIntervalIndex.sirt(matr,rn) # first index in row nn when matr(nn,zz) > rn(nn)  rowKSmallest.sirt(matr, K, break.ties=TRUE) # k smallest elements in a row rowKSmallest2.sirt(matr, K )"},{"path":"/reference/matrixfunctions.sirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Some Matrix Functions — matrixfunctions.sirt","text":"matr numeric matrix rn vector, usually random number applications K integer indicating number smallest elements extracted break.ties logical indicates ties randomly     broken. default TRUE.","code":""},{"path":"/reference/matrixfunctions.sirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Some Matrix Functions — matrixfunctions.sirt","text":"function rowIntervalIndex.sirt searches rows n first index matr(n,) > rn(n) holds. functions rowKSmallest.sirt rowKSmallest2.sirt extract \\(K\\) smallest entries matrix row. small numbers \\(K\\) function rowKSmallest2.sirt faster one.","code":""},{"path":"/reference/matrixfunctions.sirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Some Matrix Functions — matrixfunctions.sirt","text":"output rowMaxs.sirt list elements maxval (rowwise maximum values) maxind (rowwise maximum indices). output rowMins.sirt contains corresponding minimum values entries minval minind. output rowKSmallest.sirt two matrices: smallval contains \\(K\\) smallest values whereas smallind contains \\(K\\) smallest indices.","code":""},{"path":"/reference/matrixfunctions.sirt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Some Matrix Functions — matrixfunctions.sirt","text":"Alexander Robitzsch Rcpp code rowCumsums.sirt copied code Romain Francois (https://lists.r-forge.r-project.org/pipermail/rcpp-devel/2010-October/001198.html).","code":""},{"path":[]},{"path":"/reference/matrixfunctions.sirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Some Matrix Functions — matrixfunctions.sirt","text":"","code":"############################################################################# # EXAMPLE 1: a small toy example (I) ############################################################################# set.seed(789) N1 <- 10 ; N2 <- 4 M1 <- round( matrix( runif(N1*N2), nrow=N1, ncol=N2), 1 )  rowMaxs.sirt(M1)      # rowwise maximum rowMins.sirt(M1)      # rowwise minimum rowCumsums.sirt(M1)   # rowwise cumulative sum  # row index for exceeding a certain threshold value matr <- M1 matr <- matr / rowSums( matr ) matr <- sirt::rowCumsums.sirt( matr ) rn <- runif(N1)    # generate random numbers rowIntervalIndex.sirt(matr,rn)  # select the two smallest values rowKSmallest.sirt(matr=M1, K=2) rowKSmallest2.sirt(matr=M1, K=2)"},{"path":"/reference/mcmc.2pno.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","title":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","text":"function estimates Two-Parameter normal ogive item response model MCMC sampling (Johnson & Albert, 1999, p. 195ff.).","code":""},{"path":"/reference/mcmc.2pno.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","text":"","code":"mcmc.2pno(dat, weights=NULL, burnin=500, iter=1000, N.sampvalues=1000,       progress.iter=50, save.theta=FALSE)"},{"path":"/reference/mcmc.2pno.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","text":"dat Data frame dichotomous item responses weights optional vector student sample weights burnin Number burnin iterations iter Total number iterations N.sampvalues Maximum number sampled values save progress.iter Display progress every progress.iter-th iteration. progress display wanted, choose progress.iter larger iter. save.theta theta values saved?","code":""},{"path":"/reference/mcmc.2pno.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","text":"two-parameter normal ogive item response model probit link function defined $$ P(X_{pi}=1 | \\theta_p )=\\Phi ( a_i \\theta_p - b_i )         \\quad,  \\quad \\theta_p \\sim N(0,1) $$ Note implementation non-informative priors item parameters chosen (Johnson & Albert, 1999, p. 195ff.).","code":""},{"path":"/reference/mcmc.2pno.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","text":"list class mcmc.sirt following entries: mcmcobj Object class mcmc.list summary.mcmcobj Summary mcmcobj object.   summary Rhat statistic mode estimate MAP included.   variable PercSEratio indicates proportion Monte Carlo   standard error relation total standard deviation   posterior distribution. burnin Number burnin iterations iter Total number iterations .chain Sampled values \\(a_i\\) parameters b.chain Sampled values \\(b_i\\) parameters theta.chain Sampled values \\(\\theta_p\\) parameters deviance.chain Sampled values Deviance values EAP.rel EAP reliability person Data frame EAP person parameter estimates         \\(\\theta_p\\) corresponding posterior standard       deviations dat Used data frame weights Used student weights ... values","code":""},{"path":"/reference/mcmc.2pno.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","text":"Johnson, V. E., & Albert, J. H. (1999). Ordinal Data Modeling. New York: Springer.","code":""},{"path":[]},{"path":"/reference/mcmc.2pno.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC Estimation of the Two-Parameter Normal Ogive Item Response Model — mcmc.2pno","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Dataset Reading ############################################################################# data(data.read) # estimate 2PNO with MCMC with 3000 iterations and 500 burn-in iterations mod <- sirt::mcmc.2pno( dat=data.read, iter=3000, burnin=500 ) # plot MCMC chains plot( mod$mcmcobj, ask=TRUE ) # write sampled chains into codafile mcmclist2coda( mod$mcmcobj, name=\"dataread_2pno\" ) # summary summary(mod)  ############################################################################# # EXAMPLE 2 ############################################################################# # simulate data N <- 1000 I <- 10 b <- seq( -1.5, 1.5, len=I ) a <- rep( c(1,2), I/2 ) theta1 <- stats::rnorm(N) dat <- sirt::sim.raschtype( theta=theta1, fixed.a=a, b=b )  #*** # Model 1: estimate model without weights mod1 <- sirt::mcmc.2pno( dat, iter=1500, burnin=500) mod1$summary.mcmcobj plot( mod1$mcmcobj, ask=TRUE )  #*** # Model 2: estimate model with weights # define weights weights <- c( rep( 5, N/4 ), rep( .2, 3/4*N ) ) mod2 <- sirt::mcmc.2pno( dat, weights=weights, iter=1500, burnin=500) mod1$summary.mcmcobj }"},{"path":"/reference/mcmc.2pno.ml.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","title":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","text":"function enables estimation random item models multilevel (hierarchical) IRT models (Chaimongkol, Huffer & Kamata, 2007; Fox & Verhagen, 2010; van den Noortgate, de Boeck & Meulders, 2003; Asparouhov & Muthen, 2012; Muthen & Asparouhov, 2013, 2014). Dichotomous response data supported using probit link. Normally distributed responses can also analyzed. See Details description implemented item response models.","code":""},{"path":"/reference/mcmc.2pno.ml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","text":"","code":"mcmc.2pno.ml(dat, group, link=\"logit\", est.b.M=\"h\", est.b.Var=\"n\",     est.a.M=\"f\", est.a.Var=\"n\", burnin=500, iter=1000,     N.sampvalues=1000, progress.iter=50, prior.sigma2=c(1, 0.4),     prior.sigma.b=c(1, 1), prior.sigma.a=c(1, 1), prior.omega.b=c(1, 1),     prior.omega.a=c(1, 0.4), sigma.b.init=.3 )"},{"path":"/reference/mcmc.2pno.ml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","text":"dat Data frame item responses. group Vector group identifiers (e.g. classes, schools countries) link Link function. Choices \"logit\" dichotomous data     \"normal\" data normal distribution assumptions est.b.M Estimation type \\(b_i\\) parameters: n - non-hierarchical prior distribution, .e. \\(\\omega_b\\) set high value estimated h - hierarchical prior distribution estimated distribution parameters \\(\\mu_b\\) \\(\\omega_b\\) est.b.Var Estimation type standard deviations item difficulties \\(b_i\\). n -- estimation item variance, .e. \\(\\sigma_{b,}\\) assumed zero -- item-specific standard deviation item difficulties j -- joint standard deviation item difficulties estimated, .e. \\(\\sigma_{b,1}=\\ldots=\\sigma_{b,}=\\sigma_b\\) est..M Estimation type \\(a_i\\) parameters: f - estimation item slopes, .e item slopes \\(a_i\\) fixed one n - non-hierarchical prior distribution, .e. \\(\\omega_a=0\\) h - hierarchical prior distribution estimated distribution parameter \\(\\omega_a\\) est..Var Estimation type standard deviations item slopes \\(a_i\\). n -- estimation item variance -- item-specific standard deviation item slopes j -- joint standard deviation item slopes estimated, .e. \\(\\sigma_{,1}=\\ldots=\\sigma_{,}=\\sigma_a\\) burnin Number burnin iterations iter Total number iterations N.sampvalues Maximum number sampled values save progress.iter Display progress every progress.iter-th iteration. progress    display wanted, choose progress.iter larger iter. prior.sigma2 Prior Level 2 standard deviation \\(\\sigma_{L2}\\) prior.sigma.b Priors item difficulty standard deviations \\(\\sigma_{b,}\\) prior.sigma.Priors item difficulty standard deviations \\(\\sigma_{,}\\) prior.omega.b Prior \\(\\omega_b\\) prior.omega.Prior \\(\\omega_a\\) sigma.b.init Initial standard deviation \\(\\sigma_{b,}\\) parameters","code":""},{"path":"/reference/mcmc.2pno.ml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","text":"dichotomous item responses (link=\"logit\") persons \\(p\\) group \\(j\\) item \\(\\), probability correct response defined $$P( X_{pji}=1 | \\theta_{pj} )=\\Phi ( a_{ij} \\theta_{pj} - b_{ij} )$$ ability \\(\\theta_{pj}\\) decomposed Level 1 Level 2 effect $$\\theta_{pj}=u_j + e_{pj} \\quad, \\quad     u_j \\sim N ( 0, \\sigma_{L2}^2 ) \\quad, \\quad     e_{pj} \\sim N ( 0, \\sigma_{L1}^2 ) $$ multilevel IRT model (random item model), item parameters allowed vary across groups: $$ b_{ij} \\sim N( b_i, \\sigma^2_{b,} ) \\quad, \\quad     a_{ij} \\sim N( a_i, \\sigma^2_{,} ) $$ hierarchical IRT model, hierarchical distribution (main) item parameters assumed $$ b_{} \\sim N( \\mu_b, \\omega^2_{b} ) \\quad, \\quad     a_{} \\sim N( 1, \\omega^2_{} ) $$ Note identification purposes, mean item slopes \\(a_i\\) set one. Using arguments est.b.M, est.b.Var, est..M est..Var defines variance components estimated. normally distributed item responses (link=\"normal\"), model equations remain except item response model now written $$ X_{pji}=a_{ij} \\theta_{pj} - b_{ij} + \\varepsilon_{pji} \\quad, \\quad \\varepsilon_{pji} \\sim N( 0, \\sigma^2_{res,} ) $$","code":""},{"path":"/reference/mcmc.2pno.ml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","text":"list class mcmc.sirt following entries: mcmcobj Object class mcmc.list summary.mcmcobj Summary mcmcobj object.   summary Rhat statistic mode estimate MAP included.   variable PercSEratio indicates proportion Monte Carlo   standard error relation total standard deviation   posterior distribution. ic Information criteria (DIC) burnin Number burnin iterations iter Total number iterations theta.chain Sampled values \\(\\theta_{pj}\\) parameters theta.chain Sampled values \\(u_{j}\\) parameters deviance.chain Sampled values Deviance values EAP.rel EAP reliability person Data frame EAP person parameter estimates         \\(\\theta_pj\\) corresponding posterior standard       deviations dat Used data frame ... values","code":""},{"path":"/reference/mcmc.2pno.ml.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","text":"Asparouhov, T. & Muthen, B. (2012). General random effect latent variable modeling: Random subjects, items, contexts, parameters. http://www.statmodel.com/papers_date.shtml. Chaimongkol, S., Huffer, F. W., & Kamata, . (2007). explanatory differential item functioning (DIF) model WinBUGS 1.4. Songklanakarin Journal Science Technology, 29, 449-458. Fox, J.-P., & Verhagen, .-J. (2010). Random item effects modeling cross-national survey data. E. Davidov, P. Schmidt, & J. Billiet (Eds.), Cross-cultural Analysis: Methods Applications (pp. 467-488), London: Routledge Academic. Muthen, B. & Asparouhov, T. (2013). New methods study measurement invariance many groups. http://www.statmodel.com/papers_date.shtml Muthen, B. & Asparouhov, T. (2014). Item response modeling Mplus: multi-dimensional, multi-level, multi-timepoint example. W. Linden & R. Hambleton (2014). Handbook item response theory: Models, statistical tools, applications. http://www.statmodel.com/papers_date.shtml van den Noortgate, W., De Boeck, P., & Meulders, M. (2003). Cross-classification multilevel logistic models psychometrics. Journal Educational Behavioral Statistics, 28, 369-386.","code":""},{"path":[]},{"path":"/reference/mcmc.2pno.ml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Item Response Model / Multilevel IRT Model — mcmc.2pno.ml","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Dataset Multilevel data.ml1 - dichotomous items ############################################################################# data(data.ml1) dat <- data.ml1[,-1] group <- data.ml1$group # just for a try use a very small number of iterations burnin <- 50 ; iter <- 100  #*** # Model 1: 1PNO with no cluster item effects mod1 <- sirt::mcmc.2pno.ml( dat, group, est.b.Var=\"n\", burnin=burnin, iter=iter ) summary(mod1)    # summary plot(mod1,layout=2,ask=TRUE) # plot results # write results to coda file mcmclist2coda( mod1$mcmcobj, name=\"data.ml1_mod1\" )  #*** # Model 2: 1PNO with cluster item effects of item difficulties mod2 <- sirt::mcmc.2pno.ml( dat, group, est.b.Var=\"i\", burnin=burnin, iter=iter ) summary(mod2) plot(mod2, ask=TRUE, layout=2 )  #*** # Model 3: 2PNO with cluster item effects of item difficulties but #          joint item slopes mod3 <- sirt::mcmc.2pno.ml( dat, group, est.b.Var=\"i\", est.a.M=\"h\",               burnin=burnin, iter=iter ) summary(mod3)  #*** # Model 4: 2PNO with cluster item effects of item difficulties and #          cluster item effects with a jointly estimated SD mod4 <- sirt::mcmc.2pno.ml( dat, group, est.b.Var=\"i\", est.a.M=\"h\",                 est.a.Var=\"j\", burnin=burnin, iter=iter ) summary(mod4)  ############################################################################# # EXAMPLE 2: Dataset Multilevel data.ml2 - polytomous items #            assuming a normal distribution for polytomous items ############################################################################# data(data.ml2) dat <- data.ml2[,-1] group <- data.ml2$group # set iterations for all examples (too few!!) burnin <- 100 ; iter <- 500  #*** # Model 1: no intercept variance, no slopes mod1 <- sirt::mcmc.2pno.ml( dat=dat, group=group, est.b.Var=\"n\",              burnin=burnin, iter=iter, link=\"normal\",  progress.iter=20  ) summary(mod1)  #*** # Model 2a: itemwise intercept variance, no slopes mod2a <- sirt::mcmc.2pno.ml( dat=dat, group=group, est.b.Var=\"i\",             burnin=burnin, iter=iter,link=\"normal\",  progress.iter=20  ) summary(mod2a)  #*** # Model 2b: homogeneous intercept variance, no slopes mod2b <- sirt::mcmc.2pno.ml( dat=dat, group=group, est.b.Var=\"j\",               burnin=burnin, iter=iter,link=\"normal\",  progress.iter=20  ) summary(mod2b)  #*** # Model 3: intercept variance and slope variances #          hierarchical item and slope parameters mod3 <- sirt::mcmc.2pno.ml( dat=dat, group=group,                est.b.M=\"h\", est.b.Var=\"i\", est.a.M=\"h\", est.a.Var=\"i\",                burnin=burnin, iter=iter,link=\"normal\",  progress.iter=20  ) summary(mod3)  ############################################################################# # EXAMPLE 3: Simulated random effects model | dichotomous items ############################################################################# set.seed(7698)  #*** model parameters sig2.lev2 <- .3^2   # theta level 2 variance sig2.lev1 <- .8^2   # theta level 1 variance G <- 100            # number of groups n <- 20             # number of persons within a group I <- 12             # number of items #*** simuate theta theta2 <- stats::rnorm( G, sd=sqrt(sig2.lev2) ) theta1 <- stats::rnorm( n*G, sd=sqrt(sig2.lev1) ) theta  <- theta1 + rep( theta2, each=n ) #*** item difficulties b <- seq( -2, 2, len=I ) #*** define group identifier group <- 1000 + rep(1:G, each=n ) #*** SD of group specific difficulties for items 3 and 5 sigma.item <- rep(0,I) sigma.item[c(3,5)] <- 1 #*** simulate group specific item difficulties b.class <- sapply( sigma.item, FUN=function(sii){ stats::rnorm( G, sd=sii ) } ) b.class <- b.class[ rep( 1:G,each=n ), ] b <- matrix( b, n*G, I, byrow=TRUE ) + b.class #*** simulate item responses m1 <- stats::pnorm( theta - b ) dat <- 1 * ( m1 > matrix( stats::runif( n*G*I ), n*G, I ) )  #*** estimate model mod <- sirt::mcmc.2pno.ml( dat, group=group, burnin=burnin, iter=iter,             est.b.M=\"n\", est.b.Var=\"i\", progress.iter=20) summary(mod) plot(mod, layout=2, ask=TRUE ) }"},{"path":"/reference/mcmc.2pnoh.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","title":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","text":"function estimates hierarchical IRT model criterion-referenced measurement based two-parameter normal ogive response function (Janssen, Tuerlinckx, Meulders & de Boeck, 2000).","code":""},{"path":"/reference/mcmc.2pnoh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","text":"","code":"mcmc.2pnoh(dat, itemgroups, prob.mastery=c(.5,.8), weights=NULL,       burnin=500, iter=1000, N.sampvalues=1000,       progress.iter=50, prior.variance=c(1,1), save.theta=FALSE)"},{"path":"/reference/mcmc.2pnoh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","text":"dat Data frame dichotomous item responses itemgroups Vector characters integers define     criterion item associated. prob.mastery Probability levels define nonmastery, transition     mastery stage (see Details) weights optional vector student sample weights burnin Number burnin iterations iter Total number iterations N.sampvalues Maximum number sampled values save progress.iter Display progress every progress.iter-th iteration. progress display wanted, choose progress.iter larger iter. prior.variance Scale parameter inverse gamma distribution     \\(\\sigma^2\\) \\(\\nu^2\\) item variance parameters save.theta theta values saved?","code":""},{"path":"/reference/mcmc.2pnoh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","text":"hierarchical IRT model criterion-referenced measurement (Janssen et al., 2000) assumes every item \\(\\) intends measure criterion \\(k\\). item response function defined $$ P(X_{pik}=1 | \\theta_p )=         \\Phi [ \\alpha_{ik} ( \\theta_p - \\beta_{ik} ) ]         \\quad,  \\quad \\theta_p \\sim N(0,1) $$ Item parameters \\((\\alpha_{ik},\\beta_{ik})\\) hierarchically modeled, .e. $$ \\beta_{ik} \\sim N( \\xi_k, \\sigma^2 ) \\quad \\mbox{} \\quad     \\alpha_{ik} \\sim N( \\omega_k, \\nu^2 ) $$ mcmc.list output object, also derived parameters \\(d_{ik}=\\alpha_{ik} \\beta_{ik}\\) \\(\\tau_k=\\xi_k \\omega_k\\) calculated. Mastery nonmastery probabilities based reference item \\(Y_{k}\\) criterion \\(k\\) response function $$ P(Y_{pk}=1 | \\theta_p )=         \\Phi [ \\omega_{k} ( \\theta_p - \\xi_{k} ) ]         \\quad,  \\quad \\theta_p \\sim N(0,1) $$ known item parameters person parameters, response probabilities criterion \\(k\\) calculated. response probability criterion \\(k\\) larger prob.mastery[2], student defined master. probability smaller prob.mastery[1], student nonmaster. cases, students transition stage. mcmcobj output object, parameters d[] defined \\(d_{ik}=\\alpha_{ik} \\cdot \\beta_{ik}\\) tau[k] defined \\( \\tau_k=\\xi_k \\cdot \\omega_k \\).","code":""},{"path":"/reference/mcmc.2pnoh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","text":"list class mcmc.sirt following entries: mcmcobj Object class mcmc.list summary.mcmcobj Summary mcmcobj object.   summary Rhat statistic mode estimate MAP included.   variable PercSEratio indicates proportion Monte Carlo   standard error relation total standard deviation   posterior distribution. burnin Number burnin iterations iter Total number iterations alpha.chain Sampled values \\(\\alpha_{ik}\\) parameters beta.chain Sampled values \\(\\beta_{ik}\\) parameters xi.chain Sampled values \\(\\xi_{k}\\) parameters omega.chain Sampled values \\(\\omega_{k}\\) parameters sigma.chain Sampled values \\(\\sigma\\) parameter nu.chain Sampled values \\(\\nu\\) parameter theta.chain Sampled values \\(\\theta_p\\) parameters deviance.chain Sampled values Deviance values EAP.rel EAP reliability person Data frame EAP person parameter estimates         \\(\\theta_p\\) corresponding posterior standard       deviations dat Used data frame weights Used student weights ... values","code":""},{"path":"/reference/mcmc.2pnoh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","text":"Janssen, R., Tuerlinckx, F., Meulders, M., & De Boeck, P. (2000). hierarchical IRT model criterion-referenced measurement. Journal Educational Behavioral Statistics, 25, 285-306.","code":""},{"path":[]},{"path":"/reference/mcmc.2pnoh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC Estimation of the Hierarchical IRT Model for Criterion-Referenced\r\nMeasurement — mcmc.2pnoh","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Simulated data according to Janssen et al. (2000, Table 2) #############################################################################  N <- 1000 Ik <- c(4,6,8,5,9,6,8,6,5) xi.k <- c( -.89, -1.13, -1.23, .06, -1.41, -.66, -1.09, .57, -2.44) omega.k <- c(.98, .91, .76, .74, .71, .80, .79, .82, .54)  # select 4 attributes K <- 4 Ik <- Ik[1:K] ; xi.k <- xi.k[1:K] ; omega.k <- omega.k[1:K] sig2 <- 3.02 nu2 <- .09 I <- sum(Ik) b <- rep( xi.k, Ik ) + stats::rnorm(I, sd=sqrt(sig2) ) a <- rep( omega.k, Ik ) + stats::rnorm(I, sd=sqrt(nu2) ) theta1 <- stats::rnorm(N) t1 <- rep(1,N) p1 <- stats::pnorm( outer(t1,a) * ( theta1 - outer(t1,b) ) ) dat <- 1  * ( p1 > stats::runif(N*I)  ) itemgroups <- rep( paste0(\"A\", 1:K ), Ik )  # estimate model mod <- sirt::mcmc.2pnoh(dat, itemgroups, burnin=200, iter=1000 ) # summary summary(mod) # plot plot(mod$mcmcobj, ask=TRUE) # write coda files mcmclist2coda( mod$mcmcobj, name=\"simul_2pnoh\" ) }"},{"path":"/reference/mcmc.3pno.testlet.html","id":null,"dir":"Reference","previous_headings":"","what":"3PNO Testlet Model — mcmc.3pno.testlet","title":"3PNO Testlet Model — mcmc.3pno.testlet","text":"function estimates 3PNO testlet model (Wang, Bradlow & Wainer, 2002, 2007) Markov Chain Monte Carlo methods (Glas, 2012).","code":""},{"path":"/reference/mcmc.3pno.testlet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3PNO Testlet Model — mcmc.3pno.testlet","text":"","code":"mcmc.3pno.testlet(dat, testlets=rep(NA, ncol(dat)),    weights=NULL, est.slope=TRUE, est.guess=TRUE, guess.prior=NULL,    testlet.variance.prior=c(1, 0.2), burnin=500, iter=1000,    N.sampvalues=1000, progress.iter=50, save.theta=FALSE, save.gamma.testlet=FALSE )"},{"path":"/reference/mcmc.3pno.testlet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3PNO Testlet Model — mcmc.3pno.testlet","text":"dat Data frame dichotomous item responses \\(N\\) persons \\(\\) items testlets integer character vector indicates allocation items testlets. entries corresponds testlets. entry NA, item belong testlet. weights optional vector student sample weights est.slope item slopes estimated? default TRUE. est.guess guessing parameters estimated? default TRUE. guess.prior vector length two matrix \\(\\) items two columns defines beta prior distribution guessing parameters. default non-informative prior, .e. Beta(1,1) distribution. testlet.variance.prior vector length two defines (joint) prior testlet variances assuming inverse chi-squared distribution. first entry effective sample size prior second entry defines prior variance testlet. default c(1,.2) means prior sample size 1 prior testlet variance .2. burnin Number burnin iterations iter Number iterations N.sampvalues Maximum number sampled values save progress.iter Display progress every progress.iter-th iteration. progress display wanted, choose progress.iter larger iter. save.theta Logical indicating whether theta values saved save.gamma.testlet Logical indicating whether gamma values saved","code":""},{"path":"/reference/mcmc.3pno.testlet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"3PNO Testlet Model — mcmc.3pno.testlet","text":"testlet response model person \\(p\\) item \\(\\) defined $$ P(X_{pi}=1 )=c_i + ( 1 - c_i )         \\Phi ( a_i \\theta_p + \\gamma_{p,t()} + b_i    ) \\quad, \\quad     \\theta_p \\sim N ( 0,1 ), \\gamma_{p,t()} \\sim N( 0, \\sigma^2_t ) $$ case est.slope=FALSE, item slopes \\(a_i\\) set 1. variance \\(\\sigma^2\\) \\(\\theta_p\\) distribution estimated called Rasch testlet model literature (Wang & Wilson, 2005). case est.guess=FALSE, guessing parameters \\(c_i\\) set 0. fitting testlet model, marginal item parameters calculated (integrating testlet effects \\(\\gamma_{p,t()}\\)) according defining response equation $$ P(X_{pi}=1 )=c_i + ( 1 - c_i )         \\Phi ( a_i^\\ast \\theta_p + b_i^\\ast    ) $$","code":""},{"path":"/reference/mcmc.3pno.testlet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3PNO Testlet Model — mcmc.3pno.testlet","text":"list class mcmc.sirt following entries: mcmcobj Object class mcmc.list containing item parameters   (b_marg a_marg denote marginal item parameters)   person parameters (requested) summary.mcmcobj Summary mcmcobj object.   summary Rhat statistic mode estimate MAP included.   variable PercSEratio indicates proportion Monte Carlo   standard error relation total standard deviation   posterior distribution. ic Information criteria (DIC) burnin Number burnin iterations iter Total number iterations theta.chain Sampled values \\(\\theta_p\\) parameters deviance.chain Sampled values deviance values EAP.rel EAP reliability person Data frame EAP person parameter estimates         \\(\\theta_p\\) corresponding posterior standard       deviations testlet effects dat Used data frame weights Used student weights ... values","code":""},{"path":"/reference/mcmc.3pno.testlet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"3PNO Testlet Model — mcmc.3pno.testlet","text":"Glas, C. . W. (2012). Estimating testing extended testlet model. LSAC Research Report Series, RR 12-03. Wainer, H., Bradlow, E. T., & Wang, X. (2007). Testlet response theory applications. Cambridge: Cambridge University Press. Wang, W.-C., & Wilson, M. (2005). Rasch testlet model. Applied Psychological Measurement, 29, 126-149. Wang, X., Bradlow, E. T., & Wainer, H. (2002). general Bayesian model testlets: Theory applications. Applied Psychological Measurement, 26, 109-128.","code":""},{"path":[]},{"path":[]},{"path":"/reference/mcmc.list.descriptives.html","id":null,"dir":"Reference","previous_headings":"","what":"Computation of Descriptive Statistics for a mcmc.list Object — mcmc.list.descriptives","title":"Computation of Descriptive Statistics for a mcmc.list Object — mcmc.list.descriptives","text":"Computation descriptive statistics, Rhat convergence statistic MAP mcmc.list object. Rhat statistic computed splitting one Monte Carlo chain three segments equal length. MAP mode estimate posterior distribution approximated mode kernel density estimate.","code":""},{"path":"/reference/mcmc.list.descriptives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computation of Descriptive Statistics for a mcmc.list Object — mcmc.list.descriptives","text":"","code":"mcmc.list.descriptives( mcmcobj, quantiles=c(.025,.05,.1,.5,.9,.95,.975) )"},{"path":"/reference/mcmc.list.descriptives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computation of Descriptive Statistics for a mcmc.list Object — mcmc.list.descriptives","text":"mcmcobj Object class mcmc.list quantiles Quantiles calculated parameters","code":""},{"path":"/reference/mcmc.list.descriptives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computation of Descriptive Statistics for a mcmc.list Object — mcmc.list.descriptives","text":"data frame descriptive statistics parameters mcmc.list object.","code":""},{"path":[]},{"path":"/reference/mcmc.list.descriptives.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computation of Descriptive Statistics for a mcmc.list Object — mcmc.list.descriptives","text":"","code":"if (FALSE) { miceadds::library_install(\"coda\") miceadds::library_install(\"R2WinBUGS\")  ############################################################################# # EXAMPLE 1: Logistic regression #############################################################################  #*************************************** # (1) simulate data set.seed(8765) N <- 500 x1 <- stats::rnorm(N) x2 <- stats::rnorm(N) y <- 1*( stats::plogis( -.6 + .7*x1 + 1.1 *x2 ) > stats::runif(N) )  #*************************************** # (2) estimate logistic regression with glm mod <- stats::glm( y ~ x1 + x2, family=\"binomial\" ) summary(mod)  #*************************************** # (3) estimate model with rcppbugs package b <- rcppbugs::mcmc.normal( stats::rnorm(3),mu=0,tau=0.0001) y.hat <- rcppbugs::deterministic(function(x1,x2,b) {              stats::plogis( b[1] + b[2]*x1 + b[3]*x2 ) }, x1, x2, b) y.lik <- rcppbugs::mcmc.bernoulli( y, p=y.hat, observed=TRUE) m <- rcppbugs::create.model(b, y.hat, y.lik)  #*** estimate model in rcppbugs; 5000 iterations, 1000 burnin iterations ans <- rcppbugs::run.model(m, iterations=5000, burn=1000, adapt=1000, thin=5) print(rcppbugs::get.ar(ans))     # get acceptance rate print(apply(ans[[\"b\"]],2,mean))  # get means of posterior  #*** convert rcppbugs into mcmclist object mcmcobj <- data.frame( ans$b  ) colnames(mcmcobj) <- paste0(\"b\",1:3) mcmcobj <- as.matrix(mcmcobj) class(mcmcobj) <- \"mcmc\" attr(mcmcobj, \"mcpar\") <- c( 1, nrow(mcmcobj), 1 ) mcmcobj <- coda::as.mcmc.list( mcmcobj )  # plot results plot(mcmcobj)  # summary summ1 <-  sirt::mcmc.list.descriptives( mcmcobj ) summ1 }"},{"path":"/reference/mcmclist2coda.html","id":null,"dir":"Reference","previous_headings":"","what":"Write Coda File from an Object of Class mcmc.list — mcmclist2coda","title":"Write Coda File from an Object of Class mcmc.list — mcmclist2coda","text":"function  writes coda file object class mcmc.list. Note first entry (.e. one chain) processed.","code":""},{"path":"/reference/mcmclist2coda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write Coda File from an Object of Class mcmc.list — mcmclist2coda","text":"","code":"mcmclist2coda(mcmclist, name, coda.digits=5)"},{"path":"/reference/mcmclist2coda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write Coda File from an Object of Class mcmc.list — mcmclist2coda","text":"mcmclist object class mcmc.list. name Name coda file written coda.digits Number digits decimal coda file","code":""},{"path":"/reference/mcmclist2coda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write Coda File from an Object of Class mcmc.list — mcmclist2coda","text":"coda file corresponding index file written working directory.","code":""},{"path":"/reference/mcmclist2coda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write Coda File from an Object of Class mcmc.list — mcmclist2coda","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: MCMC estimation 2PNO dataset Reading #############################################################################  data(data.read) # estimate 2PNO with MCMC with 3000 iterations and 500 burn-in iterations mod <- sirt::mcmc.2pno( dat=data.read, iter=3000, burnin=500 ) # plot MCMC chains plot( mod$mcmcobj, ask=TRUE ) # write sampled chains into codafile mcmclist2coda( mod$mcmcobj, name=\"dataread_2pl\" ) }"},{"path":"/reference/mcmc_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Some Methods for Objects of Class mcmc.list — mcmc_coef","title":"Some Methods for Objects of Class mcmc.list — mcmc_coef","text":"methods objects class mcmc.list created coda package.","code":""},{"path":"/reference/mcmc_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Some Methods for Objects of Class mcmc.list — mcmc_coef","text":"","code":"## coefficients mcmc_coef(mcmcobj, exclude=\"deviance\")  ## covariance matrix mcmc_vcov(mcmcobj, exclude=\"deviance\")  ## confidence interval mcmc_confint( mcmcobj, parm, level=.95, exclude=\"deviance\" )  ## summary function mcmc_summary( mcmcobj, quantiles=c(.025,.05,.50,.95,.975) )  ## plot function mcmc_plot(mcmcobj, ...)  ## inclusion of derived parameters in mcmc object mcmc_derivedPars( mcmcobj, derivedPars )  ## Wald test for parameters mcmc_WaldTest( mcmcobj, hypotheses )  # S3 method for mcmc_WaldTest summary(object, digits=3, ...)"},{"path":"/reference/mcmc_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Some Methods for Objects of Class mcmc.list — mcmc_coef","text":"mcmcobj Objects class mcmc.list created coda::mcmc exclude Vector parameters excluded calculations parm Optional vector parameters level Confidence level quantiles Vector quantiles computed. ... Parameters passed mcmc_plot. See LAM::plot.amh arguments. derivedPars List derived parameters (see examples). hypotheses List hypotheses form \\(g_i( \\bold{\\theta})=0\\). object Object class mcmc_WaldTest. digits Number digits used rounding.","code":""},{"path":[]},{"path":"/reference/mcmc_coef.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Some Methods for Objects of Class mcmc.list — mcmc_coef","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Logistic regression in rcppbugs package #############################################################################   #*************************************** # (1) simulate data set.seed(8765) N <- 500 x1 <- stats::rnorm(N) x2 <- stats::rnorm(N) y <- 1*( stats::plogis( -.6 + .7*x1 + 1.1 *x2 ) > stats::runif(N) )  #*************************************** # (2) estimate logistic regression with glm mod <- stats::glm( y ~ x1 + x2, family=\"binomial\" ) summary(mod)  #*************************************** # (3) estimate model with rcppbugs package library(rcppbugs) b <- rcppbugs::mcmc.normal( stats::rnorm(3),mu=0,tau=0.0001) y.hat <- rcppbugs::deterministic( function(x1,x2,b){                 stats::plogis( b[1] + b[2]*x1 + b[3]*x2 ) },                   x1, x2, b) y.lik <- rcppbugs::mcmc.bernoulli( y, p=y.hat, observed=TRUE) model <- rcppbugs::create.model(b, y.hat, y.lik)  #*** estimate model in rcppbugs; 5000 iterations, 1000 burnin iterations n.burnin <- 500 ; n.iter <- 2000 ; thin <- 2 ans <- rcppbugs::run.model(model, iterations=n.iter, burn=n.burnin, adapt=200, thin=thin) print(rcppbugs::get.ar(ans)) # get acceptance rate print(apply(ans[[\"b\"]],2,mean)) # get means of posterior  #*** convert rcppbugs into mcmclist object mcmcobj <- data.frame( ans$b ) colnames(mcmcobj) <- paste0(\"b\",1:3) mcmcobj <- as.matrix(mcmcobj) class(mcmcobj) <- \"mcmc\" attr(mcmcobj, \"mcpar\") <- c( n.burnin+1, n.iter, thin ) mcmcobj <- coda::mcmc( mcmcobj )  # coefficients, variance covariance matrix and confidence interval mcmc_coef(mcmcobj) mcmc_vcov(mcmcobj) mcmc_confint( mcmcobj, level=.90 )  # summary and plot mcmc_summary(mcmcobj) mcmc_plot(mcmcobj, ask=TRUE)  # include derived parameters in mcmc object derivedPars <- list( \"diff12\"=~ I(b2-b1), \"diff13\"=~ I(b3-b1) ) mcmcobj2 <- sirt::mcmc_derivedPars(mcmcobj, derivedPars=derivedPars ) mcmc_summary(mcmcobj2)  #*** Wald test for parameters  # hyp1: b2 - 0.5=0  # hyp2: b2 * b3=0 hypotheses <- list( \"hyp1\"=~ I( b2 - .5 ), \"hyp2\"=~ I( b2*b3 ) ) test1 <- sirt::mcmc_WaldTest( mcmcobj, hypotheses=hypotheses ) summary(test1) }"},{"path":"/reference/mcmc_Rhat.html","id":null,"dir":"Reference","previous_headings":"","what":"Computation of the Rhat Statistic from a Single MCMC Chain — mcmc_Rhat","title":"Computation of the Rhat Statistic from a Single MCMC Chain — mcmc_Rhat","text":"Computes Rhat statistic single MCMC chain.","code":""},{"path":"/reference/mcmc_Rhat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computation of the Rhat Statistic from a Single MCMC Chain — mcmc_Rhat","text":"","code":"mcmc_Rhat(mcmc_object, n_splits=3)"},{"path":"/reference/mcmc_Rhat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computation of the Rhat Statistic from a Single MCMC Chain — mcmc_Rhat","text":"mcmc_object Object class mcmc n_splits Number splits MCMC chain","code":""},{"path":"/reference/mcmc_Rhat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computation of the Rhat Statistic from a Single MCMC Chain — mcmc_Rhat","text":"Numeric vector","code":""},{"path":"/reference/mcmc_Rhat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computation of the Rhat Statistic from a Single MCMC Chain — mcmc_Rhat","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Computation Rhat statistic for 2PNO model fitting by MCMC #############################################################################  data(data.read)  # estimate 2PNO with MCMC with 3000 iterations and 500 burn-in iterations mod <- sirt::mcmc.2pno( dat=data.read, iter=1000, burnin=100 ) # plot MCMC chains plot( mod$mcmcobj, ask=TRUE ) # compute Rhat statistics round( sirt::mcmc_Rhat( mod$mcmcobj[[1]] ), 3 ) }"},{"path":"/reference/md.pattern.sirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Response Pattern in a Binary Matrix — md.pattern.sirt","title":"Response Pattern in a Binary Matrix — md.pattern.sirt","text":"Computes different statistics response pattern binary matrix.","code":""},{"path":"/reference/md.pattern.sirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Response Pattern in a Binary Matrix — md.pattern.sirt","text":"","code":"md.pattern.sirt(dat)"},{"path":"/reference/md.pattern.sirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Response Pattern in a Binary Matrix — md.pattern.sirt","text":"dat binary data matrix","code":""},{"path":"/reference/md.pattern.sirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Response Pattern in a Binary Matrix — md.pattern.sirt","text":"list following entries: dat Original dataset dat.resp1 Indices responses 1's dat.resp0 Indices responses 0's resp_patt Vector response patterns unique_resp_patt Unique response patterns unique_resp_patt_freq Frequencies unique response patterns unique_resp_patt_firstobs First observation original dataset     dat unique response pattern freq1 Frequencies 1's freq0 Frequencies 0's dat.ordered Dataset according response patterns","code":""},{"path":[]},{"path":"/reference/md.pattern.sirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Response Pattern in a Binary Matrix — md.pattern.sirt","text":"","code":"############################################################################# # EXAMPLE 1: Response patterns ############################################################################# set.seed(7654) N <- 21         # number of rows I <- 4          # number of columns dat <- matrix( 1*( stats::runif(N*I) > .3 ), N, I ) res <- sirt::md.pattern.sirt(dat) # plot of response patterns res$dat.ordered image( z=t(res$dat.ordered), y=1:N, x=1:I, xlab=\"Items\", ylab=\"Persons\") # 0's are yellow and 1's are red  ############################################################################# # EXAMPLE 2: Item response patterns for dataset data.read #############################################################################  data(data.read) dat <- data.read  ; N <- nrow(dat) ; I <- ncol(dat) # order items according to p values dat <- dat[, order(colMeans(dat, na.rm=TRUE )) ] # analyzing response pattern res <- sirt::md.pattern.sirt(dat) res$dat.ordered image( z=t(res$dat.ordered), y=1:N, x=1:I, xlab=\"Items\", ylab=\"Persons\")"},{"path":"/reference/mgsem.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of Multiple-Group Structural Equation Models — mgsem","title":"Estimation of Multiple-Group Structural Equation Models — mgsem","text":"Estimates multiple-group structural equation model. function allows arbitrary prior distributions model parameters regularized estimation SCAD LASSO penalty. Moreover, can also conduct robust moment estimation using \\(L_p\\) loss function \\(\\rho(x)=|x|^p\\) \\(p \\ge 0\\). See Robitzsch (2023) details.","code":""},{"path":"/reference/mgsem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of Multiple-Group Structural Equation Models — mgsem","text":"","code":"mgsem(suffstat, model, data=NULL, group=NULL, weights=NULL, estimator=\"ML\",      p_me=2, p_pen=1, pen_type=\"scad\", diffpar_pen=NULL, pen_sample_size=TRUE,      a_scad=3.7, eps_approx=0.001, comp_se=TRUE, se_delta_formula=FALSE,      prior_list=NULL, hessian=TRUE, fixed_parms=FALSE, cd=FALSE,      cd_control=list(maxiter=20, tol=5*1e-04, interval_length=0.05, method=\"exact\"),      partable_start=NULL, num_approx=FALSE, technical=NULL, control=list())"},{"path":"/reference/mgsem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of Multiple-Group Structural Equation Models — mgsem","text":"suffstat List containing sufficient statistics model Model specification, see examples. Can entries est, index, lower, upper, prior, pen_l2, pen_lp, pen_difflp. entry can defined model matrices ALPHA, NU, LAM, PHI, PSI. data Optional data frame group Optional vector group identifiers weights Optional vector sampling weights estimator Character. Can either \"ML\" maximum likelihood fitting function \"\" robust moment estimation. p_me Power $L_p$ loss function robust moment estimation p_pen Power penalty regularized estimation. regular LASSO SCAD penalty functions, $p=1$. pen_type Penalty type. Can either \"scad\" \"lasso\". diffpar_pen List containing values regularization parameters fused lasso estimation pen_sample_size List containing values sample sizes regularized estimation a_scad Parameter $$ used SCAD penalty eps_approx Approximation value nondifferentiable robust moment fitting function penalty function comp_se Logical indicating whether standard errors computed se_delta_formula Logical indicating whether standard errors computed according delta formula prior_list List containing specifications prior distributions hessian Logical indicating whether Hessian matrix computed fixed_parms Logical indicating whether model parameters fixed cd Logical indicating whether coordinate descent used estimation cd_control Control parameters coordinate descent estimation partable_start Starting values parameter estimation num_approx Logical indicating whether derivatives computed based numerical differentiation technical Parameters used optimization sirt_optimizer control Control paramaters optimization","code":""},{"path":"/reference/mgsem.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of Multiple-Group Structural Equation Models — mgsem","text":"[INFORMATION ADDED]","code":""},{"path":"/reference/mgsem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of Multiple-Group Structural Equation Models — mgsem","text":"list following values coef Coeffients vcov Variance matrix se Vector standard errors partable Parameter table model Specified model opt_res Result optimization opt_value Value fitting function residuals Residuals sufficient statistics ic Information criteria technical Specifications optimizer suffstat_vcov Variance matrix sufficient statistics me_delta_method Input output matrices delta method estimator=\"\" data_proc Processed data case_ll Casewise log-likelihood function ... values","code":""},{"path":"/reference/mgsem.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of Multiple-Group Structural Equation Models — mgsem","text":"Robitzsch, . (2023). Model-robust estimation multiple-group structural equation models. Algorithms, 16(4), 210. doi:10.3390/a16040210","code":""},{"path":"/reference/mgsem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of Multiple-Group Structural Equation Models — mgsem","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Noninvariant item intercepts in a multiple-group SEM #############################################################################  #---- simulate data set.seed(65) G <- 3  # number of groups I <- 5  # number of items # define lambda and nu parameters lambda <- matrix(1, nrow=G, ncol=I) nu <- matrix(0, nrow=G, ncol=I) err_var <- matrix(1, nrow=G, ncol=I)  # define extent of noninvariance dif_int <- .5  #- 1st group: N(0,1) nu[1,4] <- dif_int #- 2nd group: N(0.3,1.5) gg <- 2 ; nu[gg,1] <- -dif_int #- 3nd group: N(.8,1.2) gg <- 3 nu[gg,2] <- -dif_int #- define distributions of groups mu <- c(0,.3,.8) sigma <- sqrt(c(1,1.5,1.2)) N <- rep(1000,3) # sample sizes per group  exact <- FALSE suffstat <- sirt::invariance_alignment_simulate(nu, lambda, err_var, mu, sigma, N,                 output=\"suffstat\", groupwise=TRUE, exact=exact)  #---- model specification  # model specifications joint group est <- list(         ALPHA=matrix( c(0), ncol=1),         NU=matrix( 0, nrow=I, ncol=1),         LAM=matrix(1, nrow=I, ncol=1),         PHI=matrix(0,nrow=1,ncol=1),         PSI=diag(rep(1,I))         )  # parameter index index <- list(         ALPHA=0*est$ALPHA,         NU=1+0*est$NU,         LAM=1+0*est$LAM,         PHI=0*est$PHI,         PSI=diag(1,I)         )  # lower bounds lower <- list(         PSI=diag(rep(0.01,I)), PHI=matrix(0.01,1,1)         )  #*** joint parameters group0 <- list(est=est, index=index, lower=lower)  #*** group1 est <- list(         ALPHA=matrix( c(0), ncol=1),         NU=matrix( 0, nrow=I, ncol=1),         LAM=matrix(0, nrow=I, ncol=1),         PHI=matrix(1,nrow=1,ncol=1)             )  # parameter index index <- list(         ALPHA=0*est$ALPHA,         NU=0*est$NU,         LAM=1*est$LAM,         PHI=0*est$PHI         )  group1 <- list(est=est, index=index, lower=lower)  #*** group 2 and group 3  # modify parameter index index$ALPHA <- 1+0*est$ALPHA index$PHI <- 1+0*est$PHI group3 <- group2 <- list(est=est, index=index, lower=lower)  #*** define model model <- list(group0=group0, group1=group1, group2=group2, group3=group3)  #-- estimate model with ML res1 <- sirt::mgsem( suffstat=suffstat, model=model2, eps_approx=1e-4, estimator=\"ML\",                     technical=list(maxiter=500, optimizer=\"optim\"),                     hessian=FALSE, comp_se=FALSE, control=list(trace=1) ) str(res1)  #-- robust moment estimation with p=0.5  optimizer <- \"optim\" technical <- list(maxiter=500, optimizer=optimizer) eps_approx <- 1e-3  res2 <- sirt::mgsem( suffstat=suffstat, model=res1$model, p_me=0.5,                     eps_approx=eps_approx, estimator=\"ME\", technical=technical,                     hessian=FALSE, comp_se=FALSE, control=list(trace=1) )  #---- regularized estimation  nu_lam <- 0.1    # regularization parameter  # redefine model define_model <- function(model, nu_lam) {     pen_lp <- list( NU=nu_lam+0*model$group1$est$NU)     ee <- \"group1\"     for (ee in c(\"group1\",\"group2\",\"group3\"))     {         model[[ee]]$index$NU <- 1+0*index$NU         model[[ee]]$pen_lp <- pen_lp     }     return(model) }  model3 <- define_model(model=model, nu_lam=nu_lam) pen_type <- \"scad\"  res3 <- sirt::mgsem( suffstat=suffstat, model=model3, p_pen=1, pen_type=pen_type,                     eps_approx=eps_approx, estimator=\"ML\",                     technical=list(maxiter=500, optimizer=\"optim\"),                     hessian=FALSE, comp_se=FALSE, control=list(trace=1) ) str(res3) }"},{"path":"/reference/mirt.specify.partable.html","id":null,"dir":"Reference","previous_headings":"","what":"Specify or modify a Parameter Table in mirt — mirt.specify.partable","title":"Specify or modify a Parameter Table in mirt — mirt.specify.partable","text":"Specify modify parameter table mirt.","code":""},{"path":"/reference/mirt.specify.partable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specify or modify a Parameter Table in mirt — mirt.specify.partable","text":"","code":"mirt.specify.partable(mirt.partable, parlist, verbose=TRUE)"},{"path":"/reference/mirt.specify.partable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specify or modify a Parameter Table in mirt — mirt.specify.partable","text":"mirt.partable Parameter table mirt package parlist List parameters used specification parameter table. See Examples. verbose optional logical indicating whether warnings printed.","code":""},{"path":"/reference/mirt.specify.partable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specify or modify a Parameter Table in mirt — mirt.specify.partable","text":"modified parameter table","code":""},{"path":"/reference/mirt.specify.partable.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Specify or modify a Parameter Table in mirt — mirt.specify.partable","text":"Alexander Robitzsch, Phil Chalmers","code":""},{"path":"/reference/mirt.specify.partable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Specify or modify a Parameter Table in mirt — mirt.specify.partable","text":"","code":"############################################################################# # EXAMPLE 1: Modifying a parameter table for single group #############################################################################  library(mirt) data(LSAT7,package=\"mirt\") data <- mirt::expand.table(LSAT7)  mirt.partable <- mirt::mirt(data, 1, pars=\"values\") colnames(mirt.partable) ## > colnames(mirt.partable) [1] 'group' 'item' 'class' 'name' 'parnum' 'value' ##   'lbound' 'ubound' 'est' 'prior.type' 'prior_1' 'prior_2'  # specify some values of item parameters value <- data.frame(d=c(0.7, -1, NA), a1=c(1, 1.2, 1.3), g=c(NA, 0.25, 0.25)) rownames(value) <- c(\"Item.1\", \"Item.4\", \"Item.3\")  # fix some item paramters est1 <- data.frame(d=c(TRUE, NA), a1=c(FALSE, TRUE)) rownames(est1) <- c(\"Item.4\", \"Item.3\")  # estimate all guessing parameters est2 <- data.frame(g=rep(TRUE, 5)) rownames(est2) <- colnames(data)  # prior distributions prior.type <- data.frame(g=rep(\"norm\", 4)) rownames(prior.type) <- c(\"Item.1\", \"Item.2\", \"Item.4\", \"Item.5\") prior_1 <- data.frame(g=rep(-1.38, 4)) rownames(prior_1) <- c(\"Item.1\", \"Item.2\", \"Item.4\", \"Item.5\") prior_2 <- data.frame(g=rep(0.5, 4)) rownames(prior_2) <- c(\"Item.1\", \"Item.2\", \"Item.4\", \"Item.5\")  # misspecify some entries rownames(prior_2)[c(3,2)] <- c(\"A\", \"B\") rownames(est1)[2] <- c(\"B\")  # define complete list with parameter specification parlist <- list(value=value, est=est1, est=est2, prior.type=prior.type,       prior_1=prior_1, prior_2=prior_2)  # modify parameter table mirt.specify.partable(mirt.partable, parlist)"},{"path":"/reference/mirt.wrapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","title":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","text":"functions wrapping mirt package.","code":""},{"path":"/reference/mirt.wrapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","text":"","code":"# extract coefficients mirt.wrapper.coef(mirt.obj)  # summary output mirt_summary(object, digits=4, file=NULL, ...)  # extract posterior, likelihood, ... mirt.wrapper.posterior(mirt.obj, weights=NULL, group=NULL) # S3 method for SingleGroupClass IRT.likelihood(object, ...) # S3 method for MultipleGroupClass IRT.likelihood(object, ...) # S3 method for SingleGroupClass IRT.posterior(object, ...) # S3 method for MultipleGroupClass IRT.posterior(object, ...) # S3 method for SingleGroupClass IRT.expectedCounts(object, ...) # S3 method for MultipleGroupClass IRT.expectedCounts(object, ...)  # S3 method for extracting item response functions # S3 method for SingleGroupClass IRT.irfprob(object, ...) # S3 method for MultipleGroupClass IRT.irfprob(object, group=1, ...)  # compute factor scores mirt.wrapper.fscores(mirt.obj, weights=NULL)  # convenience function for itemplot mirt.wrapper.itemplot( mirt.obj, ask=TRUE, ...)"},{"path":"/reference/mirt.wrapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","text":"mirt.obj fitted model mirt package object fitted object mirt package class     SingleGroupClass MultipleGroupClass. group Group index IRT.irfprob (applicable object class MultipleGroupClass) digits Number digits decimal used rounding file File name sinking summary output weights Optional vector student weights ask Optional logical indicating whether new plot confirmed. ... arguments passed.","code":""},{"path":"/reference/mirt.wrapper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","text":"function mirt.wrapper.coef collects item parameters data frame. function mirt.wrapper.posterior extracts individual likelihood, individual likelihood expected counts. function yet cover case multiple groups. function mirt.wrapper.fscores computes factor scores EAP, MAP MLE. factor scores computed discrete grid latent traits (contrary computation mirt) specified mirt.obj@Theta. function also work multiple groups. function mirt.wrapper.itemplot displays item plots .","code":""},{"path":"/reference/mirt.wrapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","text":"Function mirt.wrapper.coef -- List entries coef Data frame item parameters GroupPars Data frame list distribution parameters Function mirt.wrapper.posterior -- List entries theta.k Grid theta points pi.k Trait distribution theta.k f.yi.qk Individual likelihood f.qk.yi Individual posterior n.ik Expected counts data Used dataset Function mirt.wrapper.fscores -- List entries person Data frame person parameter estimates (factor scores)     EAP, MAP MLE dimensions. EAP.rel EAP reliabilities","code":""},{"path":[]},{"path":"/reference/mirt.wrapper.html","id":"examples-for-the-mirt-package","dir":"Reference","previous_headings":"","what":"Examples for the mirt Package","title":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","text":"Latent class analysis (data.read, Model 7)  Mixed Rasch model  (data.read, Model 8)  Located unidimensional multidimensional latent class models / Multidimensional latent class IRT models (data.read, Model 12; rasch.mirtlc, Example 4)  Multidimensional IRT model discrete latent traits  (data.read, Model 13)  DINA model (data.read, Model 14; data.dcm, CDM, Model 1m)  Unidimensional IRT model non-normal distribution  (data.read, Model 15)  Grade membership model  (gom.em, Example 2)  Rasch copula model (rasch.copula2, Example 5)  Additive GDINA model (data.dcm, CDM, Model 6m)  Longitudinal Rasch model (data.long, Model 3)  Normally distributed residuals (data.big5, Example 1, Model 5)  Nedelsky model (nedelsky.irf, Examples 1, 2)  Beta item response model (brm.irf, Example 1)","code":""},{"path":"/reference/mirt.wrapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Some Functions for Wrapping with the mirt Package — mirt.wrapper","text":"","code":"if (FALSE) { # A development version can be installed from GitHub if (FALSE){ # default is set to FALSE, use the installed version    library(devtools)    devtools::install_github(\"philchalmers/mirt\")           } # now, load mirt library(mirt)  ############################################################################# # EXAMPLE 1: Extracting item parameters and posterior LSAT data #############################################################################  data(LSAT7, package=\"mirt\") data <- mirt::expand.table(LSAT7)  #*** Model 1: 3PL model for item 5 only, other items 2PL mod1 <- mirt::mirt(data, 1, itemtype=c(\"2PL\",\"2PL\",\"2PL\",\"2PL\",\"3PL\"), verbose=TRUE) print(mod1) summary(mod1) # extracting coefficients coef(mod1) mirt.wrapper.coef(mod1)$coef # summary output mirt_summary(mod1) # extract parameter values in mirt mirt::mod2values(mod1) # extract posterior post1 <- sirt::mirt.wrapper.posterior(mod1) # extract item response functions probs1 <- IRT.irfprob(mod1) str(probs1) # extract individual likelihood likemod1 <- IRT.likelihood(mod1) str(likemod1) # extract individual posterior postmod1 <- IRT.posterior(mod1) str(postmod1)  #*** Model 2: Confirmatory model with two factors cmodel <- mirt::mirt.model(\"         F1=1,4,5         F2=2,3         \") mod2 <- mirt::mirt(data, cmodel, verbose=TRUE) print(mod2) summary(mod2) # extract coefficients coef(mod2) mirt.wrapper.coef(mod2)$coef # extract posterior post2 <- sirt::mirt.wrapper.posterior(mod2)  ############################################################################# # EXAMPLE 2: Extracting item parameters and posterior for differering #            number of response catagories | Dataset Science #############################################################################  data(Science,package=\"mirt\") library(psych) psych::describe(Science)  # modify dataset dat <- Science dat[ dat[,1] > 3,1] <- 3 psych::describe(dat)  # estimate generalized partial credit model mod1 <- mirt::mirt(dat, 1, itemtype=\"gpcm\") print(mod1) # extract coefficients coef(mod1) mirt.wrapper.coef(mod1)$coef # extract posterior post1 <- sirt::mirt.wrapper.posterior(mod1)  ############################################################################# # EXAMPLE 3: Multiple group model; simulated dataset from mirt package #############################################################################  #*** simulate data (copy from the multipleGroup manual site in mirt package) set.seed(1234) a <- matrix(c(abs( stats::rnorm(5,1,.3)), rep(0,15),abs( stats::rnorm(5,1,.3)),           rep(0,15),abs( stats::rnorm(5,1,.3))), 15, 3) d <- matrix( stats::rnorm(15,0,.7),ncol=1) mu <- c(-.4, -.7, .1) sigma <- matrix(c(1.21,.297,1.232,.297,.81,.252,1.232,.252,1.96),3,3) itemtype <- rep(\"dich\", nrow(a)) N <- 1000 dataset1 <- mirt::simdata(a, d, N, itemtype) dataset2 <- mirt::simdata(a, d, N, itemtype, mu=mu, sigma=sigma) dat <- rbind(dataset1, dataset2) group <- c(rep(\"D1\", N), rep(\"D2\", N))  #group models model <- mirt::mirt.model(\"    F1=1-5    F2=6-10    F3=11-15       \")  # separate analysis mod_configural <- mirt::multipleGroup(dat, model, group=group, verbose=TRUE) mirt.wrapper.coef(mod_configural)  # equal slopes (metric invariance) mod_metric <- mirt::multipleGroup(dat, model, group=group, invariance=c(\"slopes\"),                 verbose=TRUE) mirt.wrapper.coef(mod_metric)  # equal slopes and intercepts (scalar invariance) mod_scalar <- mirt::multipleGroup(dat, model, group=group,           invariance=c(\"slopes\",\"intercepts\",\"free_means\",\"free_varcov\"), verbose=TRUE) mirt.wrapper.coef(mod_scalar)  # full constraint mod_fullconstrain <- mirt::multipleGroup(dat, model, group=group,              invariance=c(\"slopes\", \"intercepts\", \"free_means\", \"free_var\"), verbose=TRUE ) mirt.wrapper.coef(mod_fullconstrain)  ############################################################################# # EXAMPLE 4: Nonlinear item response model #############################################################################  data(data.read) dat <- data.read # specify mirt model with some interactions mirtmodel <- mirt.model(\"    A=1-4    B=5-8    C=9-12    (A*B)=4,8    (C*C)=9    (A*B*C)=12    \" ) # estimate model res <- mirt::mirt( dat, mirtmodel, verbose=TRUE, technical=list(NCYCLES=3) ) # look at estimated parameters mirt.wrapper.coef(res) coef(res) mirt::mod2values(res) # model specification res@model  ############################################################################# # EXAMPLE 5: Extracting factor scores #############################################################################  data(data.read) dat <- data.read # define lavaan model and convert syntax to mirt lavmodel <- \"     A=~ a*A1+a*A2+1.3*A3+A4       # set loading of A3 to 1.3     B=~ B1+1*B2+b3*B3+B4     C=~ c*C1+C2+c*C3+C4     A1 | da*t1     A3 | da*t1     C4 | dg*t1     B1 | 0*t1     B3 | -1.4*t1                  # fix item threshold of B3 to -1.4     A ~~ B                        # estimate covariance between A and B     A ~~ .6 * C                   # fix covariance to .6     B ~~ B                        # estimate variance of B     A ~ .5*1                      # set mean of A to .5     B ~ 1                         # estimate mean of B     \" res <- sirt::lavaan2mirt( dat, lavmodel, verbose=TRUE, technical=list(NCYCLES=3) ) # estimated coefficients mirt.wrapper.coef(res$mirt) # extract factor scores fres <- sirt::mirt.wrapper.fscores(res$mirt) # look at factor scores head( round(fres$person,2))   ##     case    M EAP.Var1 SE.EAP.Var1 EAP.Var2 SE.EAP.Var2 EAP.Var3 SE.EAP.Var3 MLE.Var1   ##   1    1 0.92     1.26        0.67     1.61        0.60     0.05        0.69     2.65   ##   2    2 0.58     0.06        0.59     1.14        0.55    -0.80        0.56     0.00   ##   3    3 0.83     0.86        0.66     1.15        0.55     0.48        0.74     0.53   ##   4    4 1.00     1.52        0.67     1.57        0.60     0.73        0.76     2.65   ##   5    5 0.50    -0.13        0.58     0.85        0.48    -0.82        0.55    -0.53   ##   6    6 0.75     0.41        0.63     1.09        0.54     0.27        0.71     0.00   ##     MLE.Var2 MLE.Var3 MAP.Var1 MAP.Var2 MAP.Var3   ##   1     2.65    -0.53     1.06     1.59     0.00   ##   2     1.06    -1.06     0.00     1.06    -1.06   ##   3     1.06     2.65     1.06     1.06     0.53   ##   4     2.65     2.65     1.59     1.59     0.53   ##   5     0.53    -1.06    -0.53     0.53    -1.06   ##   6     1.06     2.65     0.53     1.06     0.00 # EAP reliabilities round(fres$EAP.rel,3)   ##    Var1  Var2  Var3   ##   0.574 0.452 0.541 }"},{"path":"/reference/mle.pcm.group.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","title":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","text":"function estimates person group parameters partial credit model (see Details).","code":""},{"path":"/reference/mle.pcm.group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","text":"","code":"mle.pcm.group(dat, b, a=rep(1, ncol(dat)), group=NULL,     pid=NULL, adj_eps=0.3, conv=1e-04, maxiter=30)"},{"path":"/reference/mle.pcm.group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","text":"dat numeric \\(N \\times \\) matrix b Matrix item thresholds Vector item slopes group Vector group identifiers pid Vector person identifiers adj_eps Numeric value used \\(\\varepsilon\\) adjustment likelihood. value zero (small \\(\\varepsilon>0\\)) corresponds usual maximum likelihood estimate. conv Convergence criterion maxiter Maximum number iterations","code":""},{"path":"/reference/mle.pcm.group.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","text":"assumed generalized partial credit model holds. case one estimates person parameter \\(\\theta_p\\), log-likelihood maximized following estimating equation results: (see Penfield & Bergeron, 2005): $$ 0=( \\log L )'=\\sum_i a_i \\cdot [ \\tilde{x}_{pi} -     E(X_{pi} | \\theta_p ) ] $$ \\(E(X_{pi} | \\theta_p )\\) denotes expected item response conditionally \\(\\theta_p\\). method \\(\\varepsilon\\)-adjustment (Bertoli-Barsotti & Punzo, 2012; Bertoli-Barsotti, Lando & Punzo, 2014), observed item responses \\(x_{pi}\\) transformed perfect scores arise bias reduced. \\(S_p\\) sum score person \\(p\\) \\(M_p\\) maximum score person, transformed sum scores \\(\\tilde{S}_p\\) $$ \\tilde{S}_p=\\varepsilon + \\frac{M_p - 2 \\varepsilon}{M_p} S_p$$ However, adjustment directly conducted item responses also handle case generalized partial credit model item slope parameters different 1. case one estimates group parameter \\(\\theta_g\\), following estimating equation used: $$ 0=(\\log L )'=\\sum_p \\sum_i a_i \\cdot [ \\tilde{x}_{pgi} -     E(X_{pgi} | \\theta_g ) ] $$ persons \\(p\\) nested within group \\(g\\). \\(\\varepsilon\\)-adjustment performed group level, individual level.","code":""},{"path":"/reference/mle.pcm.group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","text":"list following entries: person Data frame person group parameters data_adjeps Modified dataset according   \\(\\varepsilon\\) adjustment.","code":""},{"path":"/reference/mle.pcm.group.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","text":"Bertoli-Barsotti, L., & Punzo, . (2012). Comparison two bias reduction techniques Rasch model. Electronic Journal Applied Statistical Analysis, 5, 360-366. Bertoli-Barsotti, L., Lando, T., & Punzo, . (2014). Estimating Rasch Model via fuzzy empirical probability functions. D. Vicari, . Okada, G. Ragozini &  C. Weihs (Eds.). Analysis Modeling Complex Data Behavioral Social Sciences, Springer. Penfield, R. D., & Bergeron, J. M. (2005). Applying weighted maximum likelihood latent trait estimator generalized partial credit model. Applied Psychological Measurement, 29, 218-233.","code":""},{"path":"/reference/mle.pcm.group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum Likelihood Estimation of Person or Group Parameters\r\nin the Generalized Partial Credit Model — mle.pcm.group","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Estimation of a group parameter for only one item per group #############################################################################  data(data.si01) dat <- data.si01 # item parameter estimation (partial credit model) in TAM library(TAM) mod <- TAM::tam.mml( dat[,2:3], irtmodel=\"PCM\") # extract item difficulties b <- matrix( mod$xsi$xsi, nrow=2, byrow=TRUE ) # groupwise estimation res1 <- sirt::mle.pcm.group( dat[,2:3], b=b, group=dat$idgroup ) # individual estimation res2 <- sirt::mle.pcm.group( dat[,2:3], b=b  )  ############################################################################# # EXAMPLE 2: Data Reading data.read #############################################################################  data(data.read) # estimate Rasch model mod <- sirt::rasch.mml2( data.read ) score <- rowSums( data.read ) data.read <- data.read[ order(score), ] score <- score[ order(score) ] # compare different epsilon-adjustments res30 <- sirt::mle.pcm.group( data.read, b=matrix( mod$item$b, 12, 1 ),                adj_eps=.3 )$person res10 <- sirt::mle.pcm.group( data.read, b=matrix( mod$item$b, 12, 1 ),              adj_eps=.1 )$person res05 <- sirt::mle.pcm.group( data.read, b=matrix( mod$item$b, 12, 1 ),               adj_eps=.05 )$person # plot different scorings plot( score, res05$theta, type=\"l\", xlab=\"Raw score\", ylab=expression(theta[epsilon]),          main=\"Scoring with different epsilon-adjustments\") lines( score, res10$theta, col=2, lty=2 ) lines( score, res30$theta, col=4, lty=3 ) }"},{"path":"/reference/modelfit.sirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","title":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","text":"function computes several measures absolute model fit local dependence indices dichotomous item responses based comparing observed expected frequencies item pairs (Chen, de la Torre & Zhang, 2013; see modelfit.cor details).","code":""},{"path":"/reference/modelfit.sirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","text":"","code":"modelfit.sirt(object)  modelfit.cor.poly( data, probs, theta.k, f.qk.yi)  # S3 method for sirt IRT.modelfit(object, mod, ...)"},{"path":"/reference/modelfit.sirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","text":"object object generated rasch.mml2, rasch.mirtlc, rasch.pml3 (rasch.pml2), smirt, R2noharm, noharm.sirt, gom.em, TAM::tam.mml, TAM::tam.mml.2pl, TAM::tam.fa,   mirt::mirt data Dataset polytomous item responses probs Item response probabilities grid theta.k theta.k Grid theta vector f.qk.yi Individual posterior mod Model name ... arguments passed","code":""},{"path":"/reference/modelfit.sirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","text":"list following entries: modelfit Model fit statistics: MADcor: mean absolute deviations observed expected correlations         (DiBello et al., 2007) SRMSR: standardized mean square root squared residuals         (Maydeu-Olivares, 2013; Maydeu-Olivares & Joe, 2014) MX2: Mean \\(\\chi^2\\) statistics item pairs             (Chen & Thissen, 1997) MADRESIDCOV: Mean absolute deviations residual             covariances (McDonald & Mok, 1995) MADQ3: Mean absolute values \\(Q_3\\) statistic (Yen, 1984) MADaQ3: Mean absolute values centered \\(Q_3\\) statistic itempairs Fit every item pair","code":""},{"path":"/reference/modelfit.sirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","text":"Chen, W., & Thissen, D. (1997). Local dependence indexes item pairs  using item response theory. Journal Educational Behavioral Statistics,  22, 265-289. DiBello, L. V., Roussos, L. ., & Stout, W. F. (2007) Review   cognitively diagnostic assessment summary psychometric models.   C. R. Rao S. Sinharay (Eds.), Handbook Statistics,   Vol. 26 (pp. 979--1030). Amsterdam: Elsevier. Maydeu-Olivares, . (2013). Goodness--fit assessment item response theory models (discussion). Measurement: Interdisciplinary Research Perspectives, 11, 71-137. Maydeu-Olivares, ., & Joe, H. (2014). Assessing approximate fit categorical data analysis. Multivariate Behavioral Research, 49, 305-328. McDonald, R. P., & Mok, M. M.-C. (1995). Goodness fit item response models.   Multivariate Behavioral Research, 30, 23-40. Yen, W. M. (1984). Effects local item dependence fit equating performance three-parameter logistic model. Applied Psychological Measurement, 8, 125-145.","code":""},{"path":"/reference/modelfit.sirt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","text":"function modelfit.cor.poly just wrapper TAM::tam.modelfit TAM package.","code":""},{"path":[]},{"path":"/reference/modelfit.sirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assessing Model Fit and Local Dependence by Comparing Observed and Expected\r\nItem Pair Correlations — modelfit.sirt","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Reading data ############################################################################# data(data.read) dat <- data.read I <- ncol(dat)  #*** Model 1: Rasch model mod1 <- sirt::rasch.mml2(dat) fmod1 <- sirt::modelfit.sirt( mod1 ) summary(fmod1)  #*** Model 1b: Rasch model in TAM package library(TAM) mod1b <- TAM::tam.mml(dat) fmod1b <- sirt::modelfit.sirt( mod1b ) summary(fmod1b)  #*** Model 2: Rasch model with smoothed distribution mod2 <- sirt::rasch.mml2( dat, distribution.trait=\"smooth3\" ) fmod2 <- sirt::modelfit.sirt( mod2 ) summary(fmod2 )  #*** Model 3: 2PL model mod3 <- sirt::rasch.mml2( dat, distribution.trait=\"normal\", est.a=1:I ) fmod3 <- sirt::modelfit.sirt( mod3 ) summary(fmod3 )  #*** Model 3: 2PL model in TAM package mod3b <- TAM::tam.mml.2pl( dat ) fmod3b <- sirt::modelfit.sirt(mod3b) summary(fmod3b) # model fit in TAM package tmod3b <- TAM::tam.modelfit(mod3b) summary(tmod3b) # model fit in mirt package library(mirt) mmod3b <- sirt::tam2mirt(mod3b)   # convert to mirt object mirt::M2(mmod3b$mirt)         # global fit statistic mirt::residuals( mmod3b$mirt, type=\"LD\")  # local dependence statistics  #*** Model 4: 3PL model with equal guessing parameter mod4 <- TAM::rasch.mml2( dat, distribution.trait=\"smooth3\", est.a=1:I, est.c=rep(1,I) ) fmod4 <- sirt::modelfit.sirt( mod4 ) summary(fmod4 )  #*** Model 5: Latent class model with 2 classes mod5 <- sirt::rasch.mirtlc( dat, Nclasses=2 ) fmod5 <- sirt::modelfit.sirt( mod5 ) summary(fmod5 )  #*** Model 6: Rasch latent class model with 3 classes mod6 <- sirt::rasch.mirtlc( dat, Nclasses=3, modeltype=\"MLC1\", mmliter=100) fmod6 <- sirt::modelfit.sirt( mod6 ) summary(fmod6 )  #*** Model 7: PML estimation mod7 <- sirt::rasch.pml3( dat ) fmod7 <- sirt::modelfit.sirt( mod7 ) summary(fmod7 )  #*** Model 8: PML estimation #      Modelling error correlations: #          joint residual correlations for each item cluster error.corr <- diag(1,ncol(dat)) itemcluster <- rep( 1:4,each=3 ) for ( ii in 1:3){     ind.ii <- which( itemcluster==ii )     error.corr[ ind.ii, ind.ii ] <- ii         } mod8 <- sirt::rasch.pml3( dat, error.corr=error.corr ) fmod8 <- sirt::modelfit.sirt( mod8 ) summary(fmod8 )  #*** Model 9: 1PL in smirt Qmatrix <- matrix( 1, nrow=I, ncol=1 ) mod9 <- sirt::smirt( dat, Qmatrix=Qmatrix ) fmod9 <- sirt::modelfit.sirt( mod9 ) summary(fmod9 )  #*** Model 10: 3-dimensional Rasch model in NOHARM noharm.path <- \"c:/NOHARM\" Q <- matrix( 0, nrow=12, ncol=3 ) Q[ cbind(1:12, rep(1:3,each=4) ) ] <- 1 rownames(Q) <- colnames(dat) colnames(Q) <- c(\"A\",\"B\",\"C\") # covariance matrix P.pattern <- matrix( 1, ncol=3, nrow=3 ) P.init <- 0.8+0*P.pattern diag(P.init) <- 1 # loading matrix F.pattern <- 0*Q F.init <- Q # estimate model mod10 <- sirt::R2noharm( dat=dat, model.type=\"CFA\", F.pattern=F.pattern,             F.init=F.init, P.pattern=P.pattern, P.init=P.init,             writename=\"ex4e\", noharm.path=noharm.path, dec=\",\" ) fmod10 <- sirt::modelfit.sirt( mod10 ) summary(fmod10)  #*** Model 11: Rasch model in mirt package library(mirt) mod11 <- mirt::mirt(dat, 1, itemtype=\"Rasch\",verbose=TRUE) fmod11 <- sirt::modelfit.sirt( mod11 ) summary(fmod11) # model fit in mirt package mirt::M2(mod11) mirt::residuals(mod11) }"},{"path":"/reference/monoreg.rowwise.html","id":null,"dir":"Reference","previous_headings":"","what":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","title":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","text":"Monotone (isotone) regression rows (monoreg.rowwise) columns (monoreg.colwise) matrix.","code":""},{"path":"/reference/monoreg.rowwise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","text":"","code":"monoreg.rowwise(yM, wM)  monoreg.colwise(yM, wM)"},{"path":"/reference/monoreg.rowwise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","text":"yM Matrix dependent variable regression. Values assumed sorted. wM Matrix weights every entry yM matrix.","code":""},{"path":"/reference/monoreg.rowwise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","text":"Matrix fitted values","code":""},{"path":"/reference/monoreg.rowwise.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","text":"Alexander Robitzsch monoreg function fdrtool package simply extended handle matrix input.","code":""},{"path":"/reference/monoreg.rowwise.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","text":"function used fitting ISOP model (see isop.dich).","code":""},{"path":[]},{"path":"/reference/monoreg.rowwise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monotone Regression for Rows or Columns in a Matrix — monoreg.rowwise","text":"","code":"y <- c(22.5, 23.33, 20.83, 24.25 ) w <- c( 3,3,3,2) # define matrix input yM <- matrix( 0, nrow=2, ncol=4 ) wM <- yM yM[1,] <- yM[2,] <- y wM[1,] <- w wM[2,] <- c(1,3,4, 3 )  # fit rowwise monotone regression monoreg.rowwise( yM, wM ) # compare results with monoreg function from fdrtool package if (FALSE) { miceadds::library_install(\"fdrtool\") fdrtool::monoreg(x=yM[1,], w=wM[1,])$yf fdrtool::monoreg(x=yM[2,], w=wM[2,])$yf }"},{"path":"/reference/nedelsky.sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions for the Nedelsky Model — nedelsky-methods","title":"Functions for the Nedelsky Model — nedelsky-methods","text":"Functions simulating estimating Nedelsky model (Bechger et al., 2003, 2005). nedelsky.sim can used simulating model, nedelsky.irf computes item response function can used example estimating Nedelsky model mirt package using xxirt function sirt package.","code":""},{"path":"/reference/nedelsky.sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functions for the Nedelsky Model — nedelsky-methods","text":"","code":"# simulating the Nedelsky model nedelsky.sim(theta, b, a=NULL, tau=NULL)  # creating latent responses of the Nedelsky model nedelsky.latresp(K)  # computing the item response function of the Nedelsky model nedelsky.irf(Theta, K, b, a, tau, combis, thdim=1)"},{"path":"/reference/nedelsky.sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Functions for the Nedelsky Model — nedelsky-methods","text":"theta Unidimensional ability (theta) b Matrix category difficulties Vector item discriminations tau Category attractivity parameters \\(\\tau\\) (see Bechger et al., 2005) K (Maximum) Number distractors used multiple choice items Theta Theta vector. Note Nedelsky model can specified   models item dimensionality (defined thdim). combis Latent response classes produced nedelsky.latresp. thdim Theta dimension item loads","code":""},{"path":"/reference/nedelsky.sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Functions for the Nedelsky Model — nedelsky-methods","text":"Assume item \\(\\) exists \\(K+1\\) categories \\(0,1,...,K\\). category 0 denotes correct alternative. Nedelsky model assumes respondent eliminates distractors thought incorrect guesses solution remaining alternatives. means, item \\(\\), \\(K\\) latent variables \\(S_{ik}\\) defined indicate whether alternative \\(k\\) correctly identified distractor. definition, correct alternative never judged wrong respondent. Formally, Nedelsky model assumes 2PL model eliminating distractors $$P(S_{ik}=1 | \\theta )=invlogit[ a_i ( \\theta - b_{ik} ) ] $$ \\(\\theta\\) person ability \\(b_{ik}\\) distractor difficulties. guessing process Nedelsky model defined $$P(X_i=j | \\theta, S_{i1}, ..., S_{iK} )= \\frac{ ( 1- S_{ij} ) \\tau_{ij} }{ \\sum_{k=0}^K [ ( 1- S_{ik} ) \\tau_{ik} ] }$$ \\(\\tau_{ij}\\) attractivity parameters alternative \\(j\\). definition \\(\\tau_{i0}\\) set 1. default, attractivity parameters set 1.","code":""},{"path":"/reference/nedelsky.sim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Functions for the Nedelsky Model — nedelsky-methods","text":"Bechger, T. M., Maris, G., Verstralen, H. H. F. M., & Verhelst, N. D. (2003). Nedelsky model multiple-choice items. CITO Research Report, 2003-5. Bechger, T. M., Maris, G., Verstralen, H. H. F. M., & Verhelst, N. D. (2005). Nedelsky model multiple-choice items. L. van der Ark, M. Croon, & Sijtsma, K. (Eds.). New developments categorical data analysis social behavioral sciences, pp. 187-206. Mahwah, Lawrence Erlbaum.","code":""},{"path":"/reference/nedelsky.sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Functions for the Nedelsky Model — nedelsky-methods","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Simulated data according to the Nedelsky model #############################################################################  #*** simulate data set.seed(123) I <- 20          # number of items b <- matrix(NA,I,ncol=3) b[,1] <- -0.5 + stats::runif( I, -.75, .75 ) b[,2] <- -1.5 + stats::runif( I, -.75, .75 ) b[,3] <- -2.5 + stats::runif( I, -.75, .75 ) K <- 3           # number of distractors N <- 2000        # number of persons # apply simulation function dat <- sirt::nedelsky.sim( theta=stats::rnorm(N,sd=1.2), b=b )  #*** latent response patterns K <- 3 combis <- sirt::nedelsky.latresp(K=3)  #*** defining the Nedelsky item response function for estimation in mirt par <- c( 3, rep(-1,K), 1, rep(1,K+1),1) names(par) <- c(\"K\", paste0(\"b\",1:K), \"a\", paste0(\"tau\", 0:K),\"thdim\") est <- c( FALSE, rep(TRUE,K), rep(FALSE, K+1 + 2 ) ) names(est) <- names(par) nedelsky.icc <- function( par, Theta, ncat ){      K <- par[1]      b <- par[ 1:K + 1]      a <- par[ K+2]      tau <- par[1:(K+1) + (K+2) ]      thdim <- par[ K+2+K+1 +1 ]      probs <- sirt::nedelsky.irf( Theta, K=K, b=b, a=a, tau=tau, combis,                     thdim=thdim  )$probs      return(probs) } name <- \"nedelsky\" # create item response function nedelsky.itemfct <- mirt::createItem(name, par=par, est=est, P=nedelsky.icc)  #*** define model in mirt mirtmodel <- mirt::mirt.model(\"            F1=1-20            COV=F1*F1            # define some prior distributions            PRIOR=(1-20,b1,norm,-1,2),(1-20,b2,norm,-1,2),                    (1-20,b3,norm,-1,2)         \" )  itemtype <- rep(\"nedelsky\", I ) customItems <- list(\"nedelsky\"=nedelsky.itemfct) # define parameters to be estimated mod1.pars <- mirt::mirt(dat, mirtmodel, itemtype=itemtype,                    customItems=customItems, pars=\"values\") # estimate model mod1 <- mirt::mirt(dat,mirtmodel, itemtype=itemtype, customItems=customItems,                pars=mod1.pars, verbose=TRUE  ) # model summaries print(mod1) summary(mod1) mirt.wrapper.coef( mod1 )$coef mirt.wrapper.itemplot(mod1,ask=TRUE)  #****************************************************** # fit Nedelsky model with xxirt function in sirt  # define item class for xxirt item_nedelsky <- sirt::xxirt_createDiscItem( name=\"nedelsky\", par=par,                 est=est, P=nedelsky.icc,                 prior=c( b1=\"dnorm\", b2=\"dnorm\", b3=\"dnorm\" ),                 prior_par1=c( b1=-1, b2=-1, b3=-1),                 prior_par2=c(b1=2, b2=2, b3=2) ) customItems <- list( item_nedelsky )  #---- definition theta distribution #** theta grid Theta <- matrix( seq(-6,6,length=21), ncol=1 ) #** theta distribution P_Theta1 <- function( par, Theta, G){     mu <- par[1]     sigma <- max( par[2], .01 )     TP <- nrow(Theta)     pi_Theta <- matrix( 0, nrow=TP, ncol=G)     pi1 <- dnorm( Theta[,1], mean=mu, sd=sigma )     pi1 <- pi1 / sum(pi1)     pi_Theta[,1] <- pi1     return(pi_Theta) } #** create distribution class par_Theta <- c( \"mu\"=0, \"sigma\"=1 ) customTheta <- sirt::xxirt_createThetaDistribution( par=par_Theta, est=c(FALSE,TRUE),                    P=P_Theta1 )  #-- create parameter table itemtype <- rep( \"nedelsky\", I ) partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype, customItems=customItems)  # estimate model mod2 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable, customItems=customItems,                     customTheta=customTheta) summary(mod2) # compare sirt::xxirt and mirt::mirt logLik(mod2) mod1@Fit$logLik  ############################################################################# # EXAMPLE 2: Multiple choice dataset data.si06 #############################################################################  data(data.si06) dat <- data.si06  #*** create latent responses combis <- sirt::nedelsky.latresp(K) I <- ncol(dat) #*** define item response function K <- 3 par <- c( 3, rep(-1,K), 1, rep(1,K+1),1) names(par) <- c(\"K\", paste0(\"b\",1:K), \"a\", paste0(\"tau\", 0:K),\"thdim\") est <- c( FALSE, rep(TRUE,K), rep(FALSE, K+1 + 2 ) ) names(est) <- names(par) nedelsky.icc <- function( par, Theta, ncat ){      K <- par[1]      b <- par[ 1:K + 1]      a <- par[ K+2]      tau <- par[1:(K+1) + (K+2) ]      thdim <- par[ K+2+K+1 +1 ]      probs <- sirt::nedelsky.irf( Theta, K=K, b=b, a=a, tau=tau, combis,                     thdim=thdim  )$probs      return(probs) } name <- \"nedelsky\" # create item response function nedelsky.itemfct <- mirt::createItem(name, par=par, est=est, P=nedelsky.icc)  #*** define model in mirt mirtmodel <- mirt::mirt.model(\"            F1=1-14            COV=F1*F1            PRIOR=(1-14,b1,norm,-1,2),(1-14,b2,norm,-1,2),                    (1-14,b3,norm,-1,2)         \" )  itemtype <- rep(\"nedelsky\", I ) customItems <- list(\"nedelsky\"=nedelsky.itemfct) # define parameters to be estimated mod1.pars <- mirt::mirt(dat, mirtmodel, itemtype=itemtype,                    customItems=customItems, pars=\"values\")  #*** estimate model mod1 <- mirt::mirt(dat,mirtmodel, itemtype=itemtype, customItems=customItems,                pars=mod1.pars, verbose=TRUE ) #*** summaries print(mod1) summary(mod1) mirt.wrapper.coef( mod1 )$coef mirt.wrapper.itemplot(mod1,ask=TRUE) }"},{"path":"/reference/noharm.sirt.html","id":null,"dir":"Reference","previous_headings":"","what":"NOHARM Model in R — noharm.sirt","title":"NOHARM Model in R — noharm.sirt","text":"function R implementation normal ogive harmonic analysis robust method (NOHARM model; McDonald, 1997). Exploratory confirmatory multidimensional item response models dichotomous data using probit link function can estimated. Lower asymptotes (guessing parameters) upper asymptotes (one minus slipping parameters) can provided fixed values.","code":""},{"path":"/reference/noharm.sirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NOHARM Model in R — noharm.sirt","text":"","code":"noharm.sirt(dat, pm=NULL, N=NULL, weights=NULL, Fval=NULL, Fpatt=NULL, Pval=NULL,    Ppatt=NULL, Psival=NULL, Psipatt=NULL, dimensions=NULL, lower=0, upper=1, wgtm=NULL,    pos.loading=FALSE, pos.variance=FALSE, pos.residcorr=FALSE, maxiter=1000, conv=1e-6,    optimizer=\"nlminb\", par_lower=NULL, reliability=FALSE, ...)  # S3 method for noharm.sirt summary(object, file=NULL, ...)"},{"path":"/reference/noharm.sirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NOHARM Model in R — noharm.sirt","text":"dat Matrix dichotomous item responses. matrix may contain missing data (indicated NA) missingness assumed missing completely random (MCAR). Alternatively, product-moment matrix pm can used input. pm Optional product-moment matrix N Sample size pm provided weights Optional vector student weights. Fval Initial fixed values loading matrix \\(\\bold{F}\\). Fpatt Pattern matrix loading matrix \\(\\bold{F}\\). elements estimated, entry 1 must included pattern matrix. Parameters estimated equality constraints must indicated integers values largers 1. Pval Initial fixed values covariance matrix \\(\\bold{P}\\). Ppatt Pattern matrix covariance matrix \\(\\bold{P}\\). Psival Initial fixed values matrix residual correlations \\(\\bold{\\Psi}\\). Psipatt Pattern matrix matrix residual correlations \\(\\bold{\\Psi}\\). dimensions Number dimensions exploratory factor analysis estimated. lower Fixed vector (numeric) lower asymptotes \\(c_i\\). upper Fixed vector (numeric) upper asymptotes \\(d_i\\). wgtm Matrix positive entries indicates positive entry item pairs used estimation. pos.loading optional logical indicating whether entries loading matrix \\(\\bold{F}\\) positive pos.variance optional logical indicating whether variances (.e.     diagonal entries \\(\\bold{P}\\)) positive pos.residcorr optional logical indicating whether     entries matrix residual correlations \\(\\bold{\\Psi}\\)     positive par_lower Optional vector lower parameter bounds maxiter Maximum number iterations conv Convergence criterion parameters optimizer Optimization function used. Can \"nlminb\" stats::nlminb \"optim\" stats::optim. reliability Logical indicating whether reliability computed. ... arguments passed. object Object class noharm.sirt file String indicating file name summary.","code":""},{"path":"/reference/noharm.sirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"NOHARM Model in R — noharm.sirt","text":"NOHARM item response model follows response equation $$P( X_{pi}=1 | \\bold{\\theta}_p )=c_i + ( d_i - c_i ) \\Phi( f_{i0} + f_{i1} \\theta_{p1} + ... + f_{iD} \\theta_{pD} ) $$ item responses \\(X_{pi}\\) person \\(p\\) item \\(\\), \\(\\bold{F}=(f_{id})\\) loading matrix \\(\\bold{P}\\) covariance matrix \\(\\bold{\\theta}_p\\). lower asymptotes \\(c_i\\) upper asymptotes \\(d_i\\) must provided fixed values. response equation can equivalently written introducing latent continuous item response \\(X_{pi}^\\ast\\) $$ X_{pi}^\\ast=f_{i0} + f_{i1} \\theta_{p1} + ... +  f_{iD} \\theta_{pD} + e_{pi} $$ standard normally distributed residual \\(e_{pi}\\). residuals correlation matrix \\(\\bold{\\Psi}\\) ones diagonal. R implementation NOHARM model, correlations residuals allowed. estimation relies Hermite series approximation normal ogive item response functions. detail, series expansion $$\\Phi(x)=b_0 + b_1 H_1(x) + b_2 H_2(x) + b_3 H_3(x)$$ used (McDonald, 1982a). enables express cross products \\(p_{ij}=P(X_i=1, X_j=1)\\) function unknown model parameters $$\\hat{p}_{ij}=b_{0i} b_{0j} + \\sum_{m=1}^3 b_{mi} b_{mj} \\left( \\frac{\\bold{f}_i \\bold{P} \\bold{f}_j }{\\sqrt{ (1+\\bold{f}_i \\bold{P} \\bold{f}_i) (1+\\bold{f}_j \\bold{P} \\bold{f}_j)}} \\right) ^m $$ \\(b_{0i}=p_{}=P(X_i=1)=c_i + (d_i - c_i) \\Phi(\\tau_i)\\), \\(b_{1i}=(d_i-c_i)\\phi(\\tau_i)\\), \\(b_{2i}=(d_i-c_i)\\tau_i \\phi(\\tau_i) / \\sqrt{2}\\), \\(b_{3i}=(d_i-c_i)(\\tau_i^2 - 1)\\phi(\\tau_i) / \\sqrt{6}\\). least squares criterion \\(\\sum_{<j} ( p_{ij} - \\hat{p}_{ij})^2\\) used estimating unknown model parameters (McDonald, 1982a, 1982b, 1997). derivations standard errors fit statistics see Maydeu-Olivares (2001) Swaminathan Rogers (2016). statistical properties NOHARM approach see Knol Berger (1991), Finch (2011) Svetina Levy (2016).","code":""},{"path":"/reference/noharm.sirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NOHARM Model in R — noharm.sirt","text":"list. important entries tanaka Tanaka fit statistic rmsr RMSR fit statistic N.itempair Sample size per item pair pm Product moment matrix wgtm Matrix weights item pair sumwgtm Sum lower triangle matrix wgtm lower Lower asymptotes upper Upper asymptotes residuals Residual matrix approximation pm matrix final.constants Final constants factor.cor Covariance matrix thresholds Threshold parameters uniquenesses Uniquenesses loadings Matrix standardized factor loadings (delta parametrization) loadings.theta Matrix factor loadings \\(\\bold{F}\\) (theta parametrization) residcorr Matrix residual correlations Nobs Number observations Nitems Number items Fpatt Pattern loading matrix \\(\\bold{F}\\) Ppatt Pattern loading matrix \\(\\bold{P}\\) Psipatt Pattern loading matrix \\(\\bold{\\Psi}\\) dat Used dataset dimensions Number dimensions iter Number iterations Nestpars Number estimated parameters chisquare Statistic \\(\\chi^2\\) df Degrees freedom chisquare_df Ratio \\(\\chi^2 / df\\) rmsea RMSEA statistic p.chisquare Significance \\(\\chi^2\\) statistic omega.rel Reliability sum score according Green Yang (2009)","code":""},{"path":"/reference/noharm.sirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"NOHARM Model in R — noharm.sirt","text":"Finch, H. (2011). Multidimensional item response theory parameter estimation nonsimple structure items. Applied Psychological Measurement, 35(1), 67-82. doi:10.1177/0146621610367787 Fraser, C., & McDonald, R. P. (1988). NOHARM: Least squares item factor analysis. Multivariate Behavioral Research, 23, 267-269. doi:10.1207/s15327906mbr2302_9 Fraser, C., & McDonald, R. P. (2012). NOHARM 4 Manual.  http://noharm.niagararesearch.ca/nh4man/nhman.html. Knol, D. L., & Berger, M. P. (1991). Empirical comparison factor analysis multidimensional item response models. Multivariate Behavioral Research, 26(3), 457-477. doi:10.1207/s15327906mbr2603_5 Maydeu-Olivares, . (2001). Multidimensional item response theory modeling binary data: Large sample properties NOHARM estimates. Journal Educational Behavioral Statistics, 26(1), 51-71. doi:10.3102/10769986026001051 McDonald, R. P. (1982a). Linear versus nonlinear models item response theory. Applied Psychological Measurement, 6(4), 379-396. doi:10.1177/014662168200600402 McDonald, R. P. (1982b). Unidimensional multidimensional models item response theory. .R.T., C..T. conference, Minneapolis, 1982, Proceedings. McDonald, R. P. (1997). Normal-ogive multidimensional model. W. van der Linden & R. K. Hambleton (1997): Handbook modern item response theory (pp. 257-269). New York: Springer. doi:10.1007/978-1-4757-2691-6 Svetina, D., & Levy, R. (2016). Dimensionality compensatory MIRT complex structure exists: Evaluation DETECT NOHARM. Journal Experimental Education, 84(2), 398-420. doi:10.1080/00220973.2015.1048845 Swaminathan, H., & Rogers, H. J. (2016). Normal-ogive multidimensional models. W. J. van der Linden (Ed.). Handbook item response theory. Volume One: Models (pp. 167-187). Boca Raton: CRC Press. doi:10.1201/9781315374512","code":""},{"path":[]},{"path":"/reference/noharm.sirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"NOHARM Model in R — noharm.sirt","text":"","code":"############################################################################# # EXAMPLE 1: Two-dimensional IRT model with 10 items #############################################################################  #**** data simulation set.seed(9776) N <- 3400 # sample size # define difficulties f0 <- c( .5, .25, -.25, -.5, 0, -.5, -.25, .25, .5, 0 ) I <- length(f0) # define loadings f1 <- matrix( 0, I, 2 ) f1[ 1:5,1] <- c(.8,.7,.6,.5, .5) f1[ 6:10,2] <- c(.8,.7,.6,.5, .5 ) # covariance matrix Pval <- matrix( c(1,.5,.5,1), 2, 2 ) # simulate theta library(mvtnorm) theta <- mvtnorm::rmvnorm(N, mean=c(0,0), sigma=Pval ) # simulate item responses dat <- matrix( NA, N, I ) for (ii in 1:I){ # ii <- 1     dat[,ii] <- 1*( stats::pnorm(f0[ii]+theta[,1]*f1[ii,1]+theta[,2]*f1[ii,2])>                      stats::runif(N) )         } colnames(dat) <- paste0(\"I\", 1:I)  #**** Model 1: Two-dimensional CFA with estimated item loadings # define pattern matrices Pval <- .3+0*Pval Ppatt <- 1*(Pval>0) diag(Ppatt) <- 0 diag(Pval) <- 1 Fval <- .7 * ( f1>0) Fpatt <- 1 * ( Fval > 0 ) # estimate model mod1 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt, Fpatt=Fpatt, Fval=Fval, Pval=Pval ) summary(mod1) # EAP ability estimates pmod1 <- sirt::R2noharm.EAP(mod1, theta.k=seq(-4,4,len=10) ) # model fit summary( sirt::modelfit.sirt(mod1) )  if (FALSE) { #*** compare results with NOHARM software noharm.path <- \"c:/NOHARM\"   # specify path for noharm software mod1a <- sirt::R2noharm( dat=dat, model.type=\"CFA\",  F.pattern=Fpatt, F.init=Fval,              P.pattern=Ppatt, P.init=Pval, writename=\"r2noharm_example\",              noharm.path=noharm.path, dec=\",\" ) summary(mod1a)  #**** Model 1c: put some equality constraints Fpatt[ c(1,4),1] <- 3 Fpatt[ cbind( c(3,7), c(1,2)) ] <- 4 mod1c <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt, Fpatt=Fpatt, Fval=Fval, Pval=Pval) summary(mod1c)  #**** Model 2: Two-dimensional CFA with correlated residuals # define pattern matrix for residual correlation Psipatt <- 0*diag(I) Psipatt[1,2] <- 1 Psival <- 0*Psipatt # estimate model mod2 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval,             Psival=Psival, Psipatt=Psipatt ) summary(mod2)  #**** Model 3: Two-dimensional Rasch model # pattern matrices Fval <- matrix(0,10,2) Fval[1:5,1] <- Fval[6:10,2] <- 1 Fpatt <- 0*Fval Ppatt <- Pval <- matrix(1,2,2) Pval[1,2] <- Pval[2,1] <- 0 # estimate model mod3 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval ) summary(mod3) # model fit summary( sirt::modelfit.sirt( mod3 ))  #** compare fit with NOHARM noharm.path <- \"c:/NOHARM\" P.pattern <- Ppatt ; P.init <- Pval F.pattern <- Fpatt ; F.init <- Fval mod3b <- sirt::R2noharm( dat=dat, model.type=\"CFA\",              F.pattern=F.pattern, F.init=F.init, P.pattern=P.pattern,              P.init=P.init, writename=\"example_sim_2dim_rasch\",              noharm.path=noharm.path, dec=\",\" ) summary(mod3b)  ############################################################################# # EXAMPLE 2: data.read #############################################################################  data(data.read) dat <- data.read I <- ncol(dat)  #**** Model 1: Unidimensional Rasch model Fpatt <- matrix( 0, I, 1 ) Fval <- 1 + 0*Fpatt Ppatt <- Pval <- matrix(1,1,1) # estimate model mod1 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval ) summary(mod1) plot(mod1)    # semPaths plot  #**** Model 2: Rasch model in which item pairs within a testlet are excluded wgtm <- matrix( 1, I, I ) wgtm[1:4,1:4] <- wgtm[5:8,5:8] <- wgtm[ 9:12, 9:12] <- 0 # estimation mod2 <- sirt::noharm.sirt(dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval, wgtm=wgtm) summary(mod2)  #**** Model 3: Rasch model with correlated residuals Psipatt <- Psival <- 0*diag(I) Psipatt[1:4,1:4] <- Psipatt[5:8,5:8] <- Psipatt[ 9:12, 9:12] <- 1 diag(Psipatt) <- 0 Psival <- .6*(Psipatt>0) # estimation mod3 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval,             Psival=Psival, Psipatt=Psipatt ) summary(mod3) # allow only positive residual correlations mod3b <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt, Fpatt=Fpatt, Fval=Fval, Pval=Pval,             Psival=Psival, Psipatt=Psipatt, pos.residcorr=TRUE) summary(mod3b) #* constrain residual correlations Psipatt[1:4,1:4] <- 2 Psipatt[5:8,5:8] <- 3 Psipatt[ 9:12, 9:12] <- 4 mod3c <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt, Fpatt=Fpatt, Fval=Fval, Pval=Pval,             Psival=Psival, Psipatt=Psipatt, pos.residcorr=TRUE) summary(mod3c)  #**** Model 4: Rasch testlet model Fval <- Fpatt <- matrix( 0, I, 4 ) Fval[,1] <- Fval[1:4,2] <- Fval[5:8,3] <- Fval[9:12,4 ] <- 1 Ppatt <- Pval <- diag(4) colnames(Ppatt) <- c(\"g\", \"A\", \"B\",\"C\") Pval <- .5*Pval # estimation mod4 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval  ) summary(mod4) # allow only positive variance entries mod4b <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval,                pos.variance=TRUE ) summary(mod4b)  #**** Model 5: Bifactor model Fval <- matrix( 0, I, 4 ) Fval[,1] <- Fval[1:4,2] <- Fval[5:8,3] <- Fval[9:12,4 ] <- .6 Fpatt <- 1 * ( Fval > 0 ) Pval <- diag(4) Ppatt <- 0*Pval colnames(Ppatt) <- c(\"g\", \"A\", \"B\",\"C\") # estimation mod5 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval  ) summary(mod5) # allow only positive loadings mod5b <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval,               pos.loading=TRUE ) summary(mod5b) summary( sirt::modelfit.sirt(mod5b))  #**** Model 6: 3-dimensional Rasch model Fval <- matrix( 0, I, 3 ) Fval[1:4,1] <- Fval[5:8,2] <- Fval[9:12,3 ] <- 1 Fpatt <- 0*Fval Pval <- .6*diag(3) diag(Pval) <- 1 Ppatt <- 1+0*Pval colnames(Ppatt) <- c(\"A\", \"B\",\"C\") # estimation mod6 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval  ) summary(mod6) summary( sirt::modelfit.sirt(mod6) )  # model fit  #**** Model 7: 3-dimensional 2PL model Fval <- matrix( 0, I, 3 ) Fval[1:4,1] <- Fval[5:8,2] <- Fval[9:12,3 ] <- 1 Fpatt <- Fval Pval <- .6*diag(3) diag(Pval) <- 1 Ppatt <- 1+0*Pval diag(Ppatt) <- 0 colnames(Ppatt) <- c(\"A\", \"B\",\"C\") # estimation mod7 <- sirt::noharm.sirt( dat=dat, Ppatt=Ppatt,Fpatt=Fpatt, Fval=Fval, Pval=Pval  ) summary(mod7) summary( sirt::modelfit.sirt(mod7) )  #**** Model 8: Exploratory factor analysis with 3 dimensions # estimation mod8 <- sirt::noharm.sirt( dat=dat, dimensions=3  ) summary(mod8)  ############################################################################# # EXAMPLE 3: Product-moment matrix input, McDonald (1997) #############################################################################  # data from Table 1 of McDonald (1997, p. 266) pm0 <- \" 0.828 0.567 0.658 0.664 0.560 0.772 0.532 0.428 0.501 0.606 0.718 0.567 0.672 0.526 0.843 \" pm <- miceadds::string_to_matrix(x=pm0, as_numeric=TRUE, extend=TRUE) I <- nrow(pm) rownames(pm) <- colnames(pm) <- paste0(\"I\", 1:I)  #- Model 1: Unidimensional model Fval <- matrix(.7, nrow=I, ncol=1) Fpatt <- 1+0*Fval Pval <- matrix(1, nrow=1,ncol=1) Ppatt <- 0*Pval  mod1 <- sirt::noharm.sirt(pm=pm, N=1000, Fval=Fval, Fpatt=Fpatt, Pval=Pval, Ppatt=Ppatt) summary(mod1)  #- Model 2: Twodimensional exploratory model mod2 <- sirt::noharm.sirt(pm=pm, N=1000, dimensions=2) summary(mod2)  #- Model 3: Unidimensional model with correlated residuals Psival <- matrix(0, nrow=I, ncol=I) Psipatt <- 0*Psival Psipatt[5,1] <- 1  mod3 <- sirt::noharm.sirt(pm=pm, N=1000, Fval=Fval, Fpatt=Fpatt, Pval=Pval, Ppatt=Ppatt,             Psival=Psival, Psipatt=Psipatt) summary(mod3) }"},{"path":"/reference/np.dich.html","id":null,"dir":"Reference","previous_headings":"","what":"Nonparametric Estimation of Item Response Functions — np.dich","title":"Nonparametric Estimation of Item Response Functions — np.dich","text":"function nonparametric item response function estimation (Ramsay, 1991).","code":""},{"path":"/reference/np.dich.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nonparametric Estimation of Item Response Functions — np.dich","text":"","code":"np.dich(dat, theta, thetagrid, progress=FALSE, bwscale=1.1,        method=\"normal\")"},{"path":"/reference/np.dich.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nonparametric Estimation of Item Response Functions — np.dich","text":"dat \\(N \\times \\) data frame dichotomous item responses theta Estimated theta values, example weighted likelihood estimates wle.rasch thetagrid vector theta values nonparametric item response functions shall evaluated. progress Display progress? bwscale bandwidth parameter \\(h\\) calculated formula \\(h=\\)bwscale\\(\\cdot N^{-1/5}\\) method default normal performs kernel regression untransformed item responses. method binomial uses nonparametric logistic regression implemented sm library.","code":""},{"path":"/reference/np.dich.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nonparametric Estimation of Item Response Functions — np.dich","text":"list following entries dat Original data frame thetagrid Vector theta values item response     functions evaluated theta Used theta values person parameter estimates estimate Estimated item response functions ...","code":""},{"path":"/reference/np.dich.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nonparametric Estimation of Item Response Functions — np.dich","text":"Ramsay, J. O. (1991). Kernel smoothing approaches nonparametric item characteristic curve estimation. Psychometrika, 56, 611-630.","code":""},{"path":"/reference/np.dich.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nonparametric Estimation of Item Response Functions — np.dich","text":"","code":"############################################################################# # EXAMPLE 1: Reading dataset ############################################################################# data( data.read ) dat <- data.read  # estimate Rasch model mod <- sirt::rasch.mml2( dat ) # WLE estimation wle1 <- sirt::wle.rasch( dat=dat, b=mod$item$b )$theta # nonparametric function estimation np1 <- sirt::np.dich( dat=dat, theta=wle1, thetagrid=seq(-2.5, 2.5, len=100 ) ) print( str(np1)) # plot nonparametric item response curves plot( np1, b=mod$item$b )"},{"path":"/reference/parmsummary_extend.html","id":null,"dir":"Reference","previous_headings":"","what":"Includes Confidence Interval in Parameter Summary Table — parmsummary_extend","title":"Includes Confidence Interval in Parameter Summary Table — parmsummary_extend","text":"Includes confidence interval parameter summary table.","code":""},{"path":"/reference/parmsummary_extend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Includes Confidence Interval in Parameter Summary Table — parmsummary_extend","text":"","code":"parmsummary_extend(dfr, level=.95, est_label=\"est\", se_label=\"se\",       df_label=\"df\")"},{"path":"/reference/parmsummary_extend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Includes Confidence Interval in Parameter Summary Table — parmsummary_extend","text":"dfr Data frame containing parameter summary level Significance level est_label Label parameter estimate se_label Label standard error df_label Label degrees freedom","code":""},{"path":"/reference/parmsummary_extend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Includes Confidence Interval in Parameter Summary Table — parmsummary_extend","text":"Extended parameter summary table","code":""},{"path":[]},{"path":"/reference/parmsummary_extend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Includes Confidence Interval in Parameter Summary Table — parmsummary_extend","text":"","code":"############################################################################# ## EXAMPLE 1: Toy example parameter summary table #############################################################################  dfr <- data.frame( \"parm\"=c(\"b0\", \"b1\" ), \"est\"=c(0.1, 1.3 ),                 \"se\"=c(.21, .32) ) print( sirt::parmsummary_extend(dfr), digits=4 )   ##    parm est   se      t         p lower95 upper95   ##  1   b0 0.1 0.21 0.4762 6.339e-01 -0.3116  0.5116   ##  2   b1 1.3 0.32 4.0625 4.855e-05  0.6728  1.9272"},{"path":"/reference/pbivnorm2.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","title":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","text":"function evaluates bivariate normal distribution \\(\\Phi_2 ( x, y ; \\rho )\\) assuming zero means unit variances. uses simple approximation Cox Wermuth (1991) corrected formulas Hong (1999).","code":""},{"path":"/reference/pbivnorm2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","text":"","code":"pbivnorm2(x, y, rho)"},{"path":"/reference/pbivnorm2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","text":"x Vector \\(x\\) coordinates y Vector \\(y\\) coordinates rho Vector correlations random normal variates","code":""},{"path":"/reference/pbivnorm2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","text":"Vector probabilities","code":""},{"path":"/reference/pbivnorm2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","text":"Cox, D. R., & Wermuth, N. (1991). simple approximation bivariate trivariate normal integrals. International Statistical Review, 59(2), 263-269. Hong, H. P. (1999). approximation bivariate trivariate normal integrals. Engineering Environmental Systems, 16(2), 115-127. doi:10.1080/02630259908970256","code":""},{"path":"/reference/pbivnorm2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","text":"function less precise correlations near 1 -1.","code":""},{"path":[]},{"path":"/reference/pbivnorm2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Function for the Bivariate Normal Distribution — pbivnorm2","text":"","code":"library(pbivnorm) # define input x <- c(0, 0,  .5, 1, 1  ) y <- c( 0, -.5,  1, 3, .5 ) rho <- c( .2, .8, -.4, .6, .5 ) # compare pbivnorm2 and pbivnorm functions pbiv2 <- sirt::pbivnorm2( x=x, y=y, rho=rho ) pbiv <- pbivnorm::pbivnorm(  x,  y, rho=rho ) max( abs(pbiv-pbiv2))   ## [1] 0.0030626 round( cbind( x, y, rho,pbiv, pbiv2 ), 4 )   ##          x    y  rho   pbiv  pbiv2   ##   [1,] 0.0  0.0  0.2 0.2820 0.2821   ##   [2,] 0.0 -0.5  0.8 0.2778 0.2747   ##   [3,] 0.5  1.0 -0.4 0.5514 0.5514   ##   [4,] 1.0  3.0  0.6 0.8412 0.8412   ##   [5,] 1.0  0.5  0.5 0.6303 0.6304"},{"path":"/reference/pcm.conversion.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion of the Parameterization of the Partial Credit Model — pcm.conversion","title":"Conversion of the Parameterization of the Partial Credit Model — pcm.conversion","text":"Converts parameterization partial credit model (see Details).","code":""},{"path":"/reference/pcm.conversion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion of the Parameterization of the Partial Credit Model — pcm.conversion","text":"","code":"pcm.conversion(b)"},{"path":"/reference/pcm.conversion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion of the Parameterization of the Partial Credit Model — pcm.conversion","text":"b Matrix item-category-wise intercepts \\(b_{ik}\\) (see Details).","code":""},{"path":"/reference/pcm.conversion.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conversion of the Parameterization of the Partial Credit Model — pcm.conversion","text":"Assume input matrix b containing parameters \\(b_{ik}\\) defined according following parametrization partial credit model $$ P( X_{pi}=k | \\theta_p ) \\propto exp ( k \\theta_p - b_{ik} ) $$ item \\(\\) possesses \\(K_i\\) categories. transformed parameterization defined $$b_{ik}=k \\delta_i + \\sum_{v=1}^{k} \\tau_{iv} \\quad \\mbox{} \\quad \\sum_{k=1}^{K_i} \\tau_{ik}=0 $$ function pcm.conversion \\(\\delta\\) \\(\\tau\\) parameters values. \\(\\delta\\) parameter simply \\(\\delta_i=b_{iK_i} / K_i\\).","code":""},{"path":"/reference/pcm.conversion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion of the Parameterization of the Partial Credit Model — pcm.conversion","text":"List following entries delta Vector \\(\\delta\\) parameters tau Matrix \\(\\tau\\) parameters","code":""},{"path":"/reference/pcm.conversion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion of the Parameterization of the Partial Credit Model — pcm.conversion","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Transformation PCM for data.mg #############################################################################  library(CDM) data(data.mg,package=\"CDM\") dat <- data.mg[ 1:1000, paste0(\"I\",1:11) ]  #*** Model 1: estimate partial credit model in parameterization \"PCM\" mod1a <- TAM::tam.mml( dat, irtmodel=\"PCM\") # use parameterization \"PCM2\" mod1b <- TAM::tam.mml( dat, irtmodel=\"PCM2\") summary(mod1a) summary(mod1b)  # convert parameterization of Model 1a into parameterization of Model 1b b <- mod1a$item[, c(\"AXsi_.Cat1\",\"AXsi_.Cat2\",\"AXsi_.Cat3\") ] # compare results pcm.conversion(b) mod1b$xsi }"},{"path":"/reference/pcm.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Item and Person Fit Statistics for the Partial Credit Model — pcm.fit","title":"Item and Person Fit Statistics for the Partial Credit Model — pcm.fit","text":"Computes item person fit statistics partial credit model (Wright & Masters, 1990). rating scale model accommodated particular partial credit model (see Example 3).","code":""},{"path":"/reference/pcm.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Item and Person Fit Statistics for the Partial Credit Model — pcm.fit","text":"","code":"pcm.fit(b, theta, dat)"},{"path":"/reference/pcm.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Item and Person Fit Statistics for the Partial Credit Model — pcm.fit","text":"b Matrix item category parameters (see Examples) theta Vector estimated person parameters dat Dataset item responses","code":""},{"path":"/reference/pcm.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Item and Person Fit Statistics for the Partial Credit Model — pcm.fit","text":"list entries itemfit Item fit statistics personfit Person fit statistics","code":""},{"path":"/reference/pcm.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Item and Person Fit Statistics for the Partial Credit Model — pcm.fit","text":"Wright, B. D., & Masters, G. N. (1990). Computation outfit infit statistics. Rasch Measurement Transactions, 3:4, 84-85.","code":""},{"path":[]},{"path":"/reference/pcm.fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Item and Person Fit Statistics for the Partial Credit Model — pcm.fit","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Partial credit model #############################################################################  data(data.Students,package=\"CDM\") dat <- data.Students # select items items <- c(paste0(\"sc\", 1:4 ), paste0(\"mj\", 1:4 ) ) dat <- dat[,items] dat <- dat[ rowSums( 1 - is.na(dat) ) > 0, ]  #*** Model 1a: Partial credit model in TAM # estimate model mod1a <- TAM::tam.mml( resp=dat ) summary(mod1a) # estimate person parameters wle1a <- TAM::tam.wle(mod1a) # extract item parameters b1 <- - mod1a$AXsi[, -1 ] # parametrization in xsi parameters b2 <- matrix( mod1a$xsi$xsi, ncol=3, byrow=TRUE ) # convert b2 to b1 b1b <- 0*b1 b1b[,1] <- b2[,1] b1b[,2] <- rowSums( b2[,1:2] ) b1b[,3] <- rowSums( b2[,1:3] ) # assess fit fit1a <- sirt::pcm.fit(b=b1, theta=wle1a$theta, dat) fit1a$item  ############################################################################# # EXAMPLE 2: Rasch model #############################################################################  data(data.read) dat <- data.read  #*** Rasch model in TAM # estimate model mod <- TAM::tam.mml( resp=dat ) summary(mod) # estimate person parameters wle <- TAM::tam.wle(mod) # extract item parameters b1 <- - mod$AXsi[, -1 ] # assess fit fit1a <- sirt::pcm.fit(b=b1, theta=wle$theta, dat) fit1a$item  ############################################################################# # EXAMPLE 3: Rating scale model #############################################################################  data(data.Students,package=\"CDM\") dat <- data.Students items <- paste0(\"sc\", 1:4 ) dat <- dat[,items] dat <- dat[ rowSums( 1 - is.na(dat) ) > 0, ]  #*** Model 1: Rating scale model in TAM # estimate model mod1 <- tam.mml( resp=dat, irtmodel=\"RSM\") summary(mod1) # estimate person parameters wle1 <- tam.wle(mod1) # extract item parameters b1 <- - mod1a$AXsi[, -1 ] # fit statistic pcm.fit(b=b1, theta=wle1$theta, dat) }"},{"path":"/reference/person.parameter.rasch.copula.html","id":null,"dir":"Reference","previous_headings":"","what":"Person Parameter Estimation of the Rasch Copula Model (Braeken, 2011) — person.parameter.rasch.copula","title":"Person Parameter Estimation of the Rasch Copula Model (Braeken, 2011) — person.parameter.rasch.copula","text":"Ability estimates maximum likelihood estimates (MLE) provided Rasch copula model.","code":""},{"path":"/reference/person.parameter.rasch.copula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Person Parameter Estimation of the Rasch Copula Model (Braeken, 2011) — person.parameter.rasch.copula","text":"","code":"person.parameter.rasch.copula(raschcopula.object, numdiff.parm=0.001,     conv.parm=0.001, maxiter=20, stepwidth=1,     print.summary=TRUE, ...)"},{"path":"/reference/person.parameter.rasch.copula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Person Parameter Estimation of the Rasch Copula Model (Braeken, 2011) — person.parameter.rasch.copula","text":"raschcopula.object Object generated rasch.copula2 function. numdiff.parm Parameter \\(h\\) numerical differentiation conv.parm Convergence criterion maxiter Maximum number iterations stepwidth Maximal increment iterations print.summary Print summary? ... arguments passed","code":""},{"path":"/reference/person.parameter.rasch.copula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Person Parameter Estimation of the Rasch Copula Model (Braeken, 2011) — person.parameter.rasch.copula","text":"list following entries person Estimated person parameters se.inflat Inflation individual standard errors due local dependence theta.table Ability estimates unique response pattern pattern..data Item response pattern summary.theta.table Summary statistics person parameter estimates","code":""},{"path":[]},{"path":"/reference/person.parameter.rasch.copula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Person Parameter Estimation of the Rasch Copula Model (Braeken, 2011) — person.parameter.rasch.copula","text":"","code":"############################################################################# # EXAMPLE 1: Reading Data #############################################################################  data(data.read) dat <- data.read  # define item cluster itemcluster <- rep( 1:3, each=4 ) mod1 <- sirt::rasch.copula2( dat, itemcluster=itemcluster ) summary(mod1)  # person parameter estimation under the Rasch copula model pmod1 <- sirt::person.parameter.rasch.copula(raschcopula.object=mod1 ) ## Mean percentage standard error inflation ##   missing.pattern Mperc.seinflat ## 1               1           6.35  if (FALSE) { ############################################################################# # EXAMPLE 2: 12 items nested within 3 item clusters (testlets) #   Cluster 1 -> Items 1-4; Cluster 2 -> Items 6-9;  Cluster 3 -> Items 10-12 #############################################################################  set.seed(967) I <- 12                             # number of items n <- 450                            # number of persons b <- seq(-2,2, len=I)               # item difficulties b <- sample(b)                      # sample item difficulties theta <- stats::rnorm( n, sd=1 ) # person abilities # itemcluster itemcluster <- rep(0,I) itemcluster[ 1:4 ] <- 1 itemcluster[ 6:9 ] <- 2 itemcluster[ 10:12 ] <- 3 # residual correlations rho <- c( .35, .25, .30 )  # simulate data dat <- sirt::sim.rasch.dep( theta, b, itemcluster, rho ) colnames(dat) <- paste(\"I\", seq(1,ncol(dat)), sep=\"\")  # estimate Rasch copula model mod1 <- sirt::rasch.copula2( dat, itemcluster=itemcluster ) summary(mod1)  # person parameter estimation under the Rasch copula model pmod1 <- sirt::person.parameter.rasch.copula(raschcopula.object=mod1 )   ## Mean percentage standard error inflation   ##   missing.pattern Mperc.seinflat   ## 1               1          10.48 }"},{"path":"/reference/personfit.stat.html","id":null,"dir":"Reference","previous_headings":"","what":"Person Fit Statistics for the Rasch Model — personfit.stat","title":"Person Fit Statistics for the Rasch Model — personfit.stat","text":"function collects person fit statistics Rasch model (Karabatsos, 2003; Meijer & Sijtsma, 2001).","code":""},{"path":"/reference/personfit.stat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Person Fit Statistics for the Rasch Model — personfit.stat","text":"","code":"personfit.stat(dat, abil, b)"},{"path":"/reference/personfit.stat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Person Fit Statistics for the Rasch Model — personfit.stat","text":"dat \\(N \\times \\) data frame dichotomous item responses abil ability estimate, e.g. WLE b Estimated item difficulty","code":""},{"path":"/reference/personfit.stat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Person Fit Statistics for the Rasch Model — personfit.stat","text":"data frame following columns (see Meijer & Sijtsma 2001 review different person fit statistics): case Case index abil Ability estimate abil mean Person mean correctly solved items caution Caution index depend Dependability index ECI1 \\(ECI1\\) ECI2 \\(ECI2\\) ECI3 \\(ECI3\\) ECI4 \\(ECI4\\) ECI5 \\(ECI5\\) ECI6 \\(ECI6\\) l0 Fit statistic \\(l_0\\) lz Fit statistic \\(l_z\\) outfit Person outfit statistic infit Person infit statistic rpbis Point biserial correlation item responses item \\(p\\) values rpbis.itemdiff Point biserial correlation item responses item difficulties b U3 Fit statistic \\(U_3\\)","code":""},{"path":"/reference/personfit.stat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Person Fit Statistics for the Rasch Model — personfit.stat","text":"Karabatsos, G. (2003). Comparing aberrant response detection performance thirty-six person-fit statistics. Applied Measurement Education, 16, 277-298. Meijer, R. R., & Sijtsma, K. (2001). Methodology review: Evaluating person fit. Applied Psychological Measurement, 25, 107-135.","code":""},{"path":[]},{"path":"/reference/personfit.stat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Person Fit Statistics for the Rasch Model — personfit.stat","text":"","code":"############################################################################# # EXAMPLE 1: Person fit Reading Data #############################################################################  data(data.read) dat <- data.read  # estimate Rasch model mod <- sirt::rasch.mml2( dat ) # WLE wle1 <- sirt::wle.rasch( dat,b=mod$item$b )$theta b <- mod$item$b # item difficulty  # evaluate person fit pf1 <- sirt::personfit.stat( dat=dat, abil=wle1, b=b)  if (FALSE) { # dimensional analysis of person fit statistics x0 <- stats::na.omit(pf1[, -c(1:3) ] ) stats::factanal( x=x0, factors=2, rotation=\"promax\" )   ## Loadings:   ##                Factor1 Factor2   ## caution         0.914   ## depend          0.293   0.750   ## ECI1            0.869   0.160   ## ECI2            0.869   0.162   ## ECI3            1.011   ## ECI4            1.159  -0.269   ## ECI5            1.012   ## ECI6            0.879   0.130   ## l0              0.409  -1.255   ## lz             -0.504  -0.529   ## outfit          0.297   0.702   ## infit           0.362   0.695   ## rpbis          -1.014   ## rpbis.itemdiff  1.032   ## U3              0.735   0.309   ##   ## Factor Correlations:   ##         Factor1 Factor2   ## Factor1   1.000  -0.727   ## Factor2  -0.727   1.000   ## }"},{"path":"/reference/pgenlogis.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","title":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","text":"Calculation probabilities moments generalized logistic item response model (Stukel, 1988).","code":""},{"path":"/reference/pgenlogis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","text":"","code":"pgenlogis(x, alpha1=0, alpha2=0)  genlogis.moments(alpha1, alpha2)"},{"path":"/reference/pgenlogis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","text":"x Vector alpha1 Upper tail parameter \\(\\alpha_1\\) generalized logistic item response model. default 0. alpha2 Lower tail parameter \\(\\alpha_2\\) parameter generalized logistic item response model. default 0.","code":""},{"path":"/reference/pgenlogis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","text":"class generalized logistic link functions contain important link functions using specifications (Stukel, 1988): logistic link function \\(L\\): $$ L(x) \\approx G_{ ( \\alpha_1=0, \\alpha_2=0)}[ x ] $$ probit link function \\(\\Phi\\): $$ \\Phi(x) \\approx G_{ ( \\alpha_1=0.165, \\alpha_2=0.165)}[ 1.47 x ] $$ loglog link function \\(H\\): $$ H(x) \\approx G_{ (\\alpha_1=-0.037, \\alpha_2=0.62)}[ -0.39+1.20x-0.007x^2] $$ cloglog link function \\(H\\): $$ H(x) \\approx G_{ ( \\alpha_1=0.62, \\alpha_2=-0.037)}[ 0.54+1.64x+0.28x^2+0.046x^3] $$","code":""},{"path":"/reference/pgenlogis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","text":"Vector probabilities moments","code":""},{"path":"/reference/pgenlogis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","text":"Stukel, T. . (1988). Generalized logistic models. Journal American Statistical Association, 83(402), 426-431. doi:10.1080/01621459.1988.10478613","code":""},{"path":"/reference/pgenlogis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculation of Probabilities and Moments for the\r\nGeneralized Logistic Item Response Model — pgenlogis","text":"","code":"sirt::pgenlogis( x=c(-.3, 0, .25, 1 ), alpha1=0, alpha2=.6 )   ##   [1] 0.4185580 0.5000000 0.5621765 0.7310586  #################################################################### # compare link functions x <- seq( -3,3, .1 )  #*** # logistic link y <- sirt::pgenlogis( x, alpha1=0, alpha2=0 ) plot( x, stats::plogis(x), type=\"l\", main=\"Logistic Link\", lwd=2) points( x, y, pch=1, col=2 )  #*** # probit link round( sirt::genlogis.moments( alpha1=.165, alpha2=.165 ), 3 )   ##       M    SD   Var   ##   0.000 1.472 2.167 # SD of generalized logistic link function is 1.472 y <- sirt::pgenlogis( x * 1.47, alpha1=.165, alpha2=.165 ) plot( x, stats::pnorm(x), type=\"l\", main=\"Probit Link\", lwd=2) points( x, y, pch=1, col=2 )  #*** # loglog link y <- sirt::pgenlogis( -.39 + 1.20*x -.007*x^2, alpha1=-.037, alpha2=.62 ) plot( x, exp( - exp( -x ) ), type=\"l\", main=\"Loglog Link\", lwd=2,     ylab=\"loglog(x)=exp(-exp(-x))\" ) points( x, y, pch=17, col=2 )  #*** # cloglog link y <- sirt::pgenlogis( .54+1.64*x +.28*x^2 + .046*x^3, alpha1=.062, alpha2=-.037 ) plot( x, 1-exp( - exp(x) ), type=\"l\", main=\"Cloglog Link\", lwd=2,     ylab=\"loglog(x)=1-exp(-exp(x))\" ) points( x, y, pch=17, col=2 )"},{"path":"/reference/plausible.value.imputation.raschtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","title":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","text":"function performs unidimensional plausible value imputation (Adams & Wu, 2007; Mislevy, 1991).","code":""},{"path":"/reference/plausible.value.imputation.raschtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","text":"","code":"plausible.value.imputation.raschtype(data=NULL, f.yi.qk=NULL, X,    Z=NULL, beta0=rep(0, ncol(X)), sig0=1, b=rep(1, ncol(X)),    a=rep(1, length(b)), c=rep(0, length(b)), d=1+0*b,    alpha1=0, alpha2=0, theta.list=seq(-5, 5, len=50),    cluster=NULL, iter, burnin, nplausible=1, printprogress=TRUE)"},{"path":"/reference/plausible.value.imputation.raschtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","text":"data \\(N \\times \\) data frame dichotomous responses f.yi.qk optional matrix contains individual likelihood.   matrix produced rasch.mml2   rasch.copula2. use argument allows   estimation latent regression model independent   parameters used item response model. X matrix individual covariates latent regression \\(\\theta\\) \\(X\\) Z matrix individual covariates regression individual residual variances \\(Z\\) beta0 Initial vector regression coefficients sig0 Initial vector coefficients variance heterogeneity model b Vector item difficulties. must provided individual likelihood f.yi.qk specified. Optional vector item slopes c Optional vector lower item asymptotes d Optional vector upper item asymptotes alpha1 Parameter \\(\\alpha_1\\) generalized item response model alpha2 Parameter \\(\\alpha_2\\) generalized item response model theta.list Vector theta values ability distribution evaluated cluster Cluster identifier (e.g. schools classes) including theta means plausible imputation. iter Number iterations burnin Number burn-iterations plausible value imputation nplausible Number plausible values printprogress logical indicated whether iteration progress displayed console.","code":""},{"path":"/reference/plausible.value.imputation.raschtype.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","text":"Plausible values drawn latent regression model heterogeneous variances: $$\\theta_p=X_p \\beta + \\epsilon_p  \\quad, \\quad \\epsilon_p \\sim N( 0, \\sigma_p^2 ) \\quad, \\quad \\log( \\sigma_p )=Z_p \\gamma + \\nu_p $$","code":""},{"path":"/reference/plausible.value.imputation.raschtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","text":"list following entries: coefs.X Sampled regression coefficients covariates \\(X\\) coefs.Z Sampled coefficients modeling variance heterogeneity covariates \\(Z\\) pvdraws Matrix drawn plausible values posterior Posterior distribution last iteration EAP Individual EAP estimate SE.EAP Standard error EAP estimate pv.indexes Index iterations plausible values drawn","code":""},{"path":"/reference/plausible.value.imputation.raschtype.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","text":"Adams, R., & Wu. M. (2007). mixed-coefficients multinomial logit model: generalized form Rasch model. M. von Davier & C. H. Carstensen: Multivariate Mixture Distribution Rasch Models: Extensions Applications (pp. 57-76). New York: Springer. Mislevy, R. J. (1991). Randomization-based inference latent variables complex samples. Psychometrika, 56, 177-196.","code":""},{"path":[]},{"path":"/reference/plausible.value.imputation.raschtype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plausible Value Imputation in Generalized Logistic Item\r\nResponse Model — plausible.value.imputation.raschtype","text":"","code":"############################################################################# # EXAMPLE 1: Rasch model with covariates #############################################################################  set.seed(899) I <- 21     # number of items b <- seq(-2,2, len=I)   # item difficulties n <- 2000       # number of students  # simulate theta and covariates theta <- stats::rnorm( n ) x <- .7 * theta + stats::rnorm( n, .5 ) y <- .2 * x+ .3*theta + stats::rnorm( n, .4 ) dfr <- data.frame( theta, 1, x, y )  # simulate Rasch model dat1 <- sirt::sim.raschtype( theta=theta, b=b )  # Plausible value draws pv1 <- sirt::plausible.value.imputation.raschtype(data=dat1, X=dfr[,-1], b=b,             nplausible=3, iter=10, burnin=5) # estimate linear regression based on first plausible value mod1 <- stats::lm( pv1$pvdraws[,1] ~ x+y ) summary(mod1)   ##               Estimate Std. Error t value Pr(>|t|)   ##   (Intercept) -0.27755    0.02121  -13.09   <2e-16 ***   ##   x            0.40483    0.01640   24.69   <2e-16 ***   ##   y            0.20307    0.01822   11.15   <2e-16 ***  # true regression estimate summary( stats::lm( theta ~ x + y ) )   ## Coefficients:   ##             Estimate Std. Error t value Pr(>|t|)   ## (Intercept) -0.27821    0.01984  -14.02   <2e-16 ***   ## x            0.40747    0.01534   26.56   <2e-16 ***   ## y            0.18189    0.01704   10.67   <2e-16 ***  if (FALSE) { ############################################################################# # EXAMPLE 2: Classical test theory, homogeneous regression variance #############################################################################  set.seed(899) n <- 3000       # number of students x <- round( stats::runif( n, 0,1 ) ) y <- stats::rnorm(n) # simulate true score theta theta <- .4*x + .5 * y + stats::rnorm(n) # simulate observed score by adding measurement error sig.e <- rep( sqrt(.40), n ) theta_obs <- theta + stats::rnorm( n, sd=sig.e)  # define theta grid for evaluation of density theta.list <- mean(theta_obs) + stats::sd(theta_obs) * seq( - 5, 5, length=21) # compute individual likelihood f.yi.qk <- stats::dnorm( outer( theta_obs, theta.list, \"-\" ) / sig.e ) f.yi.qk <- f.yi.qk / rowSums(f.yi.qk) # define covariates X <- cbind( 1, x, y ) # draw plausible values mod2 <- sirt::plausible.value.imputation.raschtype( f.yi.qk=f.yi.qk,                   theta.list=theta.list, X=X, iter=10, burnin=5)  # linear regression mod1 <- stats::lm( mod2$pvdraws[,1] ~ x+y ) summary(mod1)   ##             Estimate Std. Error t value Pr(>|t|)   ## (Intercept) -0.01393    0.02655  -0.525      0.6   ## x            0.35686    0.03739   9.544   <2e-16 ***   ## y            0.53759    0.01872  28.718   <2e-16 ***  # true regression model summary( stats::lm( theta ~ x + y ) )   ##             Estimate Std. Error t value Pr(>|t|)   ## (Intercept) 0.002931   0.026171   0.112    0.911   ## x           0.359954   0.036864   9.764   <2e-16 ***   ## y           0.509073   0.018456  27.584   <2e-16 ***  ############################################################################# # EXAMPLE 3: Classical test theory, heterogeneous regression variance #############################################################################  set.seed(899) n <- 5000       # number of students x <- round( stats::runif( n, 0,1 ) ) y <- stats::rnorm(n) # simulate true score theta theta <- .4*x + .5 * y + stats::rnorm(n) * ( 1 - .4 * x ) # simulate observed score by adding measurement error sig.e <- rep( sqrt(.40), n ) theta_obs <- theta + stats::rnorm( n, sd=sig.e)  # define theta grid for evaluation of density theta.list <- mean(theta_obs) + stats::sd(theta_obs) * seq( - 5, 5, length=21) # compute individual likelihood f.yi.qk <- stats::dnorm( outer( theta_obs, theta.list, \"-\" ) / sig.e ) f.yi.qk <- f.yi.qk / rowSums(f.yi.qk) # define covariates X <- cbind( 1, x, y ) # draw plausible values (assuming variance homogeneity) mod3a <- sirt::plausible.value.imputation.raschtype( f.yi.qk=f.yi.qk,                   theta.list=theta.list, X=X, iter=10, burnin=5) # draw plausible values (assuming variance heterogeneity) #  -> include predictor Z mod3b <- sirt::plausible.value.imputation.raschtype( f.yi.qk=f.yi.qk,                   theta.list=theta.list, X=X, Z=X, iter=10, burnin=5)  # investigate variance of theta conditional on x res3 <- sapply( 0:1, FUN=function(vv){         c( stats::var(theta[x==vv]), stats::var(mod3b$pvdraw[x==vv,1]),               stats::var(mod3a$pvdraw[x==vv,1]))}) rownames(res3) <- c(\"true\", \"pv(hetero)\", \"pv(homog)\" ) colnames(res3) <- c(\"x=0\",\"x=1\")   ## > round( res3, 2 )   ##             x=0  x=1   ## true       1.30 0.58   ## pv(hetero) 1.29 0.55   ## pv(homog)  1.06 0.77 ## -> assuming heteroscedastic variances recovers true conditional variance }"},{"path":"/reference/plot.mcmc.sirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Function for Objects of Class mcmc.sirt — plot.mcmc.sirt","title":"Plot Function for Objects of Class mcmc.sirt — plot.mcmc.sirt","text":"Plot function objects class mcmc.sirt. objects generated : mcmc.2pno, mcmc.2pnoh, mcmc.3pno.testlet, mcmc.2pno.ml","code":""},{"path":"/reference/plot.mcmc.sirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Function for Objects of Class mcmc.sirt — plot.mcmc.sirt","text":"","code":"# S3 method for mcmc.sirt plot( x, layout=1, conflevel=0.9, round.summ=3,    lag.max=.1, col.smooth=\"red\", lwd.smooth=2, col.ci=\"orange\",    cex.summ=1, ask=FALSE, ...)"},{"path":"/reference/plot.mcmc.sirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Function for Objects of Class mcmc.sirt — plot.mcmc.sirt","text":"x Object class mcmc.sirt layout Layout type. layout=1 standard coda plot output, layout=2 gives slightly different display. conflevel Confidence level (applies layout=2) round.summ Number digits rounded summary (applies layout=2) lag.max Maximum lag autocorrelation plot (applies layout=2). default .1 means set 1/10 number iterations. col.smooth Color smooth trend traceplot (applies layout=2) lwd.smooth Line type smooth trend traceplot (applies layout=2) col.ci Color displaying confidence interval (applies layout=2) cex.summ Cex size descriptive summary (applies layout=2) ask Ask new plot (applies layout=2) ... arguments passed","code":""},{"path":[]},{"path":"/reference/plot.np.dich.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for Object of Class np.dich — plot.np.dich","title":"Plot Method for Object of Class np.dich — plot.np.dich","text":"function plots nonparametric item response functions estimated dich.np.","code":""},{"path":"/reference/plot.np.dich.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for Object of Class np.dich — plot.np.dich","text":"","code":"# S3 method for np.dich plot(x, b, infit=NULL, outfit=NULL,     nsize=100, askplot=TRUE, progress=TRUE, bands=FALSE,     plot.b=FALSE, shade=FALSE, shadecol=\"burlywood1\", ...)"},{"path":"/reference/plot.np.dich.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for Object of Class np.dich — plot.np.dich","text":"x Object class np.dich b Estimated item difficulty (threshold) infit Infit (optional) outfit Outfit (optional) nsize XXX askplot Ask new plot? progress Display progress? bands Draw confidence bands? plot.b Plot difficulty parameter? shade Shade curves? shadecol Shade color ... arguments passed","code":""},{"path":[]},{"path":"/reference/polychoric2.html","id":null,"dir":"Reference","previous_headings":"","what":"Polychoric Correlation — polychoric2","title":"Polychoric Correlation — polychoric2","text":"function estimates polychoric correlation coefficient using maximum likelihood estimation (Olsson, 1979).","code":""},{"path":"/reference/polychoric2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polychoric Correlation — polychoric2","text":"","code":"polychoric2(dat, maxiter=100, cor.smooth=TRUE, use_pbv=1, conv=1e-10,       rho_init=NULL, weights=NULL)  ## exported Rcpp function sirt_rcpp_polychoric2( dat, maxK, maxiter, use_pbv, conv, rho_init, weights)"},{"path":"/reference/polychoric2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polychoric Correlation — polychoric2","text":"dat dataset integer values \\(0,1,\\ldots,K\\) maxiter Maximum number iterations cor.smooth optional logical indicating whether polychoric correlation matrix smooth ensure positive definiteness. use_pbv Integer indicating whether pbv package used computation bivariate normal distribution. 0 stands simplest approximation sirt (Cox & Wermuth, 1991, implemented polychoric2) versions 1 2 uses algorithm pbv (first one copied sirt package, second one linking Rcpp code pbv.) conv Convergence criterion rho_init Optional matrix initial values polychoric correlations weights Optional vector sampling weights maxK Maximum number categories","code":""},{"path":"/reference/polychoric2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Polychoric Correlation — polychoric2","text":"list following entries tau Matrix thresholds rho Polychoric correlation matrix Nobs Sample size every item pair maxcat Maximum number categories per item","code":""},{"path":"/reference/polychoric2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Polychoric Correlation — polychoric2","text":"Cox, D. R., & Wermuth, N. (1991). simple approximation bivariate trivariate normal integrals. International Statistical Review, 59(2), 263-269. Olsson, U. (1979). Maximum likelihood estimation polychoric correlation coefficient. Psychometrika, 44(4), 443-460. doi:10.1007/BF02296207","code":""},{"path":[]},{"path":"/reference/polychoric2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polychoric Correlation — polychoric2","text":"","code":"############################################################################# # EXAMPLE 1: data.Students | activity scale #############################################################################  data(data.Students, package=\"CDM\") dat <- data.Students[, paste0(\"act\", 1:5 ) ]  # tetrachoric correlation from psych package library(psych) t0 <- psych::polychoric(dat)$rho # Olsson method (maximum likelihood estimation) t1 <- sirt::polychoric2(dat)$rho # maximum absolute difference max( abs( t0 - t1 ) )   ##   [1] 0.004102429"},{"path":"/reference/prior_model_parse.html","id":null,"dir":"Reference","previous_headings":"","what":"Parsing a Prior Model — prior_model_parse","title":"Parsing a Prior Model — prior_model_parse","text":"Parses string specifying prior model needed prior argument LAM::amh","code":""},{"path":"/reference/prior_model_parse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parsing a Prior Model — prior_model_parse","text":"","code":"prior_model_parse(prior_model)"},{"path":"/reference/prior_model_parse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parsing a Prior Model — prior_model_parse","text":"prior_model String specifying prior conforming R syntax.","code":""},{"path":"/reference/prior_model_parse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parsing a Prior Model — prior_model_parse","text":"List specified prior distributions parameters needed prior argument LAM::amh","code":""},{"path":[]},{"path":"/reference/prior_model_parse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parsing a Prior Model — prior_model_parse","text":"","code":"############################################################################# # EXAMPLE 1: Toy example prior distributions #############################################################################  #*** define prior model as a string prior_model <- \"   # prior distributions means   mu1 ~ dnorm( NA, mean=0, sd=1 )   mu2 ~ dnorm(NA)       # mean T2 and T3   # prior distribution standard deviation   sig1 ~ dunif(NA,0, max=10)       \"  #*** convert priors into a list res <- sirt::prior_model_parse( prior_model ) str(res)   ##  List of 3   ##   $ mu1 :List of 2   ##    ..$ : chr \"dnorm\"   ##    ..$ :List of 3   ##    .. ..$ NA  : num NA   ##    .. ..$ mean: num 0   ##    .. ..$ sd  : num 1   ##   $ mu2 :List of 2   ##    ..$ : chr \"dnorm\"   ##    ..$ :List of 1   ##    .. ..$ : num NA   ##   $ sig1:List of 2   ##    ..$ : chr \"dunif\"   ##    ..$ :List of 3   ##    .. ..$ NA : num NA   ##    .. ..$ NA : num 0   ##    .. ..$ max: num 10"},{"path":"/reference/prmse.subscores.scales.html","id":null,"dir":"Reference","previous_headings":"","what":"Proportional Reduction of Mean Squared\r\nError (PRMSE) for Subscale Scores — prmse.subscores.scales","title":"Proportional Reduction of Mean Squared\r\nError (PRMSE) for Subscale Scores — prmse.subscores.scales","text":"function estimates proportional reduction mean squared error (PRMSE) according Haberman (Haberman 2008; Haberman, Sinharay & Puhan, 2008; see Meijer et al. 2017 overview).","code":""},{"path":"/reference/prmse.subscores.scales.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proportional Reduction of Mean Squared\r\nError (PRMSE) for Subscale Scores — prmse.subscores.scales","text":"","code":"prmse.subscores.scales(data, subscale)"},{"path":"/reference/prmse.subscores.scales.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proportional Reduction of Mean Squared\r\nError (PRMSE) for Subscale Scores — prmse.subscores.scales","text":"data \\(N \\times \\) data frame item responses subscale Vector labels corresponding subscales","code":""},{"path":"/reference/prmse.subscores.scales.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proportional Reduction of Mean Squared\r\nError (PRMSE) for Subscale Scores — prmse.subscores.scales","text":"Matrix columns corresponding subscales symbol X denotes subscale Z whole scale (see also Examples section structure matrix).","code":""},{"path":"/reference/prmse.subscores.scales.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Proportional Reduction of Mean Squared\r\nError (PRMSE) for Subscale Scores — prmse.subscores.scales","text":"Haberman, S. J. (2008). can subscores value? Journal Educational Behavioral Statistics, 33, 204-229. Haberman, S., Sinharay, S., & Puhan, G. (2008). Reporting subscores institutions. British Journal Mathematical Statistical Psychology, 62, 79-95. Meijer, R. R., Boeve, . J., Tendeiro, J. N., Bosker, R. J., & Albers, C. J. (2017). use subscores higher education: useful?. Frontiers Psychology | Educational Psychology, 8.","code":""},{"path":[]},{"path":"/reference/prmse.subscores.scales.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proportional Reduction of Mean Squared\r\nError (PRMSE) for Subscale Scores — prmse.subscores.scales","text":"","code":"############################################################################# # EXAMPLE 1: PRMSE Reading data data.read #############################################################################  data( data.read ) p1 <- sirt::prmse.subscores.scales(data=data.read,          subscale=substring( colnames(data.read), 1,1 ) ) print( p1, digits=3 )   ##                 A       B       C   ## N         328.000 328.000 328.000   ## nX          4.000   4.000   4.000   ## M.X         2.616   2.811   3.253   ## Var.X       1.381   1.059   1.107   ## SD.X        1.175   1.029   1.052   ## alpha.X     0.545   0.381   0.640   ## [...]   ## nZ         12.000  12.000  12.000   ## M.Z         8.680   8.680   8.680   ## Var.Z       5.668   5.668   5.668   ## SD.Z        2.381   2.381   2.381   ## alpha.Z     0.677   0.677   0.677   ## [...]   ## cor.TX_Z    0.799   0.835   0.684   ## rmse.X      0.585   0.500   0.505   ## rmse.Z      0.522   0.350   0.614   ## rmse.XZ     0.495   0.350   0.478   ## prmse.X     0.545   0.381   0.640   ## prmse.Z     0.638   0.697   0.468   ## prmse.XZ    0.674   0.697   0.677 #-> Scales A and B do not have lower RMSE, #   but for scale C the RMSE is smaller than the RMSE of a #   prediction based on a whole scale."},{"path":"/reference/prob.guttman.html","id":null,"dir":"Reference","previous_headings":"","what":"Probabilistic Guttman Model — prob.guttman","title":"Probabilistic Guttman Model — prob.guttman","text":"function estimates probabilistic Guttman model special case ordered latent trait model (Hanson, 2000; Proctor, 1970).","code":""},{"path":"/reference/prob.guttman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probabilistic Guttman Model — prob.guttman","text":"","code":"prob.guttman(dat, pid=NULL, guess.equal=FALSE,  slip.equal=FALSE,     itemlevel=NULL, conv1=0.001, glob.conv=0.001, mmliter=500)  # S3 method for prob.guttman summary(object,...)  # S3 method for prob.guttman anova(object,...)  # S3 method for prob.guttman logLik(object,...)  # S3 method for prob.guttman IRT.irfprob(object,...)  # S3 method for prob.guttman IRT.likelihood(object,...)  # S3 method for prob.guttman IRT.posterior(object,...)"},{"path":"/reference/prob.guttman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probabilistic Guttman Model — prob.guttman","text":"dat \\(N \\times \\) data frame dichotomous item responses pid Optional vector person identifiers guess.equal guessing parameters items estimated? slip.equal slipping parameters items estimated? itemlevel vector item levels Guttman scale item. \\(K\\) different item levels, Guttman scale possesses \\(K\\) ordered trait values. conv1 Convergence criterion item parameters glob.conv Global convergence criterion deviance mmliter Maximum number iterations object Object class prob.guttman ... arguments passed","code":""},{"path":"/reference/prob.guttman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probabilistic Guttman Model — prob.guttman","text":"object class prob.guttman person Estimated person parameters item Estimated item parameters theta.k Ability levels trait Estimated trait distribution ic Information criteria deviance Deviance iter Number iterations itemdesign Specified allocation items trait levels","code":""},{"path":"/reference/prob.guttman.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Probabilistic Guttman Model — prob.guttman","text":"Hanson, B. (2000). IRT parameter estimation using EM algorithm. Technical Report. Proctor, C. H. (1970). probabilistic formulation statistical analysis Guttman scaling. Psychometrika, 35, 73-78.","code":""},{"path":[]},{"path":"/reference/Q3.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the \\(Q_3\\) Statistic (Yen, 1984) — Q3","title":"Estimation of the \\(Q_3\\) Statistic (Yen, 1984) — Q3","text":"function estimates \\(Q_3\\) statistic according Yen (1984). statistic \\(Q_3\\) calculated every item pair \\((,j)\\) correlation item residuals fitting Rasch model.","code":""},{"path":"/reference/Q3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the \\(Q_3\\) Statistic (Yen, 1984) — Q3","text":"","code":"Q3(dat, theta, b, progress=TRUE)"},{"path":"/reference/Q3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the \\(Q_3\\) Statistic (Yen, 1984) — Q3","text":"dat \\(N \\times \\) data frame dichotomous item responses theta Vector length \\(N\\) person parameter estimates (e.g. obtained     wle.rasch) b Vector length \\(\\) (e.g. obtained rasch.mml2) progress iteration progress displayed?","code":""},{"path":"/reference/Q3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the \\(Q_3\\) Statistic (Yen, 1984) — Q3","text":"list following entries q3.matrix \\(\\times \\) matrix \\(Q_3\\) statistics q3.long Just q3.matrix long matrix format every row                   corresponds item pair expected \\(N \\times \\) matrix expected probabilities     Rasch model residual \\(N \\times \\) matrix residuals obtained     fitting Rasch model Q3.stat Vector descriptive statistics \\(Q_3\\)","code":""},{"path":"/reference/Q3.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the \\(Q_3\\) Statistic (Yen, 1984) — Q3","text":"Yen, W. M. (1984). Effects local item dependence fit equating performance three-parameter logistic model. Applied Psychological Measurement, 8, 125-145.","code":""},{"path":[]},{"path":"/reference/Q3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the \\(Q_3\\) Statistic (Yen, 1984) — Q3","text":"","code":"############################################################################# # EXAMPLE 1: data.read. The 12 items are arranged in 4 testlets ############################################################################# data(data.read)  # estimate the Rasch model mod <- sirt::rasch.mml2( data.read) # estmate WLEs mod.wle <- sirt::wle.rasch( dat=data.read, b=mod$item$b ) # calculate Yen's Q3 statistic mod.q3 <- sirt::Q3( dat=data.read, theta=mod.wle$theta, b=mod$item$b )   ##   Yen's Q3 Statistic based on an estimated theta score   ##   *** 12 Items | 66 item pairs   ##   *** Q3 Descriptives   ##        M     SD    Min    10%    25%    50%    75%    90%    Max   ##   -0.085  0.110 -0.261 -0.194 -0.152 -0.107 -0.051  0.041  0.412  # plot Q3 statistics I <- ncol(data.read) image( 1:I, 1:I, mod.q3$q3.matrix, col=gray( 1 - (0:32)/32),         xlab=\"Item\", ylab=\"Item\") abline(v=c(5,9)) # borders for testlets abline(h=c(5,9))  if (FALSE) { # obtain Q3 statistic from modelfit.sirt function which is based on the # posterior distribution of theta and not on observed values fitmod <- sirt::modelfit.sirt( mod ) # extract Q3 statistic q3stat <- fitmod$itempairs$Q3   ##  > summary(q3stat)   ##      Min.  1st Qu.   Median     Mean  3rd Qu.     Max.   ##  -0.21760 -0.11590 -0.07280 -0.05545 -0.01220  0.44710   ##  > sd(q3stat)   ##  [1] 0.1101451 }"},{"path":"/reference/Q3.testlet.html","id":null,"dir":"Reference","previous_headings":"","what":"\\(Q_3\\) Statistic of Yen (1984) for Testlets — Q3.testlet","title":"\\(Q_3\\) Statistic of Yen (1984) for Testlets — Q3.testlet","text":"function calculates average \\(Q_3\\) statistic (Yen, 1984) within testlets.","code":""},{"path":"/reference/Q3.testlet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"\\(Q_3\\) Statistic of Yen (1984) for Testlets — Q3.testlet","text":"","code":"Q3.testlet(q3.res, testlet.matrix, progress=TRUE)"},{"path":"/reference/Q3.testlet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"\\(Q_3\\) Statistic of Yen (1984) for Testlets — Q3.testlet","text":"q3.res object generated Q3 testlet.matrix matrix two columns. first column contains names testlets second names items. See examples definition matrices. progress Logical indicating whether computation progress displayed.","code":""},{"path":"/reference/Q3.testlet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"\\(Q_3\\) Statistic of Yen (1984) for Testlets — Q3.testlet","text":"list following entries testlet.q3 Data frame average \\(Q_3\\) statistics within testlets testlet.q3.korr Matrix average \\(Q_3\\) statistics within       testlets","code":""},{"path":"/reference/Q3.testlet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"\\(Q_3\\) Statistic of Yen (1984) for Testlets — Q3.testlet","text":"Yen, W. M. (1984). Effects local item dependence fit equating performance three-parameter logistic model. Applied Psychological Measurement, 8, 125-145.","code":""},{"path":[]},{"path":"/reference/Q3.testlet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"\\(Q_3\\) Statistic of Yen (1984) for Testlets — Q3.testlet","text":"","code":"############################################################################# # EXAMPLE 1: data.read. The 12 items are arranged in 4 testlets ############################################################################# data(data.read)  # estimate the Rasch model mod <- sirt::rasch.mml2( data.read) mod$item  # estmate WLEs mod.wle <- sirt::wle.rasch( dat=data.read, b=mod$item$b )  # Yen's Q3 statistic mod.q3 <- sirt::Q3( dat=data.read, theta=mod.wle$theta, b=mod$item$b )  # Yen's Q3 statistic with testlets items <- colnames(data.read) testlet.matrix <- cbind( substring(  items,1,1), items ) mod.testletq3 <- sirt::Q3.testlet( q3.res=mod.q3,testlet.matrix=testlet.matrix) mod.testletq3"},{"path":"/reference/qmc.nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","title":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","text":"function calculates integration nodes based multivariate normal distribution zero mean vector identity covariance matrix. See Pan Thompson (2007) Gonzales et al. (2006) details.","code":""},{"path":"/reference/qmc.nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","text":"","code":"qmc.nodes(snodes, ndim)"},{"path":"/reference/qmc.nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","text":"snodes Number integration nodes ndim Number dimensions","code":""},{"path":"/reference/qmc.nodes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","text":"theta matrix integration points","code":""},{"path":"/reference/qmc.nodes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","text":"Gonzalez, J., Tuerlinckx, F., De Boeck, P., & Cools, R. (2006). Numerical integration logistic-normal models. Computational Statistics & Data Analysis, 51, 1535-1548. Pan, J., & Thompson, R. (2007). Quasi-Monte Carlo estimation generalized linear mixed models. Computational Statistics & Data Analysis, 51, 5765-5775.","code":""},{"path":"/reference/qmc.nodes.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","text":"function uses sfsmisc::QUnif function sfsmisc package.","code":""},{"path":"/reference/qmc.nodes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculation of Quasi Monte Carlo Integration Points — qmc.nodes","text":"","code":"## some toy examples  # 5 nodes on one dimension qmc.nodes( snodes=5, ndim=1 )   ##            [,1]   ## [1,]  0.0000000   ## [2,] -0.3863753   ## [3,]  0.8409238   ## [4,] -0.8426682   ## [5,]  0.3850568  # 7 nodes on two dimensions qmc.nodes( snodes=7, ndim=2 )   ##             [,1]        [,2]   ## [1,]  0.00000000 -0.43072730   ## [2,] -0.38637529  0.79736332   ## [3,]  0.84092380 -1.73230641   ## [4,] -0.84266815 -0.03840544   ## [5,]  0.38505683  1.51466109   ## [6,] -0.00122394 -0.86704605   ## [7,]  1.35539115  0.33491073"},{"path":"/reference/R2conquest.html","id":null,"dir":"Reference","previous_headings":"","what":"Running ConQuest From Within R — R2conquest","title":"Running ConQuest From Within R — R2conquest","text":"function R2conquest runs IRT software ConQuest (Wu, Adams, Wilson & Haldane, 2007) within R. functions utility functions reading item parameters, plausible values person-item maps.","code":""},{"path":"/reference/R2conquest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Running ConQuest From Within R — R2conquest","text":"","code":"R2conquest(dat, path.conquest, conquest.name=\"console\", converge=0.001,     deviancechange=1e-04, iter=800, nodes=20, minnode=-6, maxnode=6,     show.conquestoutput=FALSE, name=\"rasch\", pid=1:(nrow(dat)), wgt=NULL, X=NULL,     set.constraints=NULL, model=\"item\", regression=NULL,     itemcodes=seq(0,max(dat,na.rm=TRUE)), constraints=NULL, digits=5, onlysyntax=FALSE,     qmatrix=NULL, import.regression=NULL, anchor.regression=NULL,     anchor.covariance=NULL, pv=TRUE, designmatrix=NULL, only.calibration=FALSE,     init_parameters=NULL, n_plausible=10,  persons.elim=TRUE, est.wle=TRUE,     save.bat=TRUE, use.bat=FALSE, read.output=TRUE, ignore.pid=FALSE)  # S3 method for R2conquest summary(object, ...)  # read all terms in a show file or only some terms read.show(showfile) read.show.term(showfile, term)  # read regression parameters in a show file read.show.regression(showfile)  # read unidimensional plausible values form a pv file read.pv(pvfile, npv=5) # read multidimensional plausible values read.multidimpv(pvfile, ndim, npv=5)  # read person-item map read.pimap(showfile)"},{"path":"/reference/R2conquest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Running ConQuest From Within R — R2conquest","text":"dat Data frame item responses path.conquest Directory ConQuest executable file located conquest.name Name ConQuest executable. converge Maximal change parameters deviancechange Maximal change deviance iter Maximum number iterations nodes Number nodes integration minnode Minimum value discrete grid \\(\\theta\\) nodes maxnode Maximum value discrete grid \\(\\theta\\) nodes show.conquestoutput Show ConQuest run log file console? name Name output files. default 'rasch'. pid Person identifier wgt Vector person weights X Matrix covariates latent regression model (e.g. gender, socioeconomic status, ..) item design (e.g. raters, booklets, ...) set.constraints set.constraints ConQuest. can \"cases\" (constraint persons), \"items\" \"none\" model Definition model statement. can example \"item+item*step\" \"item+booklet+rater\" regression ConQuest regression statement (example \"gender+status\") itemcodes Vector valid codes item responses. E.g. partial credit data 3 points must c(0,1,2,3). constraints Matrix item parameter constraints. 1st column: Item names, 2nd column: Item parameters. works correctly dichotomous data. digits Number digits covariates latent regression model onlysyntax ConQuest syntax generated? qmatrix Matrix item loadings dimensions multidimensional IRT model import.regression Name file initial covariance parameters (follow ConQuest specification rules!) anchor.regression Name file anchored regression parameters anchor.covariance Name file anchored covariance parameters (follow ConQuest specification rules!) pv Draw plausible values? designmatrix Design matrix item parameters (see ConQuest manual) .calibration Estimate item parameters person parameters (WLEs plausible values estimated)? init_parameters Name file initial item parameters (follow ConQuest specification rules!) n_plausible Number plausible values persons.elim Eliminate persons missing item responses? est.wle Estimate weighted likelihood estimate? save.bat Save bat file? use.bat Run ConQuest within R due direct call via system command (use.bat=FALSE) via system call bat file working directory (use.bat=TRUE) read.output ConQuest output files processed? Default TRUE. ignore.pid Logical indicating whether person identifiers (pid) processed ConQuest input syntax. object Object class R2conquest showfile ConQuest show file (shw file) term Name term extracted show file pvfile File plausible values ndim Number dimensions npv Number plausible values ... arguments passed","code":""},{"path":"/reference/R2conquest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Running ConQuest From Within R — R2conquest","text":"Consult ConQuest manual (Wu et al., 2007) specification details.","code":""},{"path":"/reference/R2conquest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Running ConQuest From Within R — R2conquest","text":"list several entries item Data frame item parameters item statistics person Data frame person parameters shw.itemparameter ConQuest output table item parameters shw.regrparameter ConQuest output table regression parameters ... values","code":""},{"path":"/reference/R2conquest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Running ConQuest From Within R — R2conquest","text":"Wu, M. L., Adams, R. J., Wilson, M. R. & Haldane, S. (2007). ACER ConQuest Version 2.0. Mulgrave. https://shop.acer.edu.au/acer-shop/group/CON3.","code":""},{"path":[]},{"path":"/reference/R2conquest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Running ConQuest From Within R — R2conquest","text":"","code":"if (FALSE) { # define ConQuest path path.conquest <- \"C:/Conquest/\"  ############################################################################# # EXAMPLE 1: Dichotomous data (data.pisaMath) ############################################################################# library(sirt) data(data.pisaMath) dat <- data.pisaMath$data  # select items items <- colnames(dat)[ which( substring( colnames(dat), 1, 1)==\"M\" ) ]  #*** # Model 11: Rasch model mod11 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,              pid=dat$idstud, name=\"mod11\") summary(mod11) # read show file shw11 <- sirt::read.show( \"mod11.shw\" ) # read person-item map pi11 <- sirt::read.pimap(showfile=\"mod11.shw\")  #*** # Model 12: Rasch model with fixed item difficulties (from Model 1) mod12 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,              pid=dat$idstud, constraints=mod11$item[, c(\"item\",\"itemdiff\")],              name=\"mod12\") summary(mod12)  #*** # Model 13: Latent regression model with predictors female, hisei and migra mod13a <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,              pid=dat$idstud, X=dat[, c(\"female\", \"hisei\", \"migra\") ],              name=\"mod13a\") summary(mod13a)  # latent regression with a subset of predictors mod13b <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,              pid=dat$idstud, X=dat[, c(\"female\", \"hisei\", \"migra\") ],              regression=\"hisei migra\", name=\"mod13b\")  #*** # Model 14: Differential item functioning (female) mod14 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,              pid=dat$idstud, X=dat[, c(\"female\"), drop=FALSE],              model=\"item+female+item*female\",  regression=\"\",  name=\"mod14\")  ############################################################################# # EXAMPLE 2: Polytomous data (data.Students) ############################################################################# library(CDM) data(data.Students) dat <- data.Students  # select items items <- grep.vec( \"act\", colnames(dat) )$x  #*** # Model 21: Partial credit model mod21 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,               model=\"item+item*step\",  name=\"mod21\")  #*** # Model 22: Rating scale model mod22 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,               model=\"item+step\", name=\"mod22\")  #*** # Model 23: Multidimensional model items <- grep.vec( c(\"act\", \"sc\" ), colnames(dat),  \"OR\" )$x qmatrix <- matrix( 0, nrow=length(items), 2 ) qmatrix[1:5,1] <- 1 qmatrix[6:9,2] <- 1 mod23 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,             model=\"item+item*step\", qmatrix=qmatrix, name=\"mod23\")  ############################################################################# # EXAMPLE 3: Multi facet models (data.ratings1) ############################################################################# library(sirt) data(data.ratings1) dat <- data.ratings1  items <- paste0(\"k\",1:5)  # use numeric rater ID's raters <- as.numeric( substring( paste( dat$rater ), 3 ) )  #*** # Model 31: Rater model 'item+item*step+rater' mod31 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,               itemcodes=0:3, model=\"item+item*step+rater\",               pid=dat$idstud, X=data.frame(\"rater\"=raters),               regression=\"\", name=\"mod31\")  #*** # Model 32: Rater model 'item+item*step+rater+item*rater' mod32 <- sirt::R2conquest(dat=dat[,items], path.conquest=path.conquest,               model=\"item+item*step+rater+item*rater\",               pid=dat$idstud, X=data.frame(\"rater\"=raters),               regression=\"\", name=\"mod32\") }"},{"path":"/reference/R2noharm.EAP.html","id":null,"dir":"Reference","previous_headings":"","what":"EAP Factor Score Estimation — R2noharm.EAP","title":"EAP Factor Score Estimation — R2noharm.EAP","text":"function performs EAP factor score estimation item response model estimated NOHARM.","code":""},{"path":"/reference/R2noharm.EAP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EAP Factor Score Estimation — R2noharm.EAP","text":"","code":"R2noharm.EAP(noharmobj, theta.k=seq(-6, 6, len=21), print.output=TRUE)"},{"path":"/reference/R2noharm.EAP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EAP Factor Score Estimation — R2noharm.EAP","text":"noharmobj Object class R2noharm noharm.sirt theta.k Vector discretized theta values posterior evaluated. vector applies dimensions. print.output optional logical indicating whether output displayed console","code":""},{"path":"/reference/R2noharm.EAP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EAP Factor Score Estimation — R2noharm.EAP","text":"list following entries person Data frame person parameter EAP estimates   corresponding standard errors theta Grid multidimensional theta values posterior       evaluated. posterior Individual posterior distribution evaluated theta like Individual likelihood EAP.rel EAP reliabilities dimensions probs Item response probabilities evaluated theta","code":""},{"path":[]},{"path":"/reference/R2noharm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of a NOHARM Analysis from within R — R2noharm","title":"Estimation of a NOHARM Analysis from within R — R2noharm","text":"function enables estimation NOHARM analysis (Fraser & McDonald, 1988; McDonald, 1982a, 1982b, 1997) within R. NOHARM estimates compensatory multidimensional factor analysis dichotomous response data. Arguments function strictly follow rules NOHARM manual (see Fraser & McDonald, 2012; Lee & Lee, 2016).","code":""},{"path":"/reference/R2noharm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of a NOHARM Analysis from within R — R2noharm","text":"","code":"R2noharm(dat=NULL,pm=NULL, n=NULL, model.type, weights=NULL, dimensions=NULL,       guesses=NULL, noharm.path, F.pattern=NULL, F.init=NULL,       P.pattern=NULL, P.init=NULL, digits.pm=4, writename=NULL,       display.fit=5,  dec=\".\", display=TRUE)  # S3 method for R2noharm summary(object, logfile=NULL, ...)"},{"path":"/reference/R2noharm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of a NOHARM Analysis from within R — R2noharm","text":"dat \\(N \\times \\) data frame item responses \\(N\\) subjects \\(\\) items pm matrix vector containing product-moment correlations n Sample size. value must included pm provided. model.type Can \"EFA\" (exploratory factor analysis) \"CFA\" (confirmatory factor analysis). weights Optional vector student weights dimensions Number dimensions exploratory factor analysis guesses optional vector fixed guessing parameters length \\(\\). case default NULL, guessing parameters set zero. noharm.path Local path NOHARM 4 command line 64-bit version located. F.pattern Pattern matrix \\(F\\) (\\(\\times D\\)) F.init Initial matrix \\(F\\) (\\(\\times D\\)) P.pattern Pattern matrix \\(P\\) (\\(D \\times D\\)) P.init Initial matrix \\(P\\) (\\(D \\times D\\)) digits.pm Number digits decimal separator used estimation writename Name NOHARM input output files display.fit many digits (decimal separator) used printing results R console? dec Decimal separator (\".\" \",\") display Display output? object Object class R2noharm logfile File name summary sunk file ... arguments passed","code":""},{"path":"/reference/R2noharm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of a NOHARM Analysis from within R — R2noharm","text":"NOHARM estimates multidimensional compensatory item response model probit link function \\(\\Phi\\). item responses \\(X_{pi}\\) person \\(p\\) item \\(\\) model equation defined $$P( X_{pi}=1 | \\bold{\\theta}_p )=c_i + ( 1 - c_i ) \\Phi( f_{i0} + f_{i1} \\theta_{p1} + ... + f_{iD} \\theta_{pD} ) $$ \\(F=(f_{id})\\) loading matrix \\(P\\) covariance matrix \\(\\bold{\\theta}_p\\). guessing parameters \\(c_i\\) must provided fixed values. definition \\(F\\) \\(P\\) matrices, please consult NOHARM manual. function needs 64-bit command line version can downloaded (links may broken meantime)  http://noharm.niagararesearch.ca/nh4cldl.html  https://noharm.software.informer.com/4.0/    https://cehs.unl.edu/edpsych/software-urls---interesting-sites/","code":""},{"path":"/reference/R2noharm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of a NOHARM Analysis from within R — R2noharm","text":"list following entries tanaka Tanaka index rmsr RMSR statistic N.itempair Sample sizes pairwise item observations pm Product moment matrix weights Used student weights guesses Fixed guessing parameters residuals Residual covariance matrix final.constants Vector final constants thresholds Threshold parameters uniquenesses Item uniquenesses loadings.theta Matrix loadings theta parametrization     (common factor parametrization) factor.cor Covariance matrix factors difficulties Item difficulties (unidimensional models) discriminations Item discriminations (unidimensional models) loadings Loading matrix (latent trait parametrization) model.type Used model type Nobs Number observations Nitems Number items modtype Model type according NOHARM specification (see NOHARM manual) F.init Initial loading matrix \\(F\\) F.pattern Pattern loading matrix \\(F\\) P.init Initial covariance matrix \\(P\\) P.pattern Pattern covariance matrix \\(P\\) dat Original data frame systime System time noharm.path Used NOHARM directory digits.pm Number digits product moment matrix dec Used decimal symbol display.fit Number digits fit display dimensions Number dimensions chisquare Statistic \\(\\chi^2\\) Nestpars Number estimated parameters df Degrees freedom chisquare_df Ratio \\(\\chi^2 / df\\) rmsea RMSEA statistic p.chisquare Significance \\(\\chi^2\\) statistic","code":""},{"path":"/reference/R2noharm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of a NOHARM Analysis from within R — R2noharm","text":"Fraser, C., & McDonald, R. P. (1988). NOHARM: Least squares item factor analysis. Multivariate Behavioral Research, 23, 267-269. https://doi.org/10.1207/s15327906mbr2302_9 Fraser, C., & McDonald, R. P. (2012). NOHARM 4 Manual.  http://noharm.niagararesearch.ca/nh4man/nhman.html. Lee, J. J., & Lee, M. K. (2016). overview normal ogive harmonic analysis robust method (NOHARM) approach item response theory. Tutorials Quantitative Methods Psychology, 12(1), 1-8. https://doi.org/10.20982/tqmp.12.1.p001 McDonald, R. P. (1982a). Linear versus nonlinear models item response theory. Applied Psychological Measurement, 6(4), 379-396. doi:10.1177/014662168200600402 McDonald, R. P. (1982b). Unidimensional multidimensional models item response theory. .R.T., C..T. conference, Minneapolis, 1982, Proceedings. McDonald, R. P. (1997). Normal-ogive multidimensional model. W. van der Linden & R. K. Hambleton (1997): Handbook modern item response theory (pp. 257-269). New York: Springer. http://dx.doi.org/10.1007/978-1-4757-2691-6","code":""},{"path":"/reference/R2noharm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimation of a NOHARM Analysis from within R — R2noharm","text":"Possible errors often occur due wrong dec specification.","code":""},{"path":[]},{"path":[]},{"path":"/reference/R2noharm.jackknife.html","id":null,"dir":"Reference","previous_headings":"","what":"Jackknife Estimation of NOHARM Analysis — R2noharm.jackknife","title":"Jackknife Estimation of NOHARM Analysis — R2noharm.jackknife","text":"function performs jackknife estimation NOHARM analysis get standard errors based replication method (see Christoffersson, 1977).","code":""},{"path":"/reference/R2noharm.jackknife.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jackknife Estimation of NOHARM Analysis — R2noharm.jackknife","text":"","code":"R2noharm.jackknife(object, jackunits=NULL)  # S3 method for R2noharm.jackknife summary(object, logfile=NULL, ...)"},{"path":"/reference/R2noharm.jackknife.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jackknife Estimation of NOHARM Analysis — R2noharm.jackknife","text":"object Object class R2noharm jackunits vector integers number. number, refers number jackknife units. vector integers, vector defines allocation persons jackknife units. Integers corresponds row indexes data set. logfile File name summary sunk file ... arguments passed","code":""},{"path":"/reference/R2noharm.jackknife.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jackknife Estimation of NOHARM Analysis — R2noharm.jackknife","text":"list lists following entries: partable Data frame parameters se.pars List estimated standard errors parameter estimates:     tanaka.stat, rmsr.stat, rmsea.stat,     chisquare_df.stat, thresholds.stat, final.constants.stat,     uniquenesses.stat, factor.cor.stat, loadings.stat,     loadings.theta.stat jackknife.pars List obtained results jackknifing parameters:     j.tanaka, j.rmsr, rmsea, chisquare_df,     j.pm, j.thresholds, j.factor.cor,     j.loadings, j.loadings.theta u.jacknunits Unique jackknife elements","code":""},{"path":"/reference/R2noharm.jackknife.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Jackknife Estimation of NOHARM Analysis — R2noharm.jackknife","text":"Christoffersson, . (1977). Two-step weighted least squares factor analysis dichotomized variables. Psychometrika, 42, 433-438.","code":""},{"path":[]},{"path":"/reference/rasch.copula.html","id":null,"dir":"Reference","previous_headings":"","what":"Multidimensional IRT Copula Model — rasch.copula2","title":"Multidimensional IRT Copula Model — rasch.copula2","text":"function handles local dependence specifying copulas residuals multidimensional item response models dichotomous item responses (Braeken, 2011; Braeken, Tuerlinckx & de Boeck, 2007; Schroeders, Robitzsch & Schipolowski, 2014). Estimation allowed item difficulties, item slopes generalized logistic link function (Stukel, 1988). function rasch.copula3 allows estimation multidimensional models rasch.copula2 handles unidimensional models.","code":""},{"path":"/reference/rasch.copula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multidimensional IRT Copula Model — rasch.copula2","text":"","code":"rasch.copula2(dat, itemcluster, weights=NULL, copula.type=\"bound.mixt\",     progress=TRUE, mmliter=1000, delta=NULL,     theta.k=seq(-4, 4, len=21), alpha1=0, alpha2=0,     numdiff.parm=1e-06,  est.b=seq(1, ncol(dat)),     est.a=rep(1, ncol(dat)), est.delta=NULL, b.init=NULL, a.init=NULL,     est.alpha=FALSE, glob.conv=0.0001, alpha.conv=1e-04, conv1=0.001,     dev.crit=.2, increment.factor=1.01)  rasch.copula3(dat, itemcluster, dims=NULL, copula.type=\"bound.mixt\",     progress=TRUE, mmliter=1000, delta=NULL,     theta.k=seq(-4, 4, len=21), alpha1=0, alpha2=0,     numdiff.parm=1e-06,  est.b=seq(1, ncol(dat)),     est.a=rep(1, ncol(dat)), est.delta=NULL, b.init=NULL, a.init=NULL,     est.alpha=FALSE, glob.conv=0.0001, alpha.conv=1e-04, conv1=0.001,     dev.crit=.2, rho.init=.5, increment.factor=1.01)  # S3 method for rasch.copula2 summary(object, file=NULL, digits=3, ...) # S3 method for rasch.copula3 summary(object, file=NULL, digits=3, ...)  # S3 method for rasch.copula2 anova(object,...) # S3 method for rasch.copula3 anova(object,...)  # S3 method for rasch.copula2 logLik(object,...) # S3 method for rasch.copula3 logLik(object,...)  # S3 method for rasch.copula2 IRT.likelihood(object,...) # S3 method for rasch.copula3 IRT.likelihood(object,...)  # S3 method for rasch.copula2 IRT.posterior(object,...) # S3 method for rasch.copula3 IRT.posterior(object,...)"},{"path":"/reference/rasch.copula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multidimensional IRT Copula Model — rasch.copula2","text":"dat \\(N \\times \\) data frame. Cases missing responses removed analysis. itemcluster integer vector length \\(\\) (number items). Items integers define joint item cluster (positively) locally dependent items. Values zero indicate corresponding item included item cluster dependent responses. weights Optional vector sampling weights dims vector indicating dimension item allocated. default items load first dimension. copula.type character vector containing one following copula types: bound.mixt (boundary mixture copula), cook.johnson (Cook-Johnson copula) frank (Frank copula) (see Braeken, 2011). vector copula.type must match number different itemclusters. every itemcluster, different copula type may specified (see Examples).  progress Print progress? Default TRUE. mmliter Maximum number iterations. delta optional vector starting values dependency parameter delta. theta.k Discretized trait distribution alpha1 alpha1 parameter generalized logistic item response model (Stukel, 1988). default 0 leads together alpha2=0 logistic link function. alpha2 alpha2 parameter generalized logistic item response model numdiff.parm Parameter numerical differentiation est.b Integer vector item difficulties estimated est.Integer vector item discriminations estimated est.delta Integer vector length length(itemcluster). Nonzero integers correspond delta parameters estimated. Equal integers indicate parameter equality constraints. b.init Initial \\(b\\) parameters .init Initial \\(\\) parameters est.alpha alpha parameters estimated? Default FALSE. glob.conv Convergence criterion parameters alpha.conv Maximal change alpha parameters convergence conv1 Maximal change item parameters convergence dev.crit Maximal change deviance. Default .2. rho.init Initial value -diagonal elements correlation matrix increment.factor numeric value larger one controls     size increments iterations. stabilize convergence,     choose values 1.05 1.1 situations. object Object class rasch.copula2 rasch.copula3 file Optional file name summary output digits Number digits decimal summary output ... arguments passed","code":""},{"path":"/reference/rasch.copula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multidimensional IRT Copula Model — rasch.copula2","text":"list following entries N.itemclusters Number item clusters item Estimated item parameters iter Number iterations dev Deviance delta Estimated dependency parameters \\(\\delta\\) b Estimated item difficulties Estimated item slopes mu Mean sigma Standard deviation alpha1 Parameter \\(\\alpha_1\\) generalized item response model alpha2 Parameter \\(\\alpha_2\\) generalized item response model ic Information criteria theta.k Discretized ability distribution pi.k Fixed \\(\\theta\\) distribution deviance Deviance pattern Item response patterns frequencies posterior distribution person Data frame person parameters datalist List generated data frames estimation EAP.rel Reliability EAP copula.type Type copula summary.delta Summary estimated \\(\\delta\\) parameters f.qk.yi Individual posterior f.yi.qk Individual likelihood ... values","code":""},{"path":"/reference/rasch.copula.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multidimensional IRT Copula Model — rasch.copula2","text":"Braeken, J. (2011). boundary mixture approach violations conditional independence. Psychometrika, 76(1), 57-76. doi:10.1007/s11336-010-9190-4 Braeken, J., Kuppens, P., De Boeck, P., & Tuerlinckx, F. (2013). Contextualized personality questionnaires: case copulas structural equation models categorical data. Multivariate Behavioral Research, 48(6), 845-870. doi:10.1080/00273171.2013.827965 Braeken, J., & Tuerlinckx, F. (2009). Investigating latent constructs item response models: MATLAB IRTm toolbox. Behavior Research Methods, 41(4), 1127-1137. Braeken, J., Tuerlinckx, F., & De Boeck, P. (2007). Copula functions residual dependency. Psychometrika, 72(3), 393-411. doi:10.1007/s11336-007-9005-4 Schroeders, U., Robitzsch, ., & Schipolowski, S. (2014). comparison different psychometric approaches modeling testlet structures: example C-tests. Journal Educational Measurement, 51(4), 400-418. doi:10.1111/jedm.12054 Stukel, T. . (1988). Generalized logistic models. Journal American Statistical Association, 83(402), 426-431. doi:10.1080/01621459.1988.10478613","code":""},{"path":[]},{"path":[]},{"path":"/reference/rasch.evm.pcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the Partial Credit Model using the Eigenvector Method — rasch.evm.pcm","title":"Estimation of the Partial Credit Model using the Eigenvector Method — rasch.evm.pcm","text":"function performs eigenvector approach estimate item parameters based pairwise estimation approach (Garner & Engelhard, 2002). assumption person parameters required item parameter estimation. Statistical inference performed Jackknifing. group identifier provided, tests differential item functioning performed.","code":""},{"path":"/reference/rasch.evm.pcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the Partial Credit Model using the Eigenvector Method — rasch.evm.pcm","text":"","code":"rasch.evm.pcm(dat, jackunits=20, weights=NULL, pid=NULL,     group=NULL, powB=2, adj_eps=0.3, progress=TRUE )  # S3 method for rasch.evm.pcm summary(object, digits=3, file=NULL, ...)  # S3 method for rasch.evm.pcm coef(object,...)  # S3 method for rasch.evm.pcm vcov(object,...)"},{"path":"/reference/rasch.evm.pcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the Partial Credit Model using the Eigenvector Method — rasch.evm.pcm","text":"dat Data frame dichotomous polytomous item responses jackunits number Jackknife units (integer provided argument value) vector Jackknife units already defined. weights Optional vector sample weights pid Optional vector person identifiers group Optional vector group identifiers. case, item parameters group wise estimated tests differential item functioning performed. powB Power created \\(B\\) matrix basis parameter estimation adj_eps Adjustment parameter person parameter estimation (see mle.pcm.group) progress optional logical indicating whether progress displayed object Object class rasch.evm.pcm digits Number digits decimals rounding summary. file Optional file name summary sunk file. ... arguments passed","code":""},{"path":"/reference/rasch.evm.pcm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the Partial Credit Model using the Eigenvector Method — rasch.evm.pcm","text":"list following entries item Data frame item parameters. item parameter estimate     denoted est Jackknife bias-corrected estimate     est_jack. Jackknife standard error se. b Item threshold parameters person Data frame person parameters obtained (MLE) B Paired comparison matrix D Transformed paired comparison matrix coef Vector estimated coefficients vcov Covariance matrix estimated item parameters JJ Number jackknife units JJadj Reduced number jackknife units powB Used power comparison matrix \\(B\\) maxK Maximum number categories per item G Number groups desc descriptives difstats Statistics differential item functioning group provided argument","code":""},{"path":"/reference/rasch.evm.pcm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the Partial Credit Model using the Eigenvector Method — rasch.evm.pcm","text":"Choppin, B. (1985). fully conditional estimation procedure Rasch Model parameters. Evaluation Education, 9, 29-42. Garner, M., & Engelhard, G. J. (2002). eigenvector method estimating item parameters dichotomous polytomous Rasch models. Journal Applied Measurement, 3, 107-128. Wang, J., & Engelhard, G. (2014). pairwise algorithm R rater-mediated assessments. Rasch Measurement Transactions, 28(1), 1457-1459.","code":""},{"path":[]},{"path":[]},{"path":"/reference/rasch.jml.biascorr.html","id":null,"dir":"Reference","previous_headings":"","what":"Bias Correction of Item Parameters for Joint Maximum Likelihood Estimation\r\nin the Rasch model — rasch.jml.biascorr","title":"Bias Correction of Item Parameters for Joint Maximum Likelihood Estimation\r\nin the Rasch model — rasch.jml.biascorr","text":"function computes analytical bias correction Rasch model according method Arellano Hahn (2007).","code":""},{"path":"/reference/rasch.jml.biascorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bias Correction of Item Parameters for Joint Maximum Likelihood Estimation\r\nin the Rasch model — rasch.jml.biascorr","text":"","code":"rasch.jml.biascorr(jmlobj,itemfac=NULL)"},{"path":"/reference/rasch.jml.biascorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bias Correction of Item Parameters for Joint Maximum Likelihood Estimation\r\nin the Rasch model — rasch.jml.biascorr","text":"jmlobj object output rasch.jml function itemfac Number items used bias correction. default average number item responses per person.","code":""},{"path":"/reference/rasch.jml.biascorr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bias Correction of Item Parameters for Joint Maximum Likelihood Estimation\r\nin the Rasch model — rasch.jml.biascorr","text":"list following entries b.biascorr Matrix item difficulty estimates. column b.analytcorr1 contains item difficulties analytical bias correction Method 1 Arellano Hahn (2007) whereas b.analytcorr2 corresponds Method 2. b.bias1 Estimated bias Method 1 b.bias2 Estimated bias Method 2 itemfac Number items used factor bias     correction","code":""},{"path":"/reference/rasch.jml.biascorr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bias Correction of Item Parameters for Joint Maximum Likelihood Estimation\r\nin the Rasch model — rasch.jml.biascorr","text":"Arellano, M., & Hahn, J. (2007). Understanding bias nonlinear panel models: recent developments. R. Blundell, W. Newey & T. Persson (Eds.): Advances Economics Econometrics, Ninth World Congress, Cambridge University Press.","code":""},{"path":[]},{"path":"/reference/rasch.jml.biascorr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bias Correction of Item Parameters for Joint Maximum Likelihood Estimation\r\nin the Rasch model — rasch.jml.biascorr","text":"","code":"############################################################################# # EXAMPLE 1: Dataset Reading ############################################################################# data(data.read) dat <- data( data.read )  # estimate Rasch model mod <- sirt::rasch.jml( data.read  )  # JML with analytical bias correction res1 <- sirt::rasch.jml.biascorr( jmlobj=mod  ) print( res1$b.biascorr, digits=3 )   ##        b.JML b.JMLcorr b.analytcorr1 b.analytcorr2   ##   1  -2.0086   -1.8412        -1.908        -1.922   ##   2  -1.1121   -1.0194        -1.078        -1.088   ##   3  -0.0718   -0.0658        -0.150        -0.127   ##   4   0.5457    0.5002         0.393         0.431   ##   5  -0.9504   -0.8712        -0.937        -0.936   ##  [...]"},{"path":"/reference/rasch.jml.html","id":null,"dir":"Reference","previous_headings":"","what":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","title":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","text":"function estimates Rasch model using joint maximum likelihood estimation (Lincare, 1994). PROX algorithm (Lincare, 1994) used generation starting values item parameters.","code":""},{"path":"/reference/rasch.jml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","text":"","code":"rasch.jml(dat, method=\"MLE\", b.init=NULL, constraints=NULL, weights=NULL,     center=\"persons\", glob.conv=10^(-6), conv1=1e-05, conv2=0.001, progress=TRUE,     bsteps=4, thetasteps=2, wle.adj=0, jmliter=100, prox=TRUE,     proxiter=30, proxconv=0.01, dp=NULL, theta.init=NULL, calc.fit=TRUE,     prior_sd=NULL)  # S3 method for rasch.jml summary(object, digits=3, ...)"},{"path":"/reference/rasch.jml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","text":"dat \\(N \\times \\) data frame dichotomous item responses       \\(N\\) indicates number persons \\(\\) number items method Method estimating person parameters JML iterations. MLE maximum likelihood estimation (person perfect scores deleted analysis). WLE uses weighted likelihood estimation (Warm, 1989) person parameter estimation. Default MLE. b.init Initial values item difficulties constraints Optional matrix data.frame two columns. First column integer item indexes item names (colnames(dat)) shall fixed estimation. second column corresponding item difficulty. weights Person sample weights. Default NULL, .e. persons sample equally weighted. center Character indicator whether persons (\"persons\"), items (\"items\") centered (\"none\") conducted. glob.conv Global convergence criterion respect log-likelihood function conv1 Convergence criterion estimation item parameters conv2 Convergence criterion estimation person parameters progress Display progress? Default TRUE  bsteps Number steps b parameter estimation thetasteps Number steps theta parameter estimation wle.adj Score adjustment WLE estimation jmliter Number maximal iterations JML estimation prox PROX algorithm (see rasch.prox) used initial estimations? Default TRUE. proxiter Number maximal PROX iterations proxconv Convergence criterion PROX iterations dp Object created data preparation function (.data.prep)  created earlier JML runs. Default NULL. theta.init Initial person parameter estimate calc.fit itemfit calculated? prior_sd Optional value standard deviation prior distribution  ability values penalized JML utilized object Object class rasch.jml digits Number digits used rounding ... arguments passed","code":""},{"path":"/reference/rasch.jml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","text":"estimation known bias item parameters fixed (finite) number items. literature (Lincare, 1994), simple bias correction formula proposed included value item$itemdiff.correction function. \\(\\) denotes number items, correction factor \\(\\frac{-1}{}\\).","code":""},{"path":"/reference/rasch.jml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","text":"list following entries item Estimated item parameters person Estimated person parameters method Person parameter estimation method dat Original data frame deviance Deviance data.proc Processed data frames excluding persons extreme scores dp Value data preparation (used function rasch.jml.jackknife1)","code":""},{"path":"/reference/rasch.jml.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","text":"Linacre, J. M. (1994). Many-Facet Rasch Measurement. Chicago: MESA Press. Warm, T. . (1989). Weighted likelihood estimation ability item  response theory. Psychometrika, 54, 427-450.","code":""},{"path":[]},{"path":"/reference/rasch.jml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Joint Maximum Likelihood (JML) Estimation of the Rasch Model — rasch.jml","text":"","code":"############################################################################# # EXAMPLE 1: Simulated data from the Rasch model #############################################################################  set.seed(789) N <- 500    # number of persons I <- 11     # number of items b <- seq( -2, 2, length=I ) dat <- sirt::sim.raschtype( stats::rnorm( N, mean=.5 ), b ) colnames(dat) <- paste( \"I\", 1:I, sep=\"\")  # JML estimation of the Rasch model (centering persons) mod1 <- sirt::rasch.jml( dat ) summary(mod1)  # JML estimation of the Rasch model (centering items) mod1b <- sirt::rasch.jml( dat, center=\"items\" ) summary(mod1b)  # MML estimation with rasch.mml2 function mod2 <- sirt::rasch.mml2( dat ) summary(mod2)  # Pairwise method of Fischer mod3 <- sirt::rasch.pairwise( dat ) summary(mod3)  # JML estimation in TAM if (FALSE) { library(TAM) mod4 <- TAM::tam.jml( resp=dat )  #****** # item parameter constraints in JML estimation # fix item difficulties: b[4]=-.76 and b[6]=.10 constraints <- matrix( cbind( 4, -.76,                               6, .10 ),                   ncol=2, byrow=TRUE ) mod6 <- sirt::rasch.jml( dat, constraints=constraints ) summary(mod6)   # For constrained item parameters, it this not obvious   # how to calculate a 'right correction' of item parameter bias }"},{"path":"/reference/rasch.jml.jackknife1.html","id":null,"dir":"Reference","previous_headings":"","what":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","title":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","text":"Jackknife estimation alternative ad hoc proposed methods bias correction (Hahn & Newey, 2004).","code":""},{"path":"/reference/rasch.jml.jackknife1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","text":"","code":"rasch.jml.jackknife1(jmlobj)"},{"path":"/reference/rasch.jml.jackknife1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","text":"jmlobj Output rasch.jml","code":""},{"path":"/reference/rasch.jml.jackknife1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","text":"Note items used jackknifing (Hahn & Newey, 2004). default, \\(\\) items data frame used jackknife units.","code":""},{"path":"/reference/rasch.jml.jackknife1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","text":"list following entries item data frame item parameters b.JML: Item difficulty JML estimation b.JMLcorr: Item difficulty JML estimation                     applying correction factor \\((-1)/\\) b.jack: Item difficulty Jackknife estimation b.jackse: Standard error Jackknife estimation                         item difficulties.                         Note parameter refer standard error                     respect item sampling b.JMLse: Standard error item difficulties                     obtained JML estimation  jack.itemdiff matrix containing item difficulties obtained Jackknife","code":""},{"path":"/reference/rasch.jml.jackknife1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","text":"Hahn, J., & Newey, W. (2004). Jackknife analytical bias reduction nonlinear panel models. Econometrica, 72, 1295-1319.","code":""},{"path":[]},{"path":"/reference/rasch.jml.jackknife1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jackknifing the IRT Model Estimated by Joint Maximum Likelihood (JML) — rasch.jml.jackknife1","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Simulated data from the Rasch model ############################################################################# set.seed(7655) N <- 5000    # number of persons I <- 11      # number of items b <- seq( -2, 2, length=I ) dat <- sirt::sim.raschtype( rnorm( N ), b ) colnames(dat) <- paste( \"I\", 1:I, sep=\"\")  # estimate the Rasch model with JML mod <- sirt::rasch.jml(dat) summary(mod)  # re-estimate the Rasch model using Jackknife mod2 <- sirt::rasch.jml.jackknife1( mod )   ##   ##   Joint Maximum Likelihood Estimation   ##   Jackknife Estimation   ##   11 Jackknife Units are used   ##   |--------------------PROGRESS--------------------|   ##   |------------------------------------------------|   ##   ##          N     p  b.JML b.JMLcorr b.jack b.jackse b.JMLse   ##   I1  4929 0.853 -2.345    -2.131 -2.078    0.079   0.045   ##   I2  4929 0.786 -1.749    -1.590 -1.541    0.075   0.039   ##   I3  4929 0.723 -1.298    -1.180 -1.144    0.065   0.036   ##   I4  4929 0.657 -0.887    -0.806 -0.782    0.059   0.035   ##   I5  4929 0.576 -0.420    -0.382 -0.367    0.055   0.033   ##   I6  4929 0.492  0.041     0.038  0.043    0.054   0.033   ##   I7  4929 0.409  0.502     0.457  0.447    0.056   0.034   ##   I8  4929 0.333  0.939     0.854  0.842    0.058   0.035   ##   I9  4929 0.264  1.383     1.257  1.229    0.065   0.037   ##   I10 4929 0.210  1.778     1.617  1.578    0.071   0.040   ##   I11 4929 0.154  2.266     2.060  2.011    0.077   0.044 #-> Item parameters obtained by jackknife seem to be acceptable. }"},{"path":"/reference/rasch.mirtlc.html","id":null,"dir":"Reference","previous_headings":"","what":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"function estimates multidimensional latent class Rasch (1PL) 2PL model (Bartolucci, 2007; Bartolucci, Montanari & Pandolfi, 2012) dichotomous data emerges original latent class model (Goodman, 1974) multidimensional IRT model.","code":""},{"path":"/reference/rasch.mirtlc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"","code":"rasch.mirtlc(dat, Nclasses=NULL, modeltype=\"LC\", dimensions=NULL,     group=NULL, weights=rep(1,nrow(dat)), theta.k=NULL, ref.item=NULL,     distribution.trait=FALSE,  range.b=c(-8,8), range.a=c(.2, 6 ),     progress=TRUE, glob.conv=10^(-5), conv1=10^(-5), mmliter=1000,     mstep.maxit=3, seed=0, nstarts=1, fac.iter=.35)  # S3 method for rasch.mirtlc summary(object,...)  # S3 method for rasch.mirtlc anova(object,...)  # S3 method for rasch.mirtlc logLik(object,...)  # S3 method for rasch.mirtlc IRT.irfprob(object,...)  # S3 method for rasch.mirtlc IRT.likelihood(object,...)  # S3 method for rasch.mirtlc IRT.posterior(object,...)  # S3 method for rasch.mirtlc IRT.modelfit(object,...)  # S3 method for IRT.modelfit.rasch.mirtlc summary(object,...)"},{"path":"/reference/rasch.mirtlc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"dat \\(N \\times \\) data frame Nclasses Number latent classes. trait vector (matrix) theta.k specified, Nclasses set dimension theta.k. modeltype Modeltype. LC latent class model Goodman (1974). MLC1 multidimensional latent class Rasch model item discrimination parameter 1. MLC2 allows estimation item discriminations. dimensions Vector dimension integers allocate items dimensions. group group identifier multiple group estimation weights Vector sample weights theta.k grid theta values can specified theta estimated. one-dimensional case, must vector, \\(D\\)-dimensional case must matrix dimension \\(D\\). ref.item optional vector integers indicate items     whose intercept slope fixed 0 1, respectively. distribution.trait type assumed theta distribution can specified. One alternative normal normal distribution assumption. options smooth2, smooth3 smooth4 use log-linear smoothing  Xu von Davier (2008) smooth distribution  two, three four moments, respectively. function works unidimensional models.  different string provided input (e.g. ), smoothing conducted. range.b Range item difficulties allowed estimation range.Range item slopes allowed estimation progress Display progress? Default TRUE. glob.conv Global relative deviance convergence criterion conv1 Item parameter convergence criterion mmliter Maximum number iterations mstep.maxit Maximum number iterations within M step seed Set random seed latent class estimation. seed can specified. seed negative, function generate random seed. nstarts positive integer provided, nstarts     starts different starting values conducted. fac.iter parameter 0 1 control maximum increment iteration. larger parameter increments become smaller iteration iteration. object Object class rasch.mirtlc ... arguments passed","code":""},{"path":"/reference/rasch.mirtlc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"multidimensional latent class Rasch model (Bartolucci, 2007) item response model combines ideas latent class analysis item response models continuous variables. modeltype=\"MLC2\" following \\(D\\)-dimensional item response model estimated $$logit P(X_{pi}=1 | \\theta_p )=a_i \\theta_{pcd}- b_i$$ Besides item thresholds \\(b_i\\) item slopes \\(a_i\\), prespecified number latent classes \\(c=1,\\ldots,C\\) set \\(C\\) \\(D\\)-dimensional \\(\\{\\theta_{cd} \\}_{cd}\\) vectors estimated. vectors represent locations latent classes. user provides grid theta distribution theta.k argument rasch.mirtlc, ability distribution fixed. unidimensional Rasch model \\(\\) items, \\((+1)/2\\) (\\(\\) odd) \\(/2 + 1\\) (\\(\\) even) trait location parameters identified (see De Leeuw & Verhelst, 1986; Lindsay et al., 1991; review see Formann, 2007).","code":""},{"path":"/reference/rasch.mirtlc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"list following entries pjk Item probabilities evaluated discretized ability distribution rprobs Item response probabilities like pjk,     item category pi.k Estimated trait distribution theta.k Discretized ability distribution item Estimated item parameters trait Estimated ability distribution (theta.k pi.k) mean.trait Estimated mean ability distribution sd.trait Estimated standard deviation ability distribution skewness.trait Estimated skewness ability distribution cor.trait Estimated correlation abilities (applies     multidimensional models) ic Information criteria D Number dimensions G Number groups deviance Deviance ll Log-likelihood Nclasses Number classes modeltype Used model type estep.res Result E step: f.qk.yi individual posterior,     f.yi.qk individual likelihood dat Original data frame devL Vector deviances multiple random starts conducted seedL Vector seed multiple random starts conducted iter Number iterations","code":""},{"path":"/reference/rasch.mirtlc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"Bartolucci, F. (2007). class multidimensional IRT models testing unidimensionality clustering items. Psychometrika, 72(2), 141-157. doi:10.1007/s11336-005-1376-9 Bartolucci, F., Montanari, G. E., & Pandolfi, S. (2012). Dimensionality latent structure item selection via latent class multidimensional IRT models. Psychometrika, 77(4), 782-802. doi:10.1007/s11336-012-9278-0 De Leeuw, J., & Verhelst, N. (1986). Maximum likelihood estimation generalized Rasch models. Journal Educational Behavioral Statistics, 11(3), 183-196. doi:10.3102/10769986011003183 Formann, . K. (2007). (Almost) Equivalence conditional mixture maximum likelihood estimates models Rasch type. M. von Davier & C. H. Carstensen: Multivariate Mixture Distribution Rasch Models (pp. 177-189). Springer: New York. doi:10.1007/978-0-387-49839-3_11 Goodman, L. . (1974). Exploratory latent structure analysis using identifiable unidentifiable models. Biometrika, 61(2), 215-231. doi:10.1093/biomet/61.2.215 Lindsay, B., Clogg, C. C., & Grego, J. (1991). Semiparametric estimation Rasch model related exponential response models, including simple latent class model item analysis. Journal American Statistical Association, 86(413), 96-107. doi:10.1080/01621459.1991.10475008 Xu, X., & von Davier, M. (2008). Fitting structured general diagnostic model NAEP data. ETS Research Report ETS RR-08-27. Princeton, ETS. doi:10.1002/j.2333-8504.2008.tb02113.x","code":""},{"path":"/reference/rasch.mirtlc.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"estimation latent class models, rerunning model different starting values (different random seeds) recommended.","code":""},{"path":[]},{"path":"/reference/rasch.mirtlc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multidimensional Latent Class 1PL and 2PL Model — rasch.mirtlc","text":"","code":"############################################################################# # EXAMPLE 1: Reading data ############################################################################# data( data.read ) dat <- data.read  #*************** # latent class models  # latent class model with 1 class mod1 <- sirt::rasch.mirtlc( dat, Nclasses=1 ) summary(mod1)  # latent class model with 2 classes mod2 <- sirt::rasch.mirtlc( dat, Nclasses=2 ) summary(mod2)  if (FALSE) { # latent class model with 3 classes mod3 <- sirt::rasch.mirtlc( dat, Nclasses=3, seed=- 30) summary(mod3)  # extract individual likelihood lmod3 <- IRT.likelihood(mod3) str(lmod3) # extract likelihood value logLik(mod3) # extract item response functions IRT.irfprob(mod3)  # compare models 1, 2 and 3 anova(mod2,mod3) IRT.compareModels(mod1,mod2,mod3) # avsolute and relative model fit smod2 <- IRT.modelfit(mod2) smod3 <- IRT.modelfit(mod3) summary(smod2) IRT.compareModels(smod2,smod3)  # latent class model with 4 classes and 3 starts with different seeds mod4 <- sirt::rasch.mirtlc( dat, Nclasses=4,seed=-30,  nstarts=3 ) # display different solutions sort(mod4$devL) summary(mod4)  # latent class multiple group model # define group identifier group <- rep( 1, nrow(dat)) group[ 1:150 ] <- 2 mod5 <- sirt::rasch.mirtlc( dat, Nclasses=3, group=group ) summary(mod5)  #************* # Unidimensional IRT models with ordered trait  # 1PL model with 3 classes mod11 <- sirt::rasch.mirtlc( dat, Nclasses=3, modeltype=\"MLC1\", mmliter=30) summary(mod11)  # 1PL model with 11 classes mod12 <- sirt::rasch.mirtlc( dat, Nclasses=11,modeltype=\"MLC1\", mmliter=30) summary(mod12)  # 1PL model with 11 classes and fixed specified theta values mod13 <- sirt::rasch.mirtlc( dat,  modeltype=\"MLC1\",              theta.k=seq( -4, 4, len=11 ), mmliter=100) summary(mod13)  # 1PL model with fixed theta values and normal distribution mod14 <- sirt::rasch.mirtlc( dat,  modeltype=\"MLC1\", mmliter=30,              theta.k=seq( -4, 4, len=11 ), distribution.trait=\"normal\") summary(mod14)  # 1PL model with a smoothed trait distribution (up to 3 moments) mod15 <- sirt::rasch.mirtlc( dat,  modeltype=\"MLC1\", mmliter=30,              theta.k=seq( -4, 4, len=11 ),  distribution.trait=\"smooth3\") summary(mod15)  # 2PL with 3 classes mod16 <- sirt::rasch.mirtlc( dat, Nclasses=3, modeltype=\"MLC2\", mmliter=30 ) summary(mod16)  # 2PL with fixed theta and smoothed distribution mod17 <- sirt::rasch.mirtlc( dat, theta.k=seq(-4,4,len=12), mmliter=30,              modeltype=\"MLC2\", distribution.trait=\"smooth4\"  ) summary(mod17)  # 1PL multiple group model with 8 classes # define group identifier group <- rep( 1, nrow(dat)) group[ 1:150 ] <- 2 mod21 <- sirt::rasch.mirtlc( dat, Nclasses=8, modeltype=\"MLC1\", group=group ) summary(mod21)  #*************** # multidimensional latent class IRT models  # define vector of dimensions dimensions <- rep( 1:3, each=4 )  # 3-dimensional model with 8 classes and seed 145 mod31 <- sirt::rasch.mirtlc( dat, Nclasses=8, mmliter=30,              modeltype=\"MLC1\", seed=145, dimensions=dimensions ) summary(mod31)  # try the model above with different starting values mod31s <- sirt::rasch.mirtlc( dat, Nclasses=8,              modeltype=\"MLC1\", seed=-30, nstarts=30, dimensions=dimensions ) summary(mod31s)  # estimation with fixed theta vectors #=> 4^3=216 classes theta.k <- seq(-4, 4, len=6 ) theta.k <- as.matrix( expand.grid( theta.k, theta.k, theta.k ) ) mod32 <- sirt::rasch.mirtlc( dat,  dimensions=dimensions,               theta.k=theta.k, modeltype=\"MLC1\"  ) summary(mod32)  # 3-dimensional 2PL model mod33 <- sirt::rasch.mirtlc( dat, dimensions=dimensions, theta.k=theta.k, modeltype=\"MLC2\") summary(mod33)  ############################################################################# # EXAMPLE 2: Skew trait distribution ############################################################################# set.seed(789) N <- 1000   # number of persons I <- 20     # number of items theta <- sqrt( exp( stats::rnorm( N ) ) ) theta <- theta - mean(theta ) # calculate skewness of theta distribution mean( theta^3 ) / stats::sd(theta)^3 # simulate item responses dat <- sirt::sim.raschtype( theta, b=seq(-2,2,len=I ) )  # normal distribution mod1 <- sirt::rasch.mirtlc( dat, theta.k=seq(-4,4,len=15), modeltype=\"MLC1\",                distribution.trait=\"normal\", mmliter=30)  # allow for skew distribution with smoothed distribution mod2 <- sirt::rasch.mirtlc( dat, theta.k=seq(-4,4,len=15), modeltype=\"MLC1\",                distribution.trait=\"smooth3\", mmliter=30)  # nonparametric distribution mod3 <- sirt::rasch.mirtlc( dat, theta.k=seq(-4,4,len=15), modeltype=\"MLC1\", mmliter=30)  summary(mod1) summary(mod2) summary(mod3)  ############################################################################# # EXAMPLE 3: Stouffer-Toby dataset data.si02 with 5 items #############################################################################  data(dat.si02) dat <- data.si02$data weights <- data.si02$weights   # extract weights  # Model 1: 2 classes Rasch model mod1 <- sirt::rasch.mirtlc( dat, Nclasses=2, modeltype=\"MLC1\", weights=weights,                  ref.item=4, nstarts=5) summary(mod1)  # Model 2: 3 classes Rasch model: not all parameters are identified mod2 <- sirt::rasch.mirtlc( dat, Nclasses=3, modeltype=\"MLC1\", weights=weights,                 ref.item=4, nstarts=5) summary(mod2)  # Model 3: Latent class model with 2 classes mod3 <- sirt::rasch.mirtlc( dat, Nclasses=2, modeltype=\"LC\", weights=weights, nstarts=5) summary(mod3)  # Model 4: Rasch model with normal distribution mod4 <- sirt::rasch.mirtlc( dat,  modeltype=\"MLC1\", weights=weights,             theta.k=seq( -6, 6, len=21 ), distribution.trait=\"normal\", ref.item=4) summary(mod4) }  ############################################################################# # EXAMPLE 4: 5 classes, 3 dimensions and 27 items #############################################################################  set.seed(979) I <- 9 N <- 5000 b <- seq( - 1.5, 1.5, len=I) b <- rep(b,3) # define class locations theta.k <- c(-3.0, -4.1, -2.8, 1.7, 2.3, 1.8,    0.2, 0.4, -0.1,   2.6, 0.1, -0.9, -1.1,-0.7, 0.9 )  Nclasses <- 5 theta.k0 <- theta.k <- matrix( theta.k, Nclasses, 3, byrow=TRUE ) pi.k <- c(.20,.25,.25,.10,.15) theta <- theta.k[ rep( 1:Nclasses, round(N*pi.k) ), ] dimensions <- rep( 1:3, each=I) # simulate item responses dat <- matrix( NA, nrow=N, ncol=I*3) for (ii in 1:(3*I) ){     dat[,ii] <- 1 * ( stats::runif(N) < stats::plogis( theta[,dimensions[ii]] - b[ii])) } colnames(dat) <- paste0( rep( LETTERS[1:3], each=I ), 1:(3*I) )  # estimate model mod1 <- sirt::rasch.mirtlc( dat, Nclasses=Nclasses, dimensions=dimensions,              modeltype=\"MLC1\", ref.item=c(5,14,23), glob.conv=.0005, conv1=.0005)  round( cbind( mod1$theta.k, mod1$pi.k ), 3 )   ##          [,1]   [,2]   [,3]  [,4]   ##   [1,] -2.776 -3.791 -2.667 0.250   ##   [2,] -0.989 -0.605  0.957 0.151   ##   [3,]  0.332  0.418 -0.046 0.246   ##   [4,]  2.601  0.171 -0.854 0.101   ##   [5,]  1.791  2.330  1.844 0.252 cbind( theta.k, pi.k )   ##                       pi.k   ##   [1,] -3.0 -4.1 -2.8 0.20   ##   [2,]  1.7  2.3  1.8 0.25   ##   [3,]  0.2  0.4 -0.1 0.25   ##   [4,]  2.6  0.1 -0.9 0.10   ##   [5,] -1.1 -0.7  0.9 0.15  # plot class locations plot( 1:3, mod1$theta.k[1,], xlim=c(1,3), ylim=c(-5,3), col=1, pch=1, type=\"n\",     axes=FALSE, xlab=\"Dimension\", ylab=\"Location\") axis(1, 1:3 ) ;  axis(2) ; axis(4) for (cc in 1:Nclasses){ # cc <- 1     lines(1:3, mod1$theta.k[cc,], col=cc, lty=cc )     points(1:3, mod1$theta.k[cc,], col=cc,  pch=cc ) }  if (FALSE) { #------ # estimate model with gdm function in CDM package library(CDM) # define Q-matrix Qmatrix <- matrix(0,3*I,3) Qmatrix[ cbind( 1:(3*I), rep(1:3, each=I) ) ] <- 1  set.seed(9176) # random starting values for theta locations theta.k <- matrix( 2*stats::rnorm(5*3), 5, 3 ) colnames(theta.k) <- c(\"Dim1\",\"Dim2\",\"Dim3\") # try possibly different starting values  # estimate model in CDM b.constraint  <- cbind( c(5,14,23), 1, 0 ) mod2 <- CDM::gdm( dat, theta.k=theta.k, b.constraint=b.constraint, skillspace=\"est\",                irtmodel=\"1PL\",  Qmatrix=Qmatrix) summary(mod2)  #------ # estimate model with MultiLCIRT package miceadds::library_install(\"MultiLCIRT\")  # define matrix to allocate each item to one dimension multi1 <- matrix( 1:(3*I), nrow=3, byrow=TRUE ) # define reference items in item-dimension allocation matrix multi1[ 1, c(1,5)  ] <- c(5,1) multi1[ 2, c(10,14) - 9  ] <- c(14,9) multi1[ 3, c(19,23) - 18 ] <- c(23,19)  # Rasch model with 5 latent classes (random start: start=1) mod3 <- MultiLCIRT::est_multi_poly(S=dat,k=5,       # k=5 ability levels                 start=1,link=1,multi=multi1,tol=10^-5,                 output=TRUE, disp=TRUE, fort=TRUE) # estimated location points and class probabilities in MultiLCIRT cbind( t( mod3$Th ), mod3$piv ) # compare results with rasch.mirtlc cbind( mod1$theta.k, mod1$pi.k ) # simulated data parameters cbind( theta.k, pi.k )  #---- # estimate model with cutomized input in mirt library(mirt) #-- define Theta design matrix for 5 classes Theta <- diag(5) Theta <- cbind( Theta, Theta, Theta ) r1 <- rownames(Theta) <- paste0(\"C\",1:5) colnames(Theta) <- c( paste0(r1, \"D1\"), paste0(r1, \"D2\"), paste0(r1, \"D3\") )   ##      C1D1 C2D1 C3D1 C4D1 C5D1 C1D2 C2D2 C3D2 C4D2 C5D2 C1D3 C2D3 C3D3 C4D3 C5D3   ##   C1    1    0    0    0    0    1    0    0    0    0    1    0    0    0    0   ##   C2    0    1    0    0    0    0    1    0    0    0    0    1    0    0    0   ##   C3    0    0    1    0    0    0    0    1    0    0    0    0    1    0    0   ##   C4    0    0    0    1    0    0    0    0    1    0    0    0    0    1    0   ##   C5    0    0    0    0    1    0    0    0    0    1    0    0    0    0    1 #-- define mirt model I <- ncol(dat)  # I=27 mirtmodel <- mirt::mirt.model(\"         C1D1=1-9 \\n C2D1=1-9 \\n  C3D1=1-9 \\n  C4D1=1-9  \\n  C5D1=1-9         C1D2=10-18 \\n C2D2=10-18 \\n  C3D2=10-18 \\n  C4D2=10-18  \\n  C5D2=10-18         C1D3=19-27 \\n C2D3=19-27 \\n  C3D3=19-27 \\n  C4D3=19-27  \\n  C5D3=19-27         CONSTRAIN=(1-9,a1),(1-9,a2),(1-9,a3),(1-9,a4),(1-9,a5),                     (10-18,a6),(10-18,a7),(10-18,a8),(10-18,a9),(10-18,a10),                     (19-27,a11),(19-27,a12),(19-27,a13),(19-27,a14),(19-27,a15)                 \") #-- get initial parameter values mod.pars <- mirt::mirt(dat, model=mirtmodel,  pars=\"values\") #-- redefine initial parameter values # set all d parameters initially to zero ind <- which( ( mod.pars$name==\"d\" ) ) mod.pars[ ind,\"value\" ]  <- 0 # fix item difficulties of reference items to zero mod.pars[ ind[ c(5,14,23) ], \"est\"] <- FALSE mod.pars[ind,] # initial item parameters of cluster locations (a1,...,a15) ind <- which( ( mod.pars$name %in% paste0(\"a\", c(1,6,11) ) ) & ( mod.pars$est ) ) mod.pars[ind,\"value\"] <- -2 ind <- which( ( mod.pars$name %in% paste0(\"a\", c(1,6,11)+1 ) ) & ( mod.pars$est ) ) mod.pars[ind,\"value\"] <- -1 ind <- which( ( mod.pars$name %in% paste0(\"a\", c(1,6,11)+2 ) ) & ( mod.pars$est ) ) mod.pars[ind,\"value\"] <- 0 ind <- which( ( mod.pars$name %in% paste0(\"a\", c(1,6,11)+3 ) ) & ( mod.pars$est ) ) mod.pars[ind,\"value\"] <- 1 ind <- which( ( mod.pars$name %in% paste0(\"a\", c(1,6,11)+4 ) ) & ( mod.pars$est ) ) mod.pars[ind,\"value\"] <- 0 #-- define prior for latent class analysis lca_prior <- function(Theta,Etable){   TP <- nrow(Theta)   if ( is.null(Etable) ){ prior <- rep( 1/TP, TP ) }   if ( ! is.null(Etable) ){     prior <- ( rowSums(Etable[, seq(1,2*I,2)]) + rowSums(Etable[,seq(2,2*I,2)]) )/I   }   prior <- prior / sum(prior)   return(prior) }  #-- estimate model in mirt mod4 <- mirt::mirt(dat, mirtmodel, pars=mod.pars, verbose=TRUE,               technical=list( customTheta=Theta, customPriorFun=lca_prior,                     MAXQUAD=1E20) ) # correct number of estimated parameters mod4@nest <- as.integer(sum(mod.pars$est) + nrow(Theta)-1 ) # extract coefficients # source.all(pfsirt) cmod4 <- sirt::mirt.wrapper.coef(mod4)  # estimated item difficulties dfr <- data.frame( \"sim\"=b, \"mirt\"=-cmod4$coef$d, \"sirt\"=mod1$item$thresh ) round( dfr, 4 )   ##         sim    mirt    sirt   ##   1  -1.500 -1.3782 -1.3382   ##   2  -1.125 -1.0059 -0.9774   ##   3  -0.750 -0.6157 -0.6016   ##   4  -0.375 -0.2099 -0.2060   ##   5   0.000  0.0000  0.0000   ##   6   0.375  0.5085  0.4984   ##   7   0.750  0.8661  0.8504   ##   8   1.125  1.3079  1.2847   ##   9   1.500  1.5891  1.5620   ##   [...]  #-- reordering estimated latent clusters to make solutions comparable #* extract estimated cluster locations from sirt order.sirt <- c(1,5,3,4,2)  # sort(order.sirt) round(mod1$trait[,1:3],3) dfr <- data.frame( \"sim\"=theta.k, mod1$trait[order.sirt,1:3] ) colnames(dfr)[4:6] <- paste0(\"sirt\",1:3) #* extract estimated cluster locations from mirt c4 <- cmod4$coef[, paste0(\"a\",1:15) ] c4 <- apply( c4,2, FUN=function(ll){ ll[ ll!=0 ][1] } ) trait.loc <- matrix(c4,5,3) order.mirt <- c(1,4,3,5,2)  # sort(order.mirt) dfr <- cbind( dfr, trait.loc[ order.mirt, ] ) colnames(dfr)[7:9] <- paste0(\"mirt\",1:3) # compare estimated cluster locations round(dfr,3)   ##     sim.1 sim.2 sim.3  sirt1  sirt2  sirt3  mirt1  mirt2  mirt3   ##   1  -3.0  -4.1  -2.8 -2.776 -3.791 -2.667 -2.856 -4.023 -2.741   ##   5   1.7   2.3   1.8  1.791  2.330  1.844  1.817  2.373  1.869   ##   3   0.2   0.4  -0.1  0.332  0.418 -0.046  0.349  0.421 -0.051   ##   4   2.6   0.1  -0.9  2.601  0.171 -0.854  2.695  0.166 -0.876   ##   2  -1.1  -0.7   0.9 -0.989 -0.605  0.957 -1.009 -0.618  0.962 #* compare estimated cluster sizes dfr <- data.frame( \"sim\"=pi.k, \"sirt\"=mod1$pi.k[order.sirt,1],             \"mirt\"=mod4@Prior[[1]][ order.mirt] ) round(dfr,4)   ##      sim   sirt   mirt   ##   1 0.20 0.2502 0.2500   ##   2 0.25 0.2522 0.2511   ##   3 0.25 0.2458 0.2494   ##   4 0.10 0.1011 0.0986   ##   5 0.15 0.1507 0.1509  ############################################################################# # EXAMPLE 5: Dataset data.si04 from Bartolucci et al. (2012) #############################################################################  data(data.si04)  # define reference items ref.item <- c(7,17,25,44,64) dimensions <- data.si04$itempars$dim  # estimate a Rasch latent class with 9 classes mod1 <- sirt::rasch.mirtlc( data.si04$data, Nclasses=9, dimensions=dimensions,              modeltype=\"MLC1\", ref.item=ref.item, glob.conv=.005, conv1=.005,              nstarts=1, mmliter=200 )  # compare estimated distribution with simulated distribution round( cbind( mod1$theta.k, mod1$pi.k ), 4 ) # estimated   ##            [,1]    [,2]    [,3]    [,4]    [,5]   [,6]   ##    [1,] -3.6043 -5.1323 -5.3022 -6.8255 -4.3611 0.1341   ##    [2,]  0.2083 -2.7422 -2.8754 -5.3416 -2.5085 0.1573   ##    [3,] -2.8641 -4.0272 -5.0580 -0.0340 -0.9113 0.1163   ##    [4,] -0.3575 -2.0081 -1.7431  1.2992 -0.1616 0.0751   ##    [5,]  2.9329  0.3662 -1.6516 -3.0284  0.1844 0.1285   ##    [6,]  1.5092 -2.0461 -4.3093  1.0481  1.0806 0.1094   ##    [7,]  3.9899  3.1955 -4.0010  1.8879  2.2988 0.1460   ##    [8,]  4.3062  0.7080 -1.2324  1.4351  2.0893 0.1332   ##    [9,]  5.0855  4.1214 -0.9141  2.2744  1.5314 0.0000  round(d2,4) # simulated   ##         class      A      B      C      D      E     pi   ##    [1,]     1 -3.832 -5.399 -5.793 -7.042 -4.511 0.1323   ##    [2,]     2 -2.899 -4.217 -5.310 -0.055 -0.915 0.1162   ##    [3,]     3 -0.376 -2.137 -1.847  1.273 -0.078 0.0752   ##    [4,]     4  0.208 -2.934 -3.011 -5.526 -2.511 0.1583   ##    [5,]     5  1.536 -2.137 -4.606  1.045  1.143 0.1092   ##    [6,]     6  2.042 -0.573 -0.404 -4.331 -1.044 0.0471   ##    [7,]     7  3.853  0.841 -2.993 -2.746  0.803 0.0822   ##    [8,]     8  4.204  3.296 -4.328  1.892  2.419 0.1453   ##    [9,]     9  4.466  0.700 -1.334  1.439  2.161 0.1343 }"},{"path":"/reference/rasch.mml.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"function employs marginal maximum likelihood estimation item response models dichotomous data. First, Rasch type model (generalized item response model) can estimated. generalized logistic link function (Stukel, 1988) can estimated fixed conducting IRT different link functions logistic one. Four-Parameter logistic item response model special case model (Loken & Rulison, 2010). Second, Ramsay's quotient model (Ramsay, 1989) can estimated specifying irtmodel=\"ramsay.qm\". Third, quite general item response functions can estimated nonparametric framework (Rossi, Wang & Ramsay, 2002). Fourth, pseudo-likelihood estimation fractional item responses can conducted Rasch type models. Fifth, simple two-dimensional missing data item response model (irtmodel='missing1'; Mislevy & Wu, 1996) can estimated. See Details explanations.","code":""},{"path":"/reference/rasch.mml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"","code":"rasch.mml2( dat, theta.k=seq(-6,6,len=21), group=NULL, weights=NULL,    constraints=NULL, glob.conv=10^(-5), parm.conv=10^(-4), mitermax=4,    mmliter=1000, progress=TRUE,  fixed.a=rep(1,ncol(dat)),    fixed.c=rep(0,ncol(dat)), fixed.d=rep(1,ncol(dat)),    fixed.K=rep(3,ncol(dat)), b.init=NULL, est.a=NULL, est.b=NULL,    est.c=NULL, est.d=NULL, min.b=-99, max.b=99, min.a=-99, max.a=99,    min.c=0, max.c=1, min.d=0, max.d=1, prior.b=NULL, prior.a=NULL, prior.c=NULL,    prior.d=NULL, est.K=NULL, min.K=1, max.K=20, min.delta=-20, max.delta=20,    beta.init=NULL, min.beta=-8, pid=1:(nrow(dat)), trait.weights=NULL,  center.trait=TRUE,    center.b=FALSE, alpha1=0, alpha2=0,est.alpha=FALSE, equal.alpha=FALSE,    designmatrix=NULL, alpha.conv=parm.conv, numdiff.parm=0.00001,    numdiff.alpha.parm=numdiff.parm, distribution.trait=\"normal\", Qmatrix=NULL,    variance.fixed=NULL, variance.init=NULL,    mu.fixed=cbind(seq(1,ncol(Qmatrix)),rep(0,ncol(Qmatrix))),    irtmodel=\"raschtype\", npformula=NULL, npirt.monotone=TRUE,    use.freqpatt=is.null(group), delta.miss=0, est.delta=rep(NA,ncol(dat)),    nimps=0, ... )  # S3 method for rasch.mml summary(object, file=NULL, ...)  # S3 method for rasch.mml plot(x, items=NULL, xlim=NULL, main=NULL, ...)  # S3 method for rasch.mml anova(object,...)  # S3 method for rasch.mml logLik(object,...)  # S3 method for rasch.mml IRT.irfprob(object,...)  # S3 method for rasch.mml IRT.likelihood(object,...)  # S3 method for rasch.mml IRT.posterior(object,...)  # S3 method for rasch.mml IRT.modelfit(object,...)  # S3 method for rasch.mml IRT.expectedCounts(object,...)  # S3 method for IRT.modelfit.rasch.mml summary(object,...)"},{"path":"/reference/rasch.mml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"dat \\(N \\times \\) data frame dichotomous item responses.  missing data item response model (irtmodel='missing1'), code item responses 9 treated missing   data model. missing responses can coded NA. theta.k Optional vector discretized theta values. multidimensional IRT models \\(D\\) dimensions, matrix \\(D\\) columns. group Vector integers group identifiers multiple group estimation. multiple group work irtmodel=\"missing1\". weights Optional vector person weights (sample weights). constraints Constraints b parameters (item difficulties). must matrix two columns: first column contains item names, second column fixed parameter values. glob.conv Convergence criterion deviance parm.conv Convergence criterion item parameters mitermax Maximum number iterations M step. argument apply estimation \\(b\\) parameters. mmliter Maximum number iterations progress progress displayed console? fixed.Fixed initial \\(\\) parameters fixed.c Fixed initial \\(c\\) parameters fixed.d Fixed initial \\(d\\) parameters fixed.K Fixed initial \\(K\\) parameters Ramsay's quotient model. b.init Initial \\(b\\) parameters est.Vector integers indicate \\(\\) parameters estimated. Equal integers correspond estimated parameters. est.b Vector integers indicate \\(b\\) parameters estimated. Equal integers correspond estimated parameters. est.c Vector integers indicate \\(c\\) parameters estimated. Equal integers correspond estimated parameters. est.d Vector integers indicate \\(d\\) parameters estimated. Equal integers correspond estimated parameters. min.b Minimal \\(b\\) parameter estimated max.b Maximal \\(b\\) parameter estimated min.Minimal \\(\\) parameter estimated max.Maximal \\(\\) parameter estimated min.c Minimal \\(c\\) parameter estimated max.c Maximal \\(c\\) parameter estimated min.d Minimal \\(d\\) parameter estimated max.d Maximal \\(d\\) parameter estimated prior.b Optional prior distribution \\(b\\) parameters: \\(N(\\mu, \\sigma)\\). Input vector length two parameters \\(\\mu\\) \\(\\sigma\\). prior.Optional prior distribution \\(\\) parameters: \\(N(\\mu, \\sigma)\\). Input vector length two parameters \\(\\mu\\) \\(\\sigma\\). prior.c Optional prior distribution \\(c\\) parameters: \\(Beta(, b)\\). Input vector length two parameters \\(\\) \\(b\\). prior.d Optional prior distribution \\(d\\) parameters: \\(Beta(, b)\\). Input vector length two parameters \\(\\) \\(b\\). est.K Vector integers indicate \\(K\\) parameters estimated. Equal integers correspond estimated parameters. min.K Minimal \\(K\\) parameter estimated max.K Maximal \\(K\\) parameter estimated min.delta Minimal \\(delta.miss\\) parameter estimated max.delta Maximal \\(delta.miss\\) parameter estimated beta.init Optional vector initial \\(\\beta\\) parameters min.beta Minimum \\(\\beta\\) parameter estimated. pid Optional vector person identifiers trait.weights Optional vector trait weights fixing trait distribution. center.trait trait distribution centered center.b optional logical indicating whether \\(b\\) parameters centered dimension alpha1 Fixed initial \\(\\alpha_1\\) parameter alpha2 Fixed initial \\(\\alpha_2\\) parameter est.alpha \\(\\alpha\\) parameters estimated? equal.alpha Estimate \\(\\alpha\\) parameters assumption \\(\\alpha_1=\\alpha_2\\)? designmatrix Design matrix item difficulties \\(b\\) estimate linear logistic test models alpha.conv Convergence criterion \\(\\alpha\\) parameter numdiff.parm Parameter numerical differentiation numdiff.alpha.parm Parameter numerical differentiation \\(\\alpha\\) parameter distribution.trait Assumed trait distribution. default normal distribution (\"normal\"). Log-linear smoothing trait distribution also possible (\"smooth2\", \"smooth3\" \"smooth4\" smoothing 2, 3 4 moments, respectively). Qmatrix Q-matrix variance.fixed Matrix fixing covariance matrix (See Examples) variance.init Optional initial covariance matrix mu.fixed Matrix fixing mean vector (See Examples) irtmodel Specify estimable IRT models: raschtype (Rasch type model), ramsay.qm (Ramsay's quotient model), npirt (Nonparametric item response model). npirt used argument irtmodel, argument npformula specifies different item response functions R formula framework (like \"y~(theta^2)\"; see Examples). estimating missing data item response model, use irtmodel='missing1'. npformula string vector contains R formula objects specifying item response function. example, \"y~theta\" specification 2PL model (see Details). irtmodel=\"npirt\" npformula specified, unrestricted item response functions grid \\(\\theta\\) values estimated. npirt.monotone nonparametrically estimated item response functions     monotone? default TRUE. function applies     irtmodel='npirt' npformula=NULL. use.freqpatt logical frequencies pattern used .     default .null(group). means single     group analyses, frequency patterns used multiple     groups. data processing times large, use.freqpatt=FALSE     recommended. delta.miss Missingness parameter \\(\\delta\\) quantifying meaning     responding item two extremes ignoring      missing responses setting missing responses incorrect est.delta Vector indices indicating \\(\\delta\\) parameters     estimated irtmodel=\"missing1\". nimps Number imputed datasets item responses object Object class rasch.mml x Object class rasch.mml items Vector integer item names plotted xlim Specification xlim plot main Title plot file Optional file name summary output ... arguments passed","code":""},{"path":"/reference/rasch.mml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"item response function generalized item response model (irtmodel=\"raschtype\"; Stukel, 1988) can written $$P( X_{pi}=1 | \\theta_{pd} )=c_i + (d_i - c_i ) g_{\\alpha_1, \\alpha_2} [ a_i ( \\theta_{pd} - b_i ) ] $$ \\(g\\) generalized logistic link function depending parameters \\(\\alpha_1\\) \\(\\alpha_2\\). important link functions specifications (Stukel, 1988): logistic link function: \\(\\alpha_1=0\\) \\(\\alpha_2=0\\)  probit link function: \\(\\alpha_1=0.165\\) \\(\\alpha_2=0.165\\)  loglog link function: \\(\\alpha_1=-0.037\\) \\(\\alpha_2=0.62\\)  cloglog link function: \\(\\alpha_1=0.62\\) \\(\\alpha_2=-0.037\\) See pgenlogis exact transformation formulas mentioned link functions. \\(D\\)-dimensional model can also specified allows item dimensionality (one item loads one dimension). Setting \\(c_i=0\\), \\(d_i=1\\)  \\(a_i=1\\) items \\(\\), additive item response model $$P( X_{pi}=1 | \\theta_p )=g_{\\alpha_1, \\alpha_2} ( \\theta_p - b_i  ) $$ estimated. Ramsay's quotient model (irtmodel=\"qm.ramsay\") uses item response function $$P( X_{pi}=1 | \\theta_p )=\\frac{ \\exp(\\theta_p / b_i)}     { K_i + \\exp (\\theta_p / b_i )} $$ Quite general unidimensional item response models can estimated nonparametric framework (irtmodel=\"npirt\"). response functions linear combination transformed \\(\\theta\\) values $$logit[ P( X_{pi}=1 | \\theta_p ) ]=Y_\\theta \\beta $$ \\(Y_\\theta\\) design matrix \\(\\theta\\) \\(\\beta\\) item parameters estimated. formula \\(Y_\\theta \\beta\\) can specified R formula framework (see Example 3, Model 3c). Pseudo-likelihood estimation can conducted fractional item response data input (.e. item response \\(x_{pi}\\) values 0 1). pseudo-likelihood \\(L_p\\) person \\(p\\) defined $$ L_p=\\prod_i P_i ( \\theta_p )^{x_{pi}} [1-P_i ( \\theta_p )]^{(1-x_{pi})}$$ Note dichotomous responses term corresponds ordinary likelihood. See Example 7. special two-dimensional missing data item response model (irtmodel=\"missing1\") implemented according Mislevy Wu (1996). Besides unidimensional ability \\(\\theta_p\\), individual response propensity \\(\\xi_p\\) proposed. define item responses \\(X_{pi}\\) response indicators \\(R_{pi}\\) indicating whether item responses \\(X_{pi}\\) observed . Denoting logistic function \\(\\Psi\\), item response model ability defined $$ P( X_{pi}=1  | \\theta_p, \\xi_p )=P( X_{pi}=1 | \\theta_p ) =\\Psi( a_i (\\theta_p - b_i ))$$ also define measurement model response indicators \\(R_{pi}\\) depends item response \\(X_{pi}\\) : $$P( R_{pi}=1 | X_{pi}=k, \\theta_p, \\xi_p )=     P( R_{pi}=1 | X_{pi}=k, \\xi_p )= \\Psi \\left[  \\xi_p -  \\beta_i - k \\delta _i  \\right] \\quad \\mbox{ } \\quad k=0,1$$ \\(\\delta _i=0\\), probability responding item independent incompletely observed item \\(X_{pi}\\) item response model nonignorable missings (Holman & Glas, 2005; see also Pohl, Graefe & Rose, 2014). \\(\\delta _i\\) large negative number (e.g. \\(\\delta=-100\\)), follows \\(P( R_{pi}=1 | X_{pi}=1, \\theta_p, \\xi_p )=1\\) consequence holds \\(P(X_{pi}=1 | R_{pi}=0, \\theta_p, \\xi_p)=0\\), equivalent treating missing item responses incorrect. missingness parameter \\(\\delta\\) can specified user studied sensitivity analysis different missing random assumptions can estimated choosing est.delta=TRUE.","code":""},{"path":"/reference/rasch.mml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"list following entries dat Original data frame item Estimated item parameters generalized     item response model item2 Estimated item parameters Ramsay's quotient model trait.distr Discretized ability distribution points probabilities mean.trait Estimated mean vector sd.trait Estimated standard deviations skewness.trait Estimated skewnesses deviance Deviance pjk Estimated probabilities item correct evaluated theta.k rprobs Item response probabilities like pjk, slightly extended accommodate categories person Person parameter estimates: mode (MAP)     mean (EAP) posterior distribution pid Person identifier ability.est.pattern Response pattern estimates f.qk.yi Individual posterior distribution f.yi.qk Individual likelihood fixed.Estimated \\(\\) parameters fixed.c Estimated \\(c\\) parameters G Number groups alpha1 Estimated \\(\\alpha_1\\) parameter generalized logistic     item response model alpha2 Estimated \\(\\alpha_2\\) parameter generalized logistic     item response model se.b Standard error \\(b\\) parameter generalized logistic model     Ramsay's quotient model se.Standard error \\(\\) parameter generalized logistic model se.c Standard error \\(c\\) parameter generalized logistic model se.d Standard error \\(d\\) parameter generalized logistic model se.alpha Standard error \\(\\alpha\\) parameter generalized     logistic model se.K Standard error \\(K\\) parameter Ramsay's quotient model iter Number iterations reliability EAP reliability irtmodel Type estimated item response model D Number dimensions mu Mean vector (multidimensional models) Sigma.cov Covariance matrix (multdimensional models) theta.k Grid discretized ability distributions trait.weights Fixed vector probabilities ability distribution pi.k Trait distribution ic Information criteria esttype Estimation type: ll (Log-Likelihood),     pseudoll (Pseudo-Log-Likelihood) ...","code":""},{"path":"/reference/rasch.mml.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"Holman, R., & Glas, C. . (2005). Modelling non-ignorable missing-data mechanisms item response theory models. British Journal Mathematical Statistical Psychology, 58(1), 1-17. doi:10.1348/000711005X47168 Loken, E., & Rulison, K. L. (2010). Estimation four-parameter item response theory model. British Journal Mathematical Statistical Psychology, 63(3), 509-525. doi:10.1348/000711009X474502 Mislevy, R. J., & Wu, P. K. (1996). Missing responses IRT ability estimation: Omits, choice, time Limits, adaptive testing. ETS Research Report ETS RR-96-30. Princeton, ETS. doi:10.1002/j.2333-8504.1996.tb01708.x Pohl, S., Graefe, L., & Rose, N. (2014). Dealing omitted -reached items competence tests evaluating approaches accounting missing responses item response theory models. Educational Psychological Measurement, 74(3), 423-452. doi:10.1177/0013164413504926 Ramsay, J. O. (1989). comparison three simple test theory models. Psychometrika, 54, 487-499. doi:10.1007/BF02294631 Rossi, N., Wang, X., & Ramsay, J. O. (2002). Nonparametric item response function estimates EM algorithm. Journal Educational Behavioral Statistics, 27(3), 291-317. doi:10.3102/10769986027003291 Stukel, T. . (1988). Generalized logistic models. Journal American Statistical Association, 83(402), 426-431. doi:10.1080/01621459.1988.10478613 van der Maas, H. J. L., Molenaar, D., Maris, G., Kievit, R. ., & Borsboom, D. (2011). Cognitive psychology meets psychometric theory: relation process models decision making latent variable models individual differences. Psychological Review, 118(2), 339-356. doi: 10.1037/a0022749","code":""},{"path":"/reference/rasch.mml.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"Multiple group estimation possible Ramsay's quotient model multdimensional models.","code":""},{"path":[]},{"path":"/reference/rasch.mml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the Generalized Logistic Item Response Model,\r\nRamsay's Quotient Model, Nonparametric Item Response Model,\r\nPseudo-Likelihood Estimation and a Missing Data Item Response Model — rasch.mml2","text":"","code":"############################################################################# # EXAMPLE 1: Reading dataset #############################################################################  library(CDM) data(data.read) dat <- data.read I <- ncol(dat) # number of items  # Rasch model mod1 <- sirt::rasch.mml2( dat ) summary(mod1) plot( mod1 )    # plot all items # title 'Rasch model', display curves from -3 to 3 only for items 1, 5 and 8 plot(mod1, main=\"Rasch model Items 1, 5 and 8\", xlim=c(-3,3), items=c(1,5,8) )  # Rasch model with constraints on item difficulties # set item parameters of A1 and C3 equal to -2 constraints <- data.frame( c(\"A1\",\"C3\"), c(-2,-2) ) mod1a <- sirt::rasch.mml2( dat, constraints=constraints) summary(mod1a)  # estimate equal item parameters for 1st and 11th item est.b <- 1:I est.b[11] <- 1 mod1b <- sirt::rasch.mml2( dat, est.b=est.b ) summary(mod1b)  # estimate Rasch model with skew trait distribution mod1c <- sirt::rasch.mml2( dat, distribution.trait=\"smooth3\") summary(mod1c)  # 2PL model mod2 <- sirt::rasch.mml2( dat, est.a=1:I ) summary(mod2) plot(mod2)    # plot 2PL item response curves  # extract individual likelihood llmod2 <- IRT.likelihood(mod2) str(llmod2)  if (FALSE) { library(CDM) # model comparisons CDM::IRT.compareModels(mod1, mod1c, mod2 ) anova(mod1,mod2)  # assess model fit smod1 <- IRT.modelfit(mod1) smod2 <- IRT.modelfit(mod2) IRT.compareModels(smod1, smod2)  # set some bounds for a and b parameters mod2a <- sirt::rasch.mml2( dat, est.a=1:I, min.a=.7, max.a=2, min.b=-2 ) summary(mod2a)  # 3PL model mod3 <- sirt::rasch.mml2( dat, est.a=1:I, est.c=1:I,               mmliter=400 # maximal 400 iterations                  ) summary(mod3)  # 3PL model with fixed guessing paramters of .25 and equal slopes mod4 <- sirt::rasch.mml2( dat, fixed.c=rep( .25, I )   ) summary(mod4)  # 3PL model with equal guessing paramters for all items mod5 <- sirt::rasch.mml2( dat, est.c=rep(1, I )   ) summary(mod5)  # difficulty + guessing model mod6 <- sirt::rasch.mml2( dat, est.c=1:I   ) summary(mod6)  # 4PL model mod7 <- sirt::rasch.mml2( dat, est.a=1:I, est.c=1:I, est.d=1:I,             min.d=.95, max.c=.25)         # set minimal d and maximal c parameter to .95 and .25 summary(mod7)  # 4PL model with prior distributions mod7b <- sirt::rasch.mml2( dat, est.a=1:I, est.c=1:I, est.d=1:I, prior.a=c(1,2),             prior.c=c(5,17), prior.d=c(20,2) ) summary(mod7b)  # constrained 4PL model # equal slope, guessing and slipping parameters mod8 <- sirt::rasch.mml2( dat,est.c=rep(1,I), est.d=rep(1,I) ) summary(mod8)  # estimation of an item response model with an # uniform theta distribution theta.k <- seq( 0.01, .99, len=20 ) trait.weights <- rep( 1/length(theta.k), length(theta.k) ) mod9 <- sirt::rasch.mml2( dat, theta.k=theta.k, trait.weights=trait.weights,               normal.trait=FALSE, est.a=1:12  ) summary(mod9)  ############################################################################# # EXAMPLE 2: Longitudinal data #############################################################################  data(data.long) dat <- data.long[,-1]  # define Q loading matrix Qmatrix <- matrix( 0, 12, 2 ) Qmatrix[1:6,1] <- 1 # T1 items Qmatrix[7:12,2] <- 1    # T2 items  # define restrictions on item difficulties est.b <- c(1,2,3,4,5,6,   3,4,5,6,7,8) mu.fixed <- cbind(1,0)     # set first mean to 0 for identification reasons  # Model 1: 2-dimensional Rasch model mod1 <- sirt::rasch.mml2( dat, Qmatrix=Qmatrix, miterstep=4,             est.b=est.b,  mu.fixed=mu.fixed, mmliter=30 ) summary(mod1) plot(mod1) ##     Plot function is only applicable for unidimensional models }  ############################################################################# # EXAMPLE 3: One group, estimation of alpha parameter in the generalized logistic model #############################################################################  # simulate theta values set.seed(786) N <- 1000                  # number of persons theta <- stats::rnorm( N, sd=1.5 ) # N persons with SD 1.5 b <- seq( -2, 2, len=15)  # simulate data dat <- sirt::sim.raschtype( theta=theta, b=b, alpha1=0, alpha2=-0.3 )  #  estimating alpha parameters mod1 <- sirt::rasch.mml2( dat, est.alpha=TRUE, mmliter=30 ) summary(mod1) plot(mod1)  if (FALSE) { # fixed alpha parameters mod1b <- sirt::rasch.mml2( dat, est.alpha=FALSE, alpha1=0, alpha2=-.3 ) summary(mod1b)  # estimation with equal alpha parameters mod1c <- sirt::rasch.mml2( dat, est.alpha=TRUE, equal.alpha=TRUE ) summary(mod1c)  # Ramsay QM mod2a <- sirt::rasch.mml2( dat, irtmodel=\"ramsay.qm\" ) summary(mod2a) }  # Ramsay QM with estimated K parameters mod2b <- sirt::rasch.mml2( dat, irtmodel=\"ramsay.qm\", est.K=1:15, mmliter=30) summary(mod2b) plot(mod2b)  if (FALSE) { # nonparametric estimation of monotone item response curves mod3a <- sirt::rasch.mml2( dat, irtmodel=\"npirt\", mmliter=100,             theta.k=seq( -3, 3, len=10) ) # evaluations at 10 theta grid points # nonparametric ICC of first 4 items round( t(mod3a$pjk)[1:4,], 3 ) summary(mod3a) plot(mod3a)  # nonparametric IRT estimation without monotonicity assumption mod3b <- sirt::rasch.mml2( dat, irtmodel=\"npirt\", mmliter=10,             theta.k=seq( -3, 3, len=10), npirt.monotone=FALSE) plot(mod3b)  # B-Spline estimation of ICCs library(splines) mod3c <- sirt::rasch.mml2( dat, irtmodel=\"npirt\",              npformula=\"y~bs(theta,df=3)\", theta.k=seq(-3,3,len=15) ) summary(mod3c) round( t(mod3c$pjk)[1:6,], 3 ) plot(mod3c)  # estimation of quadratic item response functions: ~ theta + I( theta^2) mod3d <- sirt::rasch.mml2( dat, irtmodel=\"npirt\",              npformula=\"y~theta + I(theta^2)\" ) summary(mod3d) plot(mod3d)  # estimation of a stepwise ICC function # ICCs are constant on the theta domains: [-Inf,-1], [-1,1], [1,Inf] mod3e <- sirt::rasch.mml2( dat, irtmodel=\"npirt\",              npformula=\"y~I(theta>-1 )+I(theta>1)\" ) summary(mod3e) plot(mod3e, xlim=c(-2.5,2.5) )  # 2PL model mod4 <- sirt::rasch.mml2( dat,  est.a=1:15) summary(mod4)  ############################################################################# # EXAMPLE 4: Two groups, estimation of generalized logistic model #############################################################################  # simulate generalized logistic Rasch model in two groups set.seed(8765) N1 <- 1000     # N1=1000 persons in group 1 N2 <- 500      # N2=500 persons in group 2 dat1 <- sirt::sim.raschtype( theta=stats::rnorm( N1, sd=1.5 ), b=b,             alpha1=-0.3, alpha2=0) dat2 <- sirt::sim.raschtype( theta=stats::rnorm( N2, mean=-.5, sd=.75),             b=b, alpha1=-0.3, alpha2=0) dat1 <- rbind( dat1, dat2 ) group <- c( rep(1,N1), rep(2,N2))  mod1 <-  sirt::rasch.mml2( dat1, parm.conv=.0001, group=group, est.alpha=TRUE ) summary(mod1)  ############################################################################# # EXAMPLE 5: Multidimensional model #############################################################################  #*** # (1) simulate data set.seed(785) library(mvtnorm) N <- 500 theta <- mvtnorm::rmvnorm( N,mean=c(0,0), sigma=matrix( c(1.45,.5,.5,1.7), 2, 2 )) I <- 10 # 10 items load on the first dimension p1 <- stats::plogis( outer( theta[,1], seq( -2, 2, len=I ), \"-\" ) ) resp1 <- 1 * ( p1 > matrix( stats::runif( N*I ), nrow=N, ncol=I ) ) # 10 items load on the second dimension p1 <- stats::plogis( outer( theta[,2], seq( -2, 2, len=I ), \"-\" ) ) resp2 <- 1 * ( p1 > matrix( stats::runif( N*I ), nrow=N, ncol=I ) ) #Combine the two sets of items into one response matrix resp <- cbind(resp1,resp2) colnames(resp) <- paste(\"I\", 1:(2*I), sep=\"\") dat <- resp  # define Q-matrix Qmatrix <- matrix( 0, 2*I, 2 ) Qmatrix[1:I,1] <- 1 Qmatrix[1:I+I,2] <- 1  #*** # (2) estimation of models # 2-dimensional Rasch model mod1 <- sirt::rasch.mml2( dat, Qmatrix=Qmatrix ) summary(mod1)  # 2-dimensional 2PL model mod2 <- sirt::rasch.mml2( dat, Qmatrix=Qmatrix, est.a=1:(2*I) ) summary(mod2)  # estimation with some fixed variances and covariances # set variance of 1st dimension to 1 and #  covariance to zero variance.fixed <- matrix( cbind(c(1,1), c(1,2), c(1,0)),              byrow=FALSE, ncol=3 ) mod3 <- sirt::rasch.mml2( dat, Qmatrix=Qmatrix, variance.fixed=variance.fixed ) summary(mod3)  # constraints on item difficulties #  useful for example in longitudinal linking est.b <- c( 1:I, 1:I )     # equal indices correspond to equally estimated item parameters mu.fixed <- cbind( 1, 0 ) mod4 <- sirt::rasch.mml2( dat, Qmatrix=Qmatrix, est.b=est.b, mu.fixed=mu.fixed ) summary(mod4)  ############################################################################# # EXAMPLE 6: Two booklets with same items but with item context effects. # Therefore, item slopes and item difficulties are assumed to be shifted in the # second design group. #############################################################################  #*** # simulate data set.seed(987) I <- 10     # number of items # define person design groups 1 and 2 n1 <- 700 n2 <- 1500 # item difficulties group 1 b1 <- seq(-1.5,1.5,length=I) # item slopes group 1 a1 <- rep(1, I) # simulate data group 1 dat1 <- sirt::sim.raschtype( stats::rnorm(n1), b=b1, fixed.a=a1 ) colnames(dat1) <- paste0(\"I\", 1:I, \"des1\" ) # group 2 b2 <- b1 - .15 a2 <- 1.1*a1 # Item parameters are slightly transformed in the second group # compared to the first group. This indicates possible item context effects.  # simulate data group 2 dat2 <- sirt::sim.raschtype( stats::rnorm(n2), b=b2, fixed.a=a2 ) colnames(dat2) <- paste0(\"I\", 1:I, \"des2\" ) # define joint dataset dat <- matrix( NA, nrow=n1+n2, ncol=2*I) colnames(dat) <- c( colnames(dat1), colnames(dat2) ) dat[ 1:n1, 1:I ] <- dat1 dat[ n1 + 1:n2, I + 1:I ] <- dat2 # define group identifier group <- c( rep(1,n1), rep(2,n2) )  #*** # Model 1: Rasch model two groups itemindex <- rep( 1:I, 2 ) mod1 <- sirt::rasch.mml2( dat, group=group, est.b=itemindex ) summary(mod1)  #*** # Model 2: two item slope groups and designmatrix for intercepts designmatrix <- matrix( 0, 2*I, I+1) designmatrix[ ( 1:I )+ I,1:I] <- designmatrix[1:I,1:I] <- diag(I) designmatrix[ ( 1:I )+ I,I+1] <- 1 mod2 <- sirt::rasch.mml2( dat, est.a=rep(1:2,each=I), designmatrix=designmatrix ) summary(mod2)  ############################################################################# # EXAMPLE 7: PIRLS dataset with missing responses #############################################################################  data(data.pirlsmissing) items <- grep( \"R31\", colnames(data.pirlsmissing), value=TRUE ) I <- length(items) dat <- data.pirlsmissing  #**** # Model 1: recode missing responses as missing (missing are ignorable)  # data recoding dat1 <- dat dat1[ dat1==9 ] <- NA # estimate Rasch model mod1 <- sirt::rasch.mml2( dat1[,items], weights=dat$studwgt, group=dat$country ) summary(mod1) ##   Mean=0 0.341 -0.134 0.219 ##   SD=1.142 1.166 1.197 0.959  #**** # Model 2: recode missing responses as wrong  # data recoding dat2 <- dat dat2[ dat2==9 ] <- 0 # estimate Rasch model mod2 <- sirt::rasch.mml2( dat2[,items], weights=dat$studwgt, group=dat$country ) summary(mod2)   ##   Mean=0 0.413 -0.172 0.446   ##   SD=1.199 1.263 1.32 0.996  #**** # Model 3: recode missing responses as rho * P_i( theta ) and #          apply pseudo-log-likelihood estimation # Missing item responses are predicted by the model implied probability # P_i( theta ) where theta is the ability estimate when ignoring missings (Model 1) # and rho is an adjustment parameter. rho=0 is equivalent to Model 2 (treating # missing as wrong) and rho=1 is equivalent to Model 1 (treating missing as ignorable).  # data recoding dat3 <- dat # simulate theta estimate from posterior distribution theta <- stats::rnorm( nrow(dat3), mean=mod1$person$EAP, sd=mod1$person$SE.EAP ) rho <- .3   # define a rho parameter value of .3 for (ii in items){     ind <- which( dat[,ii]==9 )     dat3[ind,ii] <- rho*stats::plogis( theta[ind] - mod1$item$b[ which( items==ii ) ] )                 }  # estimate Rasch model mod3 <- sirt::rasch.mml2( dat3[,items], weights=dat$studwgt, group=dat$country ) summary(mod3)   ##   Mean=0 0.392 -0.153 0.38   ##   SD=1.154 1.209 1.246 0.973  #**** # Model 4: simulate missing responses as rho * P_i( theta ) # The definition is the same as in Model 3. But it is now assumed # that the missing responses are 'latent responses'. set.seed(789)  # data recoding dat4 <- dat # simulate theta estimate from posterior distribution theta <- stats::rnorm( nrow(dat4), mean=mod1$person$EAP, sd=mod1$person$SE.EAP ) rho <- .3   # define a rho parameter value of .3 for (ii in items){     ind <- which( dat[,ii]==9 )     p3 <- rho*stats::plogis( theta[ind] - mod1$item$b[ which( items==ii ) ] )     dat4[ ind, ii ] <- 1*( stats::runif( length(ind), 0, 1 ) < p3)                 }  # estimate Rasch model mod4 <- sirt::rasch.mml2( dat4[,items], weights=dat$studwgt, group=dat$country ) summary(mod4)   ##   Mean=0 0.396 -0.156 0.382   ##   SD=1.16 1.216 1.253 0.979  #**** # Model 5: recode missing responses for multiple choice items with four alternatives #          to 1/4 and apply pseudo-log-likelihood estimation. #          Missings for constructed response items are treated as incorrect.  # data recoding dat5 <- dat items_mc <- items[ substring( items, 7,7)==\"M\" ] items_cr <- items[ substring( items, 7,7)==\"C\" ] for (ii in items_mc){     ind <- which( dat[,ii]==9 )     dat5[ind,ii] <- 1/4                 } for (ii in items_cr){     ind <- which( dat[,ii]==9 )     dat5[ind,ii] <- 0                 }  # estimate Rasch model mod5 <- sirt::rasch.mml2( dat5[,items], weights=dat$studwgt, group=dat$country ) summary(mod5)   ##   Mean=0 0.411 -0.165 0.435   ##   SD=1.19 1.245 1.293 0.995  #*** For the following analyses, we ignore sample weights and the #    country grouping. data(data.pirlsmissing) items <- grep( \"R31\", colnames(data.pirlsmissing), value=TRUE ) dat <- data.pirlsmissing dat1 <- dat dat1[ dat1==9 ] <- 0  #*** Model 6: estimate item difficulties assuming incorrect missing data treatment mod6 <- sirt::rasch.mml2( dat1[,items], mmliter=50 ) summary(mod6)  #*** Model 7: reestimate model with constrained item difficulties I <- length(items) constraints <- cbind( 1:I, mod6$item$b ) mod7 <- sirt::rasch.mml2( dat1[,items], constraints=constraints) summary(mod7)  #*** Model 8: score all missings responses as missing items dat2 <- dat[,items] dat2[ dat2==9 ] <- NA mod8 <- sirt::rasch.mml2( dat2, constraints=constraints, mu.fixed=NULL ) summary(mod8)  #*** Model 9: estimate missing data model 'missing1' assuming a missingness #       parameter delta.miss of zero dat2 <-  dat[,items]    # note that missing item responses must be defined by 9 mod9 <- sirt::rasch.mml2( dat2, constraints=constraints, irtmodel=\"missing1\",             theta.k=seq(-5,5,len=10), delta.miss=0, mitermax=4, mu.fixed=NULL ) summary(mod9)  #*** Model 10: estimate missing data model with a large negative missing delta parameter #=> This model is equivalent to treating missing responses as wrong mod10 <- sirt::rasch.mml2( dat2, constraints=constraints, irtmodel=\"missing1\",              theta.k=seq(-5, 5, len=10), delta.miss=-10, mitermax=4, mmliter=200,              mu.fixed=NULL ) summary(mod10)  #*** Model 11: choose a missingness delta parameter of -1 mod11 <- sirt::rasch.mml2( dat2, constraints=constraints, irtmodel=\"missing1\",              theta.k=seq(-5, 5, len=10), delta.miss=-1, mitermax=4,              mmliter=200, mu.fixed=NULL ) summary(mod11)  #*** Model 12: estimate joint delta parameter mod12 <- sirt::rasch.mml2( dat2, irtmodel=\"missing1\", mu.fixed=cbind( c(1,2), 0 ),              theta.k=seq(-8, 8, len=10), delta.miss=0, mitermax=4,              mmliter=30, est.delta=rep(1,I)  ) summary(mod12)  #*** Model 13: estimate delta parameter in item groups defined by item format est.delta <- 1 + 1 * ( substring( colnames(dat2),7,7 )==\"M\" ) mod13 <- sirt::rasch.mml2( dat2, irtmodel=\"missing1\", mu.fixed=cbind( c(1,2), 0 ),              theta.k=seq(-8, 8, len=10), delta.miss=0, mitermax=4,              mmliter=30, est.delta=est.delta  ) summary(mod13)  #*** Model 14: estimate item specific delta parameter mod14 <- sirt::rasch.mml2( dat2, irtmodel=\"missing1\", mu.fixed=cbind( c(1,2), 0 ),              theta.k=seq(-8, 8, len=10), delta.miss=0, mitermax=4,              mmliter=30, est.delta=1:I  ) summary(mod14)  ############################################################################# # EXAMPLE 8: Comparison of different models for polytomous data #############################################################################  data(data.Students, package=\"CDM\") head(data.Students) dat <- data.Students[, paste0(\"act\",1:5) ] I <- ncol(dat)  #************************************************** #*** Model 1: Partial Credit Model (PCM)  #*** Model 1a: PCM in TAM mod1a <- TAM::tam.mml( dat ) summary(mod1a)  #*** Model 1b: PCM in sirt mod1b <- sirt::rm.facets( dat ) summary(mod1b)  #*** Model 1c: PCM in mirt mod1c <- mirt::mirt( dat, 1, itemtype=rep(\"Rasch\",I), verbose=TRUE ) print(mod1c)  #************************************************** #*** Model 2: Sequential Model (SM): Equal Loadings  #*** Model 2a: SM in sirt dat1 <- CDM::sequential.items(dat) resp <- dat1$dat.expand iteminfo <- dat1$iteminfo # fit model mod2a <- sirt::rasch.mml2( resp ) summary(mod2a)  #************************************************** #*** Model 3: Sequential Model (SM): Different Loadings  #*** Model 3a: SM in sirt mod3a <- sirt::rasch.mml2( resp, est.a=iteminfo$itemindex ) summary(mod3a)  #************************************************** #*** Model 4: Generalized partial credit model (GPCM)  #*** Model 4a: GPCM in TAM mod4a <- TAM::tam.mml.2pl( dat, irtmodel=\"GPCM\") summary(mod4a)  #************************************************** #*** Model 5: Graded response model (GRM)  #*** Model 5a: GRM in mirt mod5a <- mirt::mirt( dat, 1, itemtype=rep(\"graded\",I), verbose=TRUE) print(mod5a)  # model comparison logLik(mod1a);logLik(mod1b);mod1c@logLik  # PCM logLik(mod2a)   # SM (Rasch) logLik(mod3a)   # SM (GPCM) logLik(mod4a)   # GPCM mod5a@logLik    # GRM }"},{"path":"/reference/rasch.pairwise.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise Estimation Method of the Rasch Model — rasch.pairwise","title":"Pairwise Estimation Method of the Rasch Model — rasch.pairwise","text":"function estimates Rasch model minimum chi square estimation method (cited Fischer, 2007, p. 544) pairwise conditional likelihood estimation approach.","code":""},{"path":"/reference/rasch.pairwise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise Estimation Method of the Rasch Model — rasch.pairwise","text":"","code":"rasch.pairwise(dat, weights=NULL, conv=1e-04, maxiter=3000, progress=TRUE,         b.init=NULL, zerosum=FALSE, power=1, direct_optim=TRUE)  # S3 method for rasch.pairwise summary(object, digits=3, file=NULL, ...)"},{"path":"/reference/rasch.pairwise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise Estimation Method of the Rasch Model — rasch.pairwise","text":"dat \\(N \\times \\) data frame dichotomous item responses weights Optional vector sampling weights conv Convergence criterion maxiter Maximum number iterations progress Display iteration progress? b.init optional vector length \\(\\) item difficulties zerosum Optional logical indicating whether item difficulties     centered iteration. default         centering conducted. power Power used computing pairwise response probabilities like row averaging approach direct_optim Logical indicating whether least squares criterion funcion minimized stats::nlminb object Object class rasch.pairwise digits Number digits decimal rounding file Optional file name summary output ... arguments passed","code":""},{"path":"/reference/rasch.pairwise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pairwise Estimation Method of the Rasch Model — rasch.pairwise","text":"object class rasch.pairwise following entries b Item difficulties eps Exponentiated item difficulties, .e. eps=exp(-b) iter Number iterations conv Convergence criterion dat Original data frame freq.ij Frequency table item pairs item Summary table item parameters","code":""},{"path":"/reference/rasch.pairwise.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pairwise Estimation Method of the Rasch Model — rasch.pairwise","text":"Fischer, G. H. (2007). Rasch models.   C. R. Rao S. Sinharay (Eds.), Handbook Statistics,   Vol. 26 (pp. 515-585). Amsterdam: Elsevier.","code":""},{"path":[]},{"path":"/reference/rasch.pairwise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise Estimation Method of the Rasch Model — rasch.pairwise","text":"","code":"############################################################################# # EXAMPLE 1: Reading data set | pairwise estimation Rasch model #############################################################################  data(data.read) dat <- data.read  #*** Model 1: no constraint on item difficulties mod1 <- sirt::rasch.pairwise(dat) summary(mod1)  #*** Model 2: sum constraint on item difficulties mod2 <- sirt::rasch.pairwise(dat, zerosum=TRUE) summary(mod2)  if (FALSE) { #** obtain standard errors by bootstrap mod2$item$b   # extract item difficulties  # Bootstrap of item difficulties boot_pw <- function(data, indices ){     dd <- data[ indices, ] # bootstrap of indices     mod <- sirt::rasch.pairwise( dat=dd, zerosum=TRUE, progress=FALSE)     return(mod$item$b) } set.seed(986) library(boot) bmod2 <- boot::boot(data=dat, statistic=boot_pw, R=999 ) print(bmod2) summary(bmod2) # quantiles for bootstrap sample (and confidence interval) apply(bmod2$t, 2, stats::quantile, probs=c(.025, .5, .975) ) }"},{"path":"/reference/rasch.pairwise.itemcluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"function uses pairwise conditional likelihood estimation estimating item parameters Rasch model.","code":""},{"path":"/reference/rasch.pairwise.itemcluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"","code":"rasch.pairwise.itemcluster(dat, itemcluster=NULL, b.fixed=NULL, weights=NULL,     conv=1e-05, maxiter=3000, progress=TRUE, b.init=NULL, zerosum=FALSE)"},{"path":"/reference/rasch.pairwise.itemcluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"dat \\(N \\times \\) data frame.   Missing responses allowed must recoded NA. itemcluster Optional integer vector itemcluster (see Examples). Different integers correspond different item clusters. item cluster set default. b.fixed Matrix fixing item parameters. first columns contains item (number name), second column parameter fixed. weights Optional Vector sampling weights conv Convergence criterion maximal absolute parameter change maxiter Maximal number iterations progress logical displays progress. Default TRUE. b.init Vector initial item difficulty estimates. Default NULL. zerosum Optional logical indicating whether item difficulties     centered iteration. default         centering conducted.","code":""},{"path":"/reference/rasch.pairwise.itemcluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"adaptation algorithm van der Linden Eggen (1986). item pairs different item clusters taken account item difficulty estimation. Therefore, problem locally dependent items within itemcluster (almost) eliminated (see Examples ) contributions local dependencies appear pairwise likelihood terms. detail, estimation rests observed frequency tables items \\(\\) \\(j\\) therefore conditional probabilities $$ \\frac{P(X_i=x, X_j=y)}{P(X_i + X_j=1 )} \\quad \\mbox{} \\quad x,y=0,1 \\quad \\mbox{} \\quad x+y=1 $$ item pair \\((,j)\\) higher positive (negative) correlation expected (.e. deviation local dependence), pair removed estimation. Clearly, loss precision item parameters can less biased.","code":""},{"path":"/reference/rasch.pairwise.itemcluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"Object class rasch.pairwise elements b Vector item difficulties item Data frame item parameters (\\(N\\), \\(p\\) item difficulty)","code":""},{"path":"/reference/rasch.pairwise.itemcluster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"van der Linden, W. J., & Eggen, T. J. H. M. (1986). empirical Bayes approach item banking. Research Report 86-6, University Twente. Zwinderman, . H. (1995). Pairwise parameter estimation Rasch models. Applied Psychological Measurement, 19, 369-375.","code":""},{"path":"/reference/rasch.pairwise.itemcluster.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"standard errors provided function. Use resampling methods conducting statistical inference. Formulas asymptotic standard errors pairwise estimation method described Zwinderman (1995).","code":""},{"path":[]},{"path":"/reference/rasch.pairwise.itemcluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise Estimation of the Rasch Model for Locally Dependent Items — rasch.pairwise.itemcluster","text":"","code":"############################################################################# # EXAMPLE 1: Example with locally dependent items #      12 Items: Cluster 1 -> Items 1,...,4 #                Cluster 2 -> Items 6,...,9 #                Cluster 3 -> Items 10,11,12 #############################################################################  set.seed(7896) I <- 12                             # number of items n <- 5000                           # number of persons b <- seq(-2,2, len=I)               # item difficulties bsamp <- b <- sample(b)             # sample item difficulties theta <- stats::rnorm( n, sd=1 ) # person abilities # itemcluster itemcluster <- rep(0,I) itemcluster[ 1:4 ] <- 1 itemcluster[ 6:9 ] <- 2 itemcluster[ 10:12 ] <- 3 # residual correlations rho <- c( .55, .25, .45 )  # simulate data dat <- sirt::sim.rasch.dep( theta, b, itemcluster, rho ) colnames(dat) <- paste(\"I\", seq(1,ncol(dat)), sep=\"\")  # estimation with pairwise Rasch model mod3 <- sirt::rasch.pairwise( dat ) summary(mod3)  # use item cluster in rasch pairwise estimation mod <- sirt::rasch.pairwise.itemcluster( dat=dat, itemcluster=itemcluster ) summary(mod)  if (FALSE) { # Rasch MML estimation mod4 <- sirt::rasch.mml2( dat ) summary(mod4)  # Rasch Copula estimation mod5 <- sirt::rasch.copula2( dat, itemcluster=itemcluster ) summary(mod5)  # compare different item parameter estimates M1 <- cbind( \"true.b\"=bsamp, \"b.rasch\"=mod4$item$b, \"b.rasch.copula\"=mod5$item$thresh,          \"b.rasch.pairwise\"=mod3$b, \"b.rasch.pairwise.cluster\"=mod$b ) # center item difficulties M1 <- scale( M1, scale=FALSE ) round( M1, 3 ) round( apply( M1, 2, stats::sd ), 3 )  #  Below the output of the example is presented. #  The rasch.pairwise.itemcluster is pretty close to the estimate in the Rasch copula model.    ##   > round( M1, 3 )   ##       true.b b.rasch b.rasch.copula b.rasch.pairwise b.rasch.pairwise.cluster   ##   I1   0.545   0.561          0.526            0.628                    0.524   ##   I2  -0.182  -0.168         -0.174           -0.121                   -0.156   ##   I3  -0.909  -0.957         -0.867           -0.971                   -0.899   ##   I4  -1.636  -1.726         -1.625           -1.765                   -1.611   ##   I5   1.636   1.751          1.648            1.694                    1.649   ##   I6   0.909   0.892          0.836            0.898                    0.827   ##   I7  -2.000  -2.134         -2.020           -2.051                   -2.000   ##   I8  -1.273  -1.355         -1.252           -1.303                   -1.271   ##   I9  -0.545  -0.637         -0.589           -0.581                   -0.598   ##   I10  1.273   1.378          1.252            1.308                    1.276   ##   I11  0.182   0.241          0.226            0.109                    0.232   ##   I12  2.000   2.155          2.039            2.154                    2.026   ##   > round( apply( M1, 2, sd ), 3 )   ##                     true.b                  b.rasch           b.rasch.copula   ##                      1.311                    1.398                    1.310   ##      b.rasch.pairwise    b.rasch.pairwise.cluster   ##                 1.373                       1.310  # set item parameters of first item to 0 and of second item to -0.7 b.fixed <- cbind( c(1,2), c(0,-.7) ) mod5 <- sirt::rasch.pairwise.itemcluster( dat=dat, b.fixed=b.fixed,              itemcluster=itemcluster ) # difference between estimations 'mod' and 'mod5' dfr <- cbind( mod5$item$b, mod$item$b ) plot( mod5$item$b, mod$item$b, pch=16) apply( dfr, 1, diff) }"},{"path":"/reference/rasch.pml3.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"function estimates unidimensional 1PL 2PL models probit link using pairwise marginal maximum likelihood estimation (PMML; Renard, Molenberghs & Geys, 2004). Item pairs within itemcluster can excluded pairwise likelihood (argument itemcluster). alternative model residual error structure itemclusters (argument error.corr).","code":""},{"path":"/reference/rasch.pml3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"","code":"rasch.pml3(dat, est.b=seq(1, ncol(dat)), est.a=rep(0,ncol(dat)),     est.sigma=TRUE, itemcluster=NULL, weight=rep(1, nrow(dat)), numdiff.parm=0.001,     b.init=NULL, a.init=NULL,  sigma.init=NULL, error.corr=0*diag( 1, ncol(dat) ),     err.constraintM=NULL, err.constraintV=NULL, glob.conv=10^(-6), conv1=10^(-4),     pmliter=300, progress=TRUE, use.maxincrement=TRUE )  # S3 method for rasch.pml summary(object,...)"},{"path":"/reference/rasch.pml3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"dat \\(N \\times \\) data frame dichotomous item responses est.b Vector integers length \\(\\). integers mean corresponding items item difficulty b. Entries 0 mean fixing item parameters values specified b.init. est.Vector integers length \\(\\). integers mean corresponding items item slope . Entries 0 mean fixing item parameters values specified .init. est.sigma sigma (trait standard deviation) estimated? default TRUE. itemcluster Optional vector length \\(\\) integers indicates itemclusters. integers correspond itemcluster. entry 0 correspond item included itemcluster. weight Optional vector person weights numdiff.parm Step parameter numerical differentiation b.init Initial fixed item difficulty .init Initial fixed item slopes sigma.init Initial fixed trait standard deviation error.corr optional \\(\\times \\) integer matrix defines estimation residual correlations. Entries zero indicate corresponding residual correlation estimated. Integers differ zero indicate correlations estimated. entries equal integer estimated residual correlation. default error.corr diagonal matrix means residual correlation estimated. error.corr deviates default, argument itemcluster set NULL. error correlations estimated, itempairs itemcluster can excluded pairwise modeling.  err.constraintM optional \\(P \\times L\\) matrix \\(P\\) denotes number item pairs pseudolikelihood estimation \\(L\\) number linear constraints residual correlations (see Details). err.constraintV optional \\(L \\times 1\\) matrix specified values linear constraints residual correlations (see Details). glob.conv Global convergence criterion conv1 Convergence criterion model parameters pmliter Maximum number iterations progress Display progress? use.maxincrement Optional logical whether increments     slope parameters controlled size iterations.     default TRUE. object Object class rasch.pml ... arguments passed","code":""},{"path":"/reference/rasch.pml3.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"probit item response model can estimated function: $$P(X_{pi}=1|\\theta_p )=\\Phi( a_i  \\theta_p - b_i ) \\quad, \\quad     \\theta_p \\sim N ( 0, \\sigma^2 )$$ \\(\\Phi\\) denotes normal distribution function. model can also expressed latent variable model assumes latent response tendency \\(X_{pi}^\\ast\\) equal 1 \\(X_{pi}> - b_i\\) otherwise zero. \\(\\epsilon_{pi}\\) standard normally distributed, $$X_{pi}^{\\ast}=a_i \\theta_p - b_i + \\epsilon_{pi} $$ arbitrary pattern residual correlations \\(\\epsilon_{pi}\\) \\(\\epsilon_{pj}\\) item pairs \\(\\) \\(j\\) can imposed using error.corr argument. Linear constraints \\(=v\\) residual correlations \\(e=Cov( \\epsilon_{pi}, \\epsilon_{pj})_{ij}\\) (vectorized form) can specified using arguments err.constraintM (matrix \\(M\\)) err.constraintV (vector \\(v\\)). estimation described Neuhaus (1996). pseudo likelihood information criterion (PLIC) see Stanford Raftery (2002).","code":""},{"path":"/reference/rasch.pml3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"list following entries: item Data frame estimated item parameters iter Number iterations deviance Pseudolikelihood multiplied minus 2 b Estimated item difficulties sigma Estimated standard deviation dat Original dataset ic Data frame information criteria (sample size, number estimated parameters, pseudolikelihood information criterion PLIC) link Used link function (probit permitted) itempairs Estimated statistics item pairs error.corr Estimated error correlation matrix eps.corr Vectorized error correlation matrix omega.rel Reliability sum score according Green Yang (2009).     item pairs excluded estimation, residual     correlation item pairs assumed zero. ...","code":""},{"path":"/reference/rasch.pml3.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"Green, S. B., & Yang, Y. (2009). Reliability summed item scores using structural equation modeling: alternative coefficient alpha. Psychometrika, 74, 155-167. Neuhaus, W. (1996). Optimal estimation linear constraints. Astin Bulletin, 26, 233-245. Renard, D., Molenberghs, G., & Geys, H. (2004). pairwise likelihood approach estimation multilevel probit models. Computational Statistics & Data Analysis, 44, 649-667. Stanford, D. C., & Raftery, . E. (2002). Approximate Bayes factors image segmentation: pseudolikelihood information criterion (PLIC). IEEE Transactions Pattern Analysis Machine Intelligence, 24, 1517-1520.","code":""},{"path":"/reference/rasch.pml3.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"function needs combinat library.","code":""},{"path":[]},{"path":"/reference/rasch.pml3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise Marginal Likelihood Estimation for the Probit Rasch Model — rasch.pml3","text":"","code":"############################################################################# # EXAMPLE 1: Reading data set #############################################################################  data(data.read) dat <- data.read  #****** # Model 1: Rasch model with PML estimation mod1 <- sirt::rasch.pml3( dat ) summary(mod1)  #****** # Model 2: Excluding item pairs with local dependence #          from bivariate composite likelihood itemcluster <- rep( 1:3, each=4) mod2 <- sirt::rasch.pml3( dat, itemcluster=itemcluster ) summary(mod2)  if (FALSE) { #***** # Model 3: Modelling error correlations: #          joint residual correlations for each itemcluster error.corr <- diag(1,ncol(dat)) for ( ii in 1:3){     ind.ii <- which( itemcluster==ii )     error.corr[ ind.ii, ind.ii ] <- ii         } # estimate the model with error correlations mod3 <- sirt::rasch.pml3( dat, error.corr=error.corr ) summary(mod3)  #**** # Model 4: model separate residual correlations I <- ncol(error.corr) error.corr1 <- matrix( 1:(I*I), ncol=I ) error.corr <- error.corr1 * ( error.corr > 0 ) # estimate the model with error correlations mod4 <- sirt::rasch.pml3( dat, error.corr=error.corr ) summary(mod4)  #**** # Model 5:  assume equal item difficulties: # b_1=b_7 and b_2=b_12 # fix item difficulty of the 6th item to .1 est.b <- 1:I est.b[7] <- 1; est.b[12] <- 2 ; est.b[6] <- 0 b.init <- rep( 0, I ) ; b.init[6] <- .1 mod5 <- sirt::rasch.pml3( dat, est.b=est.b, b.init=b.init) summary(mod5)  #**** # Model 6: estimate three item slope groups est.a <- rep(1:3, each=4 ) mod6 <- sirt::rasch.pml3( dat, est.a=est.a, est.sigma=0) summary(mod6)  ############################################################################# # EXAMPLE 2: PISA reading #############################################################################  data(data.pisaRead) dat <- data.pisaRead$data  # select items dat <- dat[, substring(colnames(dat),1,1)==\"R\" ]  #****** # Model 1: Rasch model with PML estimation mod1 <- sirt::rasch.pml3( as.matrix(dat) )   ## Trait SD (Logit Link) : 1.419  #****** # Model 2: Model correlations within testlets error.corr <- diag(1,ncol(dat)) testlets <- paste( data.pisaRead$item$testlet ) itemcluster <- match( testlets, unique(testlets ) ) for ( ii in 1:(length(unique(testlets))) ){     ind.ii <- which( itemcluster==ii )     error.corr[ ind.ii, ind.ii ] <- ii         } # estimate the model with error correlations mod2 <- sirt::rasch.pml3( dat, error.corr=error.corr )   ## Trait SD (Logit Link) : 1.384  #**** # Model 3: model separate residual correlations I <- ncol(error.corr) error.corr1 <- matrix( 1:(I*I), ncol=I ) error.corr <- error.corr1 * ( error.corr > 0 ) # estimate the model with error correlations mod3 <- sirt::rasch.pml3( dat, error.corr=error.corr )   ## Trait SD (Logit Link) : 1.384  ############################################################################# # EXAMPLE 3: 10 locally independent items #############################################################################  #********** # simulate some data set.seed(554) N <- 500    # persons I <- 10        # items theta <- stats::rnorm(N,sd=1.3 )    # trait SD of 1.3 b <- seq(-2, 2, length=I) # item difficulties  # simulate data from the Rasch model dat <- sirt::sim.raschtype( theta=theta, b=b )  # estimation with rasch.pml and probit link mod1 <- sirt::rasch.pml3( dat ) summary(mod1)  # estimation with rasch.mml2 function mod2 <- sirt::rasch.mml2( dat )  # estimate item parameters for groups with five item parameters each est.b <- rep( 1:(I/2), each=2 ) mod3 <- sirt::rasch.pml3( dat, est.b=est.b ) summary(mod3)  # compare parameter estimates summary(mod1) summary(mod2) summary(mod3)  ############################################################################# # EXAMPLE 4: 11 items and 2 item clusters with 2 and 3 items #############################################################################  set.seed(5698) I <- 11                             # number of items n <- 5000                           # number of persons b <- seq(-2,2, len=I)               # item difficulties theta <- stats::rnorm( n, sd=1 ) # person abilities # itemcluster itemcluster <- rep(0,I) itemcluster[c(3,5)] <- 1 itemcluster[c(2,4,9)] <- 2 # residual correlations rho <- c( .7, .5 )  # simulate data (under the logit link) dat <- sirt::sim.rasch.dep( theta, b, itemcluster, rho ) colnames(dat) <- paste(\"I\", seq(1,ncol(dat)), sep=\"\")  #*** # Model 1: estimation using the Rasch model (with probit link) mod1 <- sirt::rasch.pml3( dat ) #*** # Model 2: estimation when pairs of locally dependent items are eliminated mod2 <- sirt::rasch.pml3( dat, itemcluster=itemcluster)  #*** # Model 3: Positive correlations within testlets est.corrs <- diag( 1, I ) est.corrs[ c(3,5), c(3,5) ] <- 2 est.corrs[ c(2,4,9), c(2,4,9) ] <- 3 mod3 <- sirt::rasch.pml3( dat, error.corr=est.corrs )  #*** # Model 4: Negative correlations between testlets est.corrs <- diag( 1, I ) est.corrs[ c(3,5), c(2,4,9) ] <- 2 est.corrs[ c(2,4,9), c(3,5) ] <- 2 mod4 <- sirt::rasch.pml3( dat, error.corr=est.corrs )  #*** # Model 5: sum constraint of zero within and between testlets est.corrs <- matrix( 1:(I*I),  I, I ) cluster2 <- c(2,4,9) est.corrs[ setdiff( 1:I, c(cluster2)),  ] <- 0 est.corrs[, setdiff( 1:I, c(cluster2))  ] <- 0 # define an error constraint matrix itempairs0 <- mod4$itempairs IP <- nrow(itempairs0) err.constraint <- matrix( 0, IP, 1 ) err.constraint[ ( itempairs0$item1 %in% cluster2 )        & ( itempairs0$item2 %in% cluster2 ), 1 ] <- 1 # set sum of error covariances to 1.2 err.constraintV <- matrix(3*.4,1,1)  mod5 <- sirt::rasch.pml3( dat, error.corr=est.corrs,          err.constraintM=err.constraint, err.constraintV=err.constraintV)  #**** # Model 6: Constraint on sum of all correlations est.corrs <- matrix( 1:(I*I),  I, I ) # define an error constraint matrix itempairs0 <- mod4$itempairs IP <- nrow(itempairs0) # define two side conditions err.constraint <- matrix( 0, IP, 2 ) err.constraintV <- matrix( 0, 2, 1) # sum of all correlations is zero err.constraint[, 1 ] <- 1 err.constraintV[1,1] <- 0 # sum of items cluster c(1,2,3) is 0 cluster2 <- c(1,2,3) err.constraint[ ( itempairs0$item1 %in%  cluster2 )        & ( itempairs0$item2 %in% cluster2 ), 2 ] <- 1 err.constraintV[2,1] <- 0  mod6 <- sirt::rasch.pml3( dat, error.corr=est.corrs,     err.constraintM=err.constraint,  err.constraintV=err.constraintV) summary(mod6)  ############################################################################# # EXAMPLE 5: 10 Items: Cluster 1 -> Items 1,2 #         Cluster 2 -> Items 3,4,5;   Cluster 3 -> Items 7,8,9 #############################################################################  set.seed(7650) I <- 10                             # number of items n <- 5000                           # number of persons b <- seq(-2,2, len=I)               # item difficulties bsamp <- b <- sample(b)             # sample item difficulties theta <- stats::rnorm( n, sd=1 ) # person abilities # define itemcluster itemcluster <- rep(0,I) itemcluster[ 1:2 ] <- 1 itemcluster[ 3:5 ] <- 2 itemcluster[ 7:9 ] <- 3 # define residual correlations rho <- c( .55, .35, .45)  # simulate data dat <- sirt::sim.rasch.dep( theta, b, itemcluster, rho ) colnames(dat) <- paste(\"I\", seq(1,ncol(dat)), sep=\"\")  #*** # Model 1: residual correlation (equal within item clusters) # define a matrix of integers for estimating error correlations error.corr <- diag(1,ncol(dat)) for ( ii in 1:3){     ind.ii <- which( itemcluster==ii )     error.corr[ ind.ii, ind.ii ] <- ii         } # estimate the model mod1 <- sirt::rasch.pml3( dat, error.corr=error.corr )  #*** # Model 2: residual correlation (different within item clusters) # define again a matrix of integers for estimating error correlations error.corr <- diag(1,ncol(dat)) for ( ii in 1:3){     ind.ii <- which( itemcluster==ii )     error.corr[ ind.ii, ind.ii ] <- ii         } I <- ncol(error.corr) error.corr1 <- matrix( 1:(I*I), ncol=I ) error.corr <- error.corr1 * ( error.corr > 0 ) # estimate the model mod2 <- sirt::rasch.pml3( dat, error.corr=error.corr )  #*** # Model 3: eliminate item pairs within itemclusters for PML estimation mod3 <- sirt::rasch.pml3( dat, itemcluster=itemcluster )  #*** # Model 4: Rasch model ignoring dependency mod4 <- sirt::rasch.pml3( dat )  # compare different models summary(mod1) summary(mod2) summary(mod3) summary(mod4) }"},{"path":"/reference/rasch.prox.html","id":null,"dir":"Reference","previous_headings":"","what":"PROX Estimation Method for the Rasch Model — rasch.prox","title":"PROX Estimation Method for the Rasch Model — rasch.prox","text":"function estimates Rasch model using PROX algorithm (cited Wright & Stone, 1999).","code":""},{"path":"/reference/rasch.prox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PROX Estimation Method for the Rasch Model — rasch.prox","text":"","code":"rasch.prox(dat, dat.resp=1 - is.na(dat), freq=rep(1,nrow(dat)),     conv=0.001, maxiter=30, progress=FALSE)"},{"path":"/reference/rasch.prox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PROX Estimation Method for the Rasch Model — rasch.prox","text":"dat \\(N \\times \\) data frame dichotomous response data. NAs allowed must indicated zero entries response indicator matrix dat.resp. dat.resp \\(N \\times \\) indicator data frame nonmissing item responses. freq vector frequencies (weights) rows data frame dat. conv Convergence criterion item parameters maxiter Maximum number iterations progress Display progress?","code":""},{"path":"/reference/rasch.prox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PROX Estimation Method for the Rasch Model — rasch.prox","text":"list following entries b Estimated item difficulties theta Estimated person abilities iter Number iterations sigma.Item standard deviations sigma.n Person standard deviations","code":""},{"path":"/reference/rasch.prox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"PROX Estimation Method for the Rasch Model — rasch.prox","text":"Wright, B., & Stone, W. (1999). Measurement Essentials. Wilmington: Wide Range.","code":""},{"path":"/reference/rasch.prox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PROX Estimation Method for the Rasch Model — rasch.prox","text":"","code":"############################################################################# # EXAMPLE 1: PROX data.read #############################################################################  data(data.read) mod <- sirt::rasch.prox( data.read ) mod$b       # item difficulties"},{"path":"/reference/rasch.va.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the Rasch Model with Variational Approximation — rasch.va","title":"Estimation of the Rasch Model with Variational Approximation — rasch.va","text":"function estimates Rasch model estimation method variational approximation (Rijmen & Vomlel, 2008).","code":""},{"path":"/reference/rasch.va.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the Rasch Model with Variational Approximation — rasch.va","text":"","code":"rasch.va(dat, globconv=0.001, maxiter=1000)"},{"path":"/reference/rasch.va.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the Rasch Model with Variational Approximation — rasch.va","text":"dat Data frame dichotomous item responses globconv Convergence criterion item parameters maxiter Maximal number iterations","code":""},{"path":"/reference/rasch.va.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the Rasch Model with Variational Approximation — rasch.va","text":"list following entries: sig Standard deviation trait item Data frame item parameters xsi.ij Data frame variational parameters \\(\\xi_{ij}\\) mu.Vector individual means \\(\\mu_i\\) sigma2.Vector individual variances \\(\\sigma_i^2\\)","code":""},{"path":"/reference/rasch.va.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the Rasch Model with Variational Approximation — rasch.va","text":"Rijmen, F., & Vomlel, J. (2008). Assessing performance variational methods mixed logistic regression models. Journal Statistical Computation Simulation, 78, 765-779.","code":""},{"path":"/reference/rasch.va.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the Rasch Model with Variational Approximation — rasch.va","text":"","code":"############################################################################# # EXAMPLE 1: Rasch model ############################################################################# set.seed(8706) N <- 5000 I <- 20 dat <- sirt::sim.raschtype( stats::rnorm(N,sd=1.3), b=seq(-2,2,len=I) )  # estimation via variational approximation mod1 <- sirt::rasch.va(dat)  # estimation via marginal maximum likelihood mod2 <- sirt::rasch.mml2(dat)  # estmation via joint maximum likelihood mod3 <- sirt::rasch.jml(dat)  # compare sigma round( c( mod1$sig, mod2$sd.trait ), 3 ) ## [1] 1.222 1.314  # compare b round( cbind( mod1$item$b, mod2$item$b, mod3$item$itemdiff), 3 ) ##         [,1]   [,2]   [,3] ##  [1,] -1.898 -1.967 -2.090 ##  [2,] -1.776 -1.841 -1.954 ##  [3,] -1.561 -1.618 -1.715 ##  [4,] -1.326 -1.375 -1.455 ##  [5,] -1.121 -1.163 -1.228"},{"path":"/reference/reliability.nonlinearSEM.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","title":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","text":"function estimates model based reliability using confirmatory factor analysis (Green & Yang, 2009).","code":""},{"path":"/reference/reliability.nonlinearSEM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","text":"","code":"reliability.nonlinearSEM(facloadings, thresh, resid.cov=NULL, cor.factors=NULL)"},{"path":"/reference/reliability.nonlinearSEM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","text":"facloadings Matrix factor loadings thresh Vector thresholds resid.cov Matrix residual covariances cor.factors Optional matrix covariances (correlations) factors. default diagonal matrix variances 1.","code":""},{"path":"/reference/reliability.nonlinearSEM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","text":"list. reliability list element omega.rel","code":""},{"path":"/reference/reliability.nonlinearSEM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","text":"Green, S. B., & Yang, Y. (2009). Reliability summed item scores using structural equation modeling: alternative coefficient alpha. Psychometrika, 74, 155-167.","code":""},{"path":"/reference/reliability.nonlinearSEM.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","text":"function needs mvtnorm package.","code":""},{"path":[]},{"path":"/reference/reliability.nonlinearSEM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of Reliability for Confirmatory Factor Analyses\r\nBased on Dichotomous Data — reliability.nonlinearSEM","text":"","code":"############################################################################# # EXAMPLE 1: Reading data set ############################################################################# data(data.read) dat <- data.read I <- ncol(dat)  # define item clusters itemcluster <- rep( 1:3, each=4) error.corr <- diag(1,ncol(dat)) for ( ii in 1:3){     ind.ii <- which( itemcluster==ii )     error.corr[ ind.ii, ind.ii ] <- ii         } # estimate the model with error correlations mod1 <- sirt::rasch.pml3( dat, error.corr=error.corr) summary(mod1)  # extract item parameters thresh <- - matrix( mod1$item$a * mod1$item$b, I, 1 ) A <- matrix( mod1$item$a * mod1$item$sigma, I, 1 ) # extract estimated correlation matrix corM <- mod1$eps.corrM # compute standardized factor loadings facA <- 1 / sqrt( A^2 + 1 ) resvar <- 1 - facA^2 covM <- outer( sqrt(resvar[,1]), sqrt(resvar[,1] ) ) * corM facloadings <- A *facA  # estimate reliability rel1 <- sirt::reliability.nonlinearSEM( facloadings=facloadings, thresh=thresh,            resid.cov=covM) rel1$omega.rel"},{"path":"/reference/resp_groupwise.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates Group-Wise Item Response Dataset — resp_groupwise","title":"Creates Group-Wise Item Response Dataset — resp_groupwise","text":"Creates group-wise item response dataset.","code":""},{"path":"/reference/resp_groupwise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates Group-Wise Item Response Dataset — resp_groupwise","text":"","code":"resp_groupwise(resp, group, items_group)"},{"path":"/reference/resp_groupwise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates Group-Wise Item Response Dataset — resp_groupwise","text":"resp Dataset item responses group Vector group identifiers items_group List containing vectors groups item made group-specific","code":""},{"path":"/reference/resp_groupwise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates Group-Wise Item Response Dataset — resp_groupwise","text":"Dataset","code":""},{"path":"/reference/resp_groupwise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates Group-Wise Item Response Dataset — resp_groupwise","text":"","code":"if (FALSE) { ############################################################################# # EXAMPLE 1: Toy dataset #############################################################################  library(CDM) library(TAM)  data(data.ex11, package=\"TAM\") dat <- data.ex11 dat[ dat==9 ] <- 0 resp <- dat[,-1]  # group labels booklets <- sort( unique(paste(dat$booklet)))  #- fit initial model mod0 <- TAM::tam.mml( resp, group=dat$booklet) summary(mod0)  # fit statistics fmod <- IRT.RMSD(mod) stat <- abs(fmod$MD[,-1]) stat[ is.na( fmod$RMSD[,2:4] ) ] <- NA thresh <- .01 round(stat,3) # define list define groups for group-specific items items_group <- apply( stat, 1, FUN=function(ll){                 v1 <- booklets[ which( ll > thresh ) ]                 v1[ ! is.na(v1) ]  } )  #- create extended response dataset dat2 <- sirt::resp_groupwise(resp=resp, group=paste(dat$booklet), items_group=items_group) colSums( ! is.na(dat2) )  #- fit model for extended response dataset mod2 <- TAM::tam.mml( dat2, group=dat$booklet) summary(mod2) }"},{"path":"/reference/rinvgamma2.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Gamma Distribution in Prior Sample Size Parameterization — rinvgamma2","title":"Inverse Gamma Distribution in Prior Sample Size Parameterization — rinvgamma2","text":"Random draws density inverse gamma distribution parameterized prior sample size n0 prior variance var0 (see Gelman et al., 2014).","code":""},{"path":"/reference/rinvgamma2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Gamma Distribution in Prior Sample Size Parameterization — rinvgamma2","text":"","code":"rinvgamma2(n, n0, var0)  dinvgamma2(x, n0, var0)"},{"path":"/reference/rinvgamma2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Gamma Distribution in Prior Sample Size Parameterization — rinvgamma2","text":"n Number draws inverse gamma distribution n0 Prior sample size var0 Prior variance x Vector numeric values density evaluation","code":""},{"path":"/reference/rinvgamma2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Gamma Distribution in Prior Sample Size Parameterization — rinvgamma2","text":"vector containing random draws density values","code":""},{"path":"/reference/rinvgamma2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Inverse Gamma Distribution in Prior Sample Size Parameterization — rinvgamma2","text":"Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, ., & Rubin, D. B. (2014). Bayesian data analysis (Vol. 3). Boca Raton, FL, USA: Chapman & Hall/CRC.","code":""},{"path":[]},{"path":"/reference/rinvgamma2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Gamma Distribution in Prior Sample Size Parameterization — rinvgamma2","text":"","code":"############################################################################# # EXAMPLE 1: Inverse gamma distribution #############################################################################  # prior sample size of 100 and prior variance of 1.5 n0 <- 100 var0 <- 1.5  # 100 random draws y1 <- sirt::rinvgamma2( n=100, n0, var0 ) summary(y1) graphics::hist(y1)  # density y at grid x x <- seq( 0, 2, len=100 ) y <- sirt::dinvgamma2( x, n0, var0 ) graphics::plot( x, y, type=\"l\")"},{"path":"/reference/rm.facets.html","id":null,"dir":"Reference","previous_headings":"","what":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"function estimates unidimensional rater facets model (Lincare, 1994) extension slopes (see Details; Robitzsch & Steinfeld, 2018). estimation conducted EM algorithm employing marginal maximum likelihood.","code":""},{"path":"/reference/rm.facets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"","code":"rm.facets(dat, pid=NULL, rater=NULL, Qmatrix=NULL, theta.k=seq(-9, 9, len=30),     est.b.rater=TRUE, est.a.item=FALSE, est.a.rater=FALSE, rater_item_int=FALSE,     est.mean=FALSE, tau.item.fixed=NULL, a.item.fixed=NULL, b.rater.fixed=NULL,     a.rater.fixed=NULL, b.rater.center=2, a.rater.center=2, a.item.center=2, a_lower=.05,     a_upper=10, reference_rater=NULL, max.b.increment=1, numdiff.parm=0.00001,     maxdevchange=0.1, globconv=0.001, maxiter=1000, msteps=4, mstepconv=0.001,     PEM=FALSE, PEM_itermax=maxiter)  # S3 method for rm.facets summary(object, file=NULL, ...)  # S3 method for rm.facets anova(object,...)  # S3 method for rm.facets logLik(object,...)  # S3 method for rm.facets IRT.irfprob(object,...)  # S3 method for rm.facets IRT.factor.scores(object, type=\"EAP\", ...)  # S3 method for rm.facets IRT.likelihood(object,...)  # S3 method for rm.facets IRT.posterior(object,...)  # S3 method for rm.facets IRT.modelfit(object,...)  # S3 method for IRT.modelfit.rm.facets summary(object, ...)  ## function for processing data rm_proc_data( dat, pid, rater, rater_item_int=FALSE, reference_rater=NULL )"},{"path":"/reference/rm.facets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"dat Original data frame. Ratings variables must rows, .e. every row corresponds person-rater combination. pid Person identifier. rater Rater identifier Qmatrix optional Q-matrix. matrix provided, default ordinary scoring categories (0 maximum score \\(K\\)) used. theta.k grid theta values ability distribution. est.b.rater rater severities \\(b_r\\) estimated? est..item item slopes \\(a_i\\) estimated? est..rater rater slopes \\(a_r\\) estimated? rater_item_int Logical indicating whether rater-item-interactions modeled. est.mean Optional logical indicating whether mean trait distribution estimated. tau.item.fixed Matrix fixed \\(\\tau\\) parameters. Non-fixed parameters must declared NA values. .item.fixed Vector fixed item discriminations b.rater.fixed Vector fixed rater intercept parameters .rater.fixed Vector fixed rater discrimination parameters b.rater.center Centering method rater intercept parameters.     value 0 corresponds centering, values 1 2 different methods ensure sum zero. .rater.center Centering method rater discrimination parameters.     value 0 corresponds centering, values 1 2 different methods ensure product equals one. .item.center Centering method item discrimination parameters.     value 0 corresponds centering, values 1 2 different methods ensure product equals one. a_lower Lower bound \\(\\) parameters a_upper Upper bound \\(\\) parameters reference_rater Identifier rater reference rater fixed rater mean 0 fixed rater slope 1 assumed. max.b.increment Maximum increment item parameters estimation numdiff.parm Numerical differentiation step width maxdevchange Maximum relative deviance change convergence criterion globconv Maximum parameter change maxiter Maximum number iterations msteps Maximum number iterations M step mstepconv Convergence criterion M step PEM Logical indicating whether P-EM acceleration applied (Berlinet & Roland, 2012). PEM_itermax Number iterations P-EM method applied. object Object class rm.facets file Optional file name summary written. type Factor score estimation method. Factor score types     \"EAP\", \"MLE\" \"WLE\" supported. ... arguments passed","code":""},{"path":"/reference/rm.facets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"function models ratings \\(X_{pri}\\) person \\(p\\), rater \\(r\\) item \\(\\) category \\(k\\) (see also Robitzsch & Steinfeld, 2018; Uto & Ueno, 2010; Wu, 2017) $$P( X_{pri}=k | \\theta_p ) \\propto     \\exp( a_i a_r q_{ik} \\theta_p - q_{ik} b_r -   \\tau_{ik} ) \\quad,     \\quad \\theta_p \\sim N( 0, \\sigma^2 )$$ default, scores \\(Q\\) matrix \\(q_{ik}=k\\). Item slopes \\(a_i\\) rater slopes \\(a_r\\) standardized product equals one, .e. \\( \\prod_i a_i=\\prod_r a_r=1\\).","code":""},{"path":"/reference/rm.facets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"list following entries: deviance Deviance ic Information criteria number parameters item Data frame item parameters rater Data frame rater parameters person Data frame person parameters: EAP corresponding     standard errors EAP.rel EAP reliability mu Mean trait distribution sigma Standard deviation trait distribution theta.k Grid theta values pi.k Fitted distribution theta.k values tau.item Item parameters \\(\\tau_{ik}\\) se.tau.item Standard error item parameters \\(\\tau_{ik}\\) .item Item slopes \\(a_i\\) se..item Standard error item slopes \\(a_i\\) delta.item Delta item parameter. See     pcm.conversion. b.rater Rater severity parameter \\(b_r\\) se.b.rater Standard error rater severity parameter \\(b_r\\) .rater Rater slope parameter \\(a_r\\) se..rater Standard error rater slope parameter \\(a_r\\) f.yi.qk Individual likelihood f.qk.yi Individual posterior distribution probs Item probabilities grid theta.k n.ik Expected counts maxK Maximum number categories procdata Processed data iter Number iterations ipars.dat2 Item parameters expanded dataset dat2 ... values","code":""},{"path":"/reference/rm.facets.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"Berlinet, . F., & Roland, C. (2012). Acceleration EM algorithm: P-EM versus epsilon algorithm. Computational Statistics & Data Analysis, 56(12), 4122-4137. Linacre, J. M. (1994). Many-Facet Rasch Measurement. Chicago: MESA Press. Robitzsch, ., & Steinfeld, J. (2018). Item response models human ratings: Overview, estimation methods, implementation R. Psychological Test Assessment Modeling, 60(1), 101-139. Uto, M., & Ueno, M. (2016). Item response theory peer assessment. IEEE Transactions Learning Technologies, 9(2), 157-170. Wu, M. (2017). IRT-based analyses interpreting rater effects. Psychological Test Assessment Modeling, 59(4), 453-470.","code":""},{"path":"/reference/rm.facets.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"trait standard deviation sigma strongly differs 1, user investigate sensitivity results using different theta integration points theta.k.","code":""},{"path":[]},{"path":"/reference/rm.facets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rater Facets Models with Item/Rater Intercepts and Slopes — rm.facets","text":"","code":"############################################################################# # EXAMPLE 1: Partial Credit Model and Generalized partial credit model #                   5 items and 1 rater ############################################################################# data(data.ratings1) dat <- data.ratings1  # select rater db01 dat <- dat[ paste(dat$rater)==\"db01\", ]  #****  Model 1: Partial Credit Model mod1 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], pid=dat$idstud )  #****  Model 2: Generalized Partial Credit Model mod2 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ],  pid=dat$idstud, est.a.item=TRUE)  summary(mod1) summary(mod2)  if (FALSE) { ############################################################################# # EXAMPLE 2: Facets Model: 5 items, 7 raters #############################################################################  data(data.ratings1) dat <- data.ratings1  #****  Model 1: Partial Credit Model: no rater effects mod1 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater,              pid=dat$idstud, est.b.rater=FALSE )  #****  Model 2: Partial Credit Model: intercept rater effects mod2 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater, pid=dat$idstud)  # extract individual likelihood lmod1 <- IRT.likelihood(mod1) str(lmod1) # likelihood value logLik(mod1) # extract item response functions pmod1 <- IRT.irfprob(mod1) str(pmod1) # model comparison anova(mod1,mod2) # absolute and relative model fit smod1 <- IRT.modelfit(mod1) summary(smod1) smod2 <- IRT.modelfit(mod2) summary(smod2) IRT.compareModels( smod1, smod2 ) # extract factor scores (EAP is the default) IRT.factor.scores(mod2) # extract WLEs IRT.factor.scores(mod2, type=\"WLE\")  #****  Model 2a: compare results with TAM package #   Results should be similar to Model 2 library(TAM) mod2a <- TAM::tam.mml.mfr( resp=dat[, paste0( \"k\",1:5) ],              facets=dat[, \"rater\", drop=FALSE],              pid=dat$pid, formulaA=~ item*step + rater )  #****  Model 2b: Partial Credit Model: some fixed parameters # fix rater parameters for raters 1, 4 and 5 b.rater.fixed <- rep(NA,7) b.rater.fixed[ c(1,4,5) ] <- c(1,-.8,0)  # fixed parameters # fix item parameters of first and second item tau.item.fixed <- round( mod2$tau.item, 1 )    # use parameters from mod2 tau.item.fixed[ 3:5, ] <- NA    # free item parameters of items 3, 4 and 5 mod2b <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater,              b.rater.fixed=b.rater.fixed, tau.item.fixed=tau.item.fixed,              est.mean=TRUE, pid=dat$idstud) summary(mod2b)  #****  Model 3: estimated rater slopes mod3 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater,             est.a.rater=TRUE)  #****  Model 4: estimated item slopes mod4 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater,              pid=dat$idstud, est.a.item=TRUE)  #****  Model 5: estimated rater and item slopes mod5 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater,              pid=dat$idstud, est.a.rater=TRUE, est.a.item=TRUE) summary(mod1) summary(mod2) summary(mod2a) summary(mod3) summary(mod4) summary(mod5)  #****  Model 5a: Some fixed parameters in Model 5 # fix rater b parameters for raters 1, 4 and 5 b.rater.fixed <- rep(NA,7) b.rater.fixed[ c(1,4,5) ] <- c(1,-.8,0) # fix rater a parameters for first four raters a.rater.fixed <- rep(NA,7) a.rater.fixed[ c(1,2,3,4) ] <- c(1.1,0.9,.85,1) # fix item b parameters of first item tau.item.fixed <- matrix( NA, nrow=5, ncol=3 ) tau.item.fixed[ 1, ] <- c(-2,-1.5, 1 ) # fix item a parameters a.item.fixed <- rep(NA,5) a.item.fixed[ 1:4 ] <- 1 # estimate model mod5a <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater,              pid=dat$idstud, est.a.rater=TRUE, est.a.item=TRUE,              tau.item.fixed=tau.item.fixed, b.rater.fixed=b.rater.fixed,              a.rater.fixed=a.rater.fixed, a.item.fixed=a.item.fixed,              est.mean=TRUE) summary(mod5a)  #****  Model 6: Estimate rater model with reference rater 'db03' mod6 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater, est.a.item=TRUE,              est.a.rater=TRUE, pid=dat$idstud, reference_rater=\"db03\" ) summary(mod6)  #**** Model 7: Modelling rater-item-interactions mod7 <- sirt::rm.facets( dat[, paste0( \"k\",1:5) ], rater=dat$rater, est.a.item=FALSE,              est.a.rater=TRUE, pid=dat$idstud, reference_rater=\"db03\",              rater_item_int=TRUE) summary(mod7) }"},{"path":"/reference/rm.sdt.html","id":null,"dir":"Reference","previous_headings":"","what":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","title":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","text":"function estimates version hierarchical rater model (HRM) based signal detection theory (HRM-SDT; DeCarlo, 2005; DeCarlo, Kim & Johnson, 2011; Robitzsch & Steinfeld, 2018). model estimated means EM algorithm adapted multilevel latent class analysis (Vermunt, 2008).","code":""},{"path":"/reference/rm.sdt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","text":"","code":"rm.sdt(dat, pid, rater, Qmatrix=NULL, theta.k=seq(-9, 9, len=30),     est.a.item=FALSE, est.c.rater=\"n\", est.d.rater=\"n\", est.mean=FALSE, est.sigma=TRUE,     skillspace=\"normal\", tau.item.fixed=NULL, a.item.fixed=NULL,     d.min=0.5, d.max=100, d.start=3, c.start=NULL, tau.start=NULL, sd.start=1,     d.prior=c(3,100), c.prior=c(3,100), tau.prior=c(0,1000), a.prior=c(1,100),     link_item=\"GPCM\", max.increment=1, numdiff.parm=0.00001, maxdevchange=0.1,     globconv=.001, maxiter=1000, msteps=4, mstepconv=0.001, optimizer=\"nlminb\" )  # S3 method for rm.sdt summary(object, file=NULL, ...)  # S3 method for rm.sdt plot(x, ask=TRUE, ...)  # S3 method for rm.sdt anova(object,...)  # S3 method for rm.sdt logLik(object,...)  # S3 method for rm.sdt IRT.factor.scores(object, type=\"EAP\", ...)  # S3 method for rm.sdt IRT.irfprob(object,...)  # S3 method for rm.sdt IRT.likelihood(object,...)  # S3 method for rm.sdt IRT.posterior(object,...)  # S3 method for rm.sdt IRT.modelfit(object,...)  # S3 method for IRT.modelfit.rm.sdt summary(object,...)"},{"path":"/reference/rm.sdt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","text":"dat Original data frame. Ratings variables must rows, .e. every row corresponds person-rater combination. pid Person identifier. rater Rater identifier. Qmatrix optional Q-matrix. matrix provided, default ordinary scoring categories (0 maximum score \\(K\\)) used. theta.k grid theta values ability distribution. est..item item parameters \\(a_i\\) estimated? est.c.rater Type estimation item-rater parameters \\(c_{ir}\\) signal detection model. Options 'n' (estimation), 'e' (set parameters equal ), '' (itemwise estimation), 'r' (rater wise estimation) '' (parameters estimated independently ). est.d.rater Type estimation \\(d\\) parameters. Options est.c.rater. est.mean Optional logical indicating whether mean trait distribution estimated. est.sigma Optional logical indicating whether standard deviation trait distribution estimated. skillspace Specified \\(\\theta\\) distribution type. can     \"normal\" \"discrete\". latter case,     probabilities distribution separately        estimated. tau.item.fixed Optional matrix three columns specifying fixed \\(\\tau\\) parameters. first two columns denote item category indices, third fixed value. See Example 3. .item.fixed Optional matrix two columns specifying fixed     \\(\\) parameters. First column: Item index. Second column: Fixed \\(\\) parameter. d.min Minimal \\(d\\) parameter estimated d.max Maximal \\(d\\) parameter estimated d.start Starting value(s) \\(d\\) parameters c.start Starting values \\(c\\) parameters tau.start Starting values \\(\\tau\\) parameters sd.start Starting value trait standard deviation d.prior Normal prior \\(N(M,S^2)\\) \\(d\\) parameters c.prior Normal prior \\(c\\) parameters. prior     parameter \\(c_{irk}\\) defined \\(M \\cdot ( k - 0.5) \\)     \\(M\\) c.prior[1]. tau.prior Normal prior \\(\\tau\\) parameters .prior Normal prior \\(\\) parameters link_item Type item response function latent responses. Can \"GPCM\" generalized partial credit model \"GRM\" graded response model. max.increment Maximum increment item parameters estimation numdiff.parm Numerical differentiation step width maxdevchange Maximum relative deviance change convergence criterion globconv Maximum parameter change maxiter Maximum number iterations msteps Maximum number iterations M step mstepconv Convergence criterion M step optimizer Choice optimization function M-step item parameters. Options \"nlminb\" stats::nlminb \"optim\" stats::optim. object Object class rm.sdt file Optional file name summary written. x Object class rm.sdt ask Optional logical indicating whether new plot asked . type Factor score estimation method. now,     type=\"EAP\" supported. ... arguments passed","code":""},{"path":"/reference/rm.sdt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","text":"specification model follows DeCarlo et al. (2011). second level models ideal rating (latent response) \\(\\eta=0, ...,K\\) person \\(p\\) item \\(\\). option link_item='GPCM' follows generalized partial credit model $$ P( \\eta_{pi}=\\eta | \\theta_p ) \\propto exp( a_{} q_{\\eta } \\theta_p - \\tau_{\\eta } ) $$. option link_item='GRM' employs graded response model   $$ P( \\eta_{pi}=\\eta | \\theta_p )= \\Psi( \\tau_{,\\eta + 1} - a_i \\theta_p ) - \\Psi( \\tau_{,\\eta} - a_i \\theta_p ) $$ first level, ratings \\(X_{pir}\\) person \\(p\\) item \\(\\) rater \\(r\\) modeled signal detection model $$ P( X_{pir} \\le k | \\eta_{pi} )= G( c_{irk} - d_{ir} \\eta_{pi} )$$ \\(G\\) logistic distribution function categories \\(k=1,\\ldots, K+1\\). Note item response model can equivalently written $$ P( X_{pir} \\ge k | \\eta_{pi} )= G(   d_{ir} \\eta_{pi} - c_{irk})$$ thresholds \\(c_{irk}\\) can restricted \\(c_{irk}=c_{k}\\) (est.c.rater='e'), \\(c_{irk}=c_{ik}\\) (est.c.rater='') \\(c_{irk}=c_{ir}\\) (est.c.rater='r'). holds rater precision parameters \\(d_{ir}\\).","code":""},{"path":"/reference/rm.sdt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","text":"list following entries: deviance Deviance ic Information criteria number parameters item Data frame item parameters. columns N M denote number observed ratings observed mean ratings, respectively.  addition item parameters \\(\\tau_{ik}\\) \\(a_i\\), mean latent response (latM) computed \\(E( \\eta_i )=\\sum_p P( \\theta_p ) q_{ik} P( \\eta_i=k | \\theta_p ) \\) provides item parameter original metric ratings. latent standard deviation (latSD) computed manner. rater Data frame rater parameters. Transformed \\(c\\) parameters (c_x.trans) computed \\(c_{irk} / ( d_{ir}  )\\). person Data frame person parameters: EAP corresponding standard errors EAP.rel EAP reliability EAP.rel EAP reliability mu Mean trait distribution sigma Standard deviation trait distribution tau.item Item parameters \\(\\tau_{ik}\\) se.tau.item Standard error item parameters \\(\\tau_{ik}\\) .item Item slopes \\(a_i\\) se..item Standard error item slopes \\(a_i\\) c.rater Rater parameters \\(c_{irk}\\) se.c.rater Standard error rater severity parameter \\(c_{irk}\\) d.rater Rater slope parameter \\(d_{ir}\\) se.d.rater Standard error rater slope parameter \\(d_{ir}\\) f.yi.qk Individual likelihood f.qk.yi Individual posterior distribution probs Item probabilities grid theta.k. Note   probabilities calculated pseudo items \\(\\times r\\),   .e. interaction item rater. prob.item Probabilities \\(P( \\eta_i=\\eta | \\theta )\\)     latent item responses evaluated theta grid \\(\\theta_p\\). n.ik Expected counts pi.k Estimated trait distribution \\(P(\\theta_p)\\). maxK Maximum number categories procdata Processed data iter Number iterations ... values","code":""},{"path":"/reference/rm.sdt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","text":"DeCarlo, L. T. (2005). model rater behavior essay grading based signal detection theory. Journal Educational Measurement, 42, 53-76. DeCarlo, L. T. (2010). Studies latent-class signal-detection model constructed response scoring II: Incomplete hierarchical designs. ETS Research Report ETS RR-10-08. Princeton NJ: ETS. DeCarlo, T., Kim, Y., & Johnson, M. S. (2011). hierarchical rater model constructed responses, signal detection rater model. Journal Educational Measurement, 48, 333-356. Robitzsch, ., & Steinfeld, J. (2018). Item response models human ratings: Overview, estimation methods, implementation R. Psychological Test Assessment Modeling, 60(1), 101-139. Vermunt, J. K. (2008). Latent class finite mixture models multilevel data sets. Statistical Methods Medical Research, 17, 33-51.","code":""},{"path":[]},{"path":"/reference/rm.sdt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hierarchical Rater Model Based on Signal Detection Theory (HRM-SDT) — rm.sdt","text":"","code":"############################################################################# # EXAMPLE 1: Hierarchical rater model (HRM-SDT) data.ratings1 ############################################################################# data(data.ratings1) dat <- data.ratings1  if (FALSE) { # Model 1: Partial Credit Model: no rater effects mod1 <- sirt::rm.sdt( dat[, paste0( \"k\",1:5) ], rater=dat$rater,             pid=dat$idstud, est.c.rater=\"n\", d.start=100,  est.d.rater=\"n\" ) summary(mod1)  # Model 2: Generalized Partial Credit Model: no rater effects mod2 <- sirt::rm.sdt( dat[, paste0( \"k\",1:5) ], rater=dat$rater,             pid=dat$idstud, est.c.rater=\"n\", est.d.rater=\"n\",             est.a.item=TRUE, d.start=100) summary(mod2)  # Model 3: Equal effects in SDT mod3 <- sirt::rm.sdt( dat[, paste0( \"k\",1:5) ], rater=dat$rater,             pid=dat$idstud, est.c.rater=\"e\", est.d.rater=\"e\") summary(mod3)  # Model 4: Rater effects in SDT mod4 <- sirt::rm.sdt( dat[, paste0( \"k\",1:5) ], rater=dat$rater,             pid=dat$idstud, est.c.rater=\"r\", est.d.rater=\"r\") summary(mod4)  ############################################################################# # EXAMPLE 2: HRM-SDT data.ratings3 #############################################################################  data(data.ratings3) dat <- data.ratings3 dat <- dat[ dat$rater < 814, ] psych::describe(dat)  # Model 1: item- and rater-specific effects mod1 <- sirt::rm.sdt( dat[, paste0( \"crit\",c(2:4)) ], rater=dat$rater,             pid=dat$idstud, est.c.rater=\"a\", est.d.rater=\"a\" ) summary(mod1) plot(mod1)  # Model 2: Differing number of categories per variable mod2 <- sirt::rm.sdt( dat[, paste0( \"crit\",c(2:4,6)) ], rater=dat$rater,             pid=dat$idstud, est.c.rater=\"a\", est.d.rater=\"a\") summary(mod2) plot(mod2)  ############################################################################# # EXAMPLE 3: Hierarchical rater model with discrete skill spaces #############################################################################  data(data.ratings3) dat <- data.ratings3 dat <- dat[ dat$rater < 814, ] psych::describe(dat)  # Model 1: Discrete theta skill space with values of 0,1,2 and 3 mod1 <- sirt::rm.sdt( dat[, paste0( \"crit\",c(2:4)) ], theta.k=0:3, rater=dat$rater,             pid=dat$idstud, est.c.rater=\"a\", est.d.rater=\"a\", skillspace=\"discrete\" ) summary(mod1) plot(mod1)  # Model 2: Modelling of one item by using a discrete skill space and #          fixed item parameters  # fixed tau and a parameters tau.item.fixed <- cbind( 1, 1:3,  100*cumsum( c( 0.5, 1.5, 2.5)) ) a.item.fixed <- cbind( 1, 100 ) # fit HRM-SDT mod2 <- sirt::rm.sdt( dat[, \"crit2\", drop=FALSE], theta.k=0:3, rater=dat$rater,             tau.item.fixed=tau.item.fixed,a.item.fixed=a.item.fixed, pid=dat$idstud,             est.c.rater=\"a\", est.d.rater=\"a\", skillspace=\"discrete\" ) summary(mod2) plot(mod2) }"},{"path":"/reference/rmvn.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation of a Multivariate Normal Distribution with Exact Moments — rmvn","title":"Simulation of a Multivariate Normal Distribution with Exact Moments — rmvn","text":"Simulates dataset multivariate univariate normal distribution exactly fulfils specified mean vector covariance matrix.","code":""},{"path":"/reference/rmvn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation of a Multivariate Normal Distribution with Exact Moments — rmvn","text":"","code":"# multivariate normal distribution rmvn(N, mu, Sigma, exact=TRUE)  # univariate normal distribution ruvn(N, mean=0, sd=1, exact=TRUE)"},{"path":"/reference/rmvn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation of a Multivariate Normal Distribution with Exact Moments — rmvn","text":"N Sample size mu Mean vector Sigma Covariance matrix exact Logical indicating whether mu Sigma exactly reproduced. mean Numeric value mean sd Numeric value standard deviation","code":""},{"path":"/reference/rmvn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulation of a Multivariate Normal Distribution with Exact Moments — rmvn","text":"dataframe vector","code":""},{"path":[]},{"path":"/reference/rmvn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation of a Multivariate Normal Distribution with Exact Moments — rmvn","text":"","code":"############################################################################# # EXAMPLE 1: Simulate multivariate normal data #############################################################################  # define covariance matrix and mean vector rho <- .8 Sigma <- matrix(rho,3,3) diag(Sigma) <- 1 mu <- c(0,.5,1)  #* simulate data set.seed(87) dat <- sirt::rmvn(N=200, mu=mu, Sigma=Sigma) #* check means and covariances stats::cov.wt(dat, method=\"ML\")  if (FALSE) { ############################################################################# # EXAMPLE 2: Simulate univariate normal data #############################################################################  #* simulate data x <- sirt::ruvn(N=20, mean=.5, sd=1.2, exact=TRUE) # check results stats::var(x) sirt:::sirt_var(x) }"},{"path":"/reference/scale_group_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Scaling of Group Means and Standard Deviations — scale_group_means","title":"Scaling of Group Means and Standard Deviations — scale_group_means","text":"Scales vector means standard deviations containing group values.","code":""},{"path":"/reference/scale_group_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scaling of Group Means and Standard Deviations — scale_group_means","text":"","code":"scale_group_means(M, SD, probs=NULL, M_target=0, SD_target=1)  ## predict method predict_scale_group_means(object, M, SD)"},{"path":"/reference/scale_group_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scaling of Group Means and Standard Deviations — scale_group_means","text":"M Vector means SD Vector standard deviations probs Optional vector containing probabilities M_target Target value mean SD_target Target value standard deviation object Fitted object scale_group_means","code":""},{"path":"/reference/scale_group_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scaling of Group Means and Standard Deviations — scale_group_means","text":"List entries M1 total mean SD1 total standard deviation M_z standardized means SD_z standardized standard deviations M_trafo transformed means SD_trafo transformed standard deviations","code":""},{"path":"/reference/scale_group_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scaling of Group Means and Standard Deviations — scale_group_means","text":"","code":"############################################################################# # EXAMPLE 1: Toy example #############################################################################  M <- c(-.03, .18, -.23, -.15, .29) SD <- c(.97, 1.13, .77, 1.05, 1.17) sirt::scale_group_means(M=M, SD=SD)"},{"path":"/reference/sia.sirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical Implicative Analysis (SIA) — sia.sirt","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"function simplified implementation statistical implicative analysis (Gras & Kuntz, 2008) aims deriving implications \\(X_i \\rightarrow X_j\\). means solving item \\(\\) implies solving item \\(j\\).","code":""},{"path":"/reference/sia.sirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"","code":"sia.sirt(dat, significance=0.85)"},{"path":"/reference/sia.sirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"dat Data frame dichotomous item responses significance Minimum implicative probability inclusion arrow graph. probability can interpreted kind significance level, .e. higher probabilities indicate probable implications.","code":""},{"path":"/reference/sia.sirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"test statistic selection implicative relation follows Gras Kuntz (2008). Transitive arrows (implications) removed graph. implications symmetric, probable implication retained.","code":""},{"path":"/reference/sia.sirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"list following entries adj.matrix Adjacency matrix graph. Transitive   symmetric implications (arrows) removed. adj.pot Adjacency matrix including powers, .e. direct   indirect paths item \\(\\) item \\(j\\). adj.matrix.trans Adjacency matrix including transitive arrows. desc List descriptive statistics graph. desc.item Descriptive statistics item. impl.int Implication intensity (probability) basis   deciding significance arrow impl.t Corresponding \\(t\\) values impl.int impl.significance Corresponding \\(p\\) values (significancies)    impl.int conf.loev Confidence according Loevinger (see Gras & Kuntz, 2008).   values just conditional probabilities \\(P( X_j=1|X_i=1)\\). graph.matr Matrix containing arrows. Can used   example Rgraphviz package. graph.edges Vector containing edges graph, e.g.   Rgraphviz package. igraph.matr Matrix containing arrows igraph       package. igraph.obj object graph igraph package.","code":""},{"path":"/reference/sia.sirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"Gras, R., & Kuntz, P. (2008). overview statistical implicative analysis (SIA) development. R. Gras, E. Suzuki, F. Guillet, & F. Spagnolo (Eds.). Statistical Implicative Analysis (pp. 11-40). Springer, Berlin Heidelberg.","code":""},{"path":"/reference/sia.sirt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"implementation statistical implicative analysis C.H..C. (Classification Hierarchique, Implicative et Cohesitive) software. See https://ardm.eu/partenaires/logiciel-danalyse-de-donnees-c-h--c/.","code":""},{"path":[]},{"path":"/reference/sia.sirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical Implicative Analysis (SIA) — sia.sirt","text":"","code":"############################################################################# # EXAMPLE 1: SIA for data.read #############################################################################  data(data.read) dat <- data.read  res <- sirt::sia.sirt(dat, significance=.85 )  #*** plot results with igraph package library(igraph) plot( res$igraph.obj ) #, vertex.shape=\"rectangle\", vertex.size=30 )  if (FALSE) { #*** plot results with qgraph package miceadds::library_install(qgraph) qgraph::qgraph( res$adj.matrix )  #*** plot results with Rgraphviz package # Rgraphviz can only be obtained from Bioconductor # If it should be downloaded, select TRUE for the following lines if (FALSE){      source(\"http://bioconductor.org/biocLite.R\")      biocLite(\"Rgraphviz\")             } # define graph grmatrix <- res$graph.matr res.graph <- new(\"graphNEL\", nodes=res$graph.edges, edgemode=\"directed\") # add edges RR <- nrow(grmatrix) for (rr in 1:RR){     res.graph <- Rgraphviz::addEdge(grmatrix[rr,1], grmatrix[rr,2], res.graph, 1)                     } # define cex sizes and shapes V <- length(res$graph.edges) size2 <- rep(16,V) shape2 <- rep(\"rectangle\", V ) names(shape2) <- names(size2) <- res$graph.edges # plot graph Rgraphviz::plot( res.graph, nodeAttrs=list(\"fontsize\"=size2, \"shape\"=shape2) ) }"},{"path":"/reference/sim.qm.ramsay.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","title":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","text":"function simulates dichotomous item response data according Ramsay's quotient model (Ramsay, 1989).","code":""},{"path":"/reference/sim.qm.ramsay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","text":"","code":"sim.qm.ramsay(theta, b, K)"},{"path":"/reference/sim.qm.ramsay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","text":"theta Vector length \\(N\\) person parameters (must positive!) b Vector length \\(\\) item difficulties (must positive) K Vector length \\(\\) guessing parameters (must positive)","code":""},{"path":"/reference/sim.qm.ramsay.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","text":"Ramsay's quotient model (Ramsay, 1989) defined equation $$P(X_{pi}=1 | \\theta_p )=\\frac{ \\exp { ( \\theta_p / b_i ) } }     { K_i + \\exp { ( \\theta_p / b_i ) } }$$","code":""},{"path":"/reference/sim.qm.ramsay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","text":"\\(N \\times \\)  data frame dichotomous item responses.","code":""},{"path":"/reference/sim.qm.ramsay.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","text":"Ramsay, J. O. (1989). comparison three simple test theory models. Psychometrika, 54, 487-499. van der Maas, H. J. L., Molenaar, D., Maris, G., Kievit, R. ., & Borsboom, D. (2011). Cognitive psychology meets psychometric theory: relation process models decision making latent variable models individual differences. Psychological Review, 318, 339-356.","code":""},{"path":[]},{"path":"/reference/sim.qm.ramsay.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from Ramsay's Quotient Model — sim.qm.ramsay","text":"","code":"############################################################################# # EXAMPLE 1: Estimate Ramsay Quotient Model with rasch.mml2 #############################################################################  set.seed(657) # simulate data according to the Ramsay model N <- 1000       # persons I <- 11         # items theta <- exp( stats::rnorm( N ) )  # person ability b <- exp( seq(-2,2,len=I))  # item difficulty K <- rep( 3, I )           # K parameter (=> guessing)  # apply simulation function dat <- sirt::sim.qm.ramsay( theta, b, K )  #*** # analysis mmliter <- 50       # maximum number of iterations I <- ncol(dat) fixed.K <- rep( 3, I )  # Ramsay QM with fixed K parameter (K=3 in fixed.K specification) mod1 <- sirt::rasch.mml2( dat, mmliter=mmliter, irtmodel=\"ramsay.qm\",               fixed.K=fixed.K ) summary(mod1)  # Ramsay QM with joint estimated K parameters mod2 <- sirt::rasch.mml2( dat, mmliter=mmliter, irtmodel=\"ramsay.qm\",              est.K=rep(1,I)  ) summary(mod2)  if (FALSE) { # Ramsay QM with itemwise estimated K parameters mod3 <- sirt::rasch.mml2( dat, mmliter=mmliter, irtmodel=\"ramsay.qm\",               est.K=1:I  ) summary(mod3)  # Rasch model mod4 <- sirt::rasch.mml2( dat ) summary(mod4)  # generalized logistic model mod5 <- sirt::rasch.mml2( dat, est.alpha=TRUE, mmliter=mmliter) summary(mod5)  # 2PL model mod6 <- sirt::rasch.mml2( dat, est.a=rep(1,I) ) summary(mod6)  # Difficulty + Guessing (b+c) Model mod7 <- sirt::rasch.mml2( dat, est.c=rep(1,I) ) summary(mod7)  # estimate separate guessing (c) parameters mod8 <- sirt::rasch.mml2( dat, est.c=1:I  ) summary(mod8)  #*** estimate Model 1 with user defined function in mirt package  # create user defined function for Ramsay's quotient model name <- 'ramsayqm' par <- c(\"K\"=3, \"b\"=1 ) est <- c(TRUE, TRUE) P.ramsay <- function(par,Theta){      eps <- .01      K <- par[1]      b <- par[2]      num <- exp( exp( Theta[,1] ) / b )      denom <- K + num      P1 <- num / denom      P1 <- eps + ( 1 - 2*eps ) * P1      cbind(1-P1, P1) }  # create item response function ramsayqm <- mirt::createItem(name, par=par, est=est, P=P.ramsay) # define parameters to be estimated mod1m.pars <- mirt::mirt(dat, 1, rep( \"ramsayqm\",I),                    customItems=list(\"ramsayqm\"=ramsayqm), pars=\"values\") mod1m.pars[ mod1m.pars$name==\"K\", \"est\" ] <- FALSE # define Theta design matrix Theta <- matrix( seq(-3,3,len=10), ncol=1) # estimate model mod1m <- mirt::mirt(dat, 1, rep( \"ramsayqm\",I), customItems=list(\"ramsayqm\"=ramsayqm),                pars=mod1m.pars, verbose=TRUE,                technical=list( customTheta=Theta, NCYCLES=50)                 ) print(mod1m) summary(mod1m) cmod1m <- sirt::mirt.wrapper.coef( mod1m )$coef # compare simulated and estimated values dfr <- cbind( b, cmod1m$b, exp(mod1$item$b ) ) colnames(dfr) <- c(\"simulated\", \"mirt\", \"sirt_rasch.mml2\") round( dfr, 2 )   ##      simulated mirt sirt_rasch.mml2   ## [1,]      0.14 0.11            0.11   ## [2,]      0.20 0.17            0.18   ## [3,]      0.30 0.27            0.29   ## [4,]      0.45 0.42            0.43   ## [5,]      0.67 0.65            0.67   ## [6,]      1.00 1.00            1.01   ## [7,]      1.49 1.53            1.54   ## [8,]      2.23 2.21            2.21   ## [9,]      3.32 3.00            2.98   ##[10,]      4.95 5.22            5.09   ##[11,]      7.39 5.62            5.51 }"},{"path":"/reference/sim.rasch.dep.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation of the Rasch Model with Locally Dependent Responses — sim.rasch.dep","title":"Simulation of the Rasch Model with Locally Dependent Responses — sim.rasch.dep","text":"function simulates dichotomous item responses itemclusters residual correlations can defined.","code":""},{"path":"/reference/sim.rasch.dep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation of the Rasch Model with Locally Dependent Responses — sim.rasch.dep","text":"","code":"sim.rasch.dep(theta, b, itemcluster, rho)"},{"path":"/reference/sim.rasch.dep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation of the Rasch Model with Locally Dependent Responses — sim.rasch.dep","text":"theta Vector person abilities length \\(N\\) b Vector item difficulties length \\(\\) itemcluster Vector integers (including 0) length \\(\\). Different integers correspond different itemclusters. rho Vector residual correlations. length vector must equal number itemclusters.","code":""},{"path":"/reference/sim.rasch.dep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulation of the Rasch Model with Locally Dependent Responses — sim.rasch.dep","text":"\\(N \\times \\) data frame dichotomous item responses.","code":""},{"path":"/reference/sim.rasch.dep.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulation of the Rasch Model with Locally Dependent Responses — sim.rasch.dep","text":"specification simulation models follows marginal interpretation latent trait. Local dependencies interpreted nuisance substantive interest. local dependencies substantively interpreted, testlet model seems preferable (see mcmc.3pno.testlet).","code":""},{"path":[]},{"path":"/reference/sim.rasch.dep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation of the Rasch Model with Locally Dependent Responses — sim.rasch.dep","text":"","code":"############################################################################# # EXAMPLE 1: 11 Items: 2 itemclusters with 2 resp. 3 dependent items #             and 6 independent items #############################################################################  set.seed(7654) I <- 11                             # number of items n <- 1500                           # number of persons b <- seq(-2,2, len=I)               # item difficulties theta <- stats::rnorm( n, sd=1 )        # person abilities # itemcluster itemcluster <- rep(0,I) itemcluster[ c(3,5)] <- 1 itemcluster[c(2,4,9)] <- 2 # residual correlations rho <- c( .7, .5 )  # simulate data dat <- sirt::sim.rasch.dep( theta, b, itemcluster, rho ) colnames(dat) <- paste(\"I\", seq(1,ncol(dat)), sep=\"\")  # estimate Rasch copula model mod1 <- sirt::rasch.copula2( dat, itemcluster=itemcluster ) summary(mod1)  # compare result with Rasch model estimation in rasch.copula # delta must be set to zero mod2 <- sirt::rasch.copula2( dat, itemcluster=itemcluster, delta=c(0,0),             est.delta=c(0,0)  ) summary(mod2)  # estimate Rasch model with rasch.mml2 function mod3 <- sirt::rasch.mml2( dat ) summary(mod3)  if (FALSE) { ############################################################################# # EXAMPLE 2: 12 Items: Cluster 1 -> Items 1,...,4; #       Cluster 2 -> Items 6,...,9; Cluster 3 -> Items 10,11,12 #############################################################################  set.seed(7896) I <- 12                             # number of items n <- 450                            # number of persons b <- seq(-2,2, len=I)               # item difficulties b <- sample(b)                      # sample item difficulties theta <- stats::rnorm( n, sd=1 )        # person abilities # itemcluster itemcluster <- rep(0,I) itemcluster[ 1:4 ] <- 1 itemcluster[ 6:9 ] <- 2 itemcluster[ 10:12 ] <- 3 # residual correlations rho <- c( .55, .25, .45 )  # simulate data dat <- sirt::sim.rasch.dep( theta, b, itemcluster, rho ) colnames(dat) <- paste(\"I\", seq(1,ncol(dat)), sep=\"\")  # estimate Rasch copula model mod1 <- sirt::rasch.copula2( dat, itemcluster=itemcluster, numdiff.parm=.001 ) summary(mod1)  # Rasch model estimation mod2 <- sirt::rasch.copula2( dat, itemcluster=itemcluster,             delta=rep(0,3), est.delta=rep(0,3) ) summary(mod2)  # estimation with pairwise Rasch model mod3 <- sirt::rasch.pairwise( dat ) summary(mod3) }"},{"path":"/reference/sim.raschtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","title":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","text":"function simulates dichotomous item responses generalized logistic item response model (Stukel, 1988). four-parameter logistic item response model (Loken & Rulison, 2010) special case. See rasch.mml2 details.","code":""},{"path":"/reference/sim.raschtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","text":"","code":"sim.raschtype(theta, b, alpha1=0, alpha2=0, fixed.a=NULL,     fixed.c=NULL, fixed.d=NULL)"},{"path":"/reference/sim.raschtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","text":"theta Unidimensional ability vector \\(\\theta\\) b Vector item difficulties \\(b\\) alpha1 Parameter \\(\\alpha_1\\) generalized logistic link function alpha2 Parameter \\(\\alpha_2\\) generalized logistic link function fixed.Vector item slopes \\(\\) fixed.c Vector lower item asymptotes \\(c\\) fixed.d Vector lower item asymptotes \\(d\\)","code":""},{"path":"/reference/sim.raschtype.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","text":"class generalized logistic link functions contain important link functions using specifications (Stukel, 1988): logistic link function: \\(\\alpha_1=0\\) \\(\\alpha_2=0\\)  probit link function: \\(\\alpha_1=0.165\\) \\(\\alpha_2=0.165\\)  loglog link function: \\(\\alpha_1=-0.037\\) \\(\\alpha_2=0.62\\)  cloglog link function: \\(\\alpha_1=0.62\\) \\(\\alpha_2=-0.037\\) See pgenlogis exact transformation formulas mentioned link functions.","code":""},{"path":"/reference/sim.raschtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","text":"Data frame simulated item responses","code":""},{"path":"/reference/sim.raschtype.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","text":"Loken, E., & Rulison, K. L. (2010). Estimation four-parameter item response theory model. British Journal Mathematical Statistical Psychology, 63, 509-525. Stukel, T. . (1988). Generalized logistic models. Journal American Statistical Association, 83, 426-431.","code":""},{"path":[]},{"path":"/reference/sim.raschtype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate from Generalized Logistic Item Response Model — sim.raschtype","text":"","code":"############################################################################# ## EXAMPLE 1: Simulation of data from a Rasch model (alpha_1=alpha_2=0) #############################################################################  set.seed(9765) N <- 500    # number of persons I <- 11     # number of items b <- seq( -2, 2, length=I ) dat <- sirt::sim.raschtype( stats::rnorm( N ), b ) colnames(dat) <- paste0( \"I\", 1:I )"},{"path":"/reference/sirt-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"Defunct sirt Functions — sirt-defunct","title":"Defunct sirt Functions — sirt-defunct","text":"functions removed replaced sirt package.","code":""},{"path":"/reference/sirt-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Defunct sirt Functions — sirt-defunct","text":"","code":"rasch.conquest(...) rasch.pml2(...) testlet.yen.q3(...) yen.q3(...)"},{"path":"/reference/sirt-defunct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Defunct sirt Functions — sirt-defunct","text":"... Arguments passed.","code":""},{"path":"/reference/sirt-defunct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Defunct sirt Functions — sirt-defunct","text":"rasch.conquest function replaced R2conquest. rasch.pml2 function superseded rasch.pml3. testlet.yen.q3 function replaced Q3.testlet. yen.q3 function replaced Q3.","code":""},{"path":"/reference/sirt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Supplementary Item Response Theory Models — sirt-package","title":"Supplementary Item Response Theory Models — sirt-package","text":"Supplementary functions item response models aiming     complement existing R packages. functionality includes among others     multidimensional compensatory noncompensatory IRT models     (Reckase, 2009, <doi:10.1007/978-0-387-89976-3>),      MCMC hierarchical IRT models testlet models     (Fox, 2010, <doi:10.1007/978-1-4419-0742-4>),      NOHARM (McDonald, 1982, <doi:10.1177/014662168200600402>),      Rasch copula model (Braeken, 2011, <doi:10.1007/s11336-010-9190-4>;     Schroeders, Robitzsch & Schipolowski, 2014, <doi:10.1111/jedm.12054>),     faceted hierarchical rater models (DeCarlo, Kim & Johnson, 2011,     <doi:10.1111/j.1745-3984.2011.00143.x>),     ordinal IRT model (ISOP; Scheiblechner, 1995, <doi:10.1007/BF02301417>),      DETECT statistic (Stout, Habing, Douglas & Kim, 1996,      <doi:10.1177/014662169602000403>), local structural equation modeling      (LSEM; Hildebrandt, Luedtke, Robitzsch, Sommer & Wilhelm, 2016,     <doi:10.1080/00273171.2016.1142856>).","code":""},{"path":"/reference/sirt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Supplementary Item Response Theory Models — sirt-package","text":"Alexander Robitzsch [aut,cre] (<https://orcid.org/0000-0002-8226-3132>) Maintainer: Alexander Robitzsch <robitzsch@ipn.uni-kiel.de>","code":""},{"path":"/reference/sirt-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Supplementary Item Response Theory Models — sirt-package","text":"sirt package enables estimation following models: Multidimensional marginal maximum likelihood estimation (MML)       generalized logistic Rasch type models using       generalized logistic link function (Stukel, 1988) can conducted       rasch.mml2 argument itemtype=\"raschtype\".       model also allows estimation 4PL item       response model (Loken & Rulison, 2010).       Multiple group estimation, latent regression models       plausible value imputation supported. addition, pseudo-likelihood       estimation fractional item response data can conducted.  Multidimensional noncompensatory, compensatory partially compensatory item response models dichotomous item responses (Reckase, 2009) can estimated smirt function options irtmodel=\"noncomp\" , irtmodel=\"comp\" irtmodel=\"partcomp\".  unidimensional quotient model (Ramsay, 1989) can estimated using rasch.mml2 itemtype=\"ramsay.qm\".  Unidimensional nonparametric item response models can estimated  employing MML estimation (Rossi, Wang & Ramsay, 2002) making use  rasch.mml2 itemtype=\"npirt\".  Kernel smoothing item response function estimation (Ramsay, 1991)  implemented np.dich.  multidimensional IRT copula model (Braeken, 2011) can applied     handling local dependencies, see rasch.copula3.  Unidimensional joint maximum likelihood estimation (JML) Rasch model possible rasch.jml function. Bias correction methods     item parameters included rasch.jml.jackknife1     rasch.jml.biascorr.  multidimensional latent class Rasch 2PL model (Bartolucci, 2007) employs discrete trait distribution can estimated rasch.mirtlc.  unidimensional 2PL rater facets model (Lincare, 1994) can estimated rm.facets. hierarchical rater model based signal detection theory (DeCarlo, Kim & Johnson, 2011) can conducted rm.sdt. simple latent class model two exchangeable raters implemented lc.2raters. See Robitzsch Steinfeld (2018) details.  discrete grade membership model (Erosheva, Fienberg & Joutard, 2007) Rasch grade membership model can estimated gom.em.  hierarchical IRT models random item models dichotomous normally distributed data (van den Noortgate, de Boeck & Meulders, 2003; Fox & Verhagen, 2010) can estimated mcmc.2pno.ml.  Unidimensional pairwise conditional likelihood estimation     (PCML; Zwinderman, 1995) implemented rasch.pairwise     rasch.pairwise.itemcluster.  Unidimensional pairwise marginal likelihood estimation    (PMML; Renard, Molenberghs & Geys, 2004)     can conducted using rasch.pml3. function     local dependence can handled imposing residual error structure     omitting item pairs within dependent item cluster     estimation.      function rasch.evm.pcm estimates multiple group     partial credit model based pairwise eigenvector approach     avoids iterative estimation.  item response models sirt can estimated via Markov Chain Monte Carlo (MCMC) methods. mcmc.2pno two-parameter normal ogive model can estimated. hierarchical version model (Janssen, Tuerlinckx, Meulders & de Boeck, 2000) implemented mcmc.2pnoh. 3PNO testlet model (Wainer, Bradlow & Wang, 2007; Glas, 2012) can estimated mcmc.3pno.testlet. hierarchical IRT models random item models (van den Noortgate, de Boeck & Meulders, 2003) can estimated mcmc.2pno.ml.  dichotomous response data, free NOHARM software (McDonald, 1982, 1997) estimates multidimensional compensatory 3PL model function R2noharm runs NOHARM within R. Note NOHARM must downloaded http://noharm.niagararesearch.ca/nh4cldl.html first. pure R implementation NOHARM model extensions can found noharm.sirt.  measurement theoretic founded nonparametric item response models Scheiblechner (1995, 1999) -- ISOP ADISOP model -- can estimated isop.dich isop.poly. Item scoring within theory can conducted isop.scoring.  functional unidimensional item response model (Ip et al., 2013) can estimated f1d.irt.  Rasch model can estimated variational approximation (Rijmen & Vomlel, 2008) using rasch.va.  unidimensional probabilistic Guttman model (Proctor, 1970) can     specified prob.guttman.  jackknife method estimation standard errors     weighted likelihood trait estimate (Warm, 1989) available     wle.rasch.jackknife.  Model based reliability dichotomous data can calculated method Green Yang (2009) greenyang.reliability marginal true score method Dimitrov (2003) using function marginal.truescore.reliability.  Essential unidimensionality can assessed DETECT     index (Stout, Habing, Douglas & Kim, 1996), see function     conf.detect.  Item parameters several studies can linked using Haberman method (Haberman, 2009) linking.haberman. See also equating.rasch linking.robust. alignment procedure (Asparouhov & Muthen, 2013) invariance.alignment originally comfirmatory factor analysis aims obtaining approximate invariance.  person fit statistics Rasch model (Meijer & Sijtsma, 2001)     included personfit.stat.  alternative linear logistic test model (LLTM),     called least squares distance model cognitive diagnosis     (LSDM; Dimitrov, 2007), can estimated function     lsdm.  Local structural equation models (LSEM) can estimated lsem.estimate function (Hildebrandt et al., 2016).","code":""},{"path":"/reference/sirt-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Supplementary Item Response Theory Models — sirt-package","text":"Asparouhov, T., & Muthen, B. (2014). Multiple-group factor analysis alignment. Structural Equation Modeling, 21(4), 1-14. doi:10.1080/10705511.2014.919210 Bartolucci, F. (2007). class multidimensional IRT models testing unidimensionality clustering items. Psychometrika, 72, 141-157. Braeken, J. (2011). boundary mixture approach violations conditional independence. Psychometrika, 76(1), 57-76. doi:10.1007/s11336-010-9190-4 DeCarlo, T., Kim, Y., & Johnson, M. S. (2011). hierarchical rater model constructed responses, signal detection rater model. Journal Educational Measurement, 48(3), 333-356. doi:10.1111/j.1745-3984.2011.00143.x Dimitrov, D. (2003). Marginal true-score measures reliability binary items function IRT parameters. Applied Psychological Measurement, 27, 440-458. Dimitrov, D. M. (2007). Least squares distance method cognitive validation analysis binary items using item response theory parameters. Applied Psychological Measurement, 31, 367-387. Erosheva, E. ., Fienberg, S. E., & Joutard, C. (2007). Describing disability individual-level mixture models multivariate binary data. Annals Applied Statistics, 1, 502-537. Fox, J.-P. (2010). Bayesian item response modeling. New York: Springer. doi:10.1007/978-1-4419-0742-4 Fox, J.-P., & Verhagen, .-J. (2010). Random item effects modeling cross-national survey data. E. Davidov, P. Schmidt, & J. Billiet (Eds.), Cross-cultural Analysis: Methods Applications (pp. 467-488), London: Routledge Academic. Fraser, C., & McDonald, R. P. (1988). NOHARM: Least squares item factor analysis. Multivariate Behavioral Research, 23, 267-269. Glas, C. . W. (2012). Estimating testing extended testlet model. LSAC Research Report Series, RR 12-03. Green, S.B., & Yang, Y. (2009). Reliability summed item scores using structural equation modeling: alternative coefficient alpha. Psychometrika, 74, 155-167. Haberman, S. J. (2009). Linking parameter estimates derived item response model separate calibrations. ETS Research Report ETS RR-09-40. Princeton, ETS. doi:10.1002/j.2333-8504.2009.tb02197.x Hildebrandt, ., Luedtke, O., Robitzsch, ., Sommer, C., & Wilhelm, O. (2016). Exploring factor model parameters across continuous variables local structural equation models. Multivariate Behavioral Research, 51(2-3), 257-278. doi:10.1080/00273171.2016.1142856 Ip, E. H., Molenberghs, G., Chen, S. H., Goegebeur, Y., & De Boeck, P. (2013). Functionally unidimensional item response models multivariate binary data. Multivariate Behavioral Research, 48, 534-562. Janssen, R., Tuerlinckx, F., Meulders, M., & de Boeck, P. (2000). hierarchical IRT model criterion-referenced measurement. Journal Educational Behavioral Statistics, 25, 285-306. Jeon, M., & Rijmen, F. (2016). modular approach item response theory modeling  R package flirt. Behavior Research Methods, 48(2), 742-755. doi:10.3758/s13428-015-0606-z Linacre, J. M. (1994). Many-Facet Rasch Measurement. Chicago: MESA Press. Loken, E. & Rulison, K. L. (2010). Estimation four-parameter item response theory model. British Journal Mathematical Statistical Psychology, 63, 509-525. McDonald, R. P. (1982). Linear versus nonlinear models item response theory. Applied Psychological Measurement, 6(4), 379-396. doi:10.1177/014662168200600402 McDonald, R. P. (1997). Normal-ogive multidimensional model. W. van der Linden & R. K. Hambleton (1997): Handbook modern item response theory (pp. 257-269). New York: Springer. doi:10.1007/978-1-4757-2691-6_15 Meijer, R. R., & Sijtsma, K. (2001). Methodology review: Evaluating person fit. Applied Psychological Measurement, 25, 107-135. Proctor, C. H. (1970). probabilistic formulation statistical analysis Guttman scaling. Psychometrika, 35, 73-78. Ramsay, J. O. (1989). comparison three simple test theory models. Psychometrika, 54, 487-499. Ramsay, J. O. (1991). Kernel smoothing approaches nonparametric item characteristic curve estimation. Psychometrika, 56, 611-630. Reckase, M. (2009). Multidimensional item response theory. New York: Springer. doi:10.1007/978-0-387-89976-3 Renard, D., Molenberghs, G., & Geys, H. (2004). pairwise likelihood approach estimation multilevel probit models. Computational Statistics & Data Analysis, 44, 649-667. Rijmen, F., & Vomlel, J. (2008). Assessing performance variational methods mixed logistic regression models. Journal Statistical Computation Simulation, 78, 765-779. Robitzsch, ., & Steinfeld, J. (2018). Item response models human ratings: Overview, estimation methods, implementation R. Psychological Test Assessment Modeling, 60(1), 101-139. Rossi, N., Wang, X. & Ramsay, J. O. (2002). Nonparametric item response function estimates EM algorithm. Journal Educational Behavioral Statistics, 27, 291-317. Rusch, T., Mair, P., & Hatzinger, R. (2013). Psychometrics R: Review CRAN Packages Item Response Theory. http://epub.wu.ac./4010/1/resrepIRThandbook.pdf Scheiblechner, H. (1995). Isotonic ordinal probabilistic models (ISOP). Psychometrika, 60(2), 281-304. doi:10.1007/BF02301417 Scheiblechner, H. (1999). Additive conjoint isotonic probabilistic models (ADISOP). Psychometrika, 64, 295-316. Schroeders, U., Robitzsch, ., & Schipolowski, S. (2014). comparison different psychometric approaches modeling testlet structures: example C-tests. Journal Educational Measurement, 51(4), 400-418. doi:10.1111/jedm.12054 Stout, W., Habing, B., Douglas, J., & Kim, H. R. (1996). Conditional covariance-based nonparametric multidimensionality assessment. Applied Psychological Measurement, 20(4), 331-354. doi:10.1177/014662169602000403 Stukel, T. . (1988). Generalized logistic models. Journal American Statistical Association, 83(402), 426-431. doi:10.1080/01621459.1988.10478613 Uenlue, ., & Yanagida, T. (2011). R ready R?: CRAN psychometrics task view. British Journal Mathematical Statistical Psychology, 64(1), 182-186. doi:10.1348/000711010X519320 van den Noortgate, W., De Boeck, P., & Meulders, M. (2003). Cross-classification multilevel logistic models psychometrics. Journal Educational Behavioral Statistics, 28, 369-386. Warm, T. . (1989). Weighted likelihood estimation ability item response theory. Psychometrika, 54, 427-450. Wainer, H., Bradlow, E. T., & Wang, X. (2007). Testlet response theory applications. Cambridge: Cambridge University Press. Zwinderman, . H. (1995). Pairwise parameter estimation Rasch models. Applied Psychological Measurement, 19, 369-375.","code":""},{"path":[]},{"path":"/reference/sirt-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Supplementary Item Response Theory Models — sirt-package","text":"","code":"## ##   |-----------------------------------------------------------------| ##   | sirt 0.40-4 (2013-11-26)                                        | ##   | Supplementary Item Response Theory                              | ##   | Maintainer: Alexander Robitzsch <a.robitzsch at bifie.at >      | ##   | https://sites.google.com/site/alexanderrobitzsch/software       | ##   |-----------------------------------------------------------------| ## ##                       _/              _/ ##              _/_/_/      _/  _/_/  _/_/_/_/ ##           _/_/      _/  _/_/        _/ ##              _/_/  _/  _/          _/ ##         _/_/_/    _/  _/            _/_/ ##"},{"path":"/reference/sirt-utilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility Functions in sirt — sirt-utilities","title":"Utility Functions in sirt — sirt-utilities","text":"Utility functions sirt.","code":""},{"path":"/reference/sirt-utilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility Functions in sirt — sirt-utilities","text":"","code":"# bounds entries in a vector bounds_parameters( pars, lower=NULL, upper=NULL)  # improper density function which always returns a value of 1 dimproper(x)  # generalized inverse of a symmetric function ginverse_sym(A, eps=1E-8) # hard thresholding function hard_thresholding(x, lambda) # soft thresholding function soft_thresholding(x, lambda)  # power function x^a, like in Cpp pow(x, a) # trace of a matrix tracemat(A)  #** matrix functions sirt_matrix2(x, nrow)   # matrix() function with byrow=TRUE sirt_colMeans(x, na.rm=TRUE) sirt_colSDs(x, na.rm=TRUE) sirt_colMins(x, na.rm=TRUE) sirt_colMaxs(x, na.rm=TRUE) sirt_colMedians(x, na.rm=TRUE)  #* normalize vector to have sum of one sirt_sum_norm(x, na.rm=TRUE) #* discrete normal distribution sirt_dnorm_discrete(x, mean=0, sd=1, ...)  # plyr::rbind.fill implementation in sirt sirt_rbind_fill(x, y)  # Fisher-z transformation, see psych::fisherz sirt_fisherz(rho) # inverse Fisher-z transformation, see psych::fisherz2r sirt_antifisherz(z)  # smooth approximation of the absolute value function sirt_abs_smooth(x, deriv=0, eps=1e-4)  # permutations with replacement sirt_permutations(r,v)   #-> is equivalent to gtools::permutations(n=length(v), r=D, v=v, repeats.allowed=TRUE)  # attach all elements in a list in a specified environment sirt_attach_list_elements(x, envir)  # switch between stats::optim and stats::nlminb sirt_optimizer(optimizer, par, fn, grad=NULL, method=\"L-BFGS-B\", hessian=TRUE,                    control=list(), ...)  # print objects in a summary sirt_summary_print_objects(obji, from=NULL, to=NULL, digits=3, rownames_null=TRUE,       grep_string=NULL) # print package version and R session sirt_summary_print_package_rsession(pack) # print package version sirt_summary_print_package(pack) # print R session sirt_summary_print_rsession() # print call sirt_summary_print_call(CALL)  # print a data frame x with fixed numbers of digits after the decimal print_digits(x, digits=NULL)  # discrete inverse function sirt_rcpp_discrete_inverse(x0, y0, y)  # move variables in a data frame move_variables_df(x, after_var, move_vars)"},{"path":"/reference/sirt-utilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility Functions in sirt — sirt-utilities","text":"pars Numeric vector lower Numeric vector upper Numeric vector x Numeric vector matrix list eps Numerical. Shrinkage parameter eigenvalue ginverse_sym Numeric vector lambda Numeric value Matrix nrow Integer na.rm Logical mean Numeric sd Numeric y Matrix rho Numeric deriv Integer indicating order derivative z Numeric r Integer v Vector envir Environment optimizer Can one following optimizers: optim, nlminb, bobyqa (minqa packlage), Rvmmin (optimx package) nloptr (nloptr package using argument opts$algorithm=\"NLOPT_LD_MMA\"). par Initial parameter fn Function grad Gradient function method Optimization method hessian Logical control Control list R optimizers ... arguments passed obji Data frame Integer Integer digits Integer rownames_null Logical grep_string String pack Package name CALL Call statement x0 Vector y0 Vector after_var String indicating variable name variable specified variables move_vars moved move_vars Variables moved after_var","code":""},{"path":"/reference/sirt-utilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility Functions in sirt — sirt-utilities","text":"","code":"############################################################################# ## EXAMPLE 1: Trace of a matrix #############################################################################  set.seed(86) A <- matrix( stats::runif(4), 2,2 ) tracemat(A) sum(diag(A))    #=sirt::tracemat(A)  ############################################################################# ## EXAMPLE 2: Power function #############################################################################  x <- 2.3 a <- 1.7 pow(x=x,a=a) x^a            #=sirt::pow(x,a)  ############################################################################# ## EXAMPLE 3: Soft and hard thresholding function (e.g. in LASSO estimation) #############################################################################  x <- seq(-2, 2, length=100) y <- sirt::soft_thresholding( x, lambda=.5) graphics::plot( x, y, type=\"l\")  z <- sirt::hard_thresholding( x, lambda=.5) graphics::lines( x, z, lty=2, col=2)  ############################################################################# ## EXAMPLE 4: Bounds on parameters #############################################################################  pars <- c(.721, .346) bounds_parameters( pars=pars, lower=c(-Inf, .5), upper=c(Inf,1) )  ############################################################################# ## EXAMPLE 5: Smooth approximation of absolute value function #############################################################################  x <- seq(-1,1,len=100) graphics::plot(x, abs(x), lwd=2, col=1, lty=1, type=\"l\", ylim=c(-1,1) ) # smooth approximation tt <- 2 graphics::lines(x, sirt::sirt_abs_smooth(x), lty=tt, col=tt, lwd=2) # first derivative tt <- 3 graphics::lines(x, sirt::sirt_abs_smooth(x, deriv=1), lty=tt, col=tt, lwd=2) # second derivative tt <- 4 graphics::lines(x, sirt::sirt_abs_smooth(x, deriv=2), lty=tt, col=tt, lwd=2)  # analytic computation of first and second derivative stats::deriv( ~ sqrt(x^2 + eps), namevec=\"x\", hessian=TRUE )  if (FALSE) { ############################################################################# ## EXAMPLE 6: Permutations with replacement #############################################################################  D <- 4 v <- 0:1 sirt::sirt_permutations(r=D, v=v) gtools::permutations(n=length(v), r=D, v=v, repeats.allowed=TRUE) }"},{"path":"/reference/sirt_eigenvalues.html","id":null,"dir":"Reference","previous_headings":"","what":"First Eigenvalues of a Symmetric Matrix — sirt_eigenvalues","title":"First Eigenvalues of a Symmetric Matrix — sirt_eigenvalues","text":"function computes first \\(D\\) eigenvalues eigenvectors symmetric positive definite matrices. eigenvalues computed Rayleigh quotient method (Lange, 2010, p. 120).","code":""},{"path":"/reference/sirt_eigenvalues.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"First Eigenvalues of a Symmetric Matrix — sirt_eigenvalues","text":"","code":"sirt_eigenvalues( X, D, maxit=200, conv=10^(-6) )"},{"path":"/reference/sirt_eigenvalues.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"First Eigenvalues of a Symmetric Matrix — sirt_eigenvalues","text":"X Symmetric matrix D Number eigenvalues estimated maxit Maximum number iterations conv Convergence criterion","code":""},{"path":"/reference/sirt_eigenvalues.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"First Eigenvalues of a Symmetric Matrix — sirt_eigenvalues","text":"list following entries: d Vector eigenvalues u Matrix eigenvectors columns","code":""},{"path":"/reference/sirt_eigenvalues.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"First Eigenvalues of a Symmetric Matrix — sirt_eigenvalues","text":"Lange, K. (2010). Numerical Analysis Statisticians. New York: Springer.","code":""},{"path":"/reference/sirt_eigenvalues.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"First Eigenvalues of a Symmetric Matrix — sirt_eigenvalues","text":"","code":"Sigma <- diag(1,3) Sigma[ lower.tri(Sigma) ] <- Sigma[ upper.tri(Sigma) ] <- c(.4,.6,.8 ) sirt::sirt_eigenvalues(X=Sigma, D=2 ) # compare with svd function svd(Sigma)"},{"path":"/reference/smirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","title":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","text":"function estimates noncompensatory compensatory multidimensional item response model (Bolt & Lall, 2003; Reckase, 2009) well partially compensatory item response model (Spray et al., 1990) dichotomous data.","code":""},{"path":"/reference/smirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","text":"","code":"smirt(dat, Qmatrix, irtmodel=\"noncomp\", est.b=NULL, est.a=NULL,      est.c=NULL, est.d=NULL, est.mu.i=NULL, b.init=NULL, a.init=NULL,      c.init=NULL, d.init=NULL, mu.i.init=NULL, Sigma.init=NULL,      b.lower=-Inf, b.upper=Inf, a.lower=-Inf, a.upper=Inf,      c.lower=-Inf, c.upper=Inf, d.lower=-Inf, d.upper=Inf,      theta.k=seq(-6,6,len=20), theta.kDES=NULL,      qmcnodes=0, mu.fixed=NULL, variance.fixed=NULL,  est.corr=FALSE,      max.increment=1, increment.factor=1, numdiff.parm=0.0001,      maxdevchange=0.1, globconv=0.001, maxiter=1000, msteps=4,      mstepconv=0.001)  # S3 method for smirt summary(object,...)  # S3 method for smirt anova(object,...)  # S3 method for smirt logLik(object,...)  # S3 method for smirt IRT.irfprob(object,...)  # S3 method for smirt IRT.likelihood(object,...)  # S3 method for smirt IRT.posterior(object,...)  # S3 method for smirt IRT.modelfit(object,...)  # S3 method for IRT.modelfit.smirt summary(object,...)"},{"path":"/reference/smirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","text":"dat Data frame dichotomous item responses Qmatrix Q-matrix specifies loadings estimated irtmodel item response model. Options noncompensatory model (\"noncomp\"), compensatory model (\"comp\") partially compensatory model (\"partcomp\"). See Details explanations. est.b integer matrix (irtmodel=\"noncomp\") integer vector (irtmodel=\"comp\") \\(b\\) parameters estimated est.integer matrix \\(\\) parameters estimated. est.=\"2PL\", item loadings estimated variances set one (therefore est.corr=TRUE). est.c integer vector \\(c\\) parameters estimated est.d integer vector \\(d\\) parameters estimated est.mu.integer vector \\(\\mu_i\\) parameters estimated b.init Initial \\(b\\) coefficients. irtmodel=\"noncomp\" must matrix, irtmodel=\"comp\" vector. .init Initial \\(\\) coefficients arranged matrix c.init Initial \\(c\\) coefficients d.init Initial \\(d\\) coefficients mu..init Initial \\(d\\) coefficients Sigma.init Initial covariance matrix \\(\\Sigma\\) b.lower Lower bound \\(b\\) parameter b.upper Upper bound \\(b\\) parameter .lower Lower bound \\(\\) parameter .upper Upper bound \\(\\) parameter c.lower Lower bound \\(c\\) parameter c.upper Upper bound \\(c\\) parameter d.lower Lower bound \\(d\\) parameter d.upper Upper bound \\(d\\) parameter theta.k Vector discretized trait distribution. vector expanded dimensions using base::expand.grid function. user specifies design matrix theta.kDES transformed \\(\\bold{\\theta}_p\\) values (see Details Examples), theta.k must matrix, . theta.kDES optional design matrix. matrix differ ordinary theta grid case nonlinear item response models. qmcnodes Number integration nodes quasi Monte Carlo integration (see Pan & Thompson, 2007; Gonzales et al., 2006). Integration points obtained using function qmc.nodes. Note using quasi Monte Carlo nodes, theta design matrix theta.kDES can specified. See Example 1, Model 11. mu.fixed Matrix fixed entries mean vector. default, means set zero. variance.fixed Matrix (rows three columns) fixed entries covariance matrix (see Examples). entry \\(c_{kd}\\) covariance dimensions   \\(k\\) \\(d\\) set \\(c_0\\) iff variance.fixed row   \\(k\\) first column, \\(d\\) second column value   \\(c_0\\) third column. est.corr correlation matrix instead covariance matrix estimated? max.increment Maximum increment increment.factor value (larger one) defines extent decrease maximum increment item parameters every iteration. maximum increment iteration iter defined max.increment*increment.factor^(-iter) max.increment=1. Using value larger 1 helps reach convergence non-converging analyses (use values 1.01, 1.02 even 1.05). See also Example 1 Model 2a. numdiff.parm Numerical differentiation parameter maxdevchange Convergence criterion change relative deviance globconv Global convergence criterion parameter change maxiter Maximum number iterations msteps Number iterations within M step mstepconv Convergence criterion within M step object Object class smirt ... arguments passed","code":""},{"path":"/reference/smirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","text":"noncompensatory item response model (irtmodel=\"noncomp\"; e.g. Bolt & Lall, 2003) defined $$P(X_{pi}=1 | \\bold{\\theta}_p )=c_i + (d_i - c_i ) \\prod_l invlogit( a_{il} q_{il}  \\theta_{pl} - b_{il} ) $$ \\(\\), \\(p\\), \\(l\\) denote items, persons dimensions respectively. compensatory item response model (irtmodel=\"comp\") defined $$P(X_{pi}=1 | \\bold{\\theta}_p )=c_i + (d_i - c_i ) invlogit( \\sum_l  a_{il}  q_{il} \\theta_{pl} - b_{} ) $$ Using design matrix theta.kDES model can made even general model linear item parameters $$P(X_{pi}=1 | \\bold{\\theta}_p )=c_i + (d_i - c_i ) invlogit( \\sum_l  a_{il}  q_{il} t_l ( \\bold{ \\theta_{p} } )   - b_{} ) $$ known functions \\(t_l\\) trait vector \\(\\bold{\\theta}_p\\). Fixed values functions \\(t_l\\) specified \\(\\bold{\\theta}_p\\) design matrix theta.kDES. partially compensatory item response model (irtmodel=\"partcomp\") defined $$P(X_{pi}=1 | \\bold{\\theta}_p )=c_i + (d_i - c_i ) \\frac{ \\exp \\left( \\sum_l ( a_{il}  q_{il} \\theta_{pl} - b_{il} ) \\right) } {  \\mu_i \\prod_l ( 1 + \\exp ( a_{il}  q_{il} \\theta_{pl} - b_{il} ) ) +     ( 1- \\mu_i) ( 1 + \\exp \\left( \\sum_l  ( a_{il}  q_{il} \\theta_{pl} - b_{il} ) \\right) )         } $$ item parameters \\(\\mu_i\\) indicating degree compensatory. \\(\\mu_i=1\\) indicates noncompensatory model \\(\\mu_i=0\\) indicates (fully) compensatory model. models estimated EM algorithm employing marginal maximum likelihood.","code":""},{"path":"/reference/smirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","text":"list following entries: deviance Deviance ic Information criteria item Data frame item parameters person Data frame person parameters. includes     person mean item responses (M; percentage correct     non-missing items), EAP estimate corresponding standard error dimensions (EAP SE.EAP) maximum likelihood estimate well mode posterior distribution (MLE MAP). EAP.rel EAP reliability mean.trait Means trait sd.trait Standard deviations trait Sigma Trait covariance matrix cor.trait Trait correlation matrix b Matrix (vector) \\(b\\) parameters se.b Matrix (vector) standard errors \\(b\\) parameters Matrix \\(\\) parameters se.Matrix standard errors \\(\\) parameters c Vector \\(c\\) parameters se.c Vector standard errors \\(c\\) parameters d Vector \\(d\\) parameters se.d Vector standard errors \\(d\\) parameters mu.Vector \\(\\mu_i\\) parameters se.mu.Vector standard errors \\(\\mu_i\\) parameters f.yi.qk Individual likelihood f.qk.yi Individual posterior probs Probabilities item response functions evaluated theta.k n.ik Expected counts iter Number iterations dat2 Processed data set dat2.resp Data set response indicators Number items D Number dimensions K Maximum item response score theta.k Used theta integration grid pi.k Distribution function evaluated theta.k irtmodel Used IRT model Qmatrix Used Q-matrix","code":""},{"path":"/reference/smirt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","text":"Bolt, D. M., & Lall, V. F. (2003). Estimation compensatory noncompensatory multidimensional item response models using Markov chain Monte Carlo. Applied Psychological Measurement, 27, 395-414. Gonzalez, J., Tuerlinckx, F., De Boeck, P., & Cools, R. (2006). Numerical integration logistic-normal models. Computational Statistics & Data Analysis, 51, 1535-1548. Pan, J., & Thompson, R. (2007). Quasi-Monte Carlo estimation generalized linear mixed models. Computational Statistics & Data Analysis, 51, 5765-5775. Reckase, M. (2009). Multidimensional item response theory. New York: Springer. doi:10.1007/978-0-387-89976-3 Spray, J. ., Davey, T. C., Reckase, M. D., Ackerman, T. ., & Carlson, J. E. (1990). Comparison two logistic multidimensional item response theory models. ACT Research Report . ACT-RR-ONR-90-8.","code":""},{"path":[]},{"path":"/reference/smirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multidimensional Noncompensatory, Compensatory and Partially\r\nCompensatory Item Response Model — smirt","text":"","code":"############################################################################# ## EXAMPLE 1: Noncompensatory and compensatory IRT models ############################################################################# set.seed(997)  # (1) simulate data from a two-dimensional noncompensatory #     item response model #   -> increase number of iterations in all models!  N <- 1000    # number of persons I <- 10        # number of items theta0 <- rnorm( N, sd=1 ) theta1 <- theta0 + rnorm(N, sd=.7 ) theta2 <- theta0 + rnorm(N, sd=.7 ) Q <- matrix( 1, nrow=I,ncol=2 ) Q[ 1:(I/2), 2 ] <- 0 Q[ I,1] <- 0 b <- matrix( rnorm( I*2 ), I, 2 ) a <- matrix( 1, I, 2 )  # simulate data prob <- dat <- matrix(0, nrow=N, ncol=I ) for (ii in 1:I){ prob[,ii] <- ( stats::plogis( theta1 - b[ii,1]  ) )^Q[ii,1] prob[,ii] <- prob[,ii] * ( stats::plogis( theta2 - b[ii,2]  ) )^Q[ii,2]             } dat[ prob > matrix( stats::runif( N*I),N,I) ] <- 1 colnames(dat) <- paste0(\"I\",1:I)  #*** # Model 1: Noncompensatory 1PL model mod1 <- sirt::smirt(dat, Qmatrix=Q, maxiter=10 ) # change number of iterations summary(mod1)  if (FALSE) { #*** # Model 2: Noncompensatory 2PL model mod2 <- sirt::smirt(dat,Qmatrix=Q, est.a=\"2PL\", maxiter=15 ) summary(mod2)  # Model 2a: avoid convergence problems with increment.factor mod2a <- sirt::smirt(dat,Qmatrix=Q, est.a=\"2PL\", maxiter=30, increment.factor=1.03) summary(mod2a)  #*** # Model 3: some fixed c and d parameters different from zero or one c.init <- rep(0,I) c.init[ c(3,7)] <- .2 d.init <- rep(1,I) d.init[c(4,8)] <- .95 mod3 <- sirt::smirt( dat, Qmatrix=Q, c.init=c.init, d.init=d.init ) summary(mod3)  #*** # Model 4: some estimated c and d parameters (in parameter groups) est.c <- c.init <- rep(0,I) c.estpars <- c(3,6,7) c.init[ c.estpars ] <- .2 est.c[c.estpars] <- 1 est.d <- rep(0,I) d.init <- rep(1,I) d.estpars <- c(6,9) d.init[ d.estpars ] <- .95 est.d[ d.estpars ] <- d.estpars   # different d parameters mod4 <- sirt::smirt(dat,Qmatrix=Q, est.c=est.c, c.init=c.init,             est.d=est.d, d.init=d.init  ) summary(mod4)  #*** # Model 5: Unidimensional 1PL model Qmatrix <- matrix( 1, nrow=I, ncol=1 ) mod5 <- sirt::smirt( dat, Qmatrix=Qmatrix ) summary(mod5)  #*** # Model 6: Unidimensional 2PL model mod6 <- sirt::smirt( dat, Qmatrix=Qmatrix, est.a=\"2PL\" ) summary(mod6)  #*** # Model 7: Compensatory model with between item dimensionality # Note that the data is simulated under the noncompensatory condition # Therefore Model 7 should have a worse model fit than Model 1 Q1 <- Q Q1[ 6:10, 1] <- 0 mod7 <- sirt::smirt(dat,Qmatrix=Q1, irtmodel=\"comp\", maxiter=30) summary(mod7)  #*** # Model 8: Compensatory model with within item dimensionality #         assuming zero correlation between dimensions variance.fixed <- as.matrix( cbind( 1,2,0) ) # set the covariance between the first and second dimension to zero mod8 <- sirt::smirt(dat,Qmatrix=Q, irtmodel=\"comp\", variance.fixed=variance.fixed,             maxiter=30) summary(mod8)  #*** # Model 8b: 2PL model with starting values for a and b parameters b.init <- rep(0,10)  # set all item difficulties initially to zero # b.init <- NULL a.init <- Q       # initialize a.init with Q-matrix # provide starting values for slopes of first three items on Dimension 1 a.init[1:3,1] <- c( .55, .32, 1.3)  mod8b <- sirt::smirt(dat,Qmatrix=Q, irtmodel=\"comp\", variance.fixed=variance.fixed,               b.init=b.init, a.init=a.init, maxiter=20, est.a=\"2PL\" ) summary(mod8b)  #*** # Model 9: Unidimensional model with quadratic item response functions # define theta theta.k <- seq( - 6, 6, len=15 ) theta.k <- as.matrix( theta.k, ncol=1 ) # define design matrix theta.kDES <- cbind( theta.k[,1], theta.k[,1]^2 ) # define Q-matrix Qmatrix <- matrix( 0, I, 2 ) Qmatrix[,1] <- 1 Qmatrix[ c(3,6,7), 2 ] <- 1 colnames(Qmatrix) <- c(\"F1\", \"F1sq\" ) # estimate model mod9 <- sirt::smirt(dat,Qmatrix=Qmatrix, maxiter=50, irtmodel=\"comp\",            theta.k=theta.k, theta.kDES=theta.kDES, est.a=\"2PL\" ) summary(mod9)  #*** # Model 10: Two-dimensional item response model with latent interaction #           between dimensions theta.k <- seq( - 6, 6, len=15 ) theta.k <- expand.grid( theta.k, theta.k )    # expand theta to 2 dimensions # define design matrix theta.kDES <- cbind( theta.k, theta.k[,1]*theta.k[,2] ) # define Q-matrix Qmatrix <- matrix( 0, I, 3 ) Qmatrix[,1] <- 1 Qmatrix[ 6:10, c(2,3) ] <- 1 colnames(Qmatrix) <- c(\"F1\", \"F2\", \"F1iF2\" ) # estimate model mod10 <- sirt::smirt(dat,Qmatrix=Qmatrix,irtmodel=\"comp\", theta.k=theta.k,             theta.kDES=theta.kDES, est.a=\"2PL\" ) summary(mod10)  #**** # Model 11: Example Quasi Monte Carlo integration Qmatrix <- matrix( 1, I, 1 ) mod11 <- sirt::smirt( dat, irtmodel=\"comp\", Qmatrix=Qmatrix, qmcnodes=1000 ) summary(mod11)  ############################################################################# ## EXAMPLE 2: Dataset Reading data.read ##            Multidimensional models for dichotomous data #############################################################################  data(data.read) dat <- data.read I <- ncol(dat)    # number of items  #*** # Model 1: 3-dimensional 2PL model  # define Q-matrix Qmatrix <- matrix(0,nrow=I,ncol=3) Qmatrix[1:4,1] <- 1 Qmatrix[5:8,2] <- 1 Qmatrix[9:12,3] <- 1  # estimate model mod1 <- sirt::smirt( dat, Qmatrix=Qmatrix, irtmodel=\"comp\", est.a=\"2PL\",             qmcnodes=1000, maxiter=20) summary(mod1)  #*** # Model 2: 3-dimensional Rasch model mod2 <- sirt::smirt( dat, Qmatrix=Qmatrix, irtmodel=\"comp\",               qmcnodes=1000, maxiter=20) summary(mod2)  #*** # Model 3: 3-dimensional 2PL model with uncorrelated dimensions # fix entries in variance matrix variance.fixed <- cbind( c(1,1,2), c(2,3,3), 0 ) # set the following covariances to zero: cov[1,2]=cov[1,3]=cov[2,3]=0  # estimate model mod3 <- sirt::smirt( dat, Qmatrix=Qmatrix, irtmodel=\"comp\", est.a=\"2PL\",              variance.fixed=variance.fixed, qmcnodes=1000, maxiter=20) summary(mod3)  #*** # Model 4: Bifactor model with one general factor (g) and #          uncorrelated specific factors  # define a new Q-matrix Qmatrix1 <- cbind( 1, Qmatrix ) # uncorrelated factors variance.fixed <- cbind( c(1,1,1,2,2,3), c(2,3,4,3,4,4), 0 ) # The first dimension refers to the general factors while the other # dimensions refer to the specific factors. # The specification means that: # Cov[1,2]=Cov[1,3]=Cov[1,4]=Cov[2,3]=Cov[2,4]=Cov[3,4]=0  # estimate model mod4 <- sirt::smirt( dat, Qmatrix=Qmatrix1, irtmodel=\"comp\", est.a=\"2PL\",              variance.fixed=variance.fixed, qmcnodes=1000, maxiter=20) summary(mod4)  ############################################################################# ## EXAMPLE 3: Partially compensatory model #############################################################################  #**** simulate data set.seed(7656) I <- 10         # number of items N <- 2000        # number of subjects Q <- matrix( 0, 3*I,2)  # Q-matrix Q[1:I,1] <- 1 Q[1:I + I,2] <- 1 Q[1:I + 2*I,1:2] <- 1 b <- matrix( stats::runif( 3*I *2, -2, 2 ), nrow=3*I, 2 ) b <- b*Q b <- round( b, 2 ) mui <- rep(0,3*I) mui[ seq(2*I+1, 3*I) ] <- 0.65 # generate data dat <- matrix( NA, N, 3*I ) colnames(dat) <- paste0(\"It\", 1:(3*I) ) # simulate item responses library(mvtnorm) theta <- mvtnorm::rmvnorm(N, mean=c(0,0), sigma=matrix( c( 1.2, .6,.6,1.6),2, 2 ) ) for (ii in 1:(3*I)){     # define probability     tmp1 <- exp( theta[,1] * Q[ii,1] - b[ii,1] +  theta[,2] * Q[ii,2] - b[ii,2] )     # non-compensatory model     nco1 <- ( 1 + exp( theta[,1] * Q[ii,1] - b[ii,1] ) ) *                   ( 1 + exp( theta[,2] * Q[ii,2] - b[ii,2] ) )     co1 <- ( 1 + tmp1 )     p1 <- tmp1 / ( mui[ii] * nco1 + ( 1 - mui[ii] )*co1 )     dat[,ii] <- 1 * ( stats::runif(N) < p1 ) }  #*** Model 1: Joint mu.i parameter for all items est.mu.i <- rep(0,3*I) est.mu.i[ seq(2*I+1,3*I)] <- 1 mod1 <- sirt::smirt( dat, Qmatrix=Q, irtmodel=\"partcomp\", est.mu.i=est.mu.i) summary(mod1)  #*** Model 2: Separate mu.i parameter for all items est.mu.i[ seq(2*I+1,3*I)] <- 1:I mod2 <- sirt::smirt( dat, Qmatrix=Q, irtmodel=\"partcomp\", est.mu.i=est.mu.i) summary(mod2) }"},{"path":"/reference/stratified.cronbach.alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratified Cronbach's Alpha — stratified.cronbach.alpha","title":"Stratified Cronbach's Alpha — stratified.cronbach.alpha","text":"function computes stratified Cronbach's Alpha composite scales (Cronbach, Schoenemann & McKie, 1965; , 2010; Meyer, 2010).","code":""},{"path":"/reference/stratified.cronbach.alpha.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratified Cronbach's Alpha — stratified.cronbach.alpha","text":"","code":"stratified.cronbach.alpha(data, itemstrata=NULL)"},{"path":"/reference/stratified.cronbach.alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratified Cronbach's Alpha — stratified.cronbach.alpha","text":"data \\(N \\times \\) data frame itemstrata matrix two columns defining item stratification. first column contains item names, second column item stratification label (can integers). default NULL compute Cronbach's Alpha whole scale.","code":""},{"path":"/reference/stratified.cronbach.alpha.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stratified Cronbach's Alpha — stratified.cronbach.alpha","text":"Cronbach, L. J., Schoenemann, P., & McKie, D. (1965). Alpha coefficient stratified-parallel tests. Educational Psychological Measurement, 25, 291-312. doi:10.1177/001316446502500201 , Q. (2010). Estimating reliability composite scores. Ofqual/10/4703. Coventry: Office Qualifications Examinations Regulation. Meyer, P. (2010). Reliability. Cambridge: Oxford University Press.","code":""},{"path":"/reference/stratified.cronbach.alpha.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stratified Cronbach's Alpha — stratified.cronbach.alpha","text":"","code":"############################################################################# # EXAMPLE 1: data.read #############################################################################  data(data.read, package=\"sirt\") dat <- data.read I <- ncol(dat)  # apply function without defining item strata sirt::stratified.cronbach.alpha( data.read  )  # define item strata itemstrata <- cbind( colnames(dat), substring( colnames(dat), 1,1 ) ) sirt::stratified.cronbach.alpha( dat, itemstrata=itemstrata )   ##   scale  I alpha mean.tot var.tot alpha.stratified   ## 1 total 12 0.677    8.680   5.668            0.703   ## 2     A  4 0.545    2.616   1.381               NA   ## 3     B  4 0.381    2.811   1.059               NA   ## 4     C  4 0.640    3.253   1.107               NA  if (FALSE) { #************************** # reliability analysis in psych package library(psych) # Cronbach's alpha and item discriminations psych::alpha(dat) # McDonald's omega psych::omega(dat, nfactors=1)     # 1 factor   ##   Alpha:                 0.69   ##   Omega Total            0.69 ##=> Note that alpha in this function is the standardized Cronbach's ##     alpha, i.e. alpha computed for standardized variables. psych::omega(dat, nfactors=2)     # 2 factors   ##   Omega Total            0.72 psych::omega(dat, nfactors=3)     # 3 factors   ##   Omega Total            0.74 }"},{"path":"/reference/summary.mcmc.sirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Objects of Class mcmc.sirt — summary.mcmc.sirt","title":"Summary Method for Objects of Class mcmc.sirt — summary.mcmc.sirt","text":"S3 method summarize objects class mcmc.sirt. object generated following functions: mcmc.2pno, mcmc.2pnoh, mcmc.3pno.testlet, mcmc.2pno.ml","code":""},{"path":"/reference/summary.mcmc.sirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Objects of Class mcmc.sirt — summary.mcmc.sirt","text":"","code":"# S3 method for mcmc.sirt summary(object,digits=3, file=NULL, ...)"},{"path":"/reference/summary.mcmc.sirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Objects of Class mcmc.sirt — summary.mcmc.sirt","text":"object Object class mcmc.sirt digits Number digits decimal file Optional file name summary output written ... arguments passed","code":""},{"path":[]},{"path":"/reference/tam2mirt.html","id":null,"dir":"Reference","previous_headings":"","what":"Converting a fitted TAM Object into a mirt Object — tam2mirt","title":"Converting a fitted TAM Object into a mirt Object — tam2mirt","text":"Converts fitted TAM object mirt object. -product, lavaan syntax generated can used lavaan2mirt re-estimating model mirt package. now, single group models supported. must exist background covariates (latent regression models!).","code":""},{"path":"/reference/tam2mirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converting a fitted TAM Object into a mirt Object — tam2mirt","text":"","code":"tam2mirt(tamobj)"},{"path":"/reference/tam2mirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converting a fitted TAM Object into a mirt Object — tam2mirt","text":"tamobj Object class  TAM::tam.mml","code":""},{"path":"/reference/tam2mirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converting a fitted TAM Object into a mirt Object — tam2mirt","text":"list following entries mirt Object generated mirt function est.mirt=TRUE mirt.model Generated mirt model mirt.syntax Generated mirt syntax mirt.pars Generated parameter specifications    mirt lavaan.model Used lavaan model transformed lavaanify function dat Used dataset. necessary, items used model included dataset. lavaan.syntax.fixed Generated lavaan syntax fixed parameter estimates. lavaan.syntax.freed Generated lavaan syntax freed parameters estimation.","code":""},{"path":[]},{"path":"/reference/tam2mirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converting a fitted TAM Object into a mirt Object — tam2mirt","text":"","code":"if (FALSE) { library(TAM) library(mirt)  ############################################################################# # EXAMPLE 1: Estimations in TAM for data.read dataset #############################################################################  data(data.read) dat <- data.read  #************************************** #*** Model 1: Rasch model #**************************************  # estimation in TAM package mod <- TAM::tam.mml( dat ) summary(mod) # conversion to mirt res <- sirt::tam2mirt(mod) # generated lavaan syntax cat(res$lavaan.syntax.fixed) cat(res$lavaan.syntax.freed) # extract object of class mirt mres <- res$mirt # print and parameter values print(mres) mirt::mod2values(mres) # model fit mirt::M2(mres) # residual statistics mirt::residuals(mres, type=\"Q3\") mirt::residuals(mres, type=\"LD\") # item fit mirt::itemfit(mres) # person fit mirt::personfit(mres) # compute several types of factor scores (quite slow) f1 <- mirt::fscores(mres, method='WLE',response.pattern=dat[1:10,])      # method=MAP and EAP also possible # item plot mirt::itemplot(mres,\"A3\")    # item A3 mirt::itemplot(mres,4)       # fourth item # some more plots plot(mres,type=\"info\") plot(mres,type=\"score\") plot(mres,type=\"trace\") # compare estimates with estimated Rasch model in mirt mres1 <- mirt::mirt(dat,1,\"Rasch\" ) print(mres1) mirt.wrapper.coef(mres1)  #************************************** #*** Model 2: 2PL model #**************************************  # estimation in TAM mod <- TAM::tam.mml.2pl( dat ) summary(mod) # conversion to mirt res <- sirt::tam2mirt(mod) mres <- res$mirt # lavaan syntax cat(res$lavaan.syntax.fixed) cat(res$lavaan.syntax.freed) # parameter estimates print(mres) mod2values(mres) mres@nest   # number of estimated parameters # some plots plot(mres,type=\"info\") plot(mres,type=\"score\") plot(mres,type=\"trace\") # model fit mirt::M2(mres) # residual statistics mirt::residuals(mres, type=\"Q3\") mirt::residuals(mres, type=\"LD\") # item fit mirt::itemfit(mres)  #************************************** #*** Model 3: 3-dimensional Rasch model #**************************************  # define Q-matrix Q <- matrix( 0, nrow=12, ncol=3 ) Q[ cbind(1:12, rep(1:3,each=4) ) ] <- 1 rownames(Q) <- colnames(dat) colnames(Q) <- c(\"A\",\"B\",\"C\") # estimation in TAM mod <- TAM::tam.mml( resp=dat, Q=Q, control=list(snodes=1000,maxiter=30) ) summary(mod) # mirt conversion res <- sirt::tam2mirt(mod) mres <- res$mirt # mirt syntax cat(res$mirt.syntax)   ##   Dim01=1,2,3,4   ##   Dim02=5,6,7,8   ##   Dim03=9,10,11,12   ##   COV=Dim01*Dim01,Dim02*Dim02,Dim03*Dim03,Dim01*Dim02,Dim01*Dim03,Dim02*Dim03   ##   MEAN=Dim01,Dim02,Dim03 # lavaan syntax cat(res$lavaan.syntax.freed)   ##   Dim01=~ 1*A1+1*A2+1*A3+1*A4   ##   Dim02=~ 1*B1+1*B2+1*B3+1*B4   ##   Dim03=~ 1*C1+1*C2+1*C3+1*C4   ##   A1 | t1_1*t1   ##   A2 | t1_2*t1   ##   A3 | t1_3*t1   ##   A4 | t1_4*t1   ##   B1 | t1_5*t1   ##   B2 | t1_6*t1   ##   B3 | t1_7*t1   ##   B4 | t1_8*t1   ##   C1 | t1_9*t1   ##   C2 | t1_10*t1   ##   C3 | t1_11*t1   ##   C4 | t1_12*t1   ##   Dim01 ~ 0*1   ##   Dim02 ~ 0*1   ##   Dim03 ~ 0*1   ##   Dim01 ~~ Cov_11*Dim01   ##   Dim02 ~~ Cov_22*Dim02   ##   Dim03 ~~ Cov_33*Dim03   ##   Dim01 ~~ Cov_12*Dim02   ##   Dim01 ~~ Cov_13*Dim03   ##   Dim02 ~~ Cov_23*Dim03 # model fit mirt::M2(mres) # residual statistics residuals(mres,type=\"LD\") # item fit mirt::itemfit(mres)  #************************************** #*** Model 4: 3-dimensional 2PL model #**************************************  # estimation in TAM mod <- TAM::tam.mml.2pl( resp=dat, Q=Q, control=list(snodes=1000,maxiter=30) ) summary(mod) # mirt conversion res <- sirt::tam2mirt(mod) mres <- res$mirt # generated lavaan syntax cat(res$lavaan.syntax.fixed) cat(res$lavaan.syntax.freed) # write lavaan syntax on disk   sink( \"mod4_lav_freed.txt\", split=TRUE ) cat(res$lavaan.syntax.freed)   sink() # some statistics from mirt print(mres) summary(mres) mirt::M2(mres) mirt::residuals(mres) mirt::itemfit(mres)  # estimate mirt model by using the generated lavaan syntax with freed parameters res2 <- sirt::lavaan2mirt( dat, res$lavaan.syntax.freed,             technical=list(NCYCLES=3), verbose=TRUE)                  # use only few cycles for illustrational purposes mirt.wrapper.coef(res2$mirt) summary(res2$mirt) print(res2$mirt)  ############################################################################# # EXAMPLE 4: mirt conversions for polytomous dataset data.big5 #############################################################################  data(data.big5) # select some items items <- c( grep( \"O\", colnames(data.big5), value=TRUE )[1:6],      grep( \"N\", colnames(data.big5), value=TRUE )[1:4] ) # O3 O8 O13 O18 O23 O28 N1 N6 N11 N16 dat <- data.big5[, items ] library(psych) psych::describe(dat)  library(TAM) #****************** #*** Model 1: Partial credit model in TAM mod1 <- TAM::tam.mml( dat[,1:6] ) summary(mod1) # convert to mirt object mmod1 <- sirt::tam2mirt( mod1 ) rmod1 <- mmod1$mirt # coefficients in mirt coef(rmod1) mirt.wrapper.coef(rmod1) # model fit mirt::M2(rmod1) # item fit mirt::itemfit(rmod1) # plots plot(rmod1,type=\"trace\") plot(rmod1, type=\"trace\", which.items=1:4 ) mirt::itemplot(rmod1,\"O3\")  #****************** #*** Model 2: Generalized partial credit model in TAM mod2 <- TAM::tam.mml.2pl( dat[,1:6], irtmodel=\"GPCM\" ) summary(mod2) # convert to mirt object mmod2 <- sirt::tam2mirt( mod2 ) rmod2 <- mmod2$mirt # coefficients in mirt mirt.wrapper.coef(rmod2) # model fit mirt::M2(rmod2) # item fit mirt::itemfit(rmod2) }"},{"path":"/reference/testlet.marginalized.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","title":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","text":"function computes marginal item parameters general factor item parameters testlet (bifactor) model provided input (see Details).","code":""},{"path":"/reference/testlet.marginalized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","text":"","code":"testlet.marginalized(tam.fa.obj=NULL,a1=NULL, d1=NULL, testlet=NULL,       a.testlet=NULL, var.testlet=NULL)"},{"path":"/reference/testlet.marginalized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","text":"tam.fa.obj Optional object class tam.fa     generated TAM::tam.fa     TAM package. a1 Vector item discriminations general factor d1 Vector item intercepts general factor testlet Integer vector testlet (bifactor) identifiers (must integers 1 \\(T\\)). .testlet Vector testlet (bifactor) item discriminations var.testlet Vector testlet (bifactor) variances","code":""},{"path":"/reference/testlet.marginalized.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","text":"testlet (bifactor) model assumed estimated: $$P(X_{pit}=1 | \\theta_{p}, u_{pt} )= invlogit( a_{i1} \\theta_p + a_t u_{pt} - d_{} ) $$ \\(Var( u_{pt} )=\\sigma_t^2 \\). multidimensional item response model locally independent items equivalent unidimensional IRT model locally dependent items (Ip, 2010). Marginal item parameters \\(a_i^\\ast\\) \\(d_i^\\ast\\) obtained according response equation $$P(X_{pit}=1 | \\theta_{p}^\\ast  )= invlogit( a_{}^\\ast \\theta_p^\\ast - d_{}^\\ast ) $$ Calculation details can found Ip (2010).","code":""},{"path":"/reference/testlet.marginalized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","text":"data frame containing input item parameters marginal item intercept \\(d_i^\\ast\\) (d1_marg) marginal item slope \\(a_i^\\ast\\) (a1_marg).","code":""},{"path":"/reference/testlet.marginalized.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","text":"Ip, E. H. (2010). Empirically indistinguishable multidimensional IRT locally dependent unidimensional item response models. British Journal Mathematical Statistical Psychology, 63, 395-416.","code":""},{"path":[]},{"path":"/reference/testlet.marginalized.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Item Parameters from a Testlet (Bifactor) Model — testlet.marginalized","text":"","code":"############################################################################# # EXAMPLE 1: Small numeric example for Rasch testlet model #############################################################################  # Rasch testlet model with 9 items contained into 3 testlets # the third testlet has essentially no dependence and therefore # no testlet variance testlet <- rep( 1:3, each=3 ) a1 <- rep(1, 9 )   # item slopes first dimension d1 <- rep( c(-1.25,0,1.5), 3 ) # item intercepts a.testlet <- rep( 1, 9 )  # item slopes testlets var.testlet <- c( .8, .2, 0 )  # testlet variances  # apply function res <- sirt::testlet.marginalized( a1=a1, d1=d1, testlet=testlet,             a.testlet=a.testlet, var.testlet=var.testlet ) round( res, 2 )   ##    item testlet a1    d1 a.testlet var.testlet a1_marg d1_marg   ##  1    1       1  1 -1.25         1         0.8    0.89   -1.11   ##  2    2       1  1  0.00         1         0.8    0.89    0.00   ##  3    3       1  1  1.50         1         0.8    0.89    1.33   ##  4    4       2  1 -1.25         1         0.2    0.97   -1.21   ##  5    5       2  1  0.00         1         0.2    0.97    0.00   ##  6    6       2  1  1.50         1         0.2    0.97    1.45   ##  7    7       3  1 -1.25         1         0.0    1.00   -1.25   ##  8    8       3  1  0.00         1         0.0    1.00    0.00   ##  9    9       3  1  1.50         1         0.0    1.00    1.50  if (FALSE) { ############################################################################# # EXAMPLE 2: Dataset reading #############################################################################  library(TAM) data(data.read) resp <- data.read maxiter <-  100  # Model 1: Rasch testlet model with 3 testlets dims <- substring( colnames(resp),1,1 )  # define dimensions mod1 <- TAM::tam.fa( resp=resp, irtmodel=\"bifactor1\", dims=dims,                control=list(maxiter=maxiter) ) # marginal item parameters res1 <- sirt::testlet.marginalized( mod1 )  #*** # Model 2: estimate bifactor model but assume that items 3 and 5 do not load on #           specific factors dims1 <- dims dims1[c(3,5)] <- NA mod2 <- TAM::tam.fa( resp=resp, irtmodel=\"bifactor2\", dims=dims1,               control=list(maxiter=maxiter) ) res2 <- sirt::testlet.marginalized( mod2 ) res2 }"},{"path":"/reference/tetrachoric2.html","id":null,"dir":"Reference","previous_headings":"","what":"Tetrachoric Correlation Matrix — tetrachoric2","title":"Tetrachoric Correlation Matrix — tetrachoric2","text":"function estimates tetrachoric correlation matrix according maximum likelihood estimation Olsson (Olsson, 1979; method=\"Ol\"), Tucker method (Method 2 Froemel, 1971; method=\"Tu\") Divgi (1979, method=\"Di\"). addition, alternative non-iterative approximation Bonett Price (2005; method=\"Bo\") provided.","code":""},{"path":"/reference/tetrachoric2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tetrachoric Correlation Matrix — tetrachoric2","text":"","code":"tetrachoric2(dat, method=\"Ol\", delta=0.007, maxit=1000000, cor.smooth=TRUE,    progress=TRUE)"},{"path":"/reference/tetrachoric2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tetrachoric Correlation Matrix — tetrachoric2","text":"dat data frame dichotomous response method Computation method calculating tetrachoric correlation.     ML method method=\"Ol\" (default),     Tucker method method=\"Tu\",     Divgi method method=\"Di\"     method Bonett     Price (2005) method=\"Bo\". delta step parameter. set default \\(2^{-7}\\) approximately .007. maxit Maximum number iterations. cor.smooth smoothing tetrachoric correlation matrix performed ensure positive definiteness? Choosing cor.smooth=TRUE, function cor.smooth psych package used obtaining positive definite tetrachoric correlation matrix. progress Display progress? Default TRUE.","code":""},{"path":"/reference/tetrachoric2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tetrachoric Correlation Matrix — tetrachoric2","text":"list following entries tau Item thresholds rho Tetrachoric correlation matrix","code":""},{"path":"/reference/tetrachoric2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tetrachoric Correlation Matrix — tetrachoric2","text":"Bonett, D. G., & Price, R. M. (2005). Inferential methods tetrachoric correlation coefficient. Journal Educational Behavioral Statistics, 30(2), 213-225. doi:10.3102/10769986030002213 Divgi, D. R. (1979). Calculation tetrachoric correlation coefficient. Psychometrika, 44(2), 169-172. doi:10.1007/BF02293968 Froemel, E. C. (1971). comparison computer routines calculation tetrachoric correlation coefficient. Psychometrika, 36(2), 165-174. doi:10.1007/BF02291396 Olsson, U. (1979). Maximum likelihood estimation polychoric correlation coefficient. Psychometrika, 44(4), 443-460. doi:10.1007/BF02296207","code":""},{"path":"/reference/tetrachoric2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Tetrachoric Correlation Matrix — tetrachoric2","text":"Alexander Robitzsch code adapted R script Cengiz Zopluoglu. See http://sites.education.miami.edu/zopluoglu/software-programs/.","code":""},{"path":[]},{"path":"/reference/tetrachoric2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tetrachoric Correlation Matrix — tetrachoric2","text":"","code":"############################################################################# # EXAMPLE 1: data.read #############################################################################  data(data.read)  # tetrachoric correlation from psych package library(psych) t0 <- psych::tetrachoric( data.read )$rho # Olsson method (maximum likelihood estimation) t1 <- sirt::tetrachoric2( data.read )$rho # Divgi method t2 <- sirt::tetrachoric2( data.read, method=\"Di\"  )$rho # Tucker method t3 <- sirt::tetrachoric2( data.read, method=\"Tu\" )$rho # Bonett method t4 <- sirt::tetrachoric2( data.read, method=\"Bo\" )$rho  # maximum absolute deviation ML method max( abs( t0 - t1 ) )   ##   [1] 0.008224986 # mean absolute deviation Divgi method max( abs( t0 - t2 ) )   ##   [1] 0.1766688 # mean absolute deviation Tucker method max( abs( t0 - t3 ) )   ##   [1] 0.1766292 # mean absolute deviation Bonett method max( abs( t0 - t4 ) )   ##   [1] 0.05695522"},{"path":"/reference/truescore.irt.html","id":null,"dir":"Reference","previous_headings":"","what":"Conversion of Trait Scores \\(\\theta\\) into\r\nTrue Scores \\(\\tau ( \\theta )\\) — truescore.irt","title":"Conversion of Trait Scores \\(\\theta\\) into\r\nTrue Scores \\(\\tau ( \\theta )\\) — truescore.irt","text":"function computes true score \\(\\tau=\\tau(\\theta)=\\sum_{=1}^P_i(\\theta)\\) unidimensional item response model \\(\\) items. addition, also transforms conditional standard errors provided.","code":""},{"path":"/reference/truescore.irt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conversion of Trait Scores \\(\\theta\\) into\r\nTrue Scores \\(\\tau ( \\theta )\\) — truescore.irt","text":"","code":"truescore.irt(A, B, c=NULL, d=NULL, theta=seq(-3, 3, len=21),     error=NULL, pid=NULL, h=0.001)"},{"path":"/reference/truescore.irt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conversion of Trait Scores \\(\\theta\\) into\r\nTrue Scores \\(\\tau ( \\theta )\\) — truescore.irt","text":"Matrix vector item slopes. See Examples polytomous responses. B Matrix vector item intercepts. Note entries B refer item intercepts item difficulties. c Optional vector guessing parameters d Optional vector slipping parameters theta Vector trait values error Optional vector standard errors trait pid Optional vector person identifiers h Numerical differentiation parameter","code":""},{"path":"/reference/truescore.irt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conversion of Trait Scores \\(\\theta\\) into\r\nTrue Scores \\(\\tau ( \\theta )\\) — truescore.irt","text":"addition, function \\(\\pi(\\theta)=\\frac{1}{} \\cdot \\tau( \\theta)\\) expected percent score approximated logistic function $$ \\pi ( \\theta ) \\approx l + ( u - l ) \\cdot invlogit ( \\theta + b ) $$","code":""},{"path":"/reference/truescore.irt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conversion of Trait Scores \\(\\theta\\) into\r\nTrue Scores \\(\\tau ( \\theta )\\) — truescore.irt","text":"data frame following columns: truescore True scores \\(\\tau=\\tau ( \\theta )\\) truescore.error Standard errors true scores percscore Expected correct scores \\(\\tau\\) divided maximum true score percscore.error Standard errors expected correct scores lower \\(l\\) parameter upper \\(u\\) parameter \\(\\) parameter b \\(b\\) parameter","code":""},{"path":"/reference/truescore.irt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conversion of Trait Scores \\(\\theta\\) into\r\nTrue Scores \\(\\tau ( \\theta )\\) — truescore.irt","text":"","code":"############################################################################# # EXAMPLE 1: Dataset with mixed dichotomous and polytomous responses #############################################################################  data(data.mixed1) dat <- data.mixed1  #**** # Model 1: Partial credit model # estimate model with TAM package library(TAM) mod1 <- TAM::tam.mml( dat ) # estimate person parameter estimates wmod1 <- TAM::tam.wle( mod1 ) wmod1 <- wmod1[ order(wmod1$theta), ] # extract item parameters A <- mod1$B[,-1,1] B <- mod1$AXsi[,-1] # person parameters and standard errors theta <- wmod1$theta error <- wmod1$error  # estimate true score transformation dfr <- sirt::truescore.irt( A=A, B=B, theta=theta, error=error )  # plot different person parameter estimates and standard errors par(mfrow=c(2,2)) plot( theta, dfr$truescore, pch=16, cex=.6, xlab=expression(theta), type=\"l\",     ylab=expression(paste( tau, \"(\",theta, \")\" )), main=\"True Score Transformation\" ) plot( theta, dfr$percscore, pch=16, cex=.6, xlab=expression(theta), type=\"l\",     ylab=expression(paste( pi, \"(\",theta, \")\" )), main=\"Percent Score Transformation\" ) points( theta, dfr$lower + (dfr$upper-dfr$lower)*                 stats::plogis(dfr$a*theta+dfr$b), col=2, lty=2) plot( theta, error, pch=16, cex=.6, xlab=expression(theta), type=\"l\",     ylab=expression(paste(\"SE(\",theta, \")\" )), main=\"Standard Error Theta\" ) plot( dfr$truescore, dfr$truescore.error, pch=16, cex=.6, xlab=expression(tau),     ylab=expression(paste(\"SE(\",tau, \")\" ) ), main=\"Standard Error True Score Tau\",     type=\"l\") par(mfrow=c(1,1))  if (FALSE) { #**** # Model 2: Generalized partial credit model mod2 <- TAM::tam.mml.2pl( dat, irtmodel=\"GPCM\") # estimate person parameter estimates wmod2 <- TAM::tam.wle( mod2 ) # extract item parameters A <- mod2$B[,-1,1] B <- mod2$AXsi[,-1] # person parameters and standard errors theta <- wmod2$theta error <- wmod2$error # estimate true score transformation dfr <- sirt::truescore.irt( A=A, B=B, theta=theta, error=error )  ############################################################################# # EXAMPLE 2: Dataset Reading data.read ############################################################################# data(data.read)  #**** # Model 1: estimate difficulty + guessing model mod1 <- sirt::rasch.mml2( data.read, fixed.c=rep(.25,12) ) mod1$person <- mod1$person[ order( mod1$person$EAP), ] # person parameters and standard errors theta <- mod1$person$EAP error <- mod1$person$SE.EAP A <- rep(1,12) B <- - mod1$item$b c <- rep(.25,12) # estimate true score transformation dfr <- sirt::truescore.irt( A=A, B=B, theta=theta, error=error,c=c)  plot( theta, dfr$percscore, pch=16, cex=.6, xlab=expression(theta), type=\"l\",     ylab=expression(paste( pi, \"(\",theta, \")\" )), main=\"Percent Score Transformation\" ) points( theta, dfr$lower + (dfr$upper-dfr$lower)*              stats::plogis(dfr$a*theta+dfr$b), col=2, lty=2)  #**** # Model 2: Rasch model mod2 <- sirt::rasch.mml2( data.read  ) # person parameters and standard errors theta <- mod2$person$EAP error <- mod2$person$SE.EAP A <- rep(1,12) B <- - mod2$item$b # estimate true score transformation dfr <- sirt::truescore.irt( A=A, B=B, theta=theta, error=error ) }"},{"path":"/reference/unidim.test.csn.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for Unidimensionality of CSN — unidim.test.csn","title":"Test for Unidimensionality of CSN — unidim.test.csn","text":"function tests whether item covariances given sum score non-positive (CSN; see Junker 1993), .e. items \\(\\) \\(j\\) holds $$ Cov( X_i, X_j | X^+ ) \\le 0 $$ Note function works dichotomous data.","code":""},{"path":"/reference/unidim.test.csn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for Unidimensionality of CSN — unidim.test.csn","text":"","code":"unidim.test.csn(dat, RR=400, prop.perm=0.75, progress=TRUE)"},{"path":"/reference/unidim.test.csn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for Unidimensionality of CSN — unidim.test.csn","text":"dat Data frame dichotomous item responses. persons () missing responses removed. RR Number permutations used statistical testing prop.perm positive value indicating amount permutation existing permuted data set progress optional logical indicating whether computation progress displayed","code":""},{"path":"/reference/unidim.test.csn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test for Unidimensionality of CSN — unidim.test.csn","text":"item pair \\((,j)\\) sum score group \\(k\\) conditional covariance \\(r(,j|k)\\) calculated. , test statistic CSN $$ h=\\sum_{k=1}^{-1} \\frac{n_k}{n} \\max_{,j} r(,j|k) $$ \\(n_k\\) number persons score group \\(k\\). \"'Large values\"' \\(h\\) agreement null hypothesis non-positivity conditional covariances. distribution test statistic \\(h\\) null hypothesis empirically obtained column wise permutation items within score groups. population, procedure corresponds conditional covariances zero. See de Gooijer Yuan (2011) details.","code":""},{"path":"/reference/unidim.test.csn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for Unidimensionality of CSN — unidim.test.csn","text":"list following entries stat Value statistic stat_perm Distribution statistic \\(H_0\\) permuted dataset p corresponding p value statistic H0_quantiles Quantiles statistic permutation (null hypothesis \\(H_0\\))","code":""},{"path":"/reference/unidim.test.csn.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test for Unidimensionality of CSN — unidim.test.csn","text":"De Gooijer, J. G., & Yuan, . (2011). exact tests manifest properties latent trait models. Computational Statistics Data Analysis, 55, 34-44. Junker, B.W. (1993). Conditional association, essential independence, monotone unidimensional item response models. Annals Statistics, 21, 1359-1378.","code":""},{"path":"/reference/unidim.test.csn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test for Unidimensionality of CSN — unidim.test.csn","text":"","code":"############################################################################# # EXAMPLE 1: Dataset data.read #############################################################################  data(data.read) dat <- data.read set.seed(778) res <- sirt::unidim.test.csn( dat )   ##  CSN Statistic=0.04737, p=0.02  if (FALSE) { ############################################################################# # EXAMPLE 2: CSN statistic for two-dimensional simulated data #############################################################################  set.seed(775) N <- 2000 I <- 30   # number of items rho <- .60   # correlation between 2 dimensions t0 <- stats::rnorm(N) t1 <- sqrt(rho)*t0 + sqrt(1-rho)*stats::rnorm(N) t2 <- sqrt(rho)*t0 + sqrt(1-rho)*stats::rnorm(N) dat1 <- sirt::sim.raschtype(t1, b=seq(-1.5,1.5,length=I/2) ) dat2 <- sirt::sim.raschtype(t2, b=seq(-1.5,1.5,length=I/2) ) dat <- as.matrix(cbind( dat1, dat2) ) res <- sirt::unidim.test.csn( dat )   ##  CSN Statistic=0.06056, p=0.02 }"},{"path":"/reference/wle.rasch.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted Likelihood Estimation of Person Abilities — wle.rasch","title":"Weighted Likelihood Estimation of Person Abilities — wle.rasch","text":"function computes weighted likelihood estimates dichotomous responses based Rasch model (Warm, 1989).","code":""},{"path":"/reference/wle.rasch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted Likelihood Estimation of Person Abilities — wle.rasch","text":"","code":"wle.rasch(dat, dat.resp=NULL, b, itemweights=1 + 0 * b,     theta=rep(0, nrow(dat)), conv=0.001, maxit=200,     wle.adj=0, progress=FALSE)"},{"path":"/reference/wle.rasch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted Likelihood Estimation of Person Abilities — wle.rasch","text":"dat \\(N \\times \\) data frame   dichotomous item responses dat.resp Optional data frame dichotomous response indicators b Vector length \\(\\) fixed item difficulties itemweights Optional vector fixed item discriminations theta Optional vector initial person parameter estimates conv Convergence criterion maxit Maximal number iterations wle.adj Constant WLE adjustment progress Display progress?","code":""},{"path":"/reference/wle.rasch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted Likelihood Estimation of Person Abilities — wle.rasch","text":"list following entries theta Estimated weighted likelihood estimate dat.resp Data frame dichotomous response indicators. one indicates         observed response, zero missing response. See also dat.resp         list arguments function. p.ia Matrix expected item response, .e.     probabilities \\(P(X_{pi}=1|\\theta_p )=invlogit( \\theta_p - b_i )\\). wle WLE reliability (Adams, 2005)","code":""},{"path":"/reference/wle.rasch.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Weighted Likelihood Estimation of Person Abilities — wle.rasch","text":"Adams, R. J. (2005). Reliability measurement design effect. Studies Educational Evaluation, 31, 162-172. Warm, T. . (1989). Weighted likelihood estimation ability item response theory. Psychometrika, 54, 427-450.","code":""},{"path":[]},{"path":"/reference/wle.rasch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted Likelihood Estimation of Person Abilities — wle.rasch","text":"","code":"############################################################################# # EXAMPLE 1: Dataset Reading ############################################################################# data(data.read)  # estimate the Rasch model mod <- sirt::rasch.mml2(data.read) mod$item  # estmate WLEs mod.wle <- sirt::wle.rasch( dat=data.read, b=mod$item$b )"},{"path":"/reference/wle.rasch.jackknife.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","title":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","text":"function calculates standard errors WLEs (Warm, 1989) stratified item designs item designs testlets Rasch model.","code":""},{"path":"/reference/wle.rasch.jackknife.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","text":"","code":"wle.rasch.jackknife(dat, b, itemweights=1 + 0 * b, pid=NULL,     testlet=NULL, stratum=NULL, size.itempop=NULL)"},{"path":"/reference/wle.rasch.jackknife.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","text":"dat \\(N \\times \\) data frame item responses b Vector item difficulties itemweights Weights items, .e. fixed item discriminations pid Person identifier testlet vector length \\(\\) defines item belongs testlet. items belong testlet, define separate testlet labels single items. stratum Item stratum size.itempop Number items item stratum finite item population.","code":""},{"path":"/reference/wle.rasch.jackknife.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","text":"idea Jackknife item response models can found Wainer Wright (1980).","code":""},{"path":"/reference/wle.rasch.jackknife.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","text":"list following entries: wle Data frame estimated statistics. column   wle WLE wle.jackse corresponding   standard error estimated jackknife. wle.rel WLE reliability (Adams, 2005)","code":""},{"path":"/reference/wle.rasch.jackknife.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","text":"Adams, R. J. (2005). Reliability measurement design effect. Studies Educational Evaluation, 31(2-3), 162-172. doi:10.1016/j.stueduc.2005.05.008 Gershunskaya, J., Jiang, J., & Lahiri, P. (2009). Resampling methods surveys. D. Pfeffermann C.R. Rao (Eds.). Handbook Statistics 29B; Sample Surveys: Inference Analysis (pp. 121-151). Amsterdam: North Holland. doi:10.1016/S0169-7161(09)00228-4 Wainer, H., & Wright, B. D. (1980). Robust estimation ability Rasch model. Psychometrika, 45(3), 373-391. doi:10.1007/BF02293910 Warm, T. . (1989). Weighted likelihood estimation ability item response theory. Psychometrika, 54(3), 427-450. doi:10.1007/BF02294627","code":""},{"path":[]},{"path":"/reference/wle.rasch.jackknife.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standard Error Estimation of WLE by Jackknifing — wle.rasch.jackknife","text":"","code":"############################################################################# # EXAMPLE 1: Dataset Reading ############################################################################# data(data.read) dat <- data.read  # estimation of the Rasch model res <- sirt::rasch.mml2( dat, parm.conv=.001)  # WLE estimation wle1 <- sirt::wle.rasch(dat, b=res$item$thresh )  # simple jackknife WLE estimation wle2 <- sirt::wle.rasch.jackknife(dat, b=res$item$thresh )   ## WLE Reliability=0.651  # SE(WLE) for testlets A, B and C wle3 <- sirt::wle.rasch.jackknife(dat, b=res$item$thresh,            testlet=substring( colnames(dat),1,1) )   ## WLE Reliability=0.572  # SE(WLE) for item strata A,B, C wle4 <- sirt::wle.rasch.jackknife(dat, b=res$item$thresh,              stratum=substring( colnames(dat),1,1) )   ## WLE Reliability=0.683  # SE (WLE) for finite item strata # A (10 items), B (7 items), C (4 items -> no sampling error) # in every stratum 4 items were sampled size.itempop <- c(10,7,4) names(size.itempop) <- c(\"A\",\"B\",\"C\") wle5 <- sirt::wle.rasch.jackknife(dat, b=res$item$thresh,              stratum=substring( colnames(dat),1,1),              size.itempop=size.itempop )   ## Stratum  A (Mean) Correction Factor 0.6   ## Stratum  B (Mean) Correction Factor 0.42857   ## Stratum  C (Mean) Correction Factor 0   ## WLE Reliability=0.876  # compare different estimated standard errors a2 <- stats::aggregate( wle2$wle$wle.jackse, list( wle2$wle$wle), mean ) colnames(a2) <- c(\"wle\", \"se.simple\") a2$se.testlet <- stats::aggregate( wle3$wle$wle.jackse, list( wle3$wle$wle), mean )[,2] a2$se.strata <- stats::aggregate( wle4$wle$wle.jackse, list( wle4$wle$wle), mean )[,2] a2$se.finitepop.strata <- stats::aggregate( wle5$wle$wle.jackse,     list( wle5$wle$wle), mean )[,2] round( a2, 3 )   ## > round( a2, 3 )   ##       wle se.simple se.testlet se.strata se.finitepop.strata   ## 1  -5.085     0.440      0.649     0.331               0.138   ## 2  -3.114     0.865      1.519     0.632               0.379   ## 3  -2.585     0.790      0.849     0.751               0.495   ## 4  -2.133     0.715      1.177     0.546               0.319   ## 5  -1.721     0.597      0.767     0.527               0.317   ## 6  -1.330     0.633      0.623     0.617               0.377   ## 7  -0.942     0.631      0.643     0.604               0.365   ## 8  -0.541     0.655      0.678     0.617               0.384   ## 9  -0.104     0.671      0.646     0.659               0.434   ## 10  0.406     0.771      0.706     0.751               0.461   ## 11  1.080     1.118      0.893     1.076               0.630   ## 12  2.332     0.400      0.631     0.272               0.195"},{"path":"/reference/xxirt.html","id":null,"dir":"Reference","previous_headings":"","what":"User Defined Item Response Model — xxirt","title":"User Defined Item Response Model — xxirt","text":"Estimates user defined item response model. , item response functions latent trait distributions can specified user (see Details). default, EM algorithm used estimation. number maximum EM iterations can defined argument maxit. xxirt function also allows Newton-Raphson optimization specifying values maximum number iterations maxit_nr larger zero. Typically, small initial number EM iterations chosen obtain reasonable starting values.","code":""},{"path":"/reference/xxirt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"User Defined Item Response Model — xxirt","text":"","code":"xxirt(dat, Theta=NULL, itemtype=NULL, customItems=NULL, partable=NULL,        customTheta=NULL, group=NULL, weights=NULL, globconv=1e-06, conv=1e-04,        maxit=1000, mstep_iter=4, mstep_reltol=1e-06, maxit_nr=0, optimizer_nr=\"nlminb\",        estimator=\"ML\", control_nr=list(trace=1), h=1E-4, use_grad=TRUE, verbose=TRUE,        penalty_fun_item=NULL, np_fun_item=NULL, pml_args=NULL, verbose_index=NULL,        cv_kfold=0, cv_maxit=10)  # S3 method for xxirt summary(object, digits=3, file=NULL, ...)  # S3 method for xxirt print(x, ...)  # S3 method for xxirt anova(object,...)  # S3 method for xxirt coef(object,...)  # S3 method for xxirt logLik(object,...)  # S3 method for xxirt vcov(object,...)  # S3 method for xxirt confint(object, parm, level=.95, ... )  # S3 method for xxirt IRT.expectedCounts(object,...)  # S3 method for xxirt IRT.factor.scores(object, type=\"EAP\", ...)  # S3 method for xxirt IRT.irfprob(object,...)  # S3 method for xxirt IRT.likelihood(object,...)  # S3 method for xxirt IRT.posterior(object,...)  # S3 method for xxirt IRT.modelfit(object,...)  # S3 method for IRT.modelfit.xxirt summary(object,...)  # S3 method for xxirt IRT.se(object,...)  # computes Hessian matrix xxirt_hessian(object, h=1e-4, use_shortcut=TRUE)  #- sandwich estimate for pairwise maximum likelihood estimation xxirt_sandwich_pml(object, h=1e-4)"},{"path":"/reference/xxirt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"User Defined Item Response Model — xxirt","text":"dat Data frame item responses Theta Matrix \\(\\bold{\\theta}\\) grid vector latent trait itemtype Vector item types customItems List containing types item response functions created xxirt_createDiscItem. partable Item parameter table initially created xxirt_createParTable can modified xxirt_modifyParTable. customTheta User defined \\(\\bold{\\theta}\\) distribution created xxirt_createThetaDistribution. group Optional vector group indicators weights Optional vector person weights globconv Convergence criterion relative change deviance conv Convergence criterion absolute change parameters maxit Maximum number iterations EM algorithm mstep_iter Maximum number iterations M-step mstep_reltol Convergence criterion M-step maxit_nr Number Newton-Raphson iterations EM algorithm optimizer_nr Type optimizer Newton-Raphson optimization. Alternatives \"optim\" \"nlminb\" options sirt_optimizer. estimator Marginal maximum likelihood (\"ML\") pairwise maximum likelihood (\"PML\") control_nr Argument control optimizer. h Numerical differentiation parameter use_grad Logical indicating whether gradient supplied stats::optim verbose Logical indicating whether iteration progress displayed penalty_fun_item Optional penalty function used regularized estimation. Used function x (vector item parameters) np_fun_item Function counts number item parameters regularized estimation. Used function x (vector item parameters) object Object class xxirt digits Number digits rounded file Optional file name summary output written parm Optional vector parameters level Confidence level pml_args Weight matrices estimator=\"PML\" verbose_index Logical indicating whether item index printed estimation output cv_kfold Number k folds cross validation. default 0 (cross-validation) cv_maxit Maximum number iterations cross-validation sample x Object class xxirt type Type person parameter estimate. Currently, EAP implemented. use_shortcut Logical indicating whether shortcut computation utilized ... arguments passed","code":""},{"path":"/reference/xxirt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"User Defined Item Response Model — xxirt","text":"Item response functions can specified functions unknown parameters \\(\\bold{\\delta}_i\\) \\(P(X_{}=x | \\bold{\\theta})=f_i( x | \\bold{\\theta} ; \\bold{\\delta}_i  )\\) item response model estimated assumption local stochastic independence items. Equality constraints item parameters \\(\\bold{\\delta}_i\\) among items allowed. probability distribution \\(P(\\bold{\\theta})\\) specified functions unknown parameter vector \\(\\bold{\\gamma}\\). penalty function item parameters can specified penalty_fun_item. penalty function differentiable non-differentiable function (e.g., absolute value function) approximated differentiable function.","code":""},{"path":"/reference/xxirt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"User Defined Item Response Model — xxirt","text":"List following entries partable Item parameter table par_items Vector estimated item parameters par_items_summary Data frame item parameters par_items_bounds Data frame summary bounds estimated  item parameters par_Theta Vector estimated parameters theta distribution Theta Matrix \\(\\bold{\\theta}\\) grid probs_items Item response functions probs_Theta Theta distribution deviance Deviance loglik Log likelihood value ic Information criteria item_list List item functions customItems Used customized item response functions customTheta Used customized theta distribution cv_loglike Cross-validated log-likelihood value (cv_kfold>0) p.xi.aj Individual likelihood p.aj.xi Individual posterior ll_case Case-wise log-likelihood values n.ik Array expected counts EAP EAP person parameter estimates dat Used dataset item responses dat_resp Dataset response indicators weights Vector person weights G Number groups group Integer vector group indicators group_orig Vector original group_identifiers ncat Number categories per item converged Logical whether model converged iter Number iterations needed","code":""},{"path":[]},{"path":"/reference/xxirt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"User Defined Item Response Model — xxirt","text":"","code":"if (FALSE) { ############################################################################# ## EXAMPLE 1: Unidimensional item response functions #############################################################################  data(data.read) dat <- data.read  #------ Definition of item response functions  #*** IRF 2PL P_2PL <- function( par, Theta, ncat){     a <- par[1]     b <- par[2]     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,1] <- 1     for (cc in 2:ncat){         P[,cc] <- exp( (cc-1) * a * Theta[,1] - b )     }     P <- P / rowSums(P)     return(P) }  #*** IRF 1PL P_1PL <- function( par, Theta, ncat){     b <- par[1]     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,1] <- 1     for (cc in 2:ncat){         P[,cc] <- exp( (cc-1) * Theta[,1] - b )     }     P <- P / rowSums(P)     return(P) }  #** created item classes of 1PL and 2PL models par <- c( \"a\"=1, \"b\"=0 ) # define some slightly informative prior of 2PL item_2PL <- sirt::xxirt_createDiscItem( name=\"2PL\", par=par, est=c(TRUE,TRUE),                P=P_2PL, prior=c(a=\"dlnorm\"), prior_par1=c( a=0 ),                prior_par2=c(a=5) ) item_1PL <- sirt::xxirt_createDiscItem( name=\"1PL\", par=par[2], est=c(TRUE),                P=P_1PL ) customItems <- list( item_1PL,  item_2PL )  #---- definition theta distribution  #** theta grid Theta <- matrix( seq(-6,6,length=21), ncol=1 )  #** theta distribution P_Theta1 <- function( par, Theta, G){     mu <- par[1]     sigma <- max( par[2], .01 )     TP <- nrow(Theta)     pi_Theta <- matrix( 0, nrow=TP, ncol=G)     pi1 <- dnorm( Theta[,1], mean=mu, sd=sigma )     pi1 <- pi1 / sum(pi1)     pi_Theta[,1] <- pi1     return(pi_Theta) } #** create distribution class par_Theta <- c( \"mu\"=0, \"sigma\"=1 ) customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta, est=c(FALSE,TRUE),                        P=P_Theta1 )  #**************************************************************************** #******* Model 1: Rasch model  #-- create parameter table itemtype <- rep( \"1PL\", 12 ) partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype,                         customItems=customItems )  # estimate model mod1 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable,                    customItems=customItems, customTheta=customTheta) summary(mod1)  # estimate Rasch model by providing starting values partable1 <- sirt::xxirt_modifyParTable( partable, parname=\"b\",                    value=- stats::qlogis( colMeans(dat) ) ) # estimate model again mod1b <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable1,                    customItems=customItems, customTheta=customTheta ) summary(mod1b)  # extract coefficients, covariance matrix and standard errors coef(mod1b) vcov(mod1b) IRT.se(mod1b)  #** start with EM and finalize with Newton-Raphson algorithm mod1c <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable,                    customItems=customItems, customTheta=customTheta,                    maxit=20, maxit_nr=300) summary(mod1c)  #**************************************************************************** #******* Model 2: 2PL Model with three groups of item discriminations  #-- create parameter table itemtype <- rep( \"2PL\", 12 ) partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype, customItems=customItems) # modify parameter table: set constraints for item groups A, B and C partable1 <- sirt::xxirt_modifyParTable(partable, item=paste0(\"A\",1:4),                          parname=\"a\", parindex=111) partable1 <- sirt::xxirt_modifyParTable(partable1, item=paste0(\"B\",1:4),                          parname=\"a\", parindex=112) partable1 <- sirt::xxirt_modifyParTable(partable1, item=paste0(\"C\",1:4),                          parname=\"a\", parindex=113) # delete prior distributions partable1 <- sirt::xxirt_modifyParTable(partable1, parname=\"a\", prior=NA)  #-- fix sigma to 1 customTheta1 <- customTheta customTheta1$est <- c(\"mu\"=FALSE,\"sigma\"=FALSE )  # estimate model mod2 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable1,                   customItems=customItems, customTheta=customTheta1 ) summary(mod2)  #**************************************************************************** #******* Model 3: Cloglog link function  #*** IRF cloglog P_1N <- function( par, Theta, ncat){     b <- par     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,2] <- 1 - exp( - exp( Theta - b ) )     P[,1] <- 1 - P[,2]     return(P) } par <- c(\"b\"=0) item_1N <- sirt::xxirt_createDiscItem( name=\"1N\", par=par, est=c(TRUE),                     P=P_1N ) customItems <- list( item_1N ) itemtype <- rep( \"1N\", I ) partable <- sirt::xxirt_createParTable( dat[,items], itemtype=itemtype,                       customItems=customItems ) partable <- sirt::xxirt_modifyParTable( partable=partable, parname=\"b\",                  value=- stats::qnorm( colMeans(dat[,items] )) )  #*** estimate model mod3 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable, customItems=customItems,                 customTheta=customTheta ) summary(mod3) IRT.compareModels(mod1,mod3)  #**************************************************************************** #******* Model 4: Latent class model  K <- 3 # number of classes Theta <- diag(K)  #*** Theta distribution P_Theta1 <- function( par, Theta, G  ){     logitprobs <- par[1:(K-1)]     l1 <- exp( c( logitprobs, 0 ) )     probs <- matrix( l1/sum(l1), ncol=1)     return(probs) }  par_Theta <- stats::qlogis( rep( 1/K, K-1 ) ) names(par_Theta) <- paste0(\"pi\",1:(K-1) ) customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta,                      est=rep(TRUE,K-1), P=P_Theta1)  #*** IRF latent class P_lc <- function( par, Theta, ncat){     b <- par     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,1] <- 1     for (cc in 2:ncat){         P[,cc] <- exp( Theta %*% b )     }     P <- P / rowSums(P)     return(P) } par <- seq( -1.5, 1.5, length=K ) names(par) <- paste0(\"b\",1:K) item_lc <- sirt::xxirt_createDiscItem( name=\"LC\", par=par,                  est=rep(TRUE,K), P=P_lc ) customItems <- list( item_lc )  # create parameter table itemtype <- rep( \"LC\", 12 ) partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype, customItems=customItems) partable  #*** estimate model mod4 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable, customItems=customItems,                 customTheta=customTheta) summary(mod4) # class probabilities mod4$probs_Theta # item response functions imod4 <- IRT.irfprob( mod5 ) round( imod4[,2,], 3 )  #**************************************************************************** #******* Model 5: Ordered latent class model  K <- 3 # number of classes Theta <- diag(K) Theta <- apply( Theta, 1, cumsum )  #*** Theta distribution P_Theta1 <- function( par, Theta, G  ){     logitprobs <- par[1:(K-1)]     l1 <- exp( c( logitprobs, 0 ) )     probs <- matrix( l1/sum(l1), ncol=1)     return(probs) } par_Theta <- stats::qlogis( rep( 1/K, K-1 ) ) names(par_Theta) <- paste0(\"pi\",1:(K-1) ) customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta,                 est=rep(TRUE,K-1), P=P_Theta1  )  #*** IRF ordered latent class P_olc <- function( par, Theta, ncat){     b <- par     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,1] <- 1     for (cc in 2:ncat){         P[,cc] <- exp( Theta %*% b )     }     P <- P / rowSums(P)     return(P) }  par <- c( -1, rep( .5,, length=K-1 ) ) names(par) <- paste0(\"b\",1:K) item_olc <- sirt::xxirt_createDiscItem( name=\"OLC\", par=par, est=rep(TRUE,K),                     P=P_olc, lower=c( -Inf, 0, 0 ) ) customItems <- list( item_olc ) itemtype <- rep( \"OLC\", 12 ) partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype, customItems=customItems) partable  #*** estimate model mod5 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable, customItems=customItems,                 customTheta=customTheta ) summary(mod5) # estimated item response functions imod5 <- IRT.irfprob( mod5 ) round( imod5[,2,], 3 )  ############################################################################# ## EXAMPLE 2: Multiple group models with xxirt #############################################################################  data(data.math) dat <- data.math$data items <- grep( \"M[A-Z]\", colnames(dat), value=TRUE ) I <- length(items)  Theta <- matrix( seq(-8,8,len=31), ncol=1 )  #**************************************************************************** #******* Model 1: Rasch model, single group  #*** Theta distribution P_Theta1 <- function( par, Theta, G  ){     mu <- par[1]     sigma <- max( par[2], .01 )     p1 <- stats::dnorm( Theta[,1], mean=mu, sd=sigma)     p1 <- p1 / sum(p1)     probs <- matrix( p1, ncol=1)     return(probs) }  par_Theta <- c(0,1) names(par_Theta) <- c(\"mu\",\"sigma\") customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta,                    est=c(FALSE,TRUE), P=P_Theta1  ) customTheta  #*** IRF 1PL logit P_1PL <- function( par, Theta, ncat){     b <- par     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,2] <- plogis( Theta - b )     P[,1] <- 1 - P[,2]     return(P) } par <- c(\"b\"=0) item_1PL <- sirt::xxirt_createDiscItem( name=\"1PL\", par=par, est=c(TRUE), P=P_1PL) customItems <- list( item_1PL )  itemtype <- rep( \"1PL\", I ) partable <- sirt::xxirt_createParTable( dat[,items], itemtype=itemtype,                        customItems=customItems ) partable <- sirt::xxirt_modifyParTable( partable=partable, parname=\"b\",                   value=- stats::qlogis( colMeans(dat[,items] )) )  #*** estimate model mod1 <- sirt::xxirt( dat=dat[,items], Theta=Theta, partable=partable,                 customItems=customItems, customTheta=customTheta ) summary(mod1)  #**************************************************************************** #******* Model 2: Rasch model, multiple groups  #*** Theta distribution P_Theta2 <- function( par, Theta, G  ){     mu1 <- par[1]     mu2 <- par[2]     sigma1 <- max( par[3], .01 )     sigma2 <- max( par[4], .01 )     TP <- nrow(Theta)     probs <- matrix( NA, nrow=TP, ncol=G)     p1 <- stats::dnorm( Theta[,1], mean=mu1, sd=sigma1)     probs[,1] <- p1 / sum(p1)     p1 <- stats::dnorm( Theta[,1], mean=mu2, sd=sigma2)     probs[,2] <- p1 / sum(p1)     return(probs) } par_Theta <- c(0,0,1,1) names(par_Theta) <- c(\"mu1\",\"mu2\",\"sigma1\",\"sigma2\") customTheta2  <- sirt::xxirt_createThetaDistribution( par=par_Theta,                     est=c(FALSE,TRUE,TRUE,TRUE), P=P_Theta2  ) print(customTheta2)  #*** estimate model mod2 <- sirt::xxirt( dat=dat[,items], group=dat$female, Theta=Theta, partable=partable,            customItems=customItems, customTheta=customTheta2, maxit=40) summary(mod2) IRT.compareModels(mod1, mod2)  #*** compare results with TAM package library(TAM) mod2b <- TAM::tam.mml( resp=dat[,items], group=dat$female ) summary(mod2b) IRT.compareModels(mod1, mod2, mod2b)  ############################################################################# ## EXAMPLE 3: Regularized 2PL model #############################################################################  data(data.read, package=\"sirt\") dat <- data.read  #------ Definition of item response functions  #*** IRF 2PL P_2PL <- function( par, Theta, ncat){     a <- par[1]     b <- par[2]     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,1] <- 1     for (cc in 2:ncat){         P[,cc] <- exp( (cc-1) * a * Theta[,1] - b )     }     P <- P / rowSums(P)     return(P) }  #** created item classes of 1PL and 2PL models par <- c( \"a\"=1, \"b\"=0 ) # define some slightly informative prior of 2PL item_2PL <- sirt::xxirt_createDiscItem( name=\"2PL\", par=par, est=c(TRUE,TRUE),                P=P_2PL, prior=c(a=\"dlnorm\"), prior_par1=c( a=0 ),                prior_par2=c(a=5) ) customItems <- list( item_2PL )  #---- definition theta distribution  #** theta grid Theta <- matrix( seq(-6,6,length=21), ncol=1 )  #** theta distribution P_Theta1 <- function( par, Theta, G){     mu <- par[1]     sigma <- max( par[2], .01 )     TP <- nrow(Theta)     pi_Theta <- matrix( 0, nrow=TP, ncol=G)     pi1 <- dnorm( Theta[,1], mean=mu, sd=sigma )     pi1 <- pi1 / sum(pi1)     pi_Theta[,1] <- pi1     return(pi_Theta) } #** create distribution class par_Theta <- c( \"mu\"=0, \"sigma\"=1 ) customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta, est=c(FALSE,FALSE),                        P=P_Theta1 )  #**************************************************************************** #******* Model 1: 2PL model  itemtype <- rep( \"2PL\", 12 ) partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype,                         customItems=customItems )  mod1 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable,                    customItems=customItems, customTheta=customTheta) summary(mod1)  #**************************************************************************** #******* Model 2: Regularized 2PL model with regularization on item loadings  # define regularized estimation of item loadings parindex <- partable[ partable$parname==\"a\",\"parindex\"]  #** penalty is defined by -N*lambda*sum_i (a_i-1)^2 N <- nrow(dat) lambda <- .02 penalty_fun_item <- function(x) {     val <- N*lambda*sum( ( x[parindex]-1)^2)     return(val) } # estimate standard deviation customTheta1  <- sirt::xxirt_createThetaDistribution( par=par_Theta, est=c(FALSE,TRUE),                        P=P_Theta1 ) mod2 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable,                    customItems=customItems, customTheta=customTheta1,                    penalty_fun_item=penalty_fun_item) summary(mod2)  ############################################################################# ## EXAMPLE 4: 2PL mixture model #############################################################################  #*** simulate data set.seed(123) N <- 4000   # number of persons I <- 15     # number of items prop <- .25 # mixture proportion for second class  # discriminations and difficulties in first class a1 <- rep(1,I) b1 <- seq(-2,2,len=I) # distribution in second class mu2 <- 1 sigma2 <- 1.2 # compute parameters with constraint N(0,1) in second class # a*(sigma*theta+mu-b)=a*sigma*(theta-(b-mu)/sigma) #=> a2=a*sigma and b2=(b-mu)/sigma a2 <- a1 a2[c(2,4,6,8)] <- 0.2  # some items with different discriminations a2 <- a2*sigma2 b2 <- b1 b2[1:5] <- 1   # first 5 item with different difficulties b2 <- (b2-mu2)/sigma2 dat1 <- sirt::sim.raschtype(theta=stats::rnorm(N*(1-prop)), b=b1, fixed.a=a1) dat2 <- sirt::sim.raschtype(theta=stats::rnorm(N*prop), b=b2, fixed.a=a2) dat <- rbind(dat1, dat2)  #**** model specification  #*** define theta distribution TP <- 21 theta <- seq(-6,6,length=TP) # stack theta vectors below each others=> 2 latent classes Theta <- matrix( c(theta, theta ), ncol=1 ) # distribution of theta (i.e., N(0,1)) w_theta <- dnorm(theta) w_theta <- w_theta / sum(w_theta)  P_Theta1 <- function( par, Theta, G){     p2_logis <- par[1]     p2 <- stats::plogis( p2_logis )     p1 <- 1-p2     pi_Theta <- c( p1*w_theta, p2*w_theta)     pi_Theta <- matrix(pi_Theta, ncol=1)     return(pi_Theta) }  par_Theta <- c( p2_logis=qlogis(.25)) customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta, est=c(TRUE),                        P=P_Theta1)  # IRF for 2-class mixture 2PL model par <- c(a1=1, a2=1, b1=0, b2=.5)  P_2PLmix <- function( par, Theta, ncat) {     a1 <- par[1]     a2 <- par[2]     b1 <- par[3]     b2 <- par[4]     P <- matrix( NA, nrow=2*TP, ncol=ncat)     TP <- nrow(Theta)/2     P1 <- stats::plogis( a1*(Theta[1:TP,1]-b1) )     P2 <- stats::plogis( a2*(Theta[TP+1:(2*TP),1]-b2) )     P[,2] <- c(P1, P2)     P[,1] <- 1-P[,2]     return(P) }  # define some slightly informative prior of 2PL item_2PLmix <- sirt::xxirt_createDiscItem( name=\"2PLmix\", par=par,                est=c(TRUE,TRUE,TRUE,TRUE), P=P_2PLmix ) customItems <- list( item_2PLmix )  #**************************************************************************** #******* Model 1: 2PL mixture model  itemtype <- rep( \"2PLmix\", I ) partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype,                         customItems=customItems ) mod1 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable,                    customItems=customItems, customTheta=customTheta) summary(mod1)  ############################################################################# ## EXAMPLE 5: Partial credit model with MML and PML #############################################################################  data(data.gpcm, package=\"TAM\") dat <- data.gpcm  # recode data and include some missings dat[ dat[,1]==3, 1] <- 2 dat[ 1, c(1,2) ] <- NA dat[2,3] <- NA  #------ Definition of item response functions #*** IRF 2PL P_2PL <- function( par, Theta, ncat) {     b <- par     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,1] <- 1     for (cc in 2:ncat){         P[,cc] <- exp( Theta[,1] - b[cc-1] )     }     P <- P / rowSums(P)     return(P) }  P_PCM2 <- function( par, Theta, ncat=3) {     P <- P_2PL(par=par, Theta=Theta, ncat=ncat)     return(P) }  P_PCM3 <- function( par, Theta, ncat=4) {     P <- P_2PL(par=par, Theta=Theta, ncat=ncat)     return(P) }  # define some slightly informative prior of 2PL par <- c( b1=-1, b2=1 ) NP <- length(par) item_PCM2 <- sirt::xxirt_createDiscItem( name=\"PCM2\", par=par, est=rep(TRUE,NP),                P=P_PCM2 ) par <- c( b1=-1, b2=0, b3=1 ) ; NP <- length(par) item_PCM3 <- sirt::xxirt_createDiscItem( name=\"PCM3\", par=par, est=rep(TRUE,NP),                P=P_PCM3 )  customItems <- list( item_PCM2,  item_PCM3 )  #---- definition theta distribution #** theta grid Theta <- matrix( seq(-6,6,length=21), ncol=1 )  #** theta distribution P_Theta1 <- function( par, Theta, G){     mu <- par[1]     sigma <- max( par[2], .01 )     TP <- nrow(Theta)     pi_Theta <- matrix( 0, nrow=TP, ncol=G)     pi1 <- dnorm( Theta[,1], mean=mu, sd=sigma )     pi1 <- pi1 / sum(pi1)     pi_Theta[,1] <- pi1     return(pi_Theta) } #** create distribution class par_Theta <- c( \"mu\"=0, \"sigma\"=1 ) customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta, est=c(FALSE,TRUE),                        P=P_Theta1 )  #-- create parameter table itemtype <- c(\"PCM2\", \"PCM3\", \"PCM3\") partable <- sirt::xxirt_createParTable( dat, itemtype=itemtype,                         customItems=customItems )  #***** Model 1: MML mod1 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable,                    customItems=customItems, customTheta=customTheta) summary(mod1)  #***** Model 2: PML I <- ncol(dat) W1 <- rep(1,I) W2 <- 1-diag(I) W2[3,2] <- 0 W2[ upper.tri(W2)] <- 0 pml_args <- list(W1=W1/sum(W1), W2=W2/sum(W2) )  mod2 <- sirt::xxirt( dat=dat, Theta=Theta, partable=partable,                    customItems=customItems, customTheta=mod1$customTheta,                    estimator=\"PML\", pml_args=pml_args)  # variance matrix smod2 <- sirt::xxirt_sandwich_pml(object=mod2) smod2 }"},{"path":"/reference/xxirt_createParTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Item Response Functions and Item Parameter Table — xxirt_createParTable","title":"Create Item Response Functions and Item Parameter Table — xxirt_createParTable","text":"Create item response functions item parameter table","code":""},{"path":"/reference/xxirt_createParTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Item Response Functions and Item Parameter Table — xxirt_createParTable","text":"","code":"xxirt_createDiscItem( name, par, est, P, lower=-Inf, upper=Inf,      prior=NULL, prior_par1=NULL, prior_par2=NULL)  xxirt_createParTable(dat, itemtype, customItems=NULL)  xxirt_modifyParTable( partable, parname, item=NULL, value=NULL,      est=NULL, parlabel=NULL, parindex=NULL, lower=NULL,      upper=NULL, prior=NULL, prior_par1=NULL, prior_par2=NULL )"},{"path":"/reference/xxirt_createParTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Item Response Functions and Item Parameter Table — xxirt_createParTable","text":"name Type item response function par Named vector starting values item parameters est Logical vector indicating parameters estimated P Item response function lower Lower bounds upper Upper bounds prior Prior distribution prior_par1 First parameter prior distribution prior_par2 Second parameter prior distribution dat Data frame item responses itemtype Vector item types customItems List item objects created xxirt_createDiscItem partable Item parameter table parname Parameter name item Item value Value item parameter parindex Parameter index parlabel Item parameter label","code":""},{"path":[]},{"path":"/reference/xxirt_createParTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Item Response Functions and Item Parameter Table — xxirt_createParTable","text":"","code":"############################################################################# ## EXAMPLE 1: Definition of item response functions #############################################################################  data(data.read) dat <- data.read  #------ Definition of item response functions #*** IRF 2PL P_2PL <- function( par, Theta, ncat){     a <- par[1]     b <- par[2]     TP <- nrow(Theta)     P <- matrix( NA, nrow=TP, ncol=ncat)     P[,1] <- 1     for (cc in 2:ncat){         P[,cc] <- exp( (cc-1) * a * Theta[,1] - b )     }     P <- P / rowSums(P)     return(P) }  #*** IRF 1PL P_1PL <- function( par, Theta, ncat){     b <- par[1]     TP <- nrow(Theta)     par0 <- c(1,b)     P <- P_2PL( par=par0, Theta=Theta, ncat=ncat)     return(P) }  #** created item classes of 1PL and 2PL models par <- c( \"a\"=1, \"b\"=0 ) # define some slightly informative prior of 2PL item_2PL <- sirt::xxirt_createDiscItem( name=\"2PL\", par=par, est=c(TRUE,TRUE),                 P=P_2PL, prior=c( a=\"dlnorm\"), prior_par1=c(a=0),                 prior_par2=c(a=5) ) item_1PL <- sirt::xxirt_createDiscItem( name=\"1PL\", par=par[2], est=c(TRUE),                 P=P_1PL ) # list of item classes in customItems customItems <- list( item_1PL,  item_2PL )  #-- create parameter table itemtype <- rep( \"1PL\", 12 ) partable <- sirt::xxirt_createParTable(dat, itemtype=itemtype, customItems=customItems) # privide starting values partable1 <- sirt::xxirt_modifyParTable( partable, parname=\"b\",                    value=- stats::qlogis( colMeans(dat) ) ) # equality constraint of parameters and definition of lower bounds partable1 <- sirt::xxirt_modifyParTable( partable1, item=c(\"A1\",\"A2\"),                 parname=\"b\", parindex=110, lower=-1, value=0) print(partable1)"},{"path":"/reference/xxirt_createThetaDistribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a User Defined Theta Distribution — xxirt_createThetaDistribution","title":"Creates a User Defined Theta Distribution — xxirt_createThetaDistribution","text":"Creates user defined theta distribution.","code":""},{"path":"/reference/xxirt_createThetaDistribution.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a User Defined Theta Distribution — xxirt_createThetaDistribution","text":"","code":"xxirt_createThetaDistribution(par, est, P, prior=NULL, prior_par1=NULL,        prior_par2=NULL, lower=NULL, upper=NULL)"},{"path":"/reference/xxirt_createThetaDistribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a User Defined Theta Distribution — xxirt_createThetaDistribution","text":"par Parameter vector starting values est Vector logicals indicating parameters estimated P Distribution function \\(\\bold{\\theta}\\) prior Prior distribution prior_par1 First parameter prior distribution prior_par2 Second parameter prior distribution lower Lower bounds parameters upper Upper bounds parameters","code":""},{"path":[]},{"path":"/reference/xxirt_createThetaDistribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a User Defined Theta Distribution — xxirt_createThetaDistribution","text":"","code":"############################################################################# ## EXAMPLE 1: Definition of theta distribution #############################################################################  #** theta grid Theta <- matrix( seq(-10,10,length=31), ncol=1 )  #** theta distribution P_Theta1 <- function( par, Theta, G){     mu <- par[1]     sigma <- max( par[2], .01 )     TP <- nrow(Theta)     pi_Theta <- matrix( 0, nrow=TP, ncol=G)     pi1 <- stats::dnorm( Theta[,1], mean=mu, sd=sigma )     pi1 <- pi1 / sum(pi1)     pi_Theta[,1] <- pi1     return(pi_Theta)                 } #** create distribution class par_Theta <- c( \"mu\"=0, \"sigma\"=1 ) customTheta  <- sirt::xxirt_createThetaDistribution( par=par_Theta,                        est=c(FALSE,TRUE), P=P_Theta1 )"}]
